{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.2326],\n        [3.7667]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "linear_model = nn.Linear(1, 1)\n",
    "t = torch.tensor([[1.2999999], [3.9]])\n",
    "linear_model(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(Parameter containing:\n tensor([[0.9747]], requires_grad=True),\n Parameter containing:\n tensor([-0.0345], requires_grad=True))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.weight, linear_model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(<generator object Module.parameters at 0x7fa60c35aac0>,\n [Parameter containing:\n  tensor([[0.9747]], requires_grad=True),\n  Parameter containing:\n  tensor([-0.0345], requires_grad=True)])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 1)\n",
    "linear_model(x)\n",
    "x.unsqueeze_(0).unsqueeze_(0)\n",
    "x\n",
    "linear_model.parameters(), list(linear_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.4700)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)\n",
    "\n",
    "t_u.shape\n",
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "shuffled_indices\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "validation_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_indices, validation_indices\n",
    "\n",
    "train_t_u = t_u[train_indices].unsqueeze_(1)\n",
    "train_t_c = t_c[train_indices].unsqueeze_(1)\n",
    "\n",
    "val_t_u = t_u[validation_indices].unsqueeze_(1)\n",
    "val_t_c = t_c[validation_indices].unsqueeze_(1)\n",
    "\n",
    "def loss_fn(t_u, t_c):\n",
    "    loss = ((t_u - t_c)**2).sum()\n",
    "    return loss\n",
    "\n",
    "loss_fn(torch.tensor([1,2,3]), torch.tensor([0.9, 0.9, 3.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, \n",
    "                  t_u_val, t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_u_train)\n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "        \n",
    "        t_p_val = model(t_u_val)\n",
    "        loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        # print(model.hidden_linear.weight.grad)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 500 == 0:\n",
    "            print(f'Epoch {epoch}, Training loss {loss_train.item():.4f}')\n",
    "            print(f'    Validation loss {loss_val.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Training loss 5.6785\n",
      "    Validation loss 21.9305\n",
      "Epoch 1000, Training loss 3.0104\n",
      "    Validation loss 6.4761\n",
      "Epoch 1500, Training loss 2.9726\n",
      "    Validation loss 5.1805\n",
      "Epoch 2000, Training loss 2.9725\n",
      "    Validation loss 5.1325\n",
      "Epoch 2500, Training loss 2.9725\n",
      "    Validation loss 5.1322\n",
      "Epoch 3000, Training loss 2.9725\n",
      "    Validation loss 5.1321\n",
      "Epoch 3500, Training loss 2.9725\n",
      "    Validation loss 5.1321\n",
      "Epoch 4000, Training loss 2.9725\n",
      "    Validation loss 5.1321\n",
      "Epoch 4500, Training loss 2.9725\n",
      "    Validation loss 5.1321\n",
      "Epoch 5000, Training loss 2.9725\n",
      "    Validation loss 5.1320\n",
      "Epoch 5500, Training loss 2.9727\n",
      "    Validation loss 5.2194\n",
      "Epoch 6000, Training loss 2.9725\n",
      "    Validation loss 5.1320\n",
      "Epoch 6500, Training loss 2.9725\n",
      "    Validation loss 5.1321\n",
      "Epoch 7000, Training loss 2.9725\n",
      "    Validation loss 5.1320\n",
      "Epoch 7500, Training loss 2.9729\n",
      "    Validation loss 5.0044\n",
      "Epoch 8000, Training loss 2.9725\n",
      "    Validation loss 5.1368\n",
      "Epoch 8500, Training loss 2.9725\n",
      "    Validation loss 5.1321\n",
      "Epoch 9000, Training loss 2.9725\n",
      "    Validation loss 5.1451\n",
      "Epoch 9500, Training loss 2.9725\n",
      "    Validation loss 5.1320\n",
      "Epoch 10000, Training loss 2.9725\n",
      "    Validation loss 5.1324\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "linear_model = nn.Linear(1, 1)\n",
    "optimizer = optim.Adam(linear_model.parameters(), lr=0.1)\n",
    "\n",
    "params = training_loop(\n",
    "    n_epochs=10000,\n",
    "    optimizer=optimizer,\n",
    "    model=linear_model,\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    t_u_train=train_t_u,\n",
    "    t_c_train=train_t_c,\n",
    "    t_c_val=val_t_c,\n",
    "    t_u_val=val_t_u\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(Parameter containing:\n tensor([-16.0064], requires_grad=True),\n Parameter containing:\n tensor([[0.5040]], requires_grad=True))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.bias, linear_model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(Sequential(\n   (0): Linear(in_features=1, out_features=13, bias=True)\n   (1): Tanh()\n   (2): Linear(in_features=13, out_features=1, bias=True)\n ),\n [Parameter containing:\n  tensor([[ 0.3807],\n          [ 0.0495],\n          [-0.7050],\n          [ 0.5971],\n          [-0.4850],\n          [ 0.6231],\n          [-0.8809],\n          [-0.9657],\n          [-0.3604],\n          [ 0.6533],\n          [ 0.2142],\n          [ 0.7012],\n          [ 0.8259]], requires_grad=True),\n  Parameter containing:\n  tensor([ 0.3919,  0.9131,  0.5843,  0.2170,  0.0036,  0.5820, -0.1230, -0.0416,\n          -0.6134,  0.8160,  0.7807,  0.1644,  0.0200], requires_grad=True),\n  Parameter containing:\n  tensor([[-0.0394, -0.0236, -0.1129,  0.0835, -0.1775, -0.0183, -0.1539, -0.1141,\n            0.0556, -0.1768, -0.1651,  0.1102,  0.0501]], requires_grad=True),\n  Parameter containing:\n  tensor([-0.0973], requires_grad=True)],\n [torch.Size([13, 1]), torch.Size([13]), torch.Size([1, 13]), torch.Size([1])])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model = nn.Sequential(\n",
    "    nn.Linear(1, 13),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(13, 1)\n",
    ")\n",
    "\n",
    "seq_model, list(seq_model.parameters()), [p.shape for p in seq_model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "seq_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(1, 50)),\n",
    "    ('hidden _activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(50, 1))\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_linear.weight torch.Size([50, 1])\n",
      "hidden_linear.bias torch.Size([50])\n",
      "output_linear.weight torch.Size([1, 50])\n",
      "output_linear.bias torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([-0.0579], requires_grad=True)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name, param in seq_model.named_parameters():\n",
    "    print(name, param.shape)\n",
    "    \n",
    "seq_model.output_linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Training loss 88.9327\n",
      "    Validation loss 424.3661\n",
      "Epoch 1000, Training loss 66.5249\n",
      "    Validation loss 349.2887\n",
      "Epoch 1500, Training loss 52.2778\n",
      "    Validation loss 292.0929\n",
      "Epoch 2000, Training loss 43.1479\n",
      "    Validation loss 248.8533\n",
      "Epoch 2500, Training loss 36.8437\n",
      "    Validation loss 215.5152\n",
      "Epoch 3000, Training loss 32.2718\n",
      "    Validation loss 189.7220\n",
      "Epoch 3500, Training loss 28.4578\n",
      "    Validation loss 169.1539\n",
      "Epoch 4000, Training loss 25.0955\n",
      "    Validation loss 152.1056\n",
      "Epoch 4500, Training loss 21.9436\n",
      "    Validation loss 137.5216\n",
      "Epoch 5000, Training loss 18.9406\n",
      "    Validation loss 124.5877\n",
      "Epoch 5500, Training loss 16.1086\n",
      "    Validation loss 112.7553\n",
      "Epoch 6000, Training loss 13.5067\n",
      "    Validation loss 101.6619\n",
      "Epoch 6500, Training loss 11.1974\n",
      "    Validation loss 91.0817\n",
      "Epoch 7000, Training loss 9.2247\n",
      "    Validation loss 80.8968\n",
      "Epoch 7500, Training loss 7.6036\n",
      "    Validation loss 71.0697\n",
      "Epoch 8000, Training loss 6.3186\n",
      "    Validation loss 61.6349\n",
      "Epoch 8500, Training loss 5.3290\n",
      "    Validation loss 52.6573\n",
      "Epoch 9000, Training loss 4.5802\n",
      "    Validation loss 44.4295\n",
      "Epoch 9500, Training loss 4.0161\n",
      "    Validation loss 36.9565\n",
      "Epoch 10000, Training loss 3.5888\n",
      "    Validation loss 30.3994\n"
     ]
    },
    {
     "data": {
      "text/plain": "Linear(in_features=1, out_features=1, bias=True)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_optim = optim.Adam(seq_model.parameters(), lr=1e-4)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=10000,\n",
    "    optimizer=seq_optim,\n",
    "    model=seq_model,\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    t_u_train=train_t_u,\n",
    "    t_c_train=train_t_c,\n",
    "    t_u_val=val_t_u,\n",
    "    t_c_val=val_t_c\n",
    ")\n",
    "\n",
    "linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(Parameter containing:\n tensor([[0.5040]], requires_grad=True),\n Parameter containing:\n tensor([-16.0064], requires_grad=True))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.weight, linear_model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7fa6034da5e0>]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light",
      "transient": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(train_t_u, train_t_c, 'o')\n",
    "plt.plot(val_t_u, val_t_c, 'o')\n",
    "input_t = torch.tensor(np.arange(20, 85, 0.1)).unsqueeze_(1).to(torch.float32)\n",
    "plt.plot(np.arange(20,85,0.1), [seq_model(a).item() for a in input_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4898, 12])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_path = '../dlwpt-code/data/p1ch4/tabular-wine/winequality-white.csv'\n",
    "wine_data = np.loadtxt(wine_path, skiprows=1, delimiter=';', dtype='float32')\n",
    "wine_t = torch.from_numpy(wine_data)\n",
    "wine_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2398, 3155, 3635, 1385, 1594,   44, 2532,  800,  820, 3771])\n"
     ]
    },
    {
     "data": {
      "text/plain": "(torch.Size([3919, 10]),\n torch.Size([3919, 10]),\n torch.Size([979, 10]),\n torch.Size([979, 10]))"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_model = nn.Sequential(\n",
    "    nn.Linear(10, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10),\n",
    "    nn.Softmax()\n",
    ")\n",
    "\n",
    "val_prop = 0.2\n",
    "\n",
    "n_row, n_col = wine_t.shape\n",
    "\n",
    "n_val = int(n_row * val_prop)\n",
    "val_indices = torch.randperm(n_row)\n",
    "\n",
    "print(val_indices[:10])\n",
    "wine_train_i = wine_t[val_indices[:-n_val], :n_col - 2]\n",
    "wine_train_s = wine_t[val_indices[:-n_val], n_col - 1].to(torch.int64).unsqueeze_(1)\n",
    "wine_train_o = torch.zeros([wine_train_s.shape[0], 10])\n",
    "wine_train_o = wine_train_o.scatter_(1, wine_train_s, 1.0)\n",
    "\n",
    "wine_val_i = wine_t[val_indices[-n_val:], :n_col - 2]\n",
    "wine_val_s = wine_t[val_indices[-n_val:], n_col - 1].to(torch.int64).unsqueeze_(1)\n",
    "wine_val_o = torch.zeros([wine_val_s.shape[0], 10])\n",
    "wine_val_o = wine_val_o.scatter_(1, wine_val_s, 1.0)\n",
    "\n",
    "wine_train_i.shape, wine_train_o.shape, wine_val_i.shape, wine_val_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "wine_optim = optim.Adam(wine_model.parameters(), lr=1e-1)\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, \n",
    "                  t_u_val, t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_u_train)\n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "        \n",
    "        t_p_val = model(t_u_val)\n",
    "        loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 500 == 0:\n",
    "            print(f'Epoch {epoch}, Training loss {loss_train.item():.4f}')\n",
    "            print(f'    Validation loss {loss_val.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoagy/AIS/muz/venv/lib/python3.8/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Training loss 2.0115\n",
      "    Validation loss 2.0158\n",
      "Epoch 1000, Training loss 2.0115\n",
      "    Validation loss 2.0158\n",
      "Epoch 1500, Training loss 2.0115\n",
      "    Validation loss 2.0158\n",
      "Epoch 2000, Training loss 2.0115\n",
      "    Validation loss 2.0158\n",
      "Epoch 2500, Training loss 2.0115\n",
      "    Validation loss 2.0158\n",
      "Epoch 3000, Training loss 2.0115\n",
      "    Validation loss 2.0158\n",
      "Epoch 3500, Training loss 2.0115\n",
      "    Validation loss 2.0158\n",
      "Epoch 4000, Training loss 2.0115\n",
      "    Validation loss 2.0158\n",
      "Epoch 4500, Training loss 2.0115\n",
      "    Validation loss 2.0158\n",
      "Epoch 5000, Training loss 2.0115\n",
      "    Validation loss 2.0158\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs=5000,\n",
    "    optimizer=wine_optim,\n",
    "    model=wine_model,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    t_u_train=wine_train_i,\n",
    "    t_c_train=wine_train_o,\n",
    "    t_u_val=wine_val_i,\n",
    "    t_c_val=wine_val_o\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "d6a4bbd05ce9c893b429f45c3c159d278c088d407cccb8e9de1a5ef0145565cd"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}