{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x7f6a67c98ee0>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light",
      "transient": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(t_c, t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return w * t_u + b\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()\n",
    "\n",
    "w = torch.ones(()) # 0 dimension tensor for just a single tensor\n",
    "w, w.size(), w.dtype, w.dim()\n",
    "b = torch.zeros(())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n        48.4000, 60.4000, 68.4000])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_p = model(t_u, w, b)\n",
    "t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1763.8848)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(t_p, t_c)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1, 3]),\n torch.Size([3, 1]),\n tensor([[1., 2., 3.],\n         [2., 4., 6.],\n         [3., 6., 9.]]))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2,3]])\n",
    "b = torch.Tensor([[1],[2],[3]])\n",
    "a.shape, b.shape, a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(4724.4980)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = 0.1\n",
    "loss_rate_of_change_w = \\\n",
    "    (loss_fn(model(t_u, w + delta, b), t_c) - \n",
    "    loss_fn(model(t_u, w - delta, b), t_c)) / (2.0 * delta)\n",
    "    \n",
    "loss_rate_of_change_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "w = w - learning_rate * loss_rate_of_change_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-4812.5000)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_rate_of_change_b = \\\n",
    "    (loss_fn(model(t_u, w, b + delta), t_c) - \n",
    "     loss_fn(model(t_u, w, b - delta), t_c)) / (delta * 2.0)\n",
    "    \n",
    "loss_rate_of_change_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss_fn(t_p, t_c):\n",
    "    dsq_diffs = 2 * (t_p - t_c) / t_p.size(0)\n",
    "    return dsq_diffs\n",
    "\n",
    "def dmodel_dw(t_u, w, b):\n",
    "    return t_u\n",
    "\n",
    "def dmodel_db(t_u, w, b):\n",
    "    return 1.0\n",
    "\n",
    "def grad_fn(t_u, t_c, t_p, w, b):\n",
    "    dloss_dtp = dloss_fn(t_p, t_c)\n",
    "    dloss_dw = dloss_dtp * dmodel_dw(t_u, w, b)\n",
    "    dloss_db = dloss_dtp * dmodel_db(t_u, w, b)\n",
    "    # at this point we have the derivatives from each element of t_u separately\n",
    "    return torch.stack([dloss_dw.sum(), dloss_db.sum()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(n_epochs):\n",
    "        w, b = params\n",
    "        \n",
    "        t_p = model(t_u, w, b)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        grad = grad_fn(t_u, t_c, t_p, w, b)\n",
    "        \n",
    "        params = params - learning_rate * grad\n",
    "        \n",
    "        print(f'Epoch {epoch}, Loss {torch.round(loss)}')\n",
    "        print(f'    Params: {params}')\n",
    "        print(f'    Grad: {grad}')\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 187.0\n",
      "    Params: tensor([0.1364, 0.0021])\n",
      "    Grad: tensor([-1364.3002,   -21.0000])\n",
      "Epoch 1, Loss 56.0\n",
      "    Params: tensor([0.1926, 0.0028])\n",
      "    Grad: tensor([-561.6561,   -6.8617])\n",
      "Epoch 2, Loss 34.0\n",
      "    Params: tensor([0.2157, 0.0029])\n",
      "    Grad: tensor([-231.2415,   -1.0415])\n",
      "Epoch 3, Loss 30.0\n",
      "    Params: tensor([0.2252, 0.0028])\n",
      "    Grad: tensor([-95.2238,   1.3544])\n",
      "Epoch 4, Loss 29.0\n",
      "    Params: tensor([0.2292, 0.0025])\n",
      "    Grad: tensor([-39.2310,   2.3406])\n",
      "Epoch 5, Loss 29.0\n",
      "    Params: tensor([0.2308, 0.0022])\n",
      "    Grad: tensor([-16.1812,   2.7466])\n",
      "Epoch 6, Loss 29.0\n",
      "    Params: tensor([0.2315, 0.0020])\n",
      "    Grad: tensor([-6.6926,  2.9137])\n",
      "Epoch 7, Loss 29.0\n",
      "    Params: tensor([0.2317, 0.0017])\n",
      "    Grad: tensor([-2.7864,  2.9824])\n",
      "Epoch 8, Loss 29.0\n",
      "    Params: tensor([0.2318, 0.0014])\n",
      "    Grad: tensor([-1.1785,  3.0107])\n",
      "Epoch 9, Loss 29.0\n",
      "    Params: tensor([0.2319, 0.0011])\n",
      "    Grad: tensor([-0.5165,  3.0223])\n",
      "Epoch 10, Loss 29.0\n",
      "    Params: tensor([0.2319, 0.0008])\n",
      "    Grad: tensor([-0.2441,  3.0270])\n",
      "Epoch 11, Loss 29.0\n",
      "    Params: tensor([0.2319, 0.0004])\n",
      "    Grad: tensor([-0.1319,  3.0290])\n",
      "Epoch 12, Loss 29.0\n",
      "    Params: tensor([2.3195e-01, 1.4469e-04])\n",
      "    Grad: tensor([-0.0857,  3.0297])\n",
      "Epoch 13, Loss 29.0\n",
      "    Params: tensor([ 2.3195e-01, -1.5830e-04])\n",
      "    Grad: tensor([-0.0667,  3.0300])\n",
      "Epoch 14, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0005])\n",
      "    Grad: tensor([-0.0588,  3.0301])\n",
      "Epoch 15, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0008])\n",
      "    Grad: tensor([-0.0556,  3.0301])\n",
      "Epoch 16, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0011])\n",
      "    Grad: tensor([-0.0542,  3.0301])\n",
      "Epoch 17, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0014])\n",
      "    Grad: tensor([-0.0538,  3.0300])\n",
      "Epoch 18, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0017])\n",
      "    Grad: tensor([-0.0535,  3.0300])\n",
      "Epoch 19, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0020])\n",
      "    Grad: tensor([-0.0535,  3.0299])\n",
      "Epoch 20, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0023])\n",
      "    Grad: tensor([-0.0534,  3.0299])\n",
      "Epoch 21, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0026])\n",
      "    Grad: tensor([-0.0534,  3.0298])\n",
      "Epoch 22, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0029])\n",
      "    Grad: tensor([-0.0534,  3.0297])\n",
      "Epoch 23, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0032])\n",
      "    Grad: tensor([-0.0533,  3.0297])\n",
      "Epoch 24, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0035])\n",
      "    Grad: tensor([-0.0533,  3.0296])\n",
      "Epoch 25, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0038])\n",
      "    Grad: tensor([-0.0533,  3.0296])\n",
      "Epoch 26, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0041])\n",
      "    Grad: tensor([-0.0533,  3.0295])\n",
      "Epoch 27, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0044])\n",
      "    Grad: tensor([-0.0533,  3.0295])\n",
      "Epoch 28, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0047])\n",
      "    Grad: tensor([-0.0534,  3.0294])\n",
      "Epoch 29, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0050])\n",
      "    Grad: tensor([-0.0534,  3.0294])\n",
      "Epoch 30, Loss 29.0\n",
      "    Params: tensor([ 0.2320, -0.0053])\n",
      "    Grad: tensor([-0.0534,  3.0293])\n",
      "Epoch 31, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0056])\n",
      "    Grad: tensor([-0.0534,  3.0293])\n",
      "Epoch 32, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0059])\n",
      "    Grad: tensor([-0.0534,  3.0292])\n",
      "Epoch 33, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0062])\n",
      "    Grad: tensor([-0.0534,  3.0292])\n",
      "Epoch 34, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0065])\n",
      "    Grad: tensor([-0.0534,  3.0291])\n",
      "Epoch 35, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0068])\n",
      "    Grad: tensor([-0.0533,  3.0291])\n",
      "Epoch 36, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0071])\n",
      "    Grad: tensor([-0.0533,  3.0290])\n",
      "Epoch 37, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0074])\n",
      "    Grad: tensor([-0.0534,  3.0290])\n",
      "Epoch 38, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0077])\n",
      "    Grad: tensor([-0.0533,  3.0289])\n",
      "Epoch 39, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0080])\n",
      "    Grad: tensor([-0.0534,  3.0288])\n",
      "Epoch 40, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0083])\n",
      "    Grad: tensor([-0.0534,  3.0288])\n",
      "Epoch 41, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0086])\n",
      "    Grad: tensor([-0.0534,  3.0287])\n",
      "Epoch 42, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0089])\n",
      "    Grad: tensor([-0.0534,  3.0287])\n",
      "Epoch 43, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0092])\n",
      "    Grad: tensor([-0.0534,  3.0286])\n",
      "Epoch 44, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0095])\n",
      "    Grad: tensor([-0.0534,  3.0286])\n",
      "Epoch 45, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0099])\n",
      "    Grad: tensor([-0.0533,  3.0285])\n",
      "Epoch 46, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0102])\n",
      "    Grad: tensor([-0.0534,  3.0285])\n",
      "Epoch 47, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0105])\n",
      "    Grad: tensor([-0.0533,  3.0284])\n",
      "Epoch 48, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0108])\n",
      "    Grad: tensor([-0.0534,  3.0284])\n",
      "Epoch 49, Loss 29.0\n",
      "    Params: tensor([ 0.2321, -0.0111])\n",
      "    Grad: tensor([-0.0533,  3.0283])\n",
      "Epoch 50, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0114])\n",
      "    Grad: tensor([-0.0533,  3.0283])\n",
      "Epoch 51, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0117])\n",
      "    Grad: tensor([-0.0534,  3.0282])\n",
      "Epoch 52, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0120])\n",
      "    Grad: tensor([-0.0533,  3.0282])\n",
      "Epoch 53, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0123])\n",
      "    Grad: tensor([-0.0534,  3.0281])\n",
      "Epoch 54, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0126])\n",
      "    Grad: tensor([-0.0533,  3.0281])\n",
      "Epoch 55, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0129])\n",
      "    Grad: tensor([-0.0534,  3.0280])\n",
      "Epoch 56, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0132])\n",
      "    Grad: tensor([-0.0533,  3.0279])\n",
      "Epoch 57, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0135])\n",
      "    Grad: tensor([-0.0534,  3.0279])\n",
      "Epoch 58, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0138])\n",
      "    Grad: tensor([-0.0533,  3.0278])\n",
      "Epoch 59, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0141])\n",
      "    Grad: tensor([-0.0533,  3.0278])\n",
      "Epoch 60, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0144])\n",
      "    Grad: tensor([-0.0533,  3.0277])\n",
      "Epoch 61, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0147])\n",
      "    Grad: tensor([-0.0533,  3.0277])\n",
      "Epoch 62, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0150])\n",
      "    Grad: tensor([-0.0533,  3.0276])\n",
      "Epoch 63, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0153])\n",
      "    Grad: tensor([-0.0534,  3.0276])\n",
      "Epoch 64, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0156])\n",
      "    Grad: tensor([-0.0534,  3.0275])\n",
      "Epoch 65, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0159])\n",
      "    Grad: tensor([-0.0533,  3.0275])\n",
      "Epoch 66, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0162])\n",
      "    Grad: tensor([-0.0533,  3.0274])\n",
      "Epoch 67, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0165])\n",
      "    Grad: tensor([-0.0533,  3.0274])\n",
      "Epoch 68, Loss 29.0\n",
      "    Params: tensor([ 0.2322, -0.0168])\n",
      "    Grad: tensor([-0.0533,  3.0273])\n",
      "Epoch 69, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0171])\n",
      "    Grad: tensor([-0.0532,  3.0273])\n",
      "Epoch 70, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0174])\n",
      "    Grad: tensor([-0.0534,  3.0272])\n",
      "Epoch 71, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0177])\n",
      "    Grad: tensor([-0.0533,  3.0272])\n",
      "Epoch 72, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0180])\n",
      "    Grad: tensor([-0.0534,  3.0271])\n",
      "Epoch 73, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0183])\n",
      "    Grad: tensor([-0.0533,  3.0270])\n",
      "Epoch 74, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0186])\n",
      "    Grad: tensor([-0.0533,  3.0270])\n",
      "Epoch 75, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0189])\n",
      "    Grad: tensor([-0.0533,  3.0269])\n",
      "Epoch 76, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0192])\n",
      "    Grad: tensor([-0.0533,  3.0269])\n",
      "Epoch 77, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0195])\n",
      "    Grad: tensor([-0.0533,  3.0268])\n",
      "Epoch 78, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0198])\n",
      "    Grad: tensor([-0.0533,  3.0268])\n",
      "Epoch 79, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0201])\n",
      "    Grad: tensor([-0.0533,  3.0267])\n",
      "Epoch 80, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0204])\n",
      "    Grad: tensor([-0.0533,  3.0267])\n",
      "Epoch 81, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0208])\n",
      "    Grad: tensor([-0.0533,  3.0266])\n",
      "Epoch 82, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0211])\n",
      "    Grad: tensor([-0.0533,  3.0266])\n",
      "Epoch 83, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0214])\n",
      "    Grad: tensor([-0.0533,  3.0265])\n",
      "Epoch 84, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0217])\n",
      "    Grad: tensor([-0.0532,  3.0265])\n",
      "Epoch 85, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0220])\n",
      "    Grad: tensor([-0.0533,  3.0264])\n",
      "Epoch 86, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0223])\n",
      "    Grad: tensor([-0.0533,  3.0264])\n",
      "Epoch 87, Loss 29.0\n",
      "    Params: tensor([ 0.2323, -0.0226])\n",
      "    Grad: tensor([-0.0533,  3.0263])\n",
      "Epoch 88, Loss 29.0\n",
      "    Params: tensor([ 0.2324, -0.0229])\n",
      "    Grad: tensor([-0.0533,  3.0263])\n",
      "Epoch 89, Loss 29.0\n",
      "    Params: tensor([ 0.2324, -0.0232])\n",
      "    Grad: tensor([-0.0533,  3.0262])\n",
      "Epoch 90, Loss 29.0\n",
      "    Params: tensor([ 0.2324, -0.0235])\n",
      "    Grad: tensor([-0.0533,  3.0261])\n",
      "Epoch 91, Loss 29.0\n",
      "    Params: tensor([ 0.2324, -0.0238])\n",
      "    Grad: tensor([-0.0533,  3.0261])\n",
      "Epoch 92, Loss 29.0\n",
      "    Params: tensor([ 0.2324, -0.0241])\n",
      "    Grad: tensor([-0.0533,  3.0260])\n",
      "Epoch 93, Loss 29.0\n",
      "    Params: tensor([ 0.2324, -0.0244])\n",
      "    Grad: tensor([-0.0532,  3.0260])\n",
      "Epoch 94, Loss 29.0\n",
      "    Params: tensor([ 0.2324, -0.0247])\n",
      "    Grad: tensor([-0.0533,  3.0259])\n",
      "Epoch 95, Loss 29.0\n",
      "    Params: tensor([ 0.2324, -0.0250])\n",
      "    Grad: tensor([-0.0533,  3.0259])\n",
      "Epoch 96, Loss 29.0\n",
      "    Params: tensor([ 0.2324, -0.0253])\n",
      "    Grad: tensor([-0.0533,  3.0258])\n",
      "Epoch 97, Loss 29.0\n",
      "    Params: tensor([ 0.2324, -0.0256])\n",
      "    Grad: tensor([-0.0532,  3.0258])\n",
      "Epoch 98, Loss 29.0\n",
      "    Params: tensor([ 0.2324, -0.0259])\n",
      "    Grad: tensor([-0.0532,  3.0257])\n",
      "Epoch 99, Loss 29.0\n",
      "    Params: tensor([ 0.2324, -0.0262])\n",
      "    Grad: tensor([-0.0534,  3.0257])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([ 0.2324, -0.0262])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs=100,\n",
    "              learning_rate=0.0001,\n",
    "              params = torch.Tensor([0, 0]),\n",
    "              t_u=t_u,\n",
    "              t_c=t_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3.5700, 5.5900, 5.8200, 8.1900, 5.6300, 4.8900, 3.3900, 2.1800, 4.8400,\n        6.0400, 6.8400])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_un = .1 * t_u\n",
    "t_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 187.0\n",
      "    Params: tensor([1.3643, 0.2100])\n",
      "    Grad: tensor([-136.4300,  -21.0000])\n",
      "Epoch 1, Loss 55.0\n",
      "    Params: tensor([1.9044, 0.2745])\n",
      "    Grad: tensor([-54.0118,  -6.4459])\n",
      "Epoch 2, Loss 34.0\n",
      "    Params: tensor([2.1202, 0.2817])\n",
      "    Grad: tensor([-21.5764,  -0.7213])\n",
      "Epoch 3, Loss 31.0\n",
      "    Params: tensor([2.2083, 0.2664])\n",
      "    Grad: tensor([-8.8113,  1.5284])\n",
      "Epoch 4, Loss 30.0\n",
      "    Params: tensor([2.2462, 0.2423])\n",
      "    Grad: tensor([-3.7872,  2.4107])\n",
      "Epoch 5, Loss 30.0\n",
      "    Params: tensor([2.2643, 0.2147])\n",
      "    Grad: tensor([-1.8095,  2.7549])\n",
      "Epoch 6, Loss 30.0\n",
      "    Params: tensor([2.2746, 0.1859])\n",
      "    Grad: tensor([-1.0306,  2.8872])\n",
      "Epoch 7, Loss 30.0\n",
      "    Params: tensor([2.2818, 0.1565])\n",
      "    Grad: tensor([-0.7236,  2.9362])\n",
      "Epoch 8, Loss 30.0\n",
      "    Params: tensor([2.2878, 0.1270])\n",
      "    Grad: tensor([-0.6022,  2.9525])\n",
      "Epoch 9, Loss 30.0\n",
      "    Params: tensor([2.2934, 0.0974])\n",
      "    Grad: tensor([-0.5539,  2.9558])\n",
      "Epoch 10, Loss 29.0\n",
      "    Params: tensor([2.2987, 0.0679])\n",
      "    Grad: tensor([-0.5343,  2.9541])\n",
      "Epoch 11, Loss 29.0\n",
      "    Params: tensor([2.3040, 0.0384])\n",
      "    Grad: tensor([-0.5261,  2.9504])\n",
      "Epoch 12, Loss 29.0\n",
      "    Params: tensor([2.3092, 0.0089])\n",
      "    Grad: tensor([-0.5223,  2.9459])\n",
      "Epoch 13, Loss 29.0\n",
      "    Params: tensor([ 2.3144, -0.0205])\n",
      "    Grad: tensor([-0.5203,  2.9411])\n",
      "Epoch 14, Loss 29.0\n",
      "    Params: tensor([ 2.3196, -0.0499])\n",
      "    Grad: tensor([-0.5190,  2.9361])\n",
      "Epoch 15, Loss 29.0\n",
      "    Params: tensor([ 2.3248, -0.0792])\n",
      "    Grad: tensor([-0.5179,  2.9312])\n",
      "Epoch 16, Loss 29.0\n",
      "    Params: tensor([ 2.3299, -0.1084])\n",
      "    Grad: tensor([-0.5170,  2.9262])\n",
      "Epoch 17, Loss 29.0\n",
      "    Params: tensor([ 2.3351, -0.1376])\n",
      "    Grad: tensor([-0.5161,  2.9212])\n",
      "Epoch 18, Loss 29.0\n",
      "    Params: tensor([ 2.3402, -0.1668])\n",
      "    Grad: tensor([-0.5152,  2.9163])\n",
      "Epoch 19, Loss 29.0\n",
      "    Params: tensor([ 2.3454, -0.1959])\n",
      "    Grad: tensor([-0.5143,  2.9113])\n",
      "Epoch 20, Loss 29.0\n",
      "    Params: tensor([ 2.3505, -0.2250])\n",
      "    Grad: tensor([-0.5134,  2.9064])\n",
      "Epoch 21, Loss 28.0\n",
      "    Params: tensor([ 2.3556, -0.2540])\n",
      "    Grad: tensor([-0.5125,  2.9015])\n",
      "Epoch 22, Loss 28.0\n",
      "    Params: tensor([ 2.3608, -0.2830])\n",
      "    Grad: tensor([-0.5117,  2.8965])\n",
      "Epoch 23, Loss 28.0\n",
      "    Params: tensor([ 2.3659, -0.3119])\n",
      "    Grad: tensor([-0.5108,  2.8916])\n",
      "Epoch 24, Loss 28.0\n",
      "    Params: tensor([ 2.3710, -0.3408])\n",
      "    Grad: tensor([-0.5099,  2.8867])\n",
      "Epoch 25, Loss 28.0\n",
      "    Params: tensor([ 2.3761, -0.3696])\n",
      "    Grad: tensor([-0.5091,  2.8818])\n",
      "Epoch 26, Loss 28.0\n",
      "    Params: tensor([ 2.3811, -0.3983])\n",
      "    Grad: tensor([-0.5082,  2.8769])\n",
      "Epoch 27, Loss 28.0\n",
      "    Params: tensor([ 2.3862, -0.4271])\n",
      "    Grad: tensor([-0.5074,  2.8720])\n",
      "Epoch 28, Loss 28.0\n",
      "    Params: tensor([ 2.3913, -0.4557])\n",
      "    Grad: tensor([-0.5065,  2.8671])\n",
      "Epoch 29, Loss 28.0\n",
      "    Params: tensor([ 2.3963, -0.4844])\n",
      "    Grad: tensor([-0.5056,  2.8623])\n",
      "Epoch 30, Loss 28.0\n",
      "    Params: tensor([ 2.4014, -0.5129])\n",
      "    Grad: tensor([-0.5048,  2.8574])\n",
      "Epoch 31, Loss 28.0\n",
      "    Params: tensor([ 2.4064, -0.5415])\n",
      "    Grad: tensor([-0.5039,  2.8525])\n",
      "Epoch 32, Loss 28.0\n",
      "    Params: tensor([ 2.4115, -0.5699])\n",
      "    Grad: tensor([-0.5031,  2.8477])\n",
      "Epoch 33, Loss 27.0\n",
      "    Params: tensor([ 2.4165, -0.5984])\n",
      "    Grad: tensor([-0.5022,  2.8429])\n",
      "Epoch 34, Loss 27.0\n",
      "    Params: tensor([ 2.4215, -0.6267])\n",
      "    Grad: tensor([-0.5013,  2.8380])\n",
      "Epoch 35, Loss 27.0\n",
      "    Params: tensor([ 2.4265, -0.6551])\n",
      "    Grad: tensor([-0.5005,  2.8332])\n",
      "Epoch 36, Loss 27.0\n",
      "    Params: tensor([ 2.4315, -0.6834])\n",
      "    Grad: tensor([-0.4996,  2.8284])\n",
      "Epoch 37, Loss 27.0\n",
      "    Params: tensor([ 2.4365, -0.7116])\n",
      "    Grad: tensor([-0.4988,  2.8236])\n",
      "Epoch 38, Loss 27.0\n",
      "    Params: tensor([ 2.4415, -0.7398])\n",
      "    Grad: tensor([-0.4980,  2.8188])\n",
      "Epoch 39, Loss 27.0\n",
      "    Params: tensor([ 2.4464, -0.7679])\n",
      "    Grad: tensor([-0.4971,  2.8140])\n",
      "Epoch 40, Loss 27.0\n",
      "    Params: tensor([ 2.4514, -0.7960])\n",
      "    Grad: tensor([-0.4963,  2.8092])\n",
      "Epoch 41, Loss 27.0\n",
      "    Params: tensor([ 2.4564, -0.8241])\n",
      "    Grad: tensor([-0.4954,  2.8044])\n",
      "Epoch 42, Loss 27.0\n",
      "    Params: tensor([ 2.4613, -0.8520])\n",
      "    Grad: tensor([-0.4946,  2.7997])\n",
      "Epoch 43, Loss 27.0\n",
      "    Params: tensor([ 2.4662, -0.8800])\n",
      "    Grad: tensor([-0.4937,  2.7949])\n",
      "Epoch 44, Loss 27.0\n",
      "    Params: tensor([ 2.4712, -0.9079])\n",
      "    Grad: tensor([-0.4929,  2.7902])\n",
      "Epoch 45, Loss 26.0\n",
      "    Params: tensor([ 2.4761, -0.9358])\n",
      "    Grad: tensor([-0.4921,  2.7854])\n",
      "Epoch 46, Loss 26.0\n",
      "    Params: tensor([ 2.4810, -0.9636])\n",
      "    Grad: tensor([-0.4912,  2.7807])\n",
      "Epoch 47, Loss 26.0\n",
      "    Params: tensor([ 2.4859, -0.9913])\n",
      "    Grad: tensor([-0.4904,  2.7760])\n",
      "Epoch 48, Loss 26.0\n",
      "    Params: tensor([ 2.4908, -1.0190])\n",
      "    Grad: tensor([-0.4896,  2.7713])\n",
      "Epoch 49, Loss 26.0\n",
      "    Params: tensor([ 2.4957, -1.0467])\n",
      "    Grad: tensor([-0.4887,  2.7666])\n",
      "Epoch 50, Loss 26.0\n",
      "    Params: tensor([ 2.5006, -1.0743])\n",
      "    Grad: tensor([-0.4879,  2.7619])\n",
      "Epoch 51, Loss 26.0\n",
      "    Params: tensor([ 2.5054, -1.1019])\n",
      "    Grad: tensor([-0.4870,  2.7572])\n",
      "Epoch 52, Loss 26.0\n",
      "    Params: tensor([ 2.5103, -1.1294])\n",
      "    Grad: tensor([-0.4862,  2.7525])\n",
      "Epoch 53, Loss 26.0\n",
      "    Params: tensor([ 2.5151, -1.1569])\n",
      "    Grad: tensor([-0.4854,  2.7478])\n",
      "Epoch 54, Loss 26.0\n",
      "    Params: tensor([ 2.5200, -1.1843])\n",
      "    Grad: tensor([-0.4846,  2.7431])\n",
      "Epoch 55, Loss 26.0\n",
      "    Params: tensor([ 2.5248, -1.2117])\n",
      "    Grad: tensor([-0.4838,  2.7385])\n",
      "Epoch 56, Loss 26.0\n",
      "    Params: tensor([ 2.5297, -1.2390])\n",
      "    Grad: tensor([-0.4829,  2.7338])\n",
      "Epoch 57, Loss 26.0\n",
      "    Params: tensor([ 2.5345, -1.2663])\n",
      "    Grad: tensor([-0.4821,  2.7292])\n",
      "Epoch 58, Loss 25.0\n",
      "    Params: tensor([ 2.5393, -1.2936])\n",
      "    Grad: tensor([-0.4813,  2.7246])\n",
      "Epoch 59, Loss 25.0\n",
      "    Params: tensor([ 2.5441, -1.3208])\n",
      "    Grad: tensor([-0.4805,  2.7199])\n",
      "Epoch 60, Loss 25.0\n",
      "    Params: tensor([ 2.5489, -1.3479])\n",
      "    Grad: tensor([-0.4797,  2.7153])\n",
      "Epoch 61, Loss 25.0\n",
      "    Params: tensor([ 2.5537, -1.3750])\n",
      "    Grad: tensor([-0.4788,  2.7107])\n",
      "Epoch 62, Loss 25.0\n",
      "    Params: tensor([ 2.5585, -1.4021])\n",
      "    Grad: tensor([-0.4780,  2.7061])\n",
      "Epoch 63, Loss 25.0\n",
      "    Params: tensor([ 2.5632, -1.4291])\n",
      "    Grad: tensor([-0.4772,  2.7015])\n",
      "Epoch 64, Loss 25.0\n",
      "    Params: tensor([ 2.5680, -1.4561])\n",
      "    Grad: tensor([-0.4764,  2.6969])\n",
      "Epoch 65, Loss 25.0\n",
      "    Params: tensor([ 2.5728, -1.4830])\n",
      "    Grad: tensor([-0.4756,  2.6923])\n",
      "Epoch 66, Loss 25.0\n",
      "    Params: tensor([ 2.5775, -1.5099])\n",
      "    Grad: tensor([-0.4748,  2.6877])\n",
      "Epoch 67, Loss 25.0\n",
      "    Params: tensor([ 2.5822, -1.5367])\n",
      "    Grad: tensor([-0.4740,  2.6832])\n",
      "Epoch 68, Loss 25.0\n",
      "    Params: tensor([ 2.5870, -1.5635])\n",
      "    Grad: tensor([-0.4732,  2.6786])\n",
      "Epoch 69, Loss 25.0\n",
      "    Params: tensor([ 2.5917, -1.5902])\n",
      "    Grad: tensor([-0.4724,  2.6741])\n",
      "Epoch 70, Loss 25.0\n",
      "    Params: tensor([ 2.5964, -1.6169])\n",
      "    Grad: tensor([-0.4716,  2.6695])\n",
      "Epoch 71, Loss 24.0\n",
      "    Params: tensor([ 2.6011, -1.6436])\n",
      "    Grad: tensor([-0.4708,  2.6650])\n",
      "Epoch 72, Loss 24.0\n",
      "    Params: tensor([ 2.6058, -1.6702])\n",
      "    Grad: tensor([-0.4700,  2.6605])\n",
      "Epoch 73, Loss 24.0\n",
      "    Params: tensor([ 2.6105, -1.6968])\n",
      "    Grad: tensor([-0.4692,  2.6559])\n",
      "Epoch 74, Loss 24.0\n",
      "    Params: tensor([ 2.6152, -1.7233])\n",
      "    Grad: tensor([-0.4684,  2.6514])\n",
      "Epoch 75, Loss 24.0\n",
      "    Params: tensor([ 2.6199, -1.7497])\n",
      "    Grad: tensor([-0.4676,  2.6469])\n",
      "Epoch 76, Loss 24.0\n",
      "    Params: tensor([ 2.6245, -1.7762])\n",
      "    Grad: tensor([-0.4668,  2.6424])\n",
      "Epoch 77, Loss 24.0\n",
      "    Params: tensor([ 2.6292, -1.8025])\n",
      "    Grad: tensor([-0.4660,  2.6379])\n",
      "Epoch 78, Loss 24.0\n",
      "    Params: tensor([ 2.6339, -1.8289])\n",
      "    Grad: tensor([-0.4652,  2.6335])\n",
      "Epoch 79, Loss 24.0\n",
      "    Params: tensor([ 2.6385, -1.8552])\n",
      "    Grad: tensor([-0.4644,  2.6290])\n",
      "Epoch 80, Loss 24.0\n",
      "    Params: tensor([ 2.6431, -1.8814])\n",
      "    Grad: tensor([-0.4636,  2.6245])\n",
      "Epoch 81, Loss 24.0\n",
      "    Params: tensor([ 2.6478, -1.9076])\n",
      "    Grad: tensor([-0.4628,  2.6201])\n",
      "Epoch 82, Loss 24.0\n",
      "    Params: tensor([ 2.6524, -1.9338])\n",
      "    Grad: tensor([-0.4621,  2.6156])\n",
      "Epoch 83, Loss 24.0\n",
      "    Params: tensor([ 2.6570, -1.9599])\n",
      "    Grad: tensor([-0.4613,  2.6112])\n",
      "Epoch 84, Loss 24.0\n",
      "    Params: tensor([ 2.6616, -1.9860])\n",
      "    Grad: tensor([-0.4605,  2.6067])\n",
      "Epoch 85, Loss 23.0\n",
      "    Params: tensor([ 2.6662, -2.0120])\n",
      "    Grad: tensor([-0.4597,  2.6023])\n",
      "Epoch 86, Loss 23.0\n",
      "    Params: tensor([ 2.6708, -2.0380])\n",
      "    Grad: tensor([-0.4589,  2.5979])\n",
      "Epoch 87, Loss 23.0\n",
      "    Params: tensor([ 2.6754, -2.0639])\n",
      "    Grad: tensor([-0.4582,  2.5935])\n",
      "Epoch 88, Loss 23.0\n",
      "    Params: tensor([ 2.6799, -2.0898])\n",
      "    Grad: tensor([-0.4574,  2.5891])\n",
      "Epoch 89, Loss 23.0\n",
      "    Params: tensor([ 2.6845, -2.1156])\n",
      "    Grad: tensor([-0.4566,  2.5847])\n",
      "Epoch 90, Loss 23.0\n",
      "    Params: tensor([ 2.6891, -2.1414])\n",
      "    Grad: tensor([-0.4558,  2.5803])\n",
      "Epoch 91, Loss 23.0\n",
      "    Params: tensor([ 2.6936, -2.1672])\n",
      "    Grad: tensor([-0.4550,  2.5759])\n",
      "Epoch 92, Loss 23.0\n",
      "    Params: tensor([ 2.6982, -2.1929])\n",
      "    Grad: tensor([-0.4543,  2.5715])\n",
      "Epoch 93, Loss 23.0\n",
      "    Params: tensor([ 2.7027, -2.2186])\n",
      "    Grad: tensor([-0.4535,  2.5671])\n",
      "Epoch 94, Loss 23.0\n",
      "    Params: tensor([ 2.7072, -2.2442])\n",
      "    Grad: tensor([-0.4527,  2.5628])\n",
      "Epoch 95, Loss 23.0\n",
      "    Params: tensor([ 2.7117, -2.2698])\n",
      "    Grad: tensor([-0.4520,  2.5584])\n",
      "Epoch 96, Loss 23.0\n",
      "    Params: tensor([ 2.7163, -2.2953])\n",
      "    Grad: tensor([-0.4512,  2.5541])\n",
      "Epoch 97, Loss 23.0\n",
      "    Params: tensor([ 2.7208, -2.3208])\n",
      "    Grad: tensor([-0.4504,  2.5498])\n",
      "Epoch 98, Loss 23.0\n",
      "    Params: tensor([ 2.7253, -2.3463])\n",
      "    Grad: tensor([-0.4497,  2.5454])\n",
      "Epoch 99, Loss 23.0\n",
      "    Params: tensor([ 2.7297, -2.3717])\n",
      "    Grad: tensor([-0.4489,  2.5411])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([ 2.7297, -2.3717])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs=100,\n",
    "              learning_rate=1e-2,\n",
    "              params = torch.Tensor([0, 0]),\n",
    "              t_u=t_un,\n",
    "              t_c=t_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 187.0\n",
      "    Params: tensor([1.3643, 0.2100])\n",
      "    Grad: tensor([-136.4300,  -21.0000])\n",
      "Epoch 1, Loss 55.0\n",
      "    Params: tensor([1.9044, 0.2745])\n",
      "    Grad: tensor([-54.0118,  -6.4459])\n",
      "Epoch 2, Loss 34.0\n",
      "    Params: tensor([2.1202, 0.2817])\n",
      "    Grad: tensor([-21.5764,  -0.7213])\n",
      "Epoch 3, Loss 31.0\n",
      "    Params: tensor([2.2083, 0.2664])\n",
      "    Grad: tensor([-8.8113,  1.5284])\n",
      "Epoch 4, Loss 30.0\n",
      "    Params: tensor([2.2462, 0.2423])\n",
      "    Grad: tensor([-3.7872,  2.4107])\n",
      "Epoch 5, Loss 30.0\n",
      "    Params: tensor([2.2643, 0.2147])\n",
      "    Grad: tensor([-1.8095,  2.7549])\n",
      "Epoch 6, Loss 30.0\n",
      "    Params: tensor([2.2746, 0.1859])\n",
      "    Grad: tensor([-1.0306,  2.8872])\n",
      "Epoch 7, Loss 30.0\n",
      "    Params: tensor([2.2818, 0.1565])\n",
      "    Grad: tensor([-0.7236,  2.9362])\n",
      "Epoch 8, Loss 30.0\n",
      "    Params: tensor([2.2878, 0.1270])\n",
      "    Grad: tensor([-0.6022,  2.9525])\n",
      "Epoch 9, Loss 30.0\n",
      "    Params: tensor([2.2934, 0.0974])\n",
      "    Grad: tensor([-0.5539,  2.9558])\n",
      "Epoch 10, Loss 29.0\n",
      "    Params: tensor([2.2987, 0.0679])\n",
      "    Grad: tensor([-0.5343,  2.9541])\n",
      "Epoch 11, Loss 29.0\n",
      "    Params: tensor([2.3040, 0.0384])\n",
      "    Grad: tensor([-0.5261,  2.9504])\n",
      "Epoch 12, Loss 29.0\n",
      "    Params: tensor([2.3092, 0.0089])\n",
      "    Grad: tensor([-0.5223,  2.9459])\n",
      "Epoch 13, Loss 29.0\n",
      "    Params: tensor([ 2.3144, -0.0205])\n",
      "    Grad: tensor([-0.5203,  2.9411])\n",
      "Epoch 14, Loss 29.0\n",
      "    Params: tensor([ 2.3196, -0.0499])\n",
      "    Grad: tensor([-0.5190,  2.9361])\n",
      "Epoch 15, Loss 29.0\n",
      "    Params: tensor([ 2.3248, -0.0792])\n",
      "    Grad: tensor([-0.5179,  2.9312])\n",
      "Epoch 16, Loss 29.0\n",
      "    Params: tensor([ 2.3299, -0.1084])\n",
      "    Grad: tensor([-0.5170,  2.9262])\n",
      "Epoch 17, Loss 29.0\n",
      "    Params: tensor([ 2.3351, -0.1376])\n",
      "    Grad: tensor([-0.5161,  2.9212])\n",
      "Epoch 18, Loss 29.0\n",
      "    Params: tensor([ 2.3402, -0.1668])\n",
      "    Grad: tensor([-0.5152,  2.9163])\n",
      "Epoch 19, Loss 29.0\n",
      "    Params: tensor([ 2.3454, -0.1959])\n",
      "    Grad: tensor([-0.5143,  2.9113])\n",
      "Epoch 20, Loss 29.0\n",
      "    Params: tensor([ 2.3505, -0.2250])\n",
      "    Grad: tensor([-0.5134,  2.9064])\n",
      "Epoch 21, Loss 28.0\n",
      "    Params: tensor([ 2.3556, -0.2540])\n",
      "    Grad: tensor([-0.5125,  2.9015])\n",
      "Epoch 22, Loss 28.0\n",
      "    Params: tensor([ 2.3608, -0.2830])\n",
      "    Grad: tensor([-0.5117,  2.8965])\n",
      "Epoch 23, Loss 28.0\n",
      "    Params: tensor([ 2.3659, -0.3119])\n",
      "    Grad: tensor([-0.5108,  2.8916])\n",
      "Epoch 24, Loss 28.0\n",
      "    Params: tensor([ 2.3710, -0.3408])\n",
      "    Grad: tensor([-0.5099,  2.8867])\n",
      "Epoch 25, Loss 28.0\n",
      "    Params: tensor([ 2.3761, -0.3696])\n",
      "    Grad: tensor([-0.5091,  2.8818])\n",
      "Epoch 26, Loss 28.0\n",
      "    Params: tensor([ 2.3811, -0.3983])\n",
      "    Grad: tensor([-0.5082,  2.8769])\n",
      "Epoch 27, Loss 28.0\n",
      "    Params: tensor([ 2.3862, -0.4271])\n",
      "    Grad: tensor([-0.5074,  2.8720])\n",
      "Epoch 28, Loss 28.0\n",
      "    Params: tensor([ 2.3913, -0.4557])\n",
      "    Grad: tensor([-0.5065,  2.8671])\n",
      "Epoch 29, Loss 28.0\n",
      "    Params: tensor([ 2.3963, -0.4844])\n",
      "    Grad: tensor([-0.5056,  2.8623])\n",
      "Epoch 30, Loss 28.0\n",
      "    Params: tensor([ 2.4014, -0.5129])\n",
      "    Grad: tensor([-0.5048,  2.8574])\n",
      "Epoch 31, Loss 28.0\n",
      "    Params: tensor([ 2.4064, -0.5415])\n",
      "    Grad: tensor([-0.5039,  2.8525])\n",
      "Epoch 32, Loss 28.0\n",
      "    Params: tensor([ 2.4115, -0.5699])\n",
      "    Grad: tensor([-0.5031,  2.8477])\n",
      "Epoch 33, Loss 27.0\n",
      "    Params: tensor([ 2.4165, -0.5984])\n",
      "    Grad: tensor([-0.5022,  2.8429])\n",
      "Epoch 34, Loss 27.0\n",
      "    Params: tensor([ 2.4215, -0.6267])\n",
      "    Grad: tensor([-0.5013,  2.8380])\n",
      "Epoch 35, Loss 27.0\n",
      "    Params: tensor([ 2.4265, -0.6551])\n",
      "    Grad: tensor([-0.5005,  2.8332])\n",
      "Epoch 36, Loss 27.0\n",
      "    Params: tensor([ 2.4315, -0.6834])\n",
      "    Grad: tensor([-0.4996,  2.8284])\n",
      "Epoch 37, Loss 27.0\n",
      "    Params: tensor([ 2.4365, -0.7116])\n",
      "    Grad: tensor([-0.4988,  2.8236])\n",
      "Epoch 38, Loss 27.0\n",
      "    Params: tensor([ 2.4415, -0.7398])\n",
      "    Grad: tensor([-0.4980,  2.8188])\n",
      "Epoch 39, Loss 27.0\n",
      "    Params: tensor([ 2.4464, -0.7679])\n",
      "    Grad: tensor([-0.4971,  2.8140])\n",
      "Epoch 40, Loss 27.0\n",
      "    Params: tensor([ 2.4514, -0.7960])\n",
      "    Grad: tensor([-0.4963,  2.8092])\n",
      "Epoch 41, Loss 27.0\n",
      "    Params: tensor([ 2.4564, -0.8241])\n",
      "    Grad: tensor([-0.4954,  2.8044])\n",
      "Epoch 42, Loss 27.0\n",
      "    Params: tensor([ 2.4613, -0.8520])\n",
      "    Grad: tensor([-0.4946,  2.7997])\n",
      "Epoch 43, Loss 27.0\n",
      "    Params: tensor([ 2.4662, -0.8800])\n",
      "    Grad: tensor([-0.4937,  2.7949])\n",
      "Epoch 44, Loss 27.0\n",
      "    Params: tensor([ 2.4712, -0.9079])\n",
      "    Grad: tensor([-0.4929,  2.7902])\n",
      "Epoch 45, Loss 26.0\n",
      "    Params: tensor([ 2.4761, -0.9358])\n",
      "    Grad: tensor([-0.4921,  2.7854])\n",
      "Epoch 46, Loss 26.0\n",
      "    Params: tensor([ 2.4810, -0.9636])\n",
      "    Grad: tensor([-0.4912,  2.7807])\n",
      "Epoch 47, Loss 26.0\n",
      "    Params: tensor([ 2.4859, -0.9913])\n",
      "    Grad: tensor([-0.4904,  2.7760])\n",
      "Epoch 48, Loss 26.0\n",
      "    Params: tensor([ 2.4908, -1.0190])\n",
      "    Grad: tensor([-0.4896,  2.7713])\n",
      "Epoch 49, Loss 26.0\n",
      "    Params: tensor([ 2.4957, -1.0467])\n",
      "    Grad: tensor([-0.4887,  2.7666])\n",
      "Epoch 50, Loss 26.0\n",
      "    Params: tensor([ 2.5006, -1.0743])\n",
      "    Grad: tensor([-0.4879,  2.7619])\n",
      "Epoch 51, Loss 26.0\n",
      "    Params: tensor([ 2.5054, -1.1019])\n",
      "    Grad: tensor([-0.4870,  2.7572])\n",
      "Epoch 52, Loss 26.0\n",
      "    Params: tensor([ 2.5103, -1.1294])\n",
      "    Grad: tensor([-0.4862,  2.7525])\n",
      "Epoch 53, Loss 26.0\n",
      "    Params: tensor([ 2.5151, -1.1569])\n",
      "    Grad: tensor([-0.4854,  2.7478])\n",
      "Epoch 54, Loss 26.0\n",
      "    Params: tensor([ 2.5200, -1.1843])\n",
      "    Grad: tensor([-0.4846,  2.7431])\n",
      "Epoch 55, Loss 26.0\n",
      "    Params: tensor([ 2.5248, -1.2117])\n",
      "    Grad: tensor([-0.4838,  2.7385])\n",
      "Epoch 56, Loss 26.0\n",
      "    Params: tensor([ 2.5297, -1.2390])\n",
      "    Grad: tensor([-0.4829,  2.7338])\n",
      "Epoch 57, Loss 26.0\n",
      "    Params: tensor([ 2.5345, -1.2663])\n",
      "    Grad: tensor([-0.4821,  2.7292])\n",
      "Epoch 58, Loss 25.0\n",
      "    Params: tensor([ 2.5393, -1.2936])\n",
      "    Grad: tensor([-0.4813,  2.7246])\n",
      "Epoch 59, Loss 25.0\n",
      "    Params: tensor([ 2.5441, -1.3208])\n",
      "    Grad: tensor([-0.4805,  2.7199])\n",
      "Epoch 60, Loss 25.0\n",
      "    Params: tensor([ 2.5489, -1.3479])\n",
      "    Grad: tensor([-0.4797,  2.7153])\n",
      "Epoch 61, Loss 25.0\n",
      "    Params: tensor([ 2.5537, -1.3750])\n",
      "    Grad: tensor([-0.4788,  2.7107])\n",
      "Epoch 62, Loss 25.0\n",
      "    Params: tensor([ 2.5585, -1.4021])\n",
      "    Grad: tensor([-0.4780,  2.7061])\n",
      "Epoch 63, Loss 25.0\n",
      "    Params: tensor([ 2.5632, -1.4291])\n",
      "    Grad: tensor([-0.4772,  2.7015])\n",
      "Epoch 64, Loss 25.0\n",
      "    Params: tensor([ 2.5680, -1.4561])\n",
      "    Grad: tensor([-0.4764,  2.6969])\n",
      "Epoch 65, Loss 25.0\n",
      "    Params: tensor([ 2.5728, -1.4830])\n",
      "    Grad: tensor([-0.4756,  2.6923])\n",
      "Epoch 66, Loss 25.0\n",
      "    Params: tensor([ 2.5775, -1.5099])\n",
      "    Grad: tensor([-0.4748,  2.6877])\n",
      "Epoch 67, Loss 25.0\n",
      "    Params: tensor([ 2.5822, -1.5367])\n",
      "    Grad: tensor([-0.4740,  2.6832])\n",
      "Epoch 68, Loss 25.0\n",
      "    Params: tensor([ 2.5870, -1.5635])\n",
      "    Grad: tensor([-0.4732,  2.6786])\n",
      "Epoch 69, Loss 25.0\n",
      "    Params: tensor([ 2.5917, -1.5902])\n",
      "    Grad: tensor([-0.4724,  2.6741])\n",
      "Epoch 70, Loss 25.0\n",
      "    Params: tensor([ 2.5964, -1.6169])\n",
      "    Grad: tensor([-0.4716,  2.6695])\n",
      "Epoch 71, Loss 24.0\n",
      "    Params: tensor([ 2.6011, -1.6436])\n",
      "    Grad: tensor([-0.4708,  2.6650])\n",
      "Epoch 72, Loss 24.0\n",
      "    Params: tensor([ 2.6058, -1.6702])\n",
      "    Grad: tensor([-0.4700,  2.6605])\n",
      "Epoch 73, Loss 24.0\n",
      "    Params: tensor([ 2.6105, -1.6968])\n",
      "    Grad: tensor([-0.4692,  2.6559])\n",
      "Epoch 74, Loss 24.0\n",
      "    Params: tensor([ 2.6152, -1.7233])\n",
      "    Grad: tensor([-0.4684,  2.6514])\n",
      "Epoch 75, Loss 24.0\n",
      "    Params: tensor([ 2.6199, -1.7497])\n",
      "    Grad: tensor([-0.4676,  2.6469])\n",
      "Epoch 76, Loss 24.0\n",
      "    Params: tensor([ 2.6245, -1.7762])\n",
      "    Grad: tensor([-0.4668,  2.6424])\n",
      "Epoch 77, Loss 24.0\n",
      "    Params: tensor([ 2.6292, -1.8025])\n",
      "    Grad: tensor([-0.4660,  2.6379])\n",
      "Epoch 78, Loss 24.0\n",
      "    Params: tensor([ 2.6339, -1.8289])\n",
      "    Grad: tensor([-0.4652,  2.6335])\n",
      "Epoch 79, Loss 24.0\n",
      "    Params: tensor([ 2.6385, -1.8552])\n",
      "    Grad: tensor([-0.4644,  2.6290])\n",
      "Epoch 80, Loss 24.0\n",
      "    Params: tensor([ 2.6431, -1.8814])\n",
      "    Grad: tensor([-0.4636,  2.6245])\n",
      "Epoch 81, Loss 24.0\n",
      "    Params: tensor([ 2.6478, -1.9076])\n",
      "    Grad: tensor([-0.4628,  2.6201])\n",
      "Epoch 82, Loss 24.0\n",
      "    Params: tensor([ 2.6524, -1.9338])\n",
      "    Grad: tensor([-0.4621,  2.6156])\n",
      "Epoch 83, Loss 24.0\n",
      "    Params: tensor([ 2.6570, -1.9599])\n",
      "    Grad: tensor([-0.4613,  2.6112])\n",
      "Epoch 84, Loss 24.0\n",
      "    Params: tensor([ 2.6616, -1.9860])\n",
      "    Grad: tensor([-0.4605,  2.6067])\n",
      "Epoch 85, Loss 23.0\n",
      "    Params: tensor([ 2.6662, -2.0120])\n",
      "    Grad: tensor([-0.4597,  2.6023])\n",
      "Epoch 86, Loss 23.0\n",
      "    Params: tensor([ 2.6708, -2.0380])\n",
      "    Grad: tensor([-0.4589,  2.5979])\n",
      "Epoch 87, Loss 23.0\n",
      "    Params: tensor([ 2.6754, -2.0639])\n",
      "    Grad: tensor([-0.4582,  2.5935])\n",
      "Epoch 88, Loss 23.0\n",
      "    Params: tensor([ 2.6799, -2.0898])\n",
      "    Grad: tensor([-0.4574,  2.5891])\n",
      "Epoch 89, Loss 23.0\n",
      "    Params: tensor([ 2.6845, -2.1156])\n",
      "    Grad: tensor([-0.4566,  2.5847])\n",
      "Epoch 90, Loss 23.0\n",
      "    Params: tensor([ 2.6891, -2.1414])\n",
      "    Grad: tensor([-0.4558,  2.5803])\n",
      "Epoch 91, Loss 23.0\n",
      "    Params: tensor([ 2.6936, -2.1672])\n",
      "    Grad: tensor([-0.4550,  2.5759])\n",
      "Epoch 92, Loss 23.0\n",
      "    Params: tensor([ 2.6982, -2.1929])\n",
      "    Grad: tensor([-0.4543,  2.5715])\n",
      "Epoch 93, Loss 23.0\n",
      "    Params: tensor([ 2.7027, -2.2186])\n",
      "    Grad: tensor([-0.4535,  2.5671])\n",
      "Epoch 94, Loss 23.0\n",
      "    Params: tensor([ 2.7072, -2.2442])\n",
      "    Grad: tensor([-0.4527,  2.5628])\n",
      "Epoch 95, Loss 23.0\n",
      "    Params: tensor([ 2.7117, -2.2698])\n",
      "    Grad: tensor([-0.4520,  2.5584])\n",
      "Epoch 96, Loss 23.0\n",
      "    Params: tensor([ 2.7163, -2.2953])\n",
      "    Grad: tensor([-0.4512,  2.5541])\n",
      "Epoch 97, Loss 23.0\n",
      "    Params: tensor([ 2.7208, -2.3208])\n",
      "    Grad: tensor([-0.4504,  2.5498])\n",
      "Epoch 98, Loss 23.0\n",
      "    Params: tensor([ 2.7253, -2.3463])\n",
      "    Grad: tensor([-0.4497,  2.5454])\n",
      "Epoch 99, Loss 23.0\n",
      "    Params: tensor([ 2.7297, -2.3717])\n",
      "    Grad: tensor([-0.4489,  2.5411])\n",
      "Epoch 100, Loss 22.0\n",
      "    Params: tensor([ 2.7342, -2.3971])\n",
      "    Grad: tensor([-0.4481,  2.5368])\n",
      "Epoch 101, Loss 22.0\n",
      "    Params: tensor([ 2.7387, -2.4224])\n",
      "    Grad: tensor([-0.4474,  2.5325])\n",
      "Epoch 102, Loss 22.0\n",
      "    Params: tensor([ 2.7432, -2.4477])\n",
      "    Grad: tensor([-0.4466,  2.5282])\n",
      "Epoch 103, Loss 22.0\n",
      "    Params: tensor([ 2.7476, -2.4729])\n",
      "    Grad: tensor([-0.4459,  2.5239])\n",
      "Epoch 104, Loss 22.0\n",
      "    Params: tensor([ 2.7521, -2.4981])\n",
      "    Grad: tensor([-0.4451,  2.5196])\n",
      "Epoch 105, Loss 22.0\n",
      "    Params: tensor([ 2.7565, -2.5233])\n",
      "    Grad: tensor([-0.4443,  2.5153])\n",
      "Epoch 106, Loss 22.0\n",
      "    Params: tensor([ 2.7610, -2.5484])\n",
      "    Grad: tensor([-0.4436,  2.5110])\n",
      "Epoch 107, Loss 22.0\n",
      "    Params: tensor([ 2.7654, -2.5734])\n",
      "    Grad: tensor([-0.4428,  2.5068])\n",
      "Epoch 108, Loss 22.0\n",
      "    Params: tensor([ 2.7698, -2.5985])\n",
      "    Grad: tensor([-0.4421,  2.5025])\n",
      "Epoch 109, Loss 22.0\n",
      "    Params: tensor([ 2.7742, -2.6234])\n",
      "    Grad: tensor([-0.4413,  2.4983])\n",
      "Epoch 110, Loss 22.0\n",
      "    Params: tensor([ 2.7786, -2.6484])\n",
      "    Grad: tensor([-0.4406,  2.4940])\n",
      "Epoch 111, Loss 22.0\n",
      "    Params: tensor([ 2.7830, -2.6733])\n",
      "    Grad: tensor([-0.4398,  2.4898])\n",
      "Epoch 112, Loss 22.0\n",
      "    Params: tensor([ 2.7874, -2.6981])\n",
      "    Grad: tensor([-0.4391,  2.4855])\n",
      "Epoch 113, Loss 22.0\n",
      "    Params: tensor([ 2.7918, -2.7229])\n",
      "    Grad: tensor([-0.4383,  2.4813])\n",
      "Epoch 114, Loss 22.0\n",
      "    Params: tensor([ 2.7962, -2.7477])\n",
      "    Grad: tensor([-0.4376,  2.4771])\n",
      "Epoch 115, Loss 21.0\n",
      "    Params: tensor([ 2.8005, -2.7724])\n",
      "    Grad: tensor([-0.4368,  2.4729])\n",
      "Epoch 116, Loss 21.0\n",
      "    Params: tensor([ 2.8049, -2.7971])\n",
      "    Grad: tensor([-0.4361,  2.4687])\n",
      "Epoch 117, Loss 21.0\n",
      "    Params: tensor([ 2.8093, -2.8218])\n",
      "    Grad: tensor([-0.4354,  2.4645])\n",
      "Epoch 118, Loss 21.0\n",
      "    Params: tensor([ 2.8136, -2.8464])\n",
      "    Grad: tensor([-0.4346,  2.4603])\n",
      "Epoch 119, Loss 21.0\n",
      "    Params: tensor([ 2.8179, -2.8709])\n",
      "    Grad: tensor([-0.4339,  2.4561])\n",
      "Epoch 120, Loss 21.0\n",
      "    Params: tensor([ 2.8223, -2.8955])\n",
      "    Grad: tensor([-0.4332,  2.4520])\n",
      "Epoch 121, Loss 21.0\n",
      "    Params: tensor([ 2.8266, -2.9199])\n",
      "    Grad: tensor([-0.4324,  2.4478])\n",
      "Epoch 122, Loss 21.0\n",
      "    Params: tensor([ 2.8309, -2.9444])\n",
      "    Grad: tensor([-0.4317,  2.4436])\n",
      "Epoch 123, Loss 21.0\n",
      "    Params: tensor([ 2.8352, -2.9688])\n",
      "    Grad: tensor([-0.4309,  2.4395])\n",
      "Epoch 124, Loss 21.0\n",
      "    Params: tensor([ 2.8395, -2.9931])\n",
      "    Grad: tensor([-0.4302,  2.4353])\n",
      "Epoch 125, Loss 21.0\n",
      "    Params: tensor([ 2.8438, -3.0174])\n",
      "    Grad: tensor([-0.4295,  2.4312])\n",
      "Epoch 126, Loss 21.0\n",
      "    Params: tensor([ 2.8481, -3.0417])\n",
      "    Grad: tensor([-0.4288,  2.4271])\n",
      "Epoch 127, Loss 21.0\n",
      "    Params: tensor([ 2.8524, -3.0659])\n",
      "    Grad: tensor([-0.4280,  2.4230])\n",
      "Epoch 128, Loss 21.0\n",
      "    Params: tensor([ 2.8567, -3.0901])\n",
      "    Grad: tensor([-0.4273,  2.4188])\n",
      "Epoch 129, Loss 21.0\n",
      "    Params: tensor([ 2.8609, -3.1143])\n",
      "    Grad: tensor([-0.4266,  2.4147])\n",
      "Epoch 130, Loss 21.0\n",
      "    Params: tensor([ 2.8652, -3.1384])\n",
      "    Grad: tensor([-0.4258,  2.4106])\n",
      "Epoch 131, Loss 21.0\n",
      "    Params: tensor([ 2.8694, -3.1624])\n",
      "    Grad: tensor([-0.4251,  2.4065])\n",
      "Epoch 132, Loss 20.0\n",
      "    Params: tensor([ 2.8737, -3.1865])\n",
      "    Grad: tensor([-0.4244,  2.4024])\n",
      "Epoch 133, Loss 20.0\n",
      "    Params: tensor([ 2.8779, -3.2104])\n",
      "    Grad: tensor([-0.4237,  2.3984])\n",
      "Epoch 134, Loss 20.0\n",
      "    Params: tensor([ 2.8821, -3.2344])\n",
      "    Grad: tensor([-0.4230,  2.3943])\n",
      "Epoch 135, Loss 20.0\n",
      "    Params: tensor([ 2.8864, -3.2583])\n",
      "    Grad: tensor([-0.4222,  2.3902])\n",
      "Epoch 136, Loss 20.0\n",
      "    Params: tensor([ 2.8906, -3.2822])\n",
      "    Grad: tensor([-0.4215,  2.3862])\n",
      "Epoch 137, Loss 20.0\n",
      "    Params: tensor([ 2.8948, -3.3060])\n",
      "    Grad: tensor([-0.4208,  2.3821])\n",
      "Epoch 138, Loss 20.0\n",
      "    Params: tensor([ 2.8990, -3.3298])\n",
      "    Grad: tensor([-0.4201,  2.3781])\n",
      "Epoch 139, Loss 20.0\n",
      "    Params: tensor([ 2.9032, -3.3535])\n",
      "    Grad: tensor([-0.4194,  2.3740])\n",
      "Epoch 140, Loss 20.0\n",
      "    Params: tensor([ 2.9074, -3.3772])\n",
      "    Grad: tensor([-0.4187,  2.3700])\n",
      "Epoch 141, Loss 20.0\n",
      "    Params: tensor([ 2.9116, -3.4009])\n",
      "    Grad: tensor([-0.4179,  2.3660])\n",
      "Epoch 142, Loss 20.0\n",
      "    Params: tensor([ 2.9157, -3.4245])\n",
      "    Grad: tensor([-0.4172,  2.3619])\n",
      "Epoch 143, Loss 20.0\n",
      "    Params: tensor([ 2.9199, -3.4481])\n",
      "    Grad: tensor([-0.4165,  2.3579])\n",
      "Epoch 144, Loss 20.0\n",
      "    Params: tensor([ 2.9240, -3.4716])\n",
      "    Grad: tensor([-0.4158,  2.3539])\n",
      "Epoch 145, Loss 20.0\n",
      "    Params: tensor([ 2.9282, -3.4951])\n",
      "    Grad: tensor([-0.4151,  2.3499])\n",
      "Epoch 146, Loss 20.0\n",
      "    Params: tensor([ 2.9323, -3.5186])\n",
      "    Grad: tensor([-0.4144,  2.3459])\n",
      "Epoch 147, Loss 20.0\n",
      "    Params: tensor([ 2.9365, -3.5420])\n",
      "    Grad: tensor([-0.4137,  2.3420])\n",
      "Epoch 148, Loss 20.0\n",
      "    Params: tensor([ 2.9406, -3.5654])\n",
      "    Grad: tensor([-0.4130,  2.3380])\n",
      "Epoch 149, Loss 19.0\n",
      "    Params: tensor([ 2.9447, -3.5887])\n",
      "    Grad: tensor([-0.4123,  2.3340])\n",
      "Epoch 150, Loss 19.0\n",
      "    Params: tensor([ 2.9488, -3.6120])\n",
      "    Grad: tensor([-0.4116,  2.3300])\n",
      "Epoch 151, Loss 19.0\n",
      "    Params: tensor([ 2.9530, -3.6353])\n",
      "    Grad: tensor([-0.4109,  2.3261])\n",
      "Epoch 152, Loss 19.0\n",
      "    Params: tensor([ 2.9571, -3.6585])\n",
      "    Grad: tensor([-0.4102,  2.3221])\n",
      "Epoch 153, Loss 19.0\n",
      "    Params: tensor([ 2.9612, -3.6817])\n",
      "    Grad: tensor([-0.4095,  2.3182])\n",
      "Epoch 154, Loss 19.0\n",
      "    Params: tensor([ 2.9652, -3.7048])\n",
      "    Grad: tensor([-0.4088,  2.3142])\n",
      "Epoch 155, Loss 19.0\n",
      "    Params: tensor([ 2.9693, -3.7279])\n",
      "    Grad: tensor([-0.4081,  2.3103])\n",
      "Epoch 156, Loss 19.0\n",
      "    Params: tensor([ 2.9734, -3.7510])\n",
      "    Grad: tensor([-0.4074,  2.3064])\n",
      "Epoch 157, Loss 19.0\n",
      "    Params: tensor([ 2.9775, -3.7740])\n",
      "    Grad: tensor([-0.4067,  2.3025])\n",
      "Epoch 158, Loss 19.0\n",
      "    Params: tensor([ 2.9815, -3.7970])\n",
      "    Grad: tensor([-0.4060,  2.2986])\n",
      "Epoch 159, Loss 19.0\n",
      "    Params: tensor([ 2.9856, -3.8199])\n",
      "    Grad: tensor([-0.4054,  2.2947])\n",
      "Epoch 160, Loss 19.0\n",
      "    Params: tensor([ 2.9896, -3.8428])\n",
      "    Grad: tensor([-0.4047,  2.2908])\n",
      "Epoch 161, Loss 19.0\n",
      "    Params: tensor([ 2.9937, -3.8657])\n",
      "    Grad: tensor([-0.4040,  2.2869])\n",
      "Epoch 162, Loss 19.0\n",
      "    Params: tensor([ 2.9977, -3.8885])\n",
      "    Grad: tensor([-0.4033,  2.2830])\n",
      "Epoch 163, Loss 19.0\n",
      "    Params: tensor([ 3.0017, -3.9113])\n",
      "    Grad: tensor([-0.4026,  2.2791])\n",
      "Epoch 164, Loss 19.0\n",
      "    Params: tensor([ 3.0057, -3.9341])\n",
      "    Grad: tensor([-0.4019,  2.2752])\n",
      "Epoch 165, Loss 19.0\n",
      "    Params: tensor([ 3.0098, -3.9568])\n",
      "    Grad: tensor([-0.4012,  2.2714])\n",
      "Epoch 166, Loss 19.0\n",
      "    Params: tensor([ 3.0138, -3.9795])\n",
      "    Grad: tensor([-0.4005,  2.2675])\n",
      "Epoch 167, Loss 18.0\n",
      "    Params: tensor([ 3.0178, -4.0021])\n",
      "    Grad: tensor([-0.3999,  2.2637])\n",
      "Epoch 168, Loss 18.0\n",
      "    Params: tensor([ 3.0218, -4.0247])\n",
      "    Grad: tensor([-0.3992,  2.2598])\n",
      "Epoch 169, Loss 18.0\n",
      "    Params: tensor([ 3.0257, -4.0473])\n",
      "    Grad: tensor([-0.3985,  2.2560])\n",
      "Epoch 170, Loss 18.0\n",
      "    Params: tensor([ 3.0297, -4.0698])\n",
      "    Grad: tensor([-0.3978,  2.2521])\n",
      "Epoch 171, Loss 18.0\n",
      "    Params: tensor([ 3.0337, -4.0923])\n",
      "    Grad: tensor([-0.3972,  2.2483])\n",
      "Epoch 172, Loss 18.0\n",
      "    Params: tensor([ 3.0377, -4.1147])\n",
      "    Grad: tensor([-0.3965,  2.2445])\n",
      "Epoch 173, Loss 18.0\n",
      "    Params: tensor([ 3.0416, -4.1371])\n",
      "    Grad: tensor([-0.3958,  2.2407])\n",
      "Epoch 174, Loss 18.0\n",
      "    Params: tensor([ 3.0456, -4.1595])\n",
      "    Grad: tensor([-0.3951,  2.2369])\n",
      "Epoch 175, Loss 18.0\n",
      "    Params: tensor([ 3.0495, -4.1818])\n",
      "    Grad: tensor([-0.3945,  2.2331])\n",
      "Epoch 176, Loss 18.0\n",
      "    Params: tensor([ 3.0534, -4.2041])\n",
      "    Grad: tensor([-0.3938,  2.2293])\n",
      "Epoch 177, Loss 18.0\n",
      "    Params: tensor([ 3.0574, -4.2264])\n",
      "    Grad: tensor([-0.3931,  2.2255])\n",
      "Epoch 178, Loss 18.0\n",
      "    Params: tensor([ 3.0613, -4.2486])\n",
      "    Grad: tensor([-0.3925,  2.2217])\n",
      "Epoch 179, Loss 18.0\n",
      "    Params: tensor([ 3.0652, -4.2708])\n",
      "    Grad: tensor([-0.3918,  2.2179])\n",
      "Epoch 180, Loss 18.0\n",
      "    Params: tensor([ 3.0691, -4.2929])\n",
      "    Grad: tensor([-0.3911,  2.2142])\n",
      "Epoch 181, Loss 18.0\n",
      "    Params: tensor([ 3.0730, -4.3150])\n",
      "    Grad: tensor([-0.3905,  2.2104])\n",
      "Epoch 182, Loss 18.0\n",
      "    Params: tensor([ 3.0769, -4.3371])\n",
      "    Grad: tensor([-0.3898,  2.2067])\n",
      "Epoch 183, Loss 18.0\n",
      "    Params: tensor([ 3.0808, -4.3591])\n",
      "    Grad: tensor([-0.3892,  2.2029])\n",
      "Epoch 184, Loss 18.0\n",
      "    Params: tensor([ 3.0847, -4.3811])\n",
      "    Grad: tensor([-0.3885,  2.1992])\n",
      "Epoch 185, Loss 18.0\n",
      "    Params: tensor([ 3.0886, -4.4030])\n",
      "    Grad: tensor([-0.3878,  2.1954])\n",
      "Epoch 186, Loss 18.0\n",
      "    Params: tensor([ 3.0925, -4.4250])\n",
      "    Grad: tensor([-0.3872,  2.1917])\n",
      "Epoch 187, Loss 17.0\n",
      "    Params: tensor([ 3.0963, -4.4468])\n",
      "    Grad: tensor([-0.3865,  2.1880])\n",
      "Epoch 188, Loss 17.0\n",
      "    Params: tensor([ 3.1002, -4.4687])\n",
      "    Grad: tensor([-0.3859,  2.1843])\n",
      "Epoch 189, Loss 17.0\n",
      "    Params: tensor([ 3.1040, -4.4905])\n",
      "    Grad: tensor([-0.3852,  2.1805])\n",
      "Epoch 190, Loss 17.0\n",
      "    Params: tensor([ 3.1079, -4.5123])\n",
      "    Grad: tensor([-0.3845,  2.1768])\n",
      "Epoch 191, Loss 17.0\n",
      "    Params: tensor([ 3.1117, -4.5340])\n",
      "    Grad: tensor([-0.3839,  2.1731])\n",
      "Epoch 192, Loss 17.0\n",
      "    Params: tensor([ 3.1156, -4.5557])\n",
      "    Grad: tensor([-0.3832,  2.1695])\n",
      "Epoch 193, Loss 17.0\n",
      "    Params: tensor([ 3.1194, -4.5773])\n",
      "    Grad: tensor([-0.3826,  2.1658])\n",
      "Epoch 194, Loss 17.0\n",
      "    Params: tensor([ 3.1232, -4.5990])\n",
      "    Grad: tensor([-0.3819,  2.1621])\n",
      "Epoch 195, Loss 17.0\n",
      "    Params: tensor([ 3.1270, -4.6205])\n",
      "    Grad: tensor([-0.3813,  2.1584])\n",
      "Epoch 196, Loss 17.0\n",
      "    Params: tensor([ 3.1308, -4.6421])\n",
      "    Grad: tensor([-0.3806,  2.1548])\n",
      "Epoch 197, Loss 17.0\n",
      "    Params: tensor([ 3.1346, -4.6636])\n",
      "    Grad: tensor([-0.3800,  2.1511])\n",
      "Epoch 198, Loss 17.0\n",
      "    Params: tensor([ 3.1384, -4.6851])\n",
      "    Grad: tensor([-0.3793,  2.1474])\n",
      "Epoch 199, Loss 17.0\n",
      "    Params: tensor([ 3.1422, -4.7065])\n",
      "    Grad: tensor([-0.3787,  2.1438])\n",
      "Epoch 200, Loss 17.0\n",
      "    Params: tensor([ 3.1460, -4.7279])\n",
      "    Grad: tensor([-0.3781,  2.1401])\n",
      "Epoch 201, Loss 17.0\n",
      "    Params: tensor([ 3.1498, -4.7493])\n",
      "    Grad: tensor([-0.3774,  2.1365])\n",
      "Epoch 202, Loss 17.0\n",
      "    Params: tensor([ 3.1535, -4.7706])\n",
      "    Grad: tensor([-0.3768,  2.1329])\n",
      "Epoch 203, Loss 17.0\n",
      "    Params: tensor([ 3.1573, -4.7919])\n",
      "    Grad: tensor([-0.3762,  2.1293])\n",
      "Epoch 204, Loss 17.0\n",
      "    Params: tensor([ 3.1610, -4.8132])\n",
      "    Grad: tensor([-0.3755,  2.1256])\n",
      "Epoch 205, Loss 17.0\n",
      "    Params: tensor([ 3.1648, -4.8344])\n",
      "    Grad: tensor([-0.3749,  2.1220])\n",
      "Epoch 206, Loss 17.0\n",
      "    Params: tensor([ 3.1685, -4.8556])\n",
      "    Grad: tensor([-0.3742,  2.1184])\n",
      "Epoch 207, Loss 17.0\n",
      "    Params: tensor([ 3.1723, -4.8767])\n",
      "    Grad: tensor([-0.3736,  2.1148])\n",
      "Epoch 208, Loss 16.0\n",
      "    Params: tensor([ 3.1760, -4.8978])\n",
      "    Grad: tensor([-0.3730,  2.1112])\n",
      "Epoch 209, Loss 16.0\n",
      "    Params: tensor([ 3.1797, -4.9189])\n",
      "    Grad: tensor([-0.3723,  2.1076])\n",
      "Epoch 210, Loss 16.0\n",
      "    Params: tensor([ 3.1834, -4.9399])\n",
      "    Grad: tensor([-0.3717,  2.1041])\n",
      "Epoch 211, Loss 16.0\n",
      "    Params: tensor([ 3.1871, -4.9609])\n",
      "    Grad: tensor([-0.3711,  2.1005])\n",
      "Epoch 212, Loss 16.0\n",
      "    Params: tensor([ 3.1908, -4.9819])\n",
      "    Grad: tensor([-0.3704,  2.0969])\n",
      "Epoch 213, Loss 16.0\n",
      "    Params: tensor([ 3.1945, -5.0029])\n",
      "    Grad: tensor([-0.3698,  2.0934])\n",
      "Epoch 214, Loss 16.0\n",
      "    Params: tensor([ 3.1982, -5.0237])\n",
      "    Grad: tensor([-0.3692,  2.0898])\n",
      "Epoch 215, Loss 16.0\n",
      "    Params: tensor([ 3.2019, -5.0446])\n",
      "    Grad: tensor([-0.3685,  2.0863])\n",
      "Epoch 216, Loss 16.0\n",
      "    Params: tensor([ 3.2056, -5.0654])\n",
      "    Grad: tensor([-0.3679,  2.0827])\n",
      "Epoch 217, Loss 16.0\n",
      "    Params: tensor([ 3.2093, -5.0862])\n",
      "    Grad: tensor([-0.3673,  2.0792])\n",
      "Epoch 218, Loss 16.0\n",
      "    Params: tensor([ 3.2129, -5.1070])\n",
      "    Grad: tensor([-0.3667,  2.0756])\n",
      "Epoch 219, Loss 16.0\n",
      "    Params: tensor([ 3.2166, -5.1277])\n",
      "    Grad: tensor([-0.3660,  2.0721])\n",
      "Epoch 220, Loss 16.0\n",
      "    Params: tensor([ 3.2203, -5.1484])\n",
      "    Grad: tensor([-0.3654,  2.0686])\n",
      "Epoch 221, Loss 16.0\n",
      "    Params: tensor([ 3.2239, -5.1690])\n",
      "    Grad: tensor([-0.3648,  2.0651])\n",
      "Epoch 222, Loss 16.0\n",
      "    Params: tensor([ 3.2275, -5.1897])\n",
      "    Grad: tensor([-0.3642,  2.0616])\n",
      "Epoch 223, Loss 16.0\n",
      "    Params: tensor([ 3.2312, -5.2102])\n",
      "    Grad: tensor([-0.3636,  2.0581])\n",
      "Epoch 224, Loss 16.0\n",
      "    Params: tensor([ 3.2348, -5.2308])\n",
      "    Grad: tensor([-0.3629,  2.0546])\n",
      "Epoch 225, Loss 16.0\n",
      "    Params: tensor([ 3.2384, -5.2513])\n",
      "    Grad: tensor([-0.3623,  2.0511])\n",
      "Epoch 226, Loss 16.0\n",
      "    Params: tensor([ 3.2421, -5.2718])\n",
      "    Grad: tensor([-0.3617,  2.0476])\n",
      "Epoch 227, Loss 16.0\n",
      "    Params: tensor([ 3.2457, -5.2922])\n",
      "    Grad: tensor([-0.3611,  2.0441])\n",
      "Epoch 228, Loss 16.0\n",
      "    Params: tensor([ 3.2493, -5.3126])\n",
      "    Grad: tensor([-0.3605,  2.0406])\n",
      "Epoch 229, Loss 16.0\n",
      "    Params: tensor([ 3.2529, -5.3330])\n",
      "    Grad: tensor([-0.3599,  2.0372])\n",
      "Epoch 230, Loss 15.0\n",
      "    Params: tensor([ 3.2565, -5.3533])\n",
      "    Grad: tensor([-0.3593,  2.0337])\n",
      "Epoch 231, Loss 15.0\n",
      "    Params: tensor([ 3.2600, -5.3736])\n",
      "    Grad: tensor([-0.3587,  2.0303])\n",
      "Epoch 232, Loss 15.0\n",
      "    Params: tensor([ 3.2636, -5.3939])\n",
      "    Grad: tensor([-0.3580,  2.0268])\n",
      "Epoch 233, Loss 15.0\n",
      "    Params: tensor([ 3.2672, -5.4141])\n",
      "    Grad: tensor([-0.3574,  2.0234])\n",
      "Epoch 234, Loss 15.0\n",
      "    Params: tensor([ 3.2708, -5.4343])\n",
      "    Grad: tensor([-0.3568,  2.0199])\n",
      "Epoch 235, Loss 15.0\n",
      "    Params: tensor([ 3.2743, -5.4545])\n",
      "    Grad: tensor([-0.3562,  2.0165])\n",
      "Epoch 236, Loss 15.0\n",
      "    Params: tensor([ 3.2779, -5.4746])\n",
      "    Grad: tensor([-0.3556,  2.0131])\n",
      "Epoch 237, Loss 15.0\n",
      "    Params: tensor([ 3.2814, -5.4947])\n",
      "    Grad: tensor([-0.3550,  2.0097])\n",
      "Epoch 238, Loss 15.0\n",
      "    Params: tensor([ 3.2850, -5.5148])\n",
      "    Grad: tensor([-0.3544,  2.0062])\n",
      "Epoch 239, Loss 15.0\n",
      "    Params: tensor([ 3.2885, -5.5348])\n",
      "    Grad: tensor([-0.3538,  2.0028])\n",
      "Epoch 240, Loss 15.0\n",
      "    Params: tensor([ 3.2921, -5.5548])\n",
      "    Grad: tensor([-0.3532,  1.9994])\n",
      "Epoch 241, Loss 15.0\n",
      "    Params: tensor([ 3.2956, -5.5748])\n",
      "    Grad: tensor([-0.3526,  1.9960])\n",
      "Epoch 242, Loss 15.0\n",
      "    Params: tensor([ 3.2991, -5.5947])\n",
      "    Grad: tensor([-0.3520,  1.9927])\n",
      "Epoch 243, Loss 15.0\n",
      "    Params: tensor([ 3.3026, -5.6146])\n",
      "    Grad: tensor([-0.3514,  1.9893])\n",
      "Epoch 244, Loss 15.0\n",
      "    Params: tensor([ 3.3061, -5.6345])\n",
      "    Grad: tensor([-0.3508,  1.9859])\n",
      "Epoch 245, Loss 15.0\n",
      "    Params: tensor([ 3.3096, -5.6543])\n",
      "    Grad: tensor([-0.3502,  1.9825])\n",
      "Epoch 246, Loss 15.0\n",
      "    Params: tensor([ 3.3131, -5.6741])\n",
      "    Grad: tensor([-0.3496,  1.9791])\n",
      "Epoch 247, Loss 15.0\n",
      "    Params: tensor([ 3.3166, -5.6938])\n",
      "    Grad: tensor([-0.3490,  1.9758])\n",
      "Epoch 248, Loss 15.0\n",
      "    Params: tensor([ 3.3201, -5.7135])\n",
      "    Grad: tensor([-0.3484,  1.9724])\n",
      "Epoch 249, Loss 15.0\n",
      "    Params: tensor([ 3.3236, -5.7332])\n",
      "    Grad: tensor([-0.3478,  1.9691])\n",
      "Epoch 250, Loss 15.0\n",
      "    Params: tensor([ 3.3270, -5.7529])\n",
      "    Grad: tensor([-0.3473,  1.9657])\n",
      "Epoch 251, Loss 15.0\n",
      "    Params: tensor([ 3.3305, -5.7725])\n",
      "    Grad: tensor([-0.3467,  1.9624])\n",
      "Epoch 252, Loss 15.0\n",
      "    Params: tensor([ 3.3340, -5.7921])\n",
      "    Grad: tensor([-0.3461,  1.9591])\n",
      "Epoch 253, Loss 15.0\n",
      "    Params: tensor([ 3.3374, -5.8117])\n",
      "    Grad: tensor([-0.3455,  1.9557])\n",
      "Epoch 254, Loss 14.0\n",
      "    Params: tensor([ 3.3409, -5.8312])\n",
      "    Grad: tensor([-0.3449,  1.9524])\n",
      "Epoch 255, Loss 14.0\n",
      "    Params: tensor([ 3.3443, -5.8507])\n",
      "    Grad: tensor([-0.3443,  1.9491])\n",
      "Epoch 256, Loss 14.0\n",
      "    Params: tensor([ 3.3478, -5.8701])\n",
      "    Grad: tensor([-0.3437,  1.9458])\n",
      "Epoch 257, Loss 14.0\n",
      "    Params: tensor([ 3.3512, -5.8896])\n",
      "    Grad: tensor([-0.3431,  1.9425])\n",
      "Epoch 258, Loss 14.0\n",
      "    Params: tensor([ 3.3546, -5.9090])\n",
      "    Grad: tensor([-0.3425,  1.9392])\n",
      "Epoch 259, Loss 14.0\n",
      "    Params: tensor([ 3.3580, -5.9283])\n",
      "    Grad: tensor([-0.3420,  1.9359])\n",
      "Epoch 260, Loss 14.0\n",
      "    Params: tensor([ 3.3614, -5.9476])\n",
      "    Grad: tensor([-0.3414,  1.9326])\n",
      "Epoch 261, Loss 14.0\n",
      "    Params: tensor([ 3.3649, -5.9669])\n",
      "    Grad: tensor([-0.3408,  1.9293])\n",
      "Epoch 262, Loss 14.0\n",
      "    Params: tensor([ 3.3683, -5.9862])\n",
      "    Grad: tensor([-0.3402,  1.9260])\n",
      "Epoch 263, Loss 14.0\n",
      "    Params: tensor([ 3.3717, -6.0054])\n",
      "    Grad: tensor([-0.3397,  1.9228])\n",
      "Epoch 264, Loss 14.0\n",
      "    Params: tensor([ 3.3750, -6.0246])\n",
      "    Grad: tensor([-0.3391,  1.9195])\n",
      "Epoch 265, Loss 14.0\n",
      "    Params: tensor([ 3.3784, -6.0438])\n",
      "    Grad: tensor([-0.3385,  1.9162])\n",
      "Epoch 266, Loss 14.0\n",
      "    Params: tensor([ 3.3818, -6.0629])\n",
      "    Grad: tensor([-0.3379,  1.9130])\n",
      "Epoch 267, Loss 14.0\n",
      "    Params: tensor([ 3.3852, -6.0820])\n",
      "    Grad: tensor([-0.3374,  1.9097])\n",
      "Epoch 268, Loss 14.0\n",
      "    Params: tensor([ 3.3886, -6.1011])\n",
      "    Grad: tensor([-0.3368,  1.9065])\n",
      "Epoch 269, Loss 14.0\n",
      "    Params: tensor([ 3.3919, -6.1201])\n",
      "    Grad: tensor([-0.3362,  1.9032])\n",
      "Epoch 270, Loss 14.0\n",
      "    Params: tensor([ 3.3953, -6.1391])\n",
      "    Grad: tensor([-0.3356,  1.9000])\n",
      "Epoch 271, Loss 14.0\n",
      "    Params: tensor([ 3.3986, -6.1581])\n",
      "    Grad: tensor([-0.3351,  1.8968])\n",
      "Epoch 272, Loss 14.0\n",
      "    Params: tensor([ 3.4020, -6.1770])\n",
      "    Grad: tensor([-0.3345,  1.8936])\n",
      "Epoch 273, Loss 14.0\n",
      "    Params: tensor([ 3.4053, -6.1959])\n",
      "    Grad: tensor([-0.3339,  1.8903])\n",
      "Epoch 274, Loss 14.0\n",
      "    Params: tensor([ 3.4086, -6.2148])\n",
      "    Grad: tensor([-0.3334,  1.8871])\n",
      "Epoch 275, Loss 14.0\n",
      "    Params: tensor([ 3.4120, -6.2336])\n",
      "    Grad: tensor([-0.3328,  1.8839])\n",
      "Epoch 276, Loss 14.0\n",
      "    Params: tensor([ 3.4153, -6.2524])\n",
      "    Grad: tensor([-0.3322,  1.8807])\n",
      "Epoch 277, Loss 14.0\n",
      "    Params: tensor([ 3.4186, -6.2712])\n",
      "    Grad: tensor([-0.3317,  1.8775])\n",
      "Epoch 278, Loss 14.0\n",
      "    Params: tensor([ 3.4219, -6.2899])\n",
      "    Grad: tensor([-0.3311,  1.8743])\n",
      "Epoch 279, Loss 14.0\n",
      "    Params: tensor([ 3.4252, -6.3087])\n",
      "    Grad: tensor([-0.3306,  1.8712])\n",
      "Epoch 280, Loss 14.0\n",
      "    Params: tensor([ 3.4285, -6.3273])\n",
      "    Grad: tensor([-0.3300,  1.8680])\n",
      "Epoch 281, Loss 13.0\n",
      "    Params: tensor([ 3.4318, -6.3460])\n",
      "    Grad: tensor([-0.3294,  1.8648])\n",
      "Epoch 282, Loss 13.0\n",
      "    Params: tensor([ 3.4351, -6.3646])\n",
      "    Grad: tensor([-0.3289,  1.8616])\n",
      "Epoch 283, Loss 13.0\n",
      "    Params: tensor([ 3.4384, -6.3832])\n",
      "    Grad: tensor([-0.3283,  1.8585])\n",
      "Epoch 284, Loss 13.0\n",
      "    Params: tensor([ 3.4417, -6.4017])\n",
      "    Grad: tensor([-0.3278,  1.8553])\n",
      "Epoch 285, Loss 13.0\n",
      "    Params: tensor([ 3.4449, -6.4203])\n",
      "    Grad: tensor([-0.3272,  1.8522])\n",
      "Epoch 286, Loss 13.0\n",
      "    Params: tensor([ 3.4482, -6.4388])\n",
      "    Grad: tensor([-0.3266,  1.8490])\n",
      "Epoch 287, Loss 13.0\n",
      "    Params: tensor([ 3.4515, -6.4572])\n",
      "    Grad: tensor([-0.3261,  1.8459])\n",
      "Epoch 288, Loss 13.0\n",
      "    Params: tensor([ 3.4547, -6.4756])\n",
      "    Grad: tensor([-0.3255,  1.8427])\n",
      "Epoch 289, Loss 13.0\n",
      "    Params: tensor([ 3.4580, -6.4940])\n",
      "    Grad: tensor([-0.3250,  1.8396])\n",
      "Epoch 290, Loss 13.0\n",
      "    Params: tensor([ 3.4612, -6.5124])\n",
      "    Grad: tensor([-0.3244,  1.8365])\n",
      "Epoch 291, Loss 13.0\n",
      "    Params: tensor([ 3.4645, -6.5307])\n",
      "    Grad: tensor([-0.3239,  1.8334])\n",
      "Epoch 292, Loss 13.0\n",
      "    Params: tensor([ 3.4677, -6.5490])\n",
      "    Grad: tensor([-0.3233,  1.8303])\n",
      "Epoch 293, Loss 13.0\n",
      "    Params: tensor([ 3.4709, -6.5673])\n",
      "    Grad: tensor([-0.3228,  1.8271])\n",
      "Epoch 294, Loss 13.0\n",
      "    Params: tensor([ 3.4741, -6.5855])\n",
      "    Grad: tensor([-0.3222,  1.8240])\n",
      "Epoch 295, Loss 13.0\n",
      "    Params: tensor([ 3.4774, -6.6038])\n",
      "    Grad: tensor([-0.3217,  1.8209])\n",
      "Epoch 296, Loss 13.0\n",
      "    Params: tensor([ 3.4806, -6.6219])\n",
      "    Grad: tensor([-0.3211,  1.8178])\n",
      "Epoch 297, Loss 13.0\n",
      "    Params: tensor([ 3.4838, -6.6401])\n",
      "    Grad: tensor([-0.3206,  1.8148])\n",
      "Epoch 298, Loss 13.0\n",
      "    Params: tensor([ 3.4870, -6.6582])\n",
      "    Grad: tensor([-0.3200,  1.8117])\n",
      "Epoch 299, Loss 13.0\n",
      "    Params: tensor([ 3.4902, -6.6763])\n",
      "    Grad: tensor([-0.3195,  1.8086])\n",
      "Epoch 300, Loss 13.0\n",
      "    Params: tensor([ 3.4934, -6.6943])\n",
      "    Grad: tensor([-0.3190,  1.8055])\n",
      "Epoch 301, Loss 13.0\n",
      "    Params: tensor([ 3.4965, -6.7124])\n",
      "    Grad: tensor([-0.3184,  1.8025])\n",
      "Epoch 302, Loss 13.0\n",
      "    Params: tensor([ 3.4997, -6.7304])\n",
      "    Grad: tensor([-0.3179,  1.7994])\n",
      "Epoch 303, Loss 13.0\n",
      "    Params: tensor([ 3.5029, -6.7483])\n",
      "    Grad: tensor([-0.3173,  1.7963])\n",
      "Epoch 304, Loss 13.0\n",
      "    Params: tensor([ 3.5061, -6.7663])\n",
      "    Grad: tensor([-0.3168,  1.7933])\n",
      "Epoch 305, Loss 13.0\n",
      "    Params: tensor([ 3.5092, -6.7842])\n",
      "    Grad: tensor([-0.3162,  1.7902])\n",
      "Epoch 306, Loss 13.0\n",
      "    Params: tensor([ 3.5124, -6.8020])\n",
      "    Grad: tensor([-0.3157,  1.7872])\n",
      "Epoch 307, Loss 13.0\n",
      "    Params: tensor([ 3.5155, -6.8199])\n",
      "    Grad: tensor([-0.3152,  1.7842])\n",
      "Epoch 308, Loss 13.0\n",
      "    Params: tensor([ 3.5187, -6.8377])\n",
      "    Grad: tensor([-0.3146,  1.7811])\n",
      "Epoch 309, Loss 13.0\n",
      "    Params: tensor([ 3.5218, -6.8555])\n",
      "    Grad: tensor([-0.3141,  1.7781])\n",
      "Epoch 310, Loss 12.0\n",
      "    Params: tensor([ 3.5250, -6.8732])\n",
      "    Grad: tensor([-0.3136,  1.7751])\n",
      "Epoch 311, Loss 12.0\n",
      "    Params: tensor([ 3.5281, -6.8909])\n",
      "    Grad: tensor([-0.3130,  1.7721])\n",
      "Epoch 312, Loss 12.0\n",
      "    Params: tensor([ 3.5312, -6.9086])\n",
      "    Grad: tensor([-0.3125,  1.7691])\n",
      "Epoch 313, Loss 12.0\n",
      "    Params: tensor([ 3.5343, -6.9263])\n",
      "    Grad: tensor([-0.3120,  1.7661])\n",
      "Epoch 314, Loss 12.0\n",
      "    Params: tensor([ 3.5374, -6.9439])\n",
      "    Grad: tensor([-0.3115,  1.7631])\n",
      "Epoch 315, Loss 12.0\n",
      "    Params: tensor([ 3.5406, -6.9615])\n",
      "    Grad: tensor([-0.3109,  1.7601])\n",
      "Epoch 316, Loss 12.0\n",
      "    Params: tensor([ 3.5437, -6.9791])\n",
      "    Grad: tensor([-0.3104,  1.7571])\n",
      "Epoch 317, Loss 12.0\n",
      "    Params: tensor([ 3.5468, -6.9966])\n",
      "    Grad: tensor([-0.3099,  1.7541])\n",
      "Epoch 318, Loss 12.0\n",
      "    Params: tensor([ 3.5498, -7.0141])\n",
      "    Grad: tensor([-0.3093,  1.7511])\n",
      "Epoch 319, Loss 12.0\n",
      "    Params: tensor([ 3.5529, -7.0316])\n",
      "    Grad: tensor([-0.3088,  1.7481])\n",
      "Epoch 320, Loss 12.0\n",
      "    Params: tensor([ 3.5560, -7.0491])\n",
      "    Grad: tensor([-0.3083,  1.7452])\n",
      "Epoch 321, Loss 12.0\n",
      "    Params: tensor([ 3.5591, -7.0665])\n",
      "    Grad: tensor([-0.3078,  1.7422])\n",
      "Epoch 322, Loss 12.0\n",
      "    Params: tensor([ 3.5622, -7.0839])\n",
      "    Grad: tensor([-0.3073,  1.7392])\n",
      "Epoch 323, Loss 12.0\n",
      "    Params: tensor([ 3.5652, -7.1013])\n",
      "    Grad: tensor([-0.3067,  1.7363])\n",
      "Epoch 324, Loss 12.0\n",
      "    Params: tensor([ 3.5683, -7.1186])\n",
      "    Grad: tensor([-0.3062,  1.7333])\n",
      "Epoch 325, Loss 12.0\n",
      "    Params: tensor([ 3.5714, -7.1359])\n",
      "    Grad: tensor([-0.3057,  1.7304])\n",
      "Epoch 326, Loss 12.0\n",
      "    Params: tensor([ 3.5744, -7.1532])\n",
      "    Grad: tensor([-0.3052,  1.7275])\n",
      "Epoch 327, Loss 12.0\n",
      "    Params: tensor([ 3.5775, -7.1704])\n",
      "    Grad: tensor([-0.3046,  1.7245])\n",
      "Epoch 328, Loss 12.0\n",
      "    Params: tensor([ 3.5805, -7.1876])\n",
      "    Grad: tensor([-0.3041,  1.7216])\n",
      "Epoch 329, Loss 12.0\n",
      "    Params: tensor([ 3.5835, -7.2048])\n",
      "    Grad: tensor([-0.3036,  1.7187])\n",
      "Epoch 330, Loss 12.0\n",
      "    Params: tensor([ 3.5866, -7.2220])\n",
      "    Grad: tensor([-0.3031,  1.7157])\n",
      "Epoch 331, Loss 12.0\n",
      "    Params: tensor([ 3.5896, -7.2391])\n",
      "    Grad: tensor([-0.3026,  1.7128])\n",
      "Epoch 332, Loss 12.0\n",
      "    Params: tensor([ 3.5926, -7.2562])\n",
      "    Grad: tensor([-0.3021,  1.7099])\n",
      "Epoch 333, Loss 12.0\n",
      "    Params: tensor([ 3.5956, -7.2733])\n",
      "    Grad: tensor([-0.3015,  1.7070])\n",
      "Epoch 334, Loss 12.0\n",
      "    Params: tensor([ 3.5986, -7.2903])\n",
      "    Grad: tensor([-0.3010,  1.7041])\n",
      "Epoch 335, Loss 12.0\n",
      "    Params: tensor([ 3.6016, -7.3073])\n",
      "    Grad: tensor([-0.3005,  1.7012])\n",
      "Epoch 336, Loss 12.0\n",
      "    Params: tensor([ 3.6046, -7.3243])\n",
      "    Grad: tensor([-0.3000,  1.6983])\n",
      "Epoch 337, Loss 12.0\n",
      "    Params: tensor([ 3.6076, -7.3413])\n",
      "    Grad: tensor([-0.2995,  1.6954])\n",
      "Epoch 338, Loss 12.0\n",
      "    Params: tensor([ 3.6106, -7.3582])\n",
      "    Grad: tensor([-0.2990,  1.6926])\n",
      "Epoch 339, Loss 12.0\n",
      "    Params: tensor([ 3.6136, -7.3751])\n",
      "    Grad: tensor([-0.2985,  1.6897])\n",
      "Epoch 340, Loss 12.0\n",
      "    Params: tensor([ 3.6166, -7.3920])\n",
      "    Grad: tensor([-0.2980,  1.6868])\n",
      "Epoch 341, Loss 12.0\n",
      "    Params: tensor([ 3.6196, -7.4088])\n",
      "    Grad: tensor([-0.2975,  1.6840])\n",
      "Epoch 342, Loss 12.0\n",
      "    Params: tensor([ 3.6225, -7.4256])\n",
      "    Grad: tensor([-0.2970,  1.6811])\n",
      "Epoch 343, Loss 11.0\n",
      "    Params: tensor([ 3.6255, -7.4424])\n",
      "    Grad: tensor([-0.2965,  1.6782])\n",
      "Epoch 344, Loss 11.0\n",
      "    Params: tensor([ 3.6285, -7.4591])\n",
      "    Grad: tensor([-0.2960,  1.6754])\n",
      "Epoch 345, Loss 11.0\n",
      "    Params: tensor([ 3.6314, -7.4759])\n",
      "    Grad: tensor([-0.2955,  1.6725])\n",
      "Epoch 346, Loss 11.0\n",
      "    Params: tensor([ 3.6344, -7.4926])\n",
      "    Grad: tensor([-0.2950,  1.6697])\n",
      "Epoch 347, Loss 11.0\n",
      "    Params: tensor([ 3.6373, -7.5092])\n",
      "    Grad: tensor([-0.2945,  1.6669])\n",
      "Epoch 348, Loss 11.0\n",
      "    Params: tensor([ 3.6402, -7.5259])\n",
      "    Grad: tensor([-0.2940,  1.6640])\n",
      "Epoch 349, Loss 11.0\n",
      "    Params: tensor([ 3.6432, -7.5425])\n",
      "    Grad: tensor([-0.2935,  1.6612])\n",
      "Epoch 350, Loss 11.0\n",
      "    Params: tensor([ 3.6461, -7.5591])\n",
      "    Grad: tensor([-0.2930,  1.6584])\n",
      "Epoch 351, Loss 11.0\n",
      "    Params: tensor([ 3.6490, -7.5756])\n",
      "    Grad: tensor([-0.2925,  1.6556])\n",
      "Epoch 352, Loss 11.0\n",
      "    Params: tensor([ 3.6520, -7.5921])\n",
      "    Grad: tensor([-0.2920,  1.6528])\n",
      "Epoch 353, Loss 11.0\n",
      "    Params: tensor([ 3.6549, -7.6086])\n",
      "    Grad: tensor([-0.2915,  1.6499])\n",
      "Epoch 354, Loss 11.0\n",
      "    Params: tensor([ 3.6578, -7.6251])\n",
      "    Grad: tensor([-0.2910,  1.6471])\n",
      "Epoch 355, Loss 11.0\n",
      "    Params: tensor([ 3.6607, -7.6416])\n",
      "    Grad: tensor([-0.2905,  1.6443])\n",
      "Epoch 356, Loss 11.0\n",
      "    Params: tensor([ 3.6636, -7.6580])\n",
      "    Grad: tensor([-0.2900,  1.6416])\n",
      "Epoch 357, Loss 11.0\n",
      "    Params: tensor([ 3.6665, -7.6744])\n",
      "    Grad: tensor([-0.2895,  1.6388])\n",
      "Epoch 358, Loss 11.0\n",
      "    Params: tensor([ 3.6694, -7.6907])\n",
      "    Grad: tensor([-0.2890,  1.6360])\n",
      "Epoch 359, Loss 11.0\n",
      "    Params: tensor([ 3.6723, -7.7071])\n",
      "    Grad: tensor([-0.2885,  1.6332])\n",
      "Epoch 360, Loss 11.0\n",
      "    Params: tensor([ 3.6751, -7.7234])\n",
      "    Grad: tensor([-0.2880,  1.6304])\n",
      "Epoch 361, Loss 11.0\n",
      "    Params: tensor([ 3.6780, -7.7396])\n",
      "    Grad: tensor([-0.2875,  1.6277])\n",
      "Epoch 362, Loss 11.0\n",
      "    Params: tensor([ 3.6809, -7.7559])\n",
      "    Grad: tensor([-0.2870,  1.6249])\n",
      "Epoch 363, Loss 11.0\n",
      "    Params: tensor([ 3.6837, -7.7721])\n",
      "    Grad: tensor([-0.2866,  1.6221])\n",
      "Epoch 364, Loss 11.0\n",
      "    Params: tensor([ 3.6866, -7.7883])\n",
      "    Grad: tensor([-0.2861,  1.6194])\n",
      "Epoch 365, Loss 11.0\n",
      "    Params: tensor([ 3.6895, -7.8045])\n",
      "    Grad: tensor([-0.2856,  1.6166])\n",
      "Epoch 366, Loss 11.0\n",
      "    Params: tensor([ 3.6923, -7.8206])\n",
      "    Grad: tensor([-0.2851,  1.6139])\n",
      "Epoch 367, Loss 11.0\n",
      "    Params: tensor([ 3.6952, -7.8367])\n",
      "    Grad: tensor([-0.2846,  1.6111])\n",
      "Epoch 368, Loss 11.0\n",
      "    Params: tensor([ 3.6980, -7.8528])\n",
      "    Grad: tensor([-0.2841,  1.6084])\n",
      "Epoch 369, Loss 11.0\n",
      "    Params: tensor([ 3.7008, -7.8689])\n",
      "    Grad: tensor([-0.2837,  1.6057])\n",
      "Epoch 370, Loss 11.0\n",
      "    Params: tensor([ 3.7037, -7.8849])\n",
      "    Grad: tensor([-0.2832,  1.6029])\n",
      "Epoch 371, Loss 11.0\n",
      "    Params: tensor([ 3.7065, -7.9009])\n",
      "    Grad: tensor([-0.2827,  1.6002])\n",
      "Epoch 372, Loss 11.0\n",
      "    Params: tensor([ 3.7093, -7.9169])\n",
      "    Grad: tensor([-0.2822,  1.5975])\n",
      "Epoch 373, Loss 11.0\n",
      "    Params: tensor([ 3.7121, -7.9328])\n",
      "    Grad: tensor([-0.2817,  1.5948])\n",
      "Epoch 374, Loss 11.0\n",
      "    Params: tensor([ 3.7149, -7.9487])\n",
      "    Grad: tensor([-0.2812,  1.5921])\n",
      "Epoch 375, Loss 11.0\n",
      "    Params: tensor([ 3.7178, -7.9646])\n",
      "    Grad: tensor([-0.2808,  1.5894])\n",
      "Epoch 376, Loss 11.0\n",
      "    Params: tensor([ 3.7206, -7.9805])\n",
      "    Grad: tensor([-0.2803,  1.5867])\n",
      "Epoch 377, Loss 11.0\n",
      "    Params: tensor([ 3.7234, -7.9963])\n",
      "    Grad: tensor([-0.2798,  1.5840])\n",
      "Epoch 378, Loss 11.0\n",
      "    Params: tensor([ 3.7261, -8.0121])\n",
      "    Grad: tensor([-0.2793,  1.5813])\n",
      "Epoch 379, Loss 10.0\n",
      "    Params: tensor([ 3.7289, -8.0279])\n",
      "    Grad: tensor([-0.2789,  1.5786])\n",
      "Epoch 380, Loss 10.0\n",
      "    Params: tensor([ 3.7317, -8.0437])\n",
      "    Grad: tensor([-0.2784,  1.5759])\n",
      "Epoch 381, Loss 10.0\n",
      "    Params: tensor([ 3.7345, -8.0594])\n",
      "    Grad: tensor([-0.2779,  1.5732])\n",
      "Epoch 382, Loss 10.0\n",
      "    Params: tensor([ 3.7373, -8.0751])\n",
      "    Grad: tensor([-0.2775,  1.5706])\n",
      "Epoch 383, Loss 10.0\n",
      "    Params: tensor([ 3.7400, -8.0908])\n",
      "    Grad: tensor([-0.2770,  1.5679])\n",
      "Epoch 384, Loss 10.0\n",
      "    Params: tensor([ 3.7428, -8.1065])\n",
      "    Grad: tensor([-0.2765,  1.5652])\n",
      "Epoch 385, Loss 10.0\n",
      "    Params: tensor([ 3.7456, -8.1221])\n",
      "    Grad: tensor([-0.2760,  1.5626])\n",
      "Epoch 386, Loss 10.0\n",
      "    Params: tensor([ 3.7483, -8.1377])\n",
      "    Grad: tensor([-0.2756,  1.5599])\n",
      "Epoch 387, Loss 10.0\n",
      "    Params: tensor([ 3.7511, -8.1533])\n",
      "    Grad: tensor([-0.2751,  1.5573])\n",
      "Epoch 388, Loss 10.0\n",
      "    Params: tensor([ 3.7538, -8.1688])\n",
      "    Grad: tensor([-0.2746,  1.5546])\n",
      "Epoch 389, Loss 10.0\n",
      "    Params: tensor([ 3.7566, -8.1843])\n",
      "    Grad: tensor([-0.2742,  1.5520])\n",
      "Epoch 390, Loss 10.0\n",
      "    Params: tensor([ 3.7593, -8.1998])\n",
      "    Grad: tensor([-0.2737,  1.5493])\n",
      "Epoch 391, Loss 10.0\n",
      "    Params: tensor([ 3.7620, -8.2153])\n",
      "    Grad: tensor([-0.2732,  1.5467])\n",
      "Epoch 392, Loss 10.0\n",
      "    Params: tensor([ 3.7648, -8.2307])\n",
      "    Grad: tensor([-0.2728,  1.5441])\n",
      "Epoch 393, Loss 10.0\n",
      "    Params: tensor([ 3.7675, -8.2461])\n",
      "    Grad: tensor([-0.2723,  1.5415])\n",
      "Epoch 394, Loss 10.0\n",
      "    Params: tensor([ 3.7702, -8.2615])\n",
      "    Grad: tensor([-0.2718,  1.5388])\n",
      "Epoch 395, Loss 10.0\n",
      "    Params: tensor([ 3.7729, -8.2769])\n",
      "    Grad: tensor([-0.2714,  1.5362])\n",
      "Epoch 396, Loss 10.0\n",
      "    Params: tensor([ 3.7756, -8.2922])\n",
      "    Grad: tensor([-0.2709,  1.5336])\n",
      "Epoch 397, Loss 10.0\n",
      "    Params: tensor([ 3.7783, -8.3075])\n",
      "    Grad: tensor([-0.2705,  1.5310])\n",
      "Epoch 398, Loss 10.0\n",
      "    Params: tensor([ 3.7810, -8.3228])\n",
      "    Grad: tensor([-0.2700,  1.5284])\n",
      "Epoch 399, Loss 10.0\n",
      "    Params: tensor([ 3.7837, -8.3381])\n",
      "    Grad: tensor([-0.2695,  1.5258])\n",
      "Epoch 400, Loss 10.0\n",
      "    Params: tensor([ 3.7864, -8.3533])\n",
      "    Grad: tensor([-0.2691,  1.5232])\n",
      "Epoch 401, Loss 10.0\n",
      "    Params: tensor([ 3.7891, -8.3685])\n",
      "    Grad: tensor([-0.2686,  1.5206])\n",
      "Epoch 402, Loss 10.0\n",
      "    Params: tensor([ 3.7918, -8.3837])\n",
      "    Grad: tensor([-0.2682,  1.5181])\n",
      "Epoch 403, Loss 10.0\n",
      "    Params: tensor([ 3.7945, -8.3989])\n",
      "    Grad: tensor([-0.2677,  1.5155])\n",
      "Epoch 404, Loss 10.0\n",
      "    Params: tensor([ 3.7971, -8.4140])\n",
      "    Grad: tensor([-0.2673,  1.5129])\n",
      "Epoch 405, Loss 10.0\n",
      "    Params: tensor([ 3.7998, -8.4291])\n",
      "    Grad: tensor([-0.2668,  1.5103])\n",
      "Epoch 406, Loss 10.0\n",
      "    Params: tensor([ 3.8025, -8.4442])\n",
      "    Grad: tensor([-0.2664,  1.5078])\n",
      "Epoch 407, Loss 10.0\n",
      "    Params: tensor([ 3.8051, -8.4592])\n",
      "    Grad: tensor([-0.2659,  1.5052])\n",
      "Epoch 408, Loss 10.0\n",
      "    Params: tensor([ 3.8078, -8.4742])\n",
      "    Grad: tensor([-0.2655,  1.5027])\n",
      "Epoch 409, Loss 10.0\n",
      "    Params: tensor([ 3.8104, -8.4892])\n",
      "    Grad: tensor([-0.2650,  1.5001])\n",
      "Epoch 410, Loss 10.0\n",
      "    Params: tensor([ 3.8131, -8.5042])\n",
      "    Grad: tensor([-0.2646,  1.4975])\n",
      "Epoch 411, Loss 10.0\n",
      "    Params: tensor([ 3.8157, -8.5192])\n",
      "    Grad: tensor([-0.2641,  1.4950])\n",
      "Epoch 412, Loss 10.0\n",
      "    Params: tensor([ 3.8184, -8.5341])\n",
      "    Grad: tensor([-0.2637,  1.4925])\n",
      "Epoch 413, Loss 10.0\n",
      "    Params: tensor([ 3.8210, -8.5490])\n",
      "    Grad: tensor([-0.2632,  1.4899])\n",
      "Epoch 414, Loss 10.0\n",
      "    Params: tensor([ 3.8236, -8.5639])\n",
      "    Grad: tensor([-0.2628,  1.4874])\n",
      "Epoch 415, Loss 10.0\n",
      "    Params: tensor([ 3.8262, -8.5787])\n",
      "    Grad: tensor([-0.2623,  1.4849])\n",
      "Epoch 416, Loss 10.0\n",
      "    Params: tensor([ 3.8289, -8.5935])\n",
      "    Grad: tensor([-0.2619,  1.4824])\n",
      "Epoch 417, Loss 10.0\n",
      "    Params: tensor([ 3.8315, -8.6083])\n",
      "    Grad: tensor([-0.2614,  1.4798])\n",
      "Epoch 418, Loss 10.0\n",
      "    Params: tensor([ 3.8341, -8.6231])\n",
      "    Grad: tensor([-0.2610,  1.4773])\n",
      "Epoch 419, Loss 10.0\n",
      "    Params: tensor([ 3.8367, -8.6379])\n",
      "    Grad: tensor([-0.2605,  1.4748])\n",
      "Epoch 420, Loss 10.0\n",
      "    Params: tensor([ 3.8393, -8.6526])\n",
      "    Grad: tensor([-0.2601,  1.4723])\n",
      "Epoch 421, Loss 9.0\n",
      "    Params: tensor([ 3.8419, -8.6673])\n",
      "    Grad: tensor([-0.2596,  1.4698])\n",
      "Epoch 422, Loss 9.0\n",
      "    Params: tensor([ 3.8445, -8.6820])\n",
      "    Grad: tensor([-0.2592,  1.4673])\n",
      "Epoch 423, Loss 9.0\n",
      "    Params: tensor([ 3.8471, -8.6966])\n",
      "    Grad: tensor([-0.2588,  1.4648])\n",
      "Epoch 424, Loss 9.0\n",
      "    Params: tensor([ 3.8496, -8.7112])\n",
      "    Grad: tensor([-0.2583,  1.4623])\n",
      "Epoch 425, Loss 9.0\n",
      "    Params: tensor([ 3.8522, -8.7258])\n",
      "    Grad: tensor([-0.2579,  1.4598])\n",
      "Epoch 426, Loss 9.0\n",
      "    Params: tensor([ 3.8548, -8.7404])\n",
      "    Grad: tensor([-0.2575,  1.4574])\n",
      "Epoch 427, Loss 9.0\n",
      "    Params: tensor([ 3.8574, -8.7550])\n",
      "    Grad: tensor([-0.2570,  1.4549])\n",
      "Epoch 428, Loss 9.0\n",
      "    Params: tensor([ 3.8599, -8.7695])\n",
      "    Grad: tensor([-0.2566,  1.4524])\n",
      "Epoch 429, Loss 9.0\n",
      "    Params: tensor([ 3.8625, -8.7840])\n",
      "    Grad: tensor([-0.2561,  1.4499])\n",
      "Epoch 430, Loss 9.0\n",
      "    Params: tensor([ 3.8651, -8.7984])\n",
      "    Grad: tensor([-0.2557,  1.4475])\n",
      "Epoch 431, Loss 9.0\n",
      "    Params: tensor([ 3.8676, -8.8129])\n",
      "    Grad: tensor([-0.2553,  1.4450])\n",
      "Epoch 432, Loss 9.0\n",
      "    Params: tensor([ 3.8702, -8.8273])\n",
      "    Grad: tensor([-0.2548,  1.4426])\n",
      "Epoch 433, Loss 9.0\n",
      "    Params: tensor([ 3.8727, -8.8417])\n",
      "    Grad: tensor([-0.2544,  1.4401])\n",
      "Epoch 434, Loss 9.0\n",
      "    Params: tensor([ 3.8752, -8.8561])\n",
      "    Grad: tensor([-0.2540,  1.4377])\n",
      "Epoch 435, Loss 9.0\n",
      "    Params: tensor([ 3.8778, -8.8705])\n",
      "    Grad: tensor([-0.2535,  1.4352])\n",
      "Epoch 436, Loss 9.0\n",
      "    Params: tensor([ 3.8803, -8.8848])\n",
      "    Grad: tensor([-0.2531,  1.4328])\n",
      "Epoch 437, Loss 9.0\n",
      "    Params: tensor([ 3.8828, -8.8991])\n",
      "    Grad: tensor([-0.2527,  1.4304])\n",
      "Epoch 438, Loss 9.0\n",
      "    Params: tensor([ 3.8854, -8.9134])\n",
      "    Grad: tensor([-0.2523,  1.4279])\n",
      "Epoch 439, Loss 9.0\n",
      "    Params: tensor([ 3.8879, -8.9276])\n",
      "    Grad: tensor([-0.2518,  1.4255])\n",
      "Epoch 440, Loss 9.0\n",
      "    Params: tensor([ 3.8904, -8.9419])\n",
      "    Grad: tensor([-0.2514,  1.4231])\n",
      "Epoch 441, Loss 9.0\n",
      "    Params: tensor([ 3.8929, -8.9561])\n",
      "    Grad: tensor([-0.2510,  1.4207])\n",
      "Epoch 442, Loss 9.0\n",
      "    Params: tensor([ 3.8954, -8.9702])\n",
      "    Grad: tensor([-0.2505,  1.4182])\n",
      "Epoch 443, Loss 9.0\n",
      "    Params: tensor([ 3.8979, -8.9844])\n",
      "    Grad: tensor([-0.2501,  1.4158])\n",
      "Epoch 444, Loss 9.0\n",
      "    Params: tensor([ 3.9004, -8.9985])\n",
      "    Grad: tensor([-0.2497,  1.4134])\n",
      "Epoch 445, Loss 9.0\n",
      "    Params: tensor([ 3.9029, -9.0126])\n",
      "    Grad: tensor([-0.2493,  1.4110])\n",
      "Epoch 446, Loss 9.0\n",
      "    Params: tensor([ 3.9054, -9.0267])\n",
      "    Grad: tensor([-0.2488,  1.4086])\n",
      "Epoch 447, Loss 9.0\n",
      "    Params: tensor([ 3.9079, -9.0408])\n",
      "    Grad: tensor([-0.2484,  1.4062])\n",
      "Epoch 448, Loss 9.0\n",
      "    Params: tensor([ 3.9103, -9.0548])\n",
      "    Grad: tensor([-0.2480,  1.4039])\n",
      "Epoch 449, Loss 9.0\n",
      "    Params: tensor([ 3.9128, -9.0688])\n",
      "    Grad: tensor([-0.2476,  1.4015])\n",
      "Epoch 450, Loss 9.0\n",
      "    Params: tensor([ 3.9153, -9.0828])\n",
      "    Grad: tensor([-0.2471,  1.3991])\n",
      "Epoch 451, Loss 9.0\n",
      "    Params: tensor([ 3.9178, -9.0968])\n",
      "    Grad: tensor([-0.2467,  1.3967])\n",
      "Epoch 452, Loss 9.0\n",
      "    Params: tensor([ 3.9202, -9.1107])\n",
      "    Grad: tensor([-0.2463,  1.3943])\n",
      "Epoch 453, Loss 9.0\n",
      "    Params: tensor([ 3.9227, -9.1247])\n",
      "    Grad: tensor([-0.2459,  1.3920])\n",
      "Epoch 454, Loss 9.0\n",
      "    Params: tensor([ 3.9251, -9.1386])\n",
      "    Grad: tensor([-0.2455,  1.3896])\n",
      "Epoch 455, Loss 9.0\n",
      "    Params: tensor([ 3.9276, -9.1524])\n",
      "    Grad: tensor([-0.2451,  1.3872])\n",
      "Epoch 456, Loss 9.0\n",
      "    Params: tensor([ 3.9300, -9.1663])\n",
      "    Grad: tensor([-0.2446,  1.3849])\n",
      "Epoch 457, Loss 9.0\n",
      "    Params: tensor([ 3.9325, -9.1801])\n",
      "    Grad: tensor([-0.2442,  1.3825])\n",
      "Epoch 458, Loss 9.0\n",
      "    Params: tensor([ 3.9349, -9.1939])\n",
      "    Grad: tensor([-0.2438,  1.3802])\n",
      "Epoch 459, Loss 9.0\n",
      "    Params: tensor([ 3.9373, -9.2077])\n",
      "    Grad: tensor([-0.2434,  1.3778])\n",
      "Epoch 460, Loss 9.0\n",
      "    Params: tensor([ 3.9398, -9.2214])\n",
      "    Grad: tensor([-0.2430,  1.3755])\n",
      "Epoch 461, Loss 9.0\n",
      "    Params: tensor([ 3.9422, -9.2352])\n",
      "    Grad: tensor([-0.2426,  1.3732])\n",
      "Epoch 462, Loss 9.0\n",
      "    Params: tensor([ 3.9446, -9.2489])\n",
      "    Grad: tensor([-0.2422,  1.3708])\n",
      "Epoch 463, Loss 9.0\n",
      "    Params: tensor([ 3.9470, -9.2626])\n",
      "    Grad: tensor([-0.2418,  1.3685])\n",
      "Epoch 464, Loss 9.0\n",
      "    Params: tensor([ 3.9495, -9.2762])\n",
      "    Grad: tensor([-0.2413,  1.3662])\n",
      "Epoch 465, Loss 9.0\n",
      "    Params: tensor([ 3.9519, -9.2899])\n",
      "    Grad: tensor([-0.2409,  1.3639])\n",
      "Epoch 466, Loss 9.0\n",
      "    Params: tensor([ 3.9543, -9.3035])\n",
      "    Grad: tensor([-0.2405,  1.3615])\n",
      "Epoch 467, Loss 9.0\n",
      "    Params: tensor([ 3.9567, -9.3171])\n",
      "    Grad: tensor([-0.2401,  1.3592])\n",
      "Epoch 468, Loss 9.0\n",
      "    Params: tensor([ 3.9591, -9.3306])\n",
      "    Grad: tensor([-0.2397,  1.3569])\n",
      "Epoch 469, Loss 8.0\n",
      "    Params: tensor([ 3.9615, -9.3442])\n",
      "    Grad: tensor([-0.2393,  1.3546])\n",
      "Epoch 470, Loss 8.0\n",
      "    Params: tensor([ 3.9638, -9.3577])\n",
      "    Grad: tensor([-0.2389,  1.3523])\n",
      "Epoch 471, Loss 8.0\n",
      "    Params: tensor([ 3.9662, -9.3712])\n",
      "    Grad: tensor([-0.2385,  1.3500])\n",
      "Epoch 472, Loss 8.0\n",
      "    Params: tensor([ 3.9686, -9.3847])\n",
      "    Grad: tensor([-0.2381,  1.3477])\n",
      "Epoch 473, Loss 8.0\n",
      "    Params: tensor([ 3.9710, -9.3981])\n",
      "    Grad: tensor([-0.2377,  1.3454])\n",
      "Epoch 474, Loss 8.0\n",
      "    Params: tensor([ 3.9734, -9.4116])\n",
      "    Grad: tensor([-0.2373,  1.3432])\n",
      "Epoch 475, Loss 8.0\n",
      "    Params: tensor([ 3.9757, -9.4250])\n",
      "    Grad: tensor([-0.2369,  1.3409])\n",
      "Epoch 476, Loss 8.0\n",
      "    Params: tensor([ 3.9781, -9.4384])\n",
      "    Grad: tensor([-0.2365,  1.3386])\n",
      "Epoch 477, Loss 8.0\n",
      "    Params: tensor([ 3.9805, -9.4517])\n",
      "    Grad: tensor([-0.2361,  1.3363])\n",
      "Epoch 478, Loss 8.0\n",
      "    Params: tensor([ 3.9828, -9.4651])\n",
      "    Grad: tensor([-0.2357,  1.3340])\n",
      "Epoch 479, Loss 8.0\n",
      "    Params: tensor([ 3.9852, -9.4784])\n",
      "    Grad: tensor([-0.2353,  1.3318])\n",
      "Epoch 480, Loss 8.0\n",
      "    Params: tensor([ 3.9875, -9.4917])\n",
      "    Grad: tensor([-0.2349,  1.3295])\n",
      "Epoch 481, Loss 8.0\n",
      "    Params: tensor([ 3.9899, -9.5050])\n",
      "    Grad: tensor([-0.2345,  1.3273])\n",
      "Epoch 482, Loss 8.0\n",
      "    Params: tensor([ 3.9922, -9.5182])\n",
      "    Grad: tensor([-0.2341,  1.3250])\n",
      "Epoch 483, Loss 8.0\n",
      "    Params: tensor([ 3.9945, -9.5314])\n",
      "    Grad: tensor([-0.2337,  1.3228])\n",
      "Epoch 484, Loss 8.0\n",
      "    Params: tensor([ 3.9969, -9.5446])\n",
      "    Grad: tensor([-0.2333,  1.3205])\n",
      "Epoch 485, Loss 8.0\n",
      "    Params: tensor([ 3.9992, -9.5578])\n",
      "    Grad: tensor([-0.2329,  1.3183])\n",
      "Epoch 486, Loss 8.0\n",
      "    Params: tensor([ 4.0015, -9.5710])\n",
      "    Grad: tensor([-0.2325,  1.3160])\n",
      "Epoch 487, Loss 8.0\n",
      "    Params: tensor([ 4.0038, -9.5841])\n",
      "    Grad: tensor([-0.2321,  1.3138])\n",
      "Epoch 488, Loss 8.0\n",
      "    Params: tensor([ 4.0062, -9.5972])\n",
      "    Grad: tensor([-0.2317,  1.3116])\n",
      "Epoch 489, Loss 8.0\n",
      "    Params: tensor([ 4.0085, -9.6103])\n",
      "    Grad: tensor([-0.2313,  1.3093])\n",
      "Epoch 490, Loss 8.0\n",
      "    Params: tensor([ 4.0108, -9.6234])\n",
      "    Grad: tensor([-0.2309,  1.3071])\n",
      "Epoch 491, Loss 8.0\n",
      "    Params: tensor([ 4.0131, -9.6365])\n",
      "    Grad: tensor([-0.2305,  1.3049])\n",
      "Epoch 492, Loss 8.0\n",
      "    Params: tensor([ 4.0154, -9.6495])\n",
      "    Grad: tensor([-0.2301,  1.3027])\n",
      "Epoch 493, Loss 8.0\n",
      "    Params: tensor([ 4.0177, -9.6625])\n",
      "    Grad: tensor([-0.2297,  1.3005])\n",
      "Epoch 494, Loss 8.0\n",
      "    Params: tensor([ 4.0200, -9.6755])\n",
      "    Grad: tensor([-0.2293,  1.2982])\n",
      "Epoch 495, Loss 8.0\n",
      "    Params: tensor([ 4.0223, -9.6884])\n",
      "    Grad: tensor([-0.2289,  1.2960])\n",
      "Epoch 496, Loss 8.0\n",
      "    Params: tensor([ 4.0246, -9.7014])\n",
      "    Grad: tensor([-0.2286,  1.2938])\n",
      "Epoch 497, Loss 8.0\n",
      "    Params: tensor([ 4.0268, -9.7143])\n",
      "    Grad: tensor([-0.2282,  1.2916])\n",
      "Epoch 498, Loss 8.0\n",
      "    Params: tensor([ 4.0291, -9.7272])\n",
      "    Grad: tensor([-0.2278,  1.2894])\n",
      "Epoch 499, Loss 8.0\n",
      "    Params: tensor([ 4.0314, -9.7401])\n",
      "    Grad: tensor([-0.2274,  1.2873])\n",
      "Epoch 500, Loss 8.0\n",
      "    Params: tensor([ 4.0337, -9.7529])\n",
      "    Grad: tensor([-0.2270,  1.2851])\n",
      "Epoch 501, Loss 8.0\n",
      "    Params: tensor([ 4.0359, -9.7657])\n",
      "    Grad: tensor([-0.2266,  1.2829])\n",
      "Epoch 502, Loss 8.0\n",
      "    Params: tensor([ 4.0382, -9.7785])\n",
      "    Grad: tensor([-0.2262,  1.2807])\n",
      "Epoch 503, Loss 8.0\n",
      "    Params: tensor([ 4.0404, -9.7913])\n",
      "    Grad: tensor([-0.2258,  1.2785])\n",
      "Epoch 504, Loss 8.0\n",
      "    Params: tensor([ 4.0427, -9.8041])\n",
      "    Grad: tensor([-0.2255,  1.2764])\n",
      "Epoch 505, Loss 8.0\n",
      "    Params: tensor([ 4.0450, -9.8168])\n",
      "    Grad: tensor([-0.2251,  1.2742])\n",
      "Epoch 506, Loss 8.0\n",
      "    Params: tensor([ 4.0472, -9.8295])\n",
      "    Grad: tensor([-0.2247,  1.2720])\n",
      "Epoch 507, Loss 8.0\n",
      "    Params: tensor([ 4.0494, -9.8422])\n",
      "    Grad: tensor([-0.2243,  1.2699])\n",
      "Epoch 508, Loss 8.0\n",
      "    Params: tensor([ 4.0517, -9.8549])\n",
      "    Grad: tensor([-0.2239,  1.2677])\n",
      "Epoch 509, Loss 8.0\n",
      "    Params: tensor([ 4.0539, -9.8676])\n",
      "    Grad: tensor([-0.2236,  1.2656])\n",
      "Epoch 510, Loss 8.0\n",
      "    Params: tensor([ 4.0561, -9.8802])\n",
      "    Grad: tensor([-0.2232,  1.2634])\n",
      "Epoch 511, Loss 8.0\n",
      "    Params: tensor([ 4.0584, -9.8928])\n",
      "    Grad: tensor([-0.2228,  1.2613])\n",
      "Epoch 512, Loss 8.0\n",
      "    Params: tensor([ 4.0606, -9.9054])\n",
      "    Grad: tensor([-0.2224,  1.2591])\n",
      "Epoch 513, Loss 8.0\n",
      "    Params: tensor([ 4.0628, -9.9180])\n",
      "    Grad: tensor([-0.2221,  1.2570])\n",
      "Epoch 514, Loss 8.0\n",
      "    Params: tensor([ 4.0650, -9.9305])\n",
      "    Grad: tensor([-0.2217,  1.2548])\n",
      "Epoch 515, Loss 8.0\n",
      "    Params: tensor([ 4.0672, -9.9431])\n",
      "    Grad: tensor([-0.2213,  1.2527])\n",
      "Epoch 516, Loss 8.0\n",
      "    Params: tensor([ 4.0695, -9.9556])\n",
      "    Grad: tensor([-0.2209,  1.2506])\n",
      "Epoch 517, Loss 8.0\n",
      "    Params: tensor([ 4.0717, -9.9681])\n",
      "    Grad: tensor([-0.2205,  1.2485])\n",
      "Epoch 518, Loss 8.0\n",
      "    Params: tensor([ 4.0739, -9.9805])\n",
      "    Grad: tensor([-0.2202,  1.2463])\n",
      "Epoch 519, Loss 8.0\n",
      "    Params: tensor([ 4.0761, -9.9930])\n",
      "    Grad: tensor([-0.2198,  1.2442])\n",
      "Epoch 520, Loss 8.0\n",
      "    Params: tensor([  4.0783, -10.0054])\n",
      "    Grad: tensor([-0.2194,  1.2421])\n",
      "Epoch 521, Loss 8.0\n",
      "    Params: tensor([  4.0804, -10.0178])\n",
      "    Grad: tensor([-0.2190,  1.2400])\n",
      "Epoch 522, Loss 8.0\n",
      "    Params: tensor([  4.0826, -10.0302])\n",
      "    Grad: tensor([-0.2187,  1.2379])\n",
      "Epoch 523, Loss 8.0\n",
      "    Params: tensor([  4.0848, -10.0425])\n",
      "    Grad: tensor([-0.2183,  1.2358])\n",
      "Epoch 524, Loss 8.0\n",
      "    Params: tensor([  4.0870, -10.0549])\n",
      "    Grad: tensor([-0.2179,  1.2337])\n",
      "Epoch 525, Loss 8.0\n",
      "    Params: tensor([  4.0892, -10.0672])\n",
      "    Grad: tensor([-0.2176,  1.2316])\n",
      "Epoch 526, Loss 8.0\n",
      "    Params: tensor([  4.0913, -10.0795])\n",
      "    Grad: tensor([-0.2172,  1.2295])\n",
      "Epoch 527, Loss 8.0\n",
      "    Params: tensor([  4.0935, -10.0917])\n",
      "    Grad: tensor([-0.2168,  1.2274])\n",
      "Epoch 528, Loss 7.0\n",
      "    Params: tensor([  4.0957, -10.1040])\n",
      "    Grad: tensor([-0.2164,  1.2253])\n",
      "Epoch 529, Loss 7.0\n",
      "    Params: tensor([  4.0978, -10.1162])\n",
      "    Grad: tensor([-0.2161,  1.2232])\n",
      "Epoch 530, Loss 7.0\n",
      "    Params: tensor([  4.1000, -10.1284])\n",
      "    Grad: tensor([-0.2157,  1.2212])\n",
      "Epoch 531, Loss 7.0\n",
      "    Params: tensor([  4.1021, -10.1406])\n",
      "    Grad: tensor([-0.2154,  1.2191])\n",
      "Epoch 532, Loss 7.0\n",
      "    Params: tensor([  4.1043, -10.1528])\n",
      "    Grad: tensor([-0.2150,  1.2170])\n",
      "Epoch 533, Loss 7.0\n",
      "    Params: tensor([  4.1064, -10.1649])\n",
      "    Grad: tensor([-0.2146,  1.2150])\n",
      "Epoch 534, Loss 7.0\n",
      "    Params: tensor([  4.1086, -10.1771])\n",
      "    Grad: tensor([-0.2143,  1.2129])\n",
      "Epoch 535, Loss 7.0\n",
      "    Params: tensor([  4.1107, -10.1892])\n",
      "    Grad: tensor([-0.2139,  1.2108])\n",
      "Epoch 536, Loss 7.0\n",
      "    Params: tensor([  4.1129, -10.2013])\n",
      "    Grad: tensor([-0.2135,  1.2088])\n",
      "Epoch 537, Loss 7.0\n",
      "    Params: tensor([  4.1150, -10.2133])\n",
      "    Grad: tensor([-0.2132,  1.2067])\n",
      "Epoch 538, Loss 7.0\n",
      "    Params: tensor([  4.1171, -10.2254])\n",
      "    Grad: tensor([-0.2128,  1.2047])\n",
      "Epoch 539, Loss 7.0\n",
      "    Params: tensor([  4.1192, -10.2374])\n",
      "    Grad: tensor([-0.2124,  1.2026])\n",
      "Epoch 540, Loss 7.0\n",
      "    Params: tensor([  4.1214, -10.2494])\n",
      "    Grad: tensor([-0.2121,  1.2006])\n",
      "Epoch 541, Loss 7.0\n",
      "    Params: tensor([  4.1235, -10.2614])\n",
      "    Grad: tensor([-0.2117,  1.1985])\n",
      "Epoch 542, Loss 7.0\n",
      "    Params: tensor([  4.1256, -10.2734])\n",
      "    Grad: tensor([-0.2114,  1.1965])\n",
      "Epoch 543, Loss 7.0\n",
      "    Params: tensor([  4.1277, -10.2853])\n",
      "    Grad: tensor([-0.2110,  1.1945])\n",
      "Epoch 544, Loss 7.0\n",
      "    Params: tensor([  4.1298, -10.2972])\n",
      "    Grad: tensor([-0.2106,  1.1924])\n",
      "Epoch 545, Loss 7.0\n",
      "    Params: tensor([  4.1319, -10.3091])\n",
      "    Grad: tensor([-0.2103,  1.1904])\n",
      "Epoch 546, Loss 7.0\n",
      "    Params: tensor([  4.1340, -10.3210])\n",
      "    Grad: tensor([-0.2099,  1.1884])\n",
      "Epoch 547, Loss 7.0\n",
      "    Params: tensor([  4.1361, -10.3329])\n",
      "    Grad: tensor([-0.2096,  1.1864])\n",
      "Epoch 548, Loss 7.0\n",
      "    Params: tensor([  4.1382, -10.3447])\n",
      "    Grad: tensor([-0.2092,  1.1844])\n",
      "Epoch 549, Loss 7.0\n",
      "    Params: tensor([  4.1403, -10.3566])\n",
      "    Grad: tensor([-0.2089,  1.1823])\n",
      "Epoch 550, Loss 7.0\n",
      "    Params: tensor([  4.1424, -10.3684])\n",
      "    Grad: tensor([-0.2085,  1.1803])\n",
      "Epoch 551, Loss 7.0\n",
      "    Params: tensor([  4.1445, -10.3801])\n",
      "    Grad: tensor([-0.2082,  1.1783])\n",
      "Epoch 552, Loss 7.0\n",
      "    Params: tensor([  4.1465, -10.3919])\n",
      "    Grad: tensor([-0.2078,  1.1763])\n",
      "Epoch 553, Loss 7.0\n",
      "    Params: tensor([  4.1486, -10.4036])\n",
      "    Grad: tensor([-0.2075,  1.1743])\n",
      "Epoch 554, Loss 7.0\n",
      "    Params: tensor([  4.1507, -10.4154])\n",
      "    Grad: tensor([-0.2071,  1.1723])\n",
      "Epoch 555, Loss 7.0\n",
      "    Params: tensor([  4.1528, -10.4271])\n",
      "    Grad: tensor([-0.2067,  1.1703])\n",
      "Epoch 556, Loss 7.0\n",
      "    Params: tensor([  4.1548, -10.4388])\n",
      "    Grad: tensor([-0.2064,  1.1684])\n",
      "Epoch 557, Loss 7.0\n",
      "    Params: tensor([  4.1569, -10.4504])\n",
      "    Grad: tensor([-0.2060,  1.1664])\n",
      "Epoch 558, Loss 7.0\n",
      "    Params: tensor([  4.1589, -10.4621])\n",
      "    Grad: tensor([-0.2057,  1.1644])\n",
      "Epoch 559, Loss 7.0\n",
      "    Params: tensor([  4.1610, -10.4737])\n",
      "    Grad: tensor([-0.2053,  1.1624])\n",
      "Epoch 560, Loss 7.0\n",
      "    Params: tensor([  4.1630, -10.4853])\n",
      "    Grad: tensor([-0.2050,  1.1604])\n",
      "Epoch 561, Loss 7.0\n",
      "    Params: tensor([  4.1651, -10.4969])\n",
      "    Grad: tensor([-0.2047,  1.1585])\n",
      "Epoch 562, Loss 7.0\n",
      "    Params: tensor([  4.1671, -10.5084])\n",
      "    Grad: tensor([-0.2043,  1.1565])\n",
      "Epoch 563, Loss 7.0\n",
      "    Params: tensor([  4.1692, -10.5200])\n",
      "    Grad: tensor([-0.2040,  1.1545])\n",
      "Epoch 564, Loss 7.0\n",
      "    Params: tensor([  4.1712, -10.5315])\n",
      "    Grad: tensor([-0.2036,  1.1526])\n",
      "Epoch 565, Loss 7.0\n",
      "    Params: tensor([  4.1732, -10.5430])\n",
      "    Grad: tensor([-0.2033,  1.1506])\n",
      "Epoch 566, Loss 7.0\n",
      "    Params: tensor([  4.1753, -10.5545])\n",
      "    Grad: tensor([-0.2029,  1.1487])\n",
      "Epoch 567, Loss 7.0\n",
      "    Params: tensor([  4.1773, -10.5660])\n",
      "    Grad: tensor([-0.2026,  1.1467])\n",
      "Epoch 568, Loss 7.0\n",
      "    Params: tensor([  4.1793, -10.5774])\n",
      "    Grad: tensor([-0.2022,  1.1448])\n",
      "Epoch 569, Loss 7.0\n",
      "    Params: tensor([  4.1813, -10.5889])\n",
      "    Grad: tensor([-0.2019,  1.1428])\n",
      "Epoch 570, Loss 7.0\n",
      "    Params: tensor([  4.1833, -10.6003])\n",
      "    Grad: tensor([-0.2015,  1.1409])\n",
      "Epoch 571, Loss 7.0\n",
      "    Params: tensor([  4.1854, -10.6117])\n",
      "    Grad: tensor([-0.2012,  1.1389])\n",
      "Epoch 572, Loss 7.0\n",
      "    Params: tensor([  4.1874, -10.6230])\n",
      "    Grad: tensor([-0.2009,  1.1370])\n",
      "Epoch 573, Loss 7.0\n",
      "    Params: tensor([  4.1894, -10.6344])\n",
      "    Grad: tensor([-0.2005,  1.1351])\n",
      "Epoch 574, Loss 7.0\n",
      "    Params: tensor([  4.1914, -10.6457])\n",
      "    Grad: tensor([-0.2002,  1.1331])\n",
      "Epoch 575, Loss 7.0\n",
      "    Params: tensor([  4.1934, -10.6570])\n",
      "    Grad: tensor([-0.1998,  1.1312])\n",
      "Epoch 576, Loss 7.0\n",
      "    Params: tensor([  4.1954, -10.6683])\n",
      "    Grad: tensor([-0.1995,  1.1293])\n",
      "Epoch 577, Loss 7.0\n",
      "    Params: tensor([  4.1974, -10.6796])\n",
      "    Grad: tensor([-0.1991,  1.1274])\n",
      "Epoch 578, Loss 7.0\n",
      "    Params: tensor([  4.1993, -10.6908])\n",
      "    Grad: tensor([-0.1988,  1.1255])\n",
      "Epoch 579, Loss 7.0\n",
      "    Params: tensor([  4.2013, -10.7021])\n",
      "    Grad: tensor([-0.1985,  1.1236])\n",
      "Epoch 580, Loss 7.0\n",
      "    Params: tensor([  4.2033, -10.7133])\n",
      "    Grad: tensor([-0.1981,  1.1216])\n",
      "Epoch 581, Loss 7.0\n",
      "    Params: tensor([  4.2053, -10.7245])\n",
      "    Grad: tensor([-0.1978,  1.1197])\n",
      "Epoch 582, Loss 7.0\n",
      "    Params: tensor([  4.2073, -10.7357])\n",
      "    Grad: tensor([-0.1975,  1.1178])\n",
      "Epoch 583, Loss 7.0\n",
      "    Params: tensor([  4.2092, -10.7468])\n",
      "    Grad: tensor([-0.1971,  1.1159])\n",
      "Epoch 584, Loss 7.0\n",
      "    Params: tensor([  4.2112, -10.7580])\n",
      "    Grad: tensor([-0.1968,  1.1140])\n",
      "Epoch 585, Loss 7.0\n",
      "    Params: tensor([  4.2132, -10.7691])\n",
      "    Grad: tensor([-0.1965,  1.1121])\n",
      "Epoch 586, Loss 7.0\n",
      "    Params: tensor([  4.2151, -10.7802])\n",
      "    Grad: tensor([-0.1961,  1.1103])\n",
      "Epoch 587, Loss 7.0\n",
      "    Params: tensor([  4.2171, -10.7913])\n",
      "    Grad: tensor([-0.1958,  1.1084])\n",
      "Epoch 588, Loss 7.0\n",
      "    Params: tensor([  4.2190, -10.8023])\n",
      "    Grad: tensor([-0.1955,  1.1065])\n",
      "Epoch 589, Loss 7.0\n",
      "    Params: tensor([  4.2210, -10.8134])\n",
      "    Grad: tensor([-0.1951,  1.1046])\n",
      "Epoch 590, Loss 7.0\n",
      "    Params: tensor([  4.2229, -10.8244])\n",
      "    Grad: tensor([-0.1948,  1.1027])\n",
      "Epoch 591, Loss 7.0\n",
      "    Params: tensor([  4.2249, -10.8354])\n",
      "    Grad: tensor([-0.1945,  1.1009])\n",
      "Epoch 592, Loss 7.0\n",
      "    Params: tensor([  4.2268, -10.8464])\n",
      "    Grad: tensor([-0.1941,  1.0990])\n",
      "Epoch 593, Loss 7.0\n",
      "    Params: tensor([  4.2288, -10.8574])\n",
      "    Grad: tensor([-0.1938,  1.0971])\n",
      "Epoch 594, Loss 7.0\n",
      "    Params: tensor([  4.2307, -10.8683])\n",
      "    Grad: tensor([-0.1935,  1.0953])\n",
      "Epoch 595, Loss 7.0\n",
      "    Params: tensor([  4.2326, -10.8793])\n",
      "    Grad: tensor([-0.1931,  1.0934])\n",
      "Epoch 596, Loss 7.0\n",
      "    Params: tensor([  4.2346, -10.8902])\n",
      "    Grad: tensor([-0.1928,  1.0915])\n",
      "Epoch 597, Loss 7.0\n",
      "    Params: tensor([  4.2365, -10.9011])\n",
      "    Grad: tensor([-0.1925,  1.0897])\n",
      "Epoch 598, Loss 7.0\n",
      "    Params: tensor([  4.2384, -10.9120])\n",
      "    Grad: tensor([-0.1922,  1.0878])\n",
      "Epoch 599, Loss 7.0\n",
      "    Params: tensor([  4.2403, -10.9228])\n",
      "    Grad: tensor([-0.1919,  1.0860])\n",
      "Epoch 600, Loss 6.0\n",
      "    Params: tensor([  4.2422, -10.9337])\n",
      "    Grad: tensor([-0.1915,  1.0841])\n",
      "Epoch 601, Loss 6.0\n",
      "    Params: tensor([  4.2442, -10.9445])\n",
      "    Grad: tensor([-0.1912,  1.0823])\n",
      "Epoch 602, Loss 6.0\n",
      "    Params: tensor([  4.2461, -10.9553])\n",
      "    Grad: tensor([-0.1909,  1.0805])\n",
      "Epoch 603, Loss 6.0\n",
      "    Params: tensor([  4.2480, -10.9661])\n",
      "    Grad: tensor([-0.1906,  1.0786])\n",
      "Epoch 604, Loss 6.0\n",
      "    Params: tensor([  4.2499, -10.9768])\n",
      "    Grad: tensor([-0.1902,  1.0768])\n",
      "Epoch 605, Loss 6.0\n",
      "    Params: tensor([  4.2518, -10.9876])\n",
      "    Grad: tensor([-0.1899,  1.0750])\n",
      "Epoch 606, Loss 6.0\n",
      "    Params: tensor([  4.2537, -10.9983])\n",
      "    Grad: tensor([-0.1896,  1.0731])\n",
      "Epoch 607, Loss 6.0\n",
      "    Params: tensor([  4.2556, -11.0090])\n",
      "    Grad: tensor([-0.1892,  1.0713])\n",
      "Epoch 608, Loss 6.0\n",
      "    Params: tensor([  4.2574, -11.0197])\n",
      "    Grad: tensor([-0.1889,  1.0695])\n",
      "Epoch 609, Loss 6.0\n",
      "    Params: tensor([  4.2593, -11.0304])\n",
      "    Grad: tensor([-0.1886,  1.0677])\n",
      "Epoch 610, Loss 6.0\n",
      "    Params: tensor([  4.2612, -11.0411])\n",
      "    Grad: tensor([-0.1883,  1.0659])\n",
      "Epoch 611, Loss 6.0\n",
      "    Params: tensor([  4.2631, -11.0517])\n",
      "    Grad: tensor([-0.1880,  1.0641])\n",
      "Epoch 612, Loss 6.0\n",
      "    Params: tensor([  4.2650, -11.0623])\n",
      "    Grad: tensor([-0.1876,  1.0623])\n",
      "Epoch 613, Loss 6.0\n",
      "    Params: tensor([  4.2668, -11.0729])\n",
      "    Grad: tensor([-0.1873,  1.0604])\n",
      "Epoch 614, Loss 6.0\n",
      "    Params: tensor([  4.2687, -11.0835])\n",
      "    Grad: tensor([-0.1870,  1.0586])\n",
      "Epoch 615, Loss 6.0\n",
      "    Params: tensor([  4.2706, -11.0941])\n",
      "    Grad: tensor([-0.1867,  1.0568])\n",
      "Epoch 616, Loss 6.0\n",
      "    Params: tensor([  4.2724, -11.1046])\n",
      "    Grad: tensor([-0.1864,  1.0550])\n",
      "Epoch 617, Loss 6.0\n",
      "    Params: tensor([  4.2743, -11.1152])\n",
      "    Grad: tensor([-0.1861,  1.0533])\n",
      "Epoch 618, Loss 6.0\n",
      "    Params: tensor([  4.2762, -11.1257])\n",
      "    Grad: tensor([-0.1857,  1.0515])\n",
      "Epoch 619, Loss 6.0\n",
      "    Params: tensor([  4.2780, -11.1362])\n",
      "    Grad: tensor([-0.1854,  1.0497])\n",
      "Epoch 620, Loss 6.0\n",
      "    Params: tensor([  4.2799, -11.1467])\n",
      "    Grad: tensor([-0.1851,  1.0479])\n",
      "Epoch 621, Loss 6.0\n",
      "    Params: tensor([  4.2817, -11.1571])\n",
      "    Grad: tensor([-0.1848,  1.0461])\n",
      "Epoch 622, Loss 6.0\n",
      "    Params: tensor([  4.2836, -11.1676])\n",
      "    Grad: tensor([-0.1845,  1.0443])\n",
      "Epoch 623, Loss 6.0\n",
      "    Params: tensor([  4.2854, -11.1780])\n",
      "    Grad: tensor([-0.1842,  1.0426])\n",
      "Epoch 624, Loss 6.0\n",
      "    Params: tensor([  4.2872, -11.1884])\n",
      "    Grad: tensor([-0.1839,  1.0408])\n",
      "Epoch 625, Loss 6.0\n",
      "    Params: tensor([  4.2891, -11.1988])\n",
      "    Grad: tensor([-0.1835,  1.0390])\n",
      "Epoch 626, Loss 6.0\n",
      "    Params: tensor([  4.2909, -11.2092])\n",
      "    Grad: tensor([-0.1832,  1.0373])\n",
      "Epoch 627, Loss 6.0\n",
      "    Params: tensor([  4.2927, -11.2195])\n",
      "    Grad: tensor([-0.1829,  1.0355])\n",
      "Epoch 628, Loss 6.0\n",
      "    Params: tensor([  4.2946, -11.2299])\n",
      "    Grad: tensor([-0.1826,  1.0337])\n",
      "Epoch 629, Loss 6.0\n",
      "    Params: tensor([  4.2964, -11.2402])\n",
      "    Grad: tensor([-0.1823,  1.0320])\n",
      "Epoch 630, Loss 6.0\n",
      "    Params: tensor([  4.2982, -11.2505])\n",
      "    Grad: tensor([-0.1820,  1.0302])\n",
      "Epoch 631, Loss 6.0\n",
      "    Params: tensor([  4.3000, -11.2608])\n",
      "    Grad: tensor([-0.1817,  1.0285])\n",
      "Epoch 632, Loss 6.0\n",
      "    Params: tensor([  4.3018, -11.2710])\n",
      "    Grad: tensor([-0.1814,  1.0267])\n",
      "Epoch 633, Loss 6.0\n",
      "    Params: tensor([  4.3036, -11.2813])\n",
      "    Grad: tensor([-0.1810,  1.0250])\n",
      "Epoch 634, Loss 6.0\n",
      "    Params: tensor([  4.3055, -11.2915])\n",
      "    Grad: tensor([-0.1807,  1.0233])\n",
      "Epoch 635, Loss 6.0\n",
      "    Params: tensor([  4.3073, -11.3017])\n",
      "    Grad: tensor([-0.1805,  1.0215])\n",
      "Epoch 636, Loss 6.0\n",
      "    Params: tensor([  4.3091, -11.3119])\n",
      "    Grad: tensor([-0.1801,  1.0198])\n",
      "Epoch 637, Loss 6.0\n",
      "    Params: tensor([  4.3109, -11.3221])\n",
      "    Grad: tensor([-0.1798,  1.0180])\n",
      "Epoch 638, Loss 6.0\n",
      "    Params: tensor([  4.3127, -11.3323])\n",
      "    Grad: tensor([-0.1795,  1.0163])\n",
      "Epoch 639, Loss 6.0\n",
      "    Params: tensor([  4.3144, -11.3424])\n",
      "    Grad: tensor([-0.1792,  1.0146])\n",
      "Epoch 640, Loss 6.0\n",
      "    Params: tensor([  4.3162, -11.3525])\n",
      "    Grad: tensor([-0.1789,  1.0129])\n",
      "Epoch 641, Loss 6.0\n",
      "    Params: tensor([  4.3180, -11.3627])\n",
      "    Grad: tensor([-0.1786,  1.0111])\n",
      "Epoch 642, Loss 6.0\n",
      "    Params: tensor([  4.3198, -11.3727])\n",
      "    Grad: tensor([-0.1783,  1.0094])\n",
      "Epoch 643, Loss 6.0\n",
      "    Params: tensor([  4.3216, -11.3828])\n",
      "    Grad: tensor([-0.1780,  1.0077])\n",
      "Epoch 644, Loss 6.0\n",
      "    Params: tensor([  4.3234, -11.3929])\n",
      "    Grad: tensor([-0.1777,  1.0060])\n",
      "Epoch 645, Loss 6.0\n",
      "    Params: tensor([  4.3251, -11.4029])\n",
      "    Grad: tensor([-0.1774,  1.0043])\n",
      "Epoch 646, Loss 6.0\n",
      "    Params: tensor([  4.3269, -11.4130])\n",
      "    Grad: tensor([-0.1771,  1.0026])\n",
      "Epoch 647, Loss 6.0\n",
      "    Params: tensor([  4.3287, -11.4230])\n",
      "    Grad: tensor([-0.1768,  1.0009])\n",
      "Epoch 648, Loss 6.0\n",
      "    Params: tensor([  4.3304, -11.4330])\n",
      "    Grad: tensor([-0.1765,  0.9992])\n",
      "Epoch 649, Loss 6.0\n",
      "    Params: tensor([  4.3322, -11.4429])\n",
      "    Grad: tensor([-0.1762,  0.9975])\n",
      "Epoch 650, Loss 6.0\n",
      "    Params: tensor([  4.3340, -11.4529])\n",
      "    Grad: tensor([-0.1759,  0.9958])\n",
      "Epoch 651, Loss 6.0\n",
      "    Params: tensor([  4.3357, -11.4628])\n",
      "    Grad: tensor([-0.1756,  0.9941])\n",
      "Epoch 652, Loss 6.0\n",
      "    Params: tensor([  4.3375, -11.4728])\n",
      "    Grad: tensor([-0.1753,  0.9924])\n",
      "Epoch 653, Loss 6.0\n",
      "    Params: tensor([  4.3392, -11.4827])\n",
      "    Grad: tensor([-0.1750,  0.9907])\n",
      "Epoch 654, Loss 6.0\n",
      "    Params: tensor([  4.3410, -11.4926])\n",
      "    Grad: tensor([-0.1747,  0.9890])\n",
      "Epoch 655, Loss 6.0\n",
      "    Params: tensor([  4.3427, -11.5024])\n",
      "    Grad: tensor([-0.1744,  0.9874])\n",
      "Epoch 656, Loss 6.0\n",
      "    Params: tensor([  4.3445, -11.5123])\n",
      "    Grad: tensor([-0.1741,  0.9857])\n",
      "Epoch 657, Loss 6.0\n",
      "    Params: tensor([  4.3462, -11.5221])\n",
      "    Grad: tensor([-0.1738,  0.9840])\n",
      "Epoch 658, Loss 6.0\n",
      "    Params: tensor([  4.3479, -11.5319])\n",
      "    Grad: tensor([-0.1735,  0.9823])\n",
      "Epoch 659, Loss 6.0\n",
      "    Params: tensor([  4.3497, -11.5418])\n",
      "    Grad: tensor([-0.1732,  0.9807])\n",
      "Epoch 660, Loss 6.0\n",
      "    Params: tensor([  4.3514, -11.5515])\n",
      "    Grad: tensor([-0.1729,  0.9790])\n",
      "Epoch 661, Loss 6.0\n",
      "    Params: tensor([  4.3531, -11.5613])\n",
      "    Grad: tensor([-0.1727,  0.9773])\n",
      "Epoch 662, Loss 6.0\n",
      "    Params: tensor([  4.3548, -11.5711])\n",
      "    Grad: tensor([-0.1723,  0.9757])\n",
      "Epoch 663, Loss 6.0\n",
      "    Params: tensor([  4.3566, -11.5808])\n",
      "    Grad: tensor([-0.1721,  0.9740])\n",
      "Epoch 664, Loss 6.0\n",
      "    Params: tensor([  4.3583, -11.5905])\n",
      "    Grad: tensor([-0.1718,  0.9724])\n",
      "Epoch 665, Loss 6.0\n",
      "    Params: tensor([  4.3600, -11.6002])\n",
      "    Grad: tensor([-0.1715,  0.9707])\n",
      "Epoch 666, Loss 6.0\n",
      "    Params: tensor([  4.3617, -11.6099])\n",
      "    Grad: tensor([-0.1712,  0.9691])\n",
      "Epoch 667, Loss 6.0\n",
      "    Params: tensor([  4.3634, -11.6196])\n",
      "    Grad: tensor([-0.1709,  0.9674])\n",
      "Epoch 668, Loss 6.0\n",
      "    Params: tensor([  4.3651, -11.6293])\n",
      "    Grad: tensor([-0.1706,  0.9658])\n",
      "Epoch 669, Loss 6.0\n",
      "    Params: tensor([  4.3668, -11.6389])\n",
      "    Grad: tensor([-0.1703,  0.9641])\n",
      "Epoch 670, Loss 6.0\n",
      "    Params: tensor([  4.3685, -11.6485])\n",
      "    Grad: tensor([-0.1700,  0.9625])\n",
      "Epoch 671, Loss 6.0\n",
      "    Params: tensor([  4.3702, -11.6581])\n",
      "    Grad: tensor([-0.1697,  0.9609])\n",
      "Epoch 672, Loss 6.0\n",
      "    Params: tensor([  4.3719, -11.6677])\n",
      "    Grad: tensor([-0.1694,  0.9592])\n",
      "Epoch 673, Loss 6.0\n",
      "    Params: tensor([  4.3736, -11.6773])\n",
      "    Grad: tensor([-0.1692,  0.9576])\n",
      "Epoch 674, Loss 6.0\n",
      "    Params: tensor([  4.3753, -11.6869])\n",
      "    Grad: tensor([-0.1689,  0.9560])\n",
      "Epoch 675, Loss 6.0\n",
      "    Params: tensor([  4.3770, -11.6964])\n",
      "    Grad: tensor([-0.1686,  0.9544])\n",
      "Epoch 676, Loss 6.0\n",
      "    Params: tensor([  4.3787, -11.7059])\n",
      "    Grad: tensor([-0.1683,  0.9527])\n",
      "Epoch 677, Loss 6.0\n",
      "    Params: tensor([  4.3803, -11.7155])\n",
      "    Grad: tensor([-0.1680,  0.9511])\n",
      "Epoch 678, Loss 6.0\n",
      "    Params: tensor([  4.3820, -11.7249])\n",
      "    Grad: tensor([-0.1677,  0.9495])\n",
      "Epoch 679, Loss 6.0\n",
      "    Params: tensor([  4.3837, -11.7344])\n",
      "    Grad: tensor([-0.1674,  0.9479])\n",
      "Epoch 680, Loss 6.0\n",
      "    Params: tensor([  4.3854, -11.7439])\n",
      "    Grad: tensor([-0.1672,  0.9463])\n",
      "Epoch 681, Loss 6.0\n",
      "    Params: tensor([  4.3870, -11.7533])\n",
      "    Grad: tensor([-0.1669,  0.9447])\n",
      "Epoch 682, Loss 6.0\n",
      "    Params: tensor([  4.3887, -11.7628])\n",
      "    Grad: tensor([-0.1666,  0.9431])\n",
      "Epoch 683, Loss 6.0\n",
      "    Params: tensor([  4.3904, -11.7722])\n",
      "    Grad: tensor([-0.1663,  0.9415])\n",
      "Epoch 684, Loss 6.0\n",
      "    Params: tensor([  4.3920, -11.7816])\n",
      "    Grad: tensor([-0.1660,  0.9399])\n",
      "Epoch 685, Loss 6.0\n",
      "    Params: tensor([  4.3937, -11.7910])\n",
      "    Grad: tensor([-0.1657,  0.9383])\n",
      "Epoch 686, Loss 6.0\n",
      "    Params: tensor([  4.3953, -11.8003])\n",
      "    Grad: tensor([-0.1654,  0.9367])\n",
      "Epoch 687, Loss 6.0\n",
      "    Params: tensor([  4.3970, -11.8097])\n",
      "    Grad: tensor([-0.1652,  0.9351])\n",
      "Epoch 688, Loss 6.0\n",
      "    Params: tensor([  4.3986, -11.8190])\n",
      "    Grad: tensor([-0.1649,  0.9335])\n",
      "Epoch 689, Loss 6.0\n",
      "    Params: tensor([  4.4003, -11.8283])\n",
      "    Grad: tensor([-0.1646,  0.9319])\n",
      "Epoch 690, Loss 6.0\n",
      "    Params: tensor([  4.4019, -11.8376])\n",
      "    Grad: tensor([-0.1644,  0.9303])\n",
      "Epoch 691, Loss 6.0\n",
      "    Params: tensor([  4.4036, -11.8469])\n",
      "    Grad: tensor([-0.1641,  0.9287])\n",
      "Epoch 692, Loss 6.0\n",
      "    Params: tensor([  4.4052, -11.8562])\n",
      "    Grad: tensor([-0.1638,  0.9272])\n",
      "Epoch 693, Loss 6.0\n",
      "    Params: tensor([  4.4068, -11.8654])\n",
      "    Grad: tensor([-0.1635,  0.9256])\n",
      "Epoch 694, Loss 6.0\n",
      "    Params: tensor([  4.4085, -11.8747])\n",
      "    Grad: tensor([-0.1632,  0.9240])\n",
      "Epoch 695, Loss 6.0\n",
      "    Params: tensor([  4.4101, -11.8839])\n",
      "    Grad: tensor([-0.1629,  0.9224])\n",
      "Epoch 696, Loss 6.0\n",
      "    Params: tensor([  4.4117, -11.8931])\n",
      "    Grad: tensor([-0.1627,  0.9209])\n",
      "Epoch 697, Loss 5.0\n",
      "    Params: tensor([  4.4134, -11.9023])\n",
      "    Grad: tensor([-0.1624,  0.9193])\n",
      "Epoch 698, Loss 5.0\n",
      "    Params: tensor([  4.4150, -11.9115])\n",
      "    Grad: tensor([-0.1621,  0.9178])\n",
      "Epoch 699, Loss 5.0\n",
      "    Params: tensor([  4.4166, -11.9207])\n",
      "    Grad: tensor([-0.1618,  0.9162])\n",
      "Epoch 700, Loss 5.0\n",
      "    Params: tensor([  4.4182, -11.9298])\n",
      "    Grad: tensor([-0.1616,  0.9146])\n",
      "Epoch 701, Loss 5.0\n",
      "    Params: tensor([  4.4198, -11.9389])\n",
      "    Grad: tensor([-0.1613,  0.9131])\n",
      "Epoch 702, Loss 5.0\n",
      "    Params: tensor([  4.4214, -11.9480])\n",
      "    Grad: tensor([-0.1610,  0.9115])\n",
      "Epoch 703, Loss 5.0\n",
      "    Params: tensor([  4.4230, -11.9571])\n",
      "    Grad: tensor([-0.1607,  0.9100])\n",
      "Epoch 704, Loss 5.0\n",
      "    Params: tensor([  4.4246, -11.9662])\n",
      "    Grad: tensor([-0.1605,  0.9084])\n",
      "Epoch 705, Loss 5.0\n",
      "    Params: tensor([  4.4263, -11.9753])\n",
      "    Grad: tensor([-0.1602,  0.9069])\n",
      "Epoch 706, Loss 5.0\n",
      "    Params: tensor([  4.4278, -11.9844])\n",
      "    Grad: tensor([-0.1599,  0.9054])\n",
      "Epoch 707, Loss 5.0\n",
      "    Params: tensor([  4.4294, -11.9934])\n",
      "    Grad: tensor([-0.1597,  0.9038])\n",
      "Epoch 708, Loss 5.0\n",
      "    Params: tensor([  4.4310, -12.0024])\n",
      "    Grad: tensor([-0.1594,  0.9023])\n",
      "Epoch 709, Loss 5.0\n",
      "    Params: tensor([  4.4326, -12.0114])\n",
      "    Grad: tensor([-0.1591,  0.9007])\n",
      "Epoch 710, Loss 5.0\n",
      "    Params: tensor([  4.4342, -12.0204])\n",
      "    Grad: tensor([-0.1588,  0.8992])\n",
      "Epoch 711, Loss 5.0\n",
      "    Params: tensor([  4.4358, -12.0294])\n",
      "    Grad: tensor([-0.1586,  0.8977])\n",
      "Epoch 712, Loss 5.0\n",
      "    Params: tensor([  4.4374, -12.0384])\n",
      "    Grad: tensor([-0.1583,  0.8962])\n",
      "Epoch 713, Loss 5.0\n",
      "    Params: tensor([  4.4390, -12.0473])\n",
      "    Grad: tensor([-0.1580,  0.8946])\n",
      "Epoch 714, Loss 5.0\n",
      "    Params: tensor([  4.4405, -12.0562])\n",
      "    Grad: tensor([-0.1578,  0.8931])\n",
      "Epoch 715, Loss 5.0\n",
      "    Params: tensor([  4.4421, -12.0651])\n",
      "    Grad: tensor([-0.1575,  0.8916])\n",
      "Epoch 716, Loss 5.0\n",
      "    Params: tensor([  4.4437, -12.0740])\n",
      "    Grad: tensor([-0.1572,  0.8901])\n",
      "Epoch 717, Loss 5.0\n",
      "    Params: tensor([  4.4453, -12.0829])\n",
      "    Grad: tensor([-0.1570,  0.8886])\n",
      "Epoch 718, Loss 5.0\n",
      "    Params: tensor([  4.4468, -12.0918])\n",
      "    Grad: tensor([-0.1567,  0.8871])\n",
      "Epoch 719, Loss 5.0\n",
      "    Params: tensor([  4.4484, -12.1007])\n",
      "    Grad: tensor([-0.1564,  0.8856])\n",
      "Epoch 720, Loss 5.0\n",
      "    Params: tensor([  4.4500, -12.1095])\n",
      "    Grad: tensor([-0.1562,  0.8841])\n",
      "Epoch 721, Loss 5.0\n",
      "    Params: tensor([  4.4515, -12.1183])\n",
      "    Grad: tensor([-0.1559,  0.8826])\n",
      "Epoch 722, Loss 5.0\n",
      "    Params: tensor([  4.4531, -12.1271])\n",
      "    Grad: tensor([-0.1556,  0.8811])\n",
      "Epoch 723, Loss 5.0\n",
      "    Params: tensor([  4.4546, -12.1359])\n",
      "    Grad: tensor([-0.1554,  0.8796])\n",
      "Epoch 724, Loss 5.0\n",
      "    Params: tensor([  4.4562, -12.1447])\n",
      "    Grad: tensor([-0.1551,  0.8781])\n",
      "Epoch 725, Loss 5.0\n",
      "    Params: tensor([  4.4577, -12.1535])\n",
      "    Grad: tensor([-0.1548,  0.8766])\n",
      "Epoch 726, Loss 5.0\n",
      "    Params: tensor([  4.4593, -12.1622])\n",
      "    Grad: tensor([-0.1546,  0.8751])\n",
      "Epoch 727, Loss 5.0\n",
      "    Params: tensor([  4.4608, -12.1710])\n",
      "    Grad: tensor([-0.1543,  0.8736])\n",
      "Epoch 728, Loss 5.0\n",
      "    Params: tensor([  4.4624, -12.1797])\n",
      "    Grad: tensor([-0.1541,  0.8721])\n",
      "Epoch 729, Loss 5.0\n",
      "    Params: tensor([  4.4639, -12.1884])\n",
      "    Grad: tensor([-0.1538,  0.8706])\n",
      "Epoch 730, Loss 5.0\n",
      "    Params: tensor([  4.4654, -12.1971])\n",
      "    Grad: tensor([-0.1535,  0.8692])\n",
      "Epoch 731, Loss 5.0\n",
      "    Params: tensor([  4.4670, -12.2058])\n",
      "    Grad: tensor([-0.1533,  0.8677])\n",
      "Epoch 732, Loss 5.0\n",
      "    Params: tensor([  4.4685, -12.2144])\n",
      "    Grad: tensor([-0.1530,  0.8662])\n",
      "Epoch 733, Loss 5.0\n",
      "    Params: tensor([  4.4700, -12.2231])\n",
      "    Grad: tensor([-0.1528,  0.8647])\n",
      "Epoch 734, Loss 5.0\n",
      "    Params: tensor([  4.4715, -12.2317])\n",
      "    Grad: tensor([-0.1525,  0.8633])\n",
      "Epoch 735, Loss 5.0\n",
      "    Params: tensor([  4.4731, -12.2403])\n",
      "    Grad: tensor([-0.1522,  0.8618])\n",
      "Epoch 736, Loss 5.0\n",
      "    Params: tensor([  4.4746, -12.2489])\n",
      "    Grad: tensor([-0.1520,  0.8603])\n",
      "Epoch 737, Loss 5.0\n",
      "    Params: tensor([  4.4761, -12.2575])\n",
      "    Grad: tensor([-0.1517,  0.8589])\n",
      "Epoch 738, Loss 5.0\n",
      "    Params: tensor([  4.4776, -12.2661])\n",
      "    Grad: tensor([-0.1515,  0.8574])\n",
      "Epoch 739, Loss 5.0\n",
      "    Params: tensor([  4.4791, -12.2746])\n",
      "    Grad: tensor([-0.1512,  0.8560])\n",
      "Epoch 740, Loss 5.0\n",
      "    Params: tensor([  4.4806, -12.2832])\n",
      "    Grad: tensor([-0.1510,  0.8545])\n",
      "Epoch 741, Loss 5.0\n",
      "    Params: tensor([  4.4821, -12.2917])\n",
      "    Grad: tensor([-0.1507,  0.8531])\n",
      "Epoch 742, Loss 5.0\n",
      "    Params: tensor([  4.4837, -12.3002])\n",
      "    Grad: tensor([-0.1504,  0.8516])\n",
      "Epoch 743, Loss 5.0\n",
      "    Params: tensor([  4.4852, -12.3087])\n",
      "    Grad: tensor([-0.1502,  0.8502])\n",
      "Epoch 744, Loss 5.0\n",
      "    Params: tensor([  4.4867, -12.3172])\n",
      "    Grad: tensor([-0.1500,  0.8487])\n",
      "Epoch 745, Loss 5.0\n",
      "    Params: tensor([  4.4881, -12.3257])\n",
      "    Grad: tensor([-0.1497,  0.8473])\n",
      "Epoch 746, Loss 5.0\n",
      "    Params: tensor([  4.4896, -12.3342])\n",
      "    Grad: tensor([-0.1494,  0.8458])\n",
      "Epoch 747, Loss 5.0\n",
      "    Params: tensor([  4.4911, -12.3426])\n",
      "    Grad: tensor([-0.1492,  0.8444])\n",
      "Epoch 748, Loss 5.0\n",
      "    Params: tensor([  4.4926, -12.3510])\n",
      "    Grad: tensor([-0.1489,  0.8430])\n",
      "Epoch 749, Loss 5.0\n",
      "    Params: tensor([  4.4941, -12.3594])\n",
      "    Grad: tensor([-0.1487,  0.8415])\n",
      "Epoch 750, Loss 5.0\n",
      "    Params: tensor([  4.4956, -12.3678])\n",
      "    Grad: tensor([-0.1484,  0.8401])\n",
      "Epoch 751, Loss 5.0\n",
      "    Params: tensor([  4.4971, -12.3762])\n",
      "    Grad: tensor([-0.1481,  0.8387])\n",
      "Epoch 752, Loss 5.0\n",
      "    Params: tensor([  4.4986, -12.3846])\n",
      "    Grad: tensor([-0.1479,  0.8372])\n",
      "Epoch 753, Loss 5.0\n",
      "    Params: tensor([  4.5000, -12.3930])\n",
      "    Grad: tensor([-0.1476,  0.8358])\n",
      "Epoch 754, Loss 5.0\n",
      "    Params: tensor([  4.5015, -12.4013])\n",
      "    Grad: tensor([-0.1474,  0.8344])\n",
      "Epoch 755, Loss 5.0\n",
      "    Params: tensor([  4.5030, -12.4096])\n",
      "    Grad: tensor([-0.1471,  0.8330])\n",
      "Epoch 756, Loss 5.0\n",
      "    Params: tensor([  4.5044, -12.4180])\n",
      "    Grad: tensor([-0.1469,  0.8316])\n",
      "Epoch 757, Loss 5.0\n",
      "    Params: tensor([  4.5059, -12.4263])\n",
      "    Grad: tensor([-0.1467,  0.8302])\n",
      "Epoch 758, Loss 5.0\n",
      "    Params: tensor([  4.5074, -12.4345])\n",
      "    Grad: tensor([-0.1464,  0.8287])\n",
      "Epoch 759, Loss 5.0\n",
      "    Params: tensor([  4.5088, -12.4428])\n",
      "    Grad: tensor([-0.1462,  0.8273])\n",
      "Epoch 760, Loss 5.0\n",
      "    Params: tensor([  4.5103, -12.4511])\n",
      "    Grad: tensor([-0.1459,  0.8259])\n",
      "Epoch 761, Loss 5.0\n",
      "    Params: tensor([  4.5118, -12.4593])\n",
      "    Grad: tensor([-0.1457,  0.8245])\n",
      "Epoch 762, Loss 5.0\n",
      "    Params: tensor([  4.5132, -12.4676])\n",
      "    Grad: tensor([-0.1454,  0.8231])\n",
      "Epoch 763, Loss 5.0\n",
      "    Params: tensor([  4.5147, -12.4758])\n",
      "    Grad: tensor([-0.1452,  0.8217])\n",
      "Epoch 764, Loss 5.0\n",
      "    Params: tensor([  4.5161, -12.4840])\n",
      "    Grad: tensor([-0.1449,  0.8203])\n",
      "Epoch 765, Loss 5.0\n",
      "    Params: tensor([  4.5176, -12.4922])\n",
      "    Grad: tensor([-0.1447,  0.8189])\n",
      "Epoch 766, Loss 5.0\n",
      "    Params: tensor([  4.5190, -12.5003])\n",
      "    Grad: tensor([-0.1444,  0.8175])\n",
      "Epoch 767, Loss 5.0\n",
      "    Params: tensor([  4.5204, -12.5085])\n",
      "    Grad: tensor([-0.1442,  0.8162])\n",
      "Epoch 768, Loss 5.0\n",
      "    Params: tensor([  4.5219, -12.5166])\n",
      "    Grad: tensor([-0.1439,  0.8148])\n",
      "Epoch 769, Loss 5.0\n",
      "    Params: tensor([  4.5233, -12.5248])\n",
      "    Grad: tensor([-0.1437,  0.8134])\n",
      "Epoch 770, Loss 5.0\n",
      "    Params: tensor([  4.5248, -12.5329])\n",
      "    Grad: tensor([-0.1435,  0.8120])\n",
      "Epoch 771, Loss 5.0\n",
      "    Params: tensor([  4.5262, -12.5410])\n",
      "    Grad: tensor([-0.1432,  0.8106])\n",
      "Epoch 772, Loss 5.0\n",
      "    Params: tensor([  4.5276, -12.5491])\n",
      "    Grad: tensor([-0.1430,  0.8093])\n",
      "Epoch 773, Loss 5.0\n",
      "    Params: tensor([  4.5290, -12.5572])\n",
      "    Grad: tensor([-0.1427,  0.8079])\n",
      "Epoch 774, Loss 5.0\n",
      "    Params: tensor([  4.5305, -12.5652])\n",
      "    Grad: tensor([-0.1425,  0.8065])\n",
      "Epoch 775, Loss 5.0\n",
      "    Params: tensor([  4.5319, -12.5733])\n",
      "    Grad: tensor([-0.1422,  0.8051])\n",
      "Epoch 776, Loss 5.0\n",
      "    Params: tensor([  4.5333, -12.5813])\n",
      "    Grad: tensor([-0.1420,  0.8038])\n",
      "Epoch 777, Loss 5.0\n",
      "    Params: tensor([  4.5347, -12.5894])\n",
      "    Grad: tensor([-0.1417,  0.8024])\n",
      "Epoch 778, Loss 5.0\n",
      "    Params: tensor([  4.5361, -12.5974])\n",
      "    Grad: tensor([-0.1415,  0.8010])\n",
      "Epoch 779, Loss 5.0\n",
      "    Params: tensor([  4.5376, -12.6054])\n",
      "    Grad: tensor([-0.1413,  0.7997])\n",
      "Epoch 780, Loss 5.0\n",
      "    Params: tensor([  4.5390, -12.6133])\n",
      "    Grad: tensor([-0.1410,  0.7983])\n",
      "Epoch 781, Loss 5.0\n",
      "    Params: tensor([  4.5404, -12.6213])\n",
      "    Grad: tensor([-0.1408,  0.7970])\n",
      "Epoch 782, Loss 5.0\n",
      "    Params: tensor([  4.5418, -12.6293])\n",
      "    Grad: tensor([-0.1406,  0.7956])\n",
      "Epoch 783, Loss 5.0\n",
      "    Params: tensor([  4.5432, -12.6372])\n",
      "    Grad: tensor([-0.1403,  0.7943])\n",
      "Epoch 784, Loss 5.0\n",
      "    Params: tensor([  4.5446, -12.6451])\n",
      "    Grad: tensor([-0.1401,  0.7929])\n",
      "Epoch 785, Loss 5.0\n",
      "    Params: tensor([  4.5460, -12.6531])\n",
      "    Grad: tensor([-0.1398,  0.7916])\n",
      "Epoch 786, Loss 5.0\n",
      "    Params: tensor([  4.5474, -12.6610])\n",
      "    Grad: tensor([-0.1396,  0.7902])\n",
      "Epoch 787, Loss 5.0\n",
      "    Params: tensor([  4.5488, -12.6689])\n",
      "    Grad: tensor([-0.1394,  0.7889])\n",
      "Epoch 788, Loss 5.0\n",
      "    Params: tensor([  4.5502, -12.6767])\n",
      "    Grad: tensor([-0.1391,  0.7875])\n",
      "Epoch 789, Loss 5.0\n",
      "    Params: tensor([  4.5515, -12.6846])\n",
      "    Grad: tensor([-0.1389,  0.7862])\n",
      "Epoch 790, Loss 5.0\n",
      "    Params: tensor([  4.5529, -12.6924])\n",
      "    Grad: tensor([-0.1387,  0.7849])\n",
      "Epoch 791, Loss 5.0\n",
      "    Params: tensor([  4.5543, -12.7003])\n",
      "    Grad: tensor([-0.1384,  0.7835])\n",
      "Epoch 792, Loss 5.0\n",
      "    Params: tensor([  4.5557, -12.7081])\n",
      "    Grad: tensor([-0.1382,  0.7822])\n",
      "Epoch 793, Loss 5.0\n",
      "    Params: tensor([  4.5571, -12.7159])\n",
      "    Grad: tensor([-0.1379,  0.7809])\n",
      "Epoch 794, Loss 5.0\n",
      "    Params: tensor([  4.5585, -12.7237])\n",
      "    Grad: tensor([-0.1377,  0.7795])\n",
      "Epoch 795, Loss 5.0\n",
      "    Params: tensor([  4.5598, -12.7315])\n",
      "    Grad: tensor([-0.1375,  0.7782])\n",
      "Epoch 796, Loss 5.0\n",
      "    Params: tensor([  4.5612, -12.7393])\n",
      "    Grad: tensor([-0.1372,  0.7769])\n",
      "Epoch 797, Loss 5.0\n",
      "    Params: tensor([  4.5626, -12.7470])\n",
      "    Grad: tensor([-0.1370,  0.7756])\n",
      "Epoch 798, Loss 5.0\n",
      "    Params: tensor([  4.5639, -12.7547])\n",
      "    Grad: tensor([-0.1368,  0.7743])\n",
      "Epoch 799, Loss 5.0\n",
      "    Params: tensor([  4.5653, -12.7625])\n",
      "    Grad: tensor([-0.1365,  0.7729])\n",
      "Epoch 800, Loss 5.0\n",
      "    Params: tensor([  4.5667, -12.7702])\n",
      "    Grad: tensor([-0.1363,  0.7716])\n",
      "Epoch 801, Loss 5.0\n",
      "    Params: tensor([  4.5680, -12.7779])\n",
      "    Grad: tensor([-0.1361,  0.7703])\n",
      "Epoch 802, Loss 5.0\n",
      "    Params: tensor([  4.5694, -12.7856])\n",
      "    Grad: tensor([-0.1358,  0.7690])\n",
      "Epoch 803, Loss 5.0\n",
      "    Params: tensor([  4.5707, -12.7933])\n",
      "    Grad: tensor([-0.1356,  0.7677])\n",
      "Epoch 804, Loss 5.0\n",
      "    Params: tensor([  4.5721, -12.8009])\n",
      "    Grad: tensor([-0.1354,  0.7664])\n",
      "Epoch 805, Loss 5.0\n",
      "    Params: tensor([  4.5735, -12.8086])\n",
      "    Grad: tensor([-0.1352,  0.7651])\n",
      "Epoch 806, Loss 5.0\n",
      "    Params: tensor([  4.5748, -12.8162])\n",
      "    Grad: tensor([-0.1349,  0.7638])\n",
      "Epoch 807, Loss 5.0\n",
      "    Params: tensor([  4.5761, -12.8238])\n",
      "    Grad: tensor([-0.1347,  0.7625])\n",
      "Epoch 808, Loss 5.0\n",
      "    Params: tensor([  4.5775, -12.8315])\n",
      "    Grad: tensor([-0.1345,  0.7612])\n",
      "Epoch 809, Loss 5.0\n",
      "    Params: tensor([  4.5788, -12.8391])\n",
      "    Grad: tensor([-0.1342,  0.7599])\n",
      "Epoch 810, Loss 5.0\n",
      "    Params: tensor([  4.5802, -12.8466])\n",
      "    Grad: tensor([-0.1340,  0.7586])\n",
      "Epoch 811, Loss 5.0\n",
      "    Params: tensor([  4.5815, -12.8542])\n",
      "    Grad: tensor([-0.1338,  0.7573])\n",
      "Epoch 812, Loss 5.0\n",
      "    Params: tensor([  4.5828, -12.8618])\n",
      "    Grad: tensor([-0.1335,  0.7560])\n",
      "Epoch 813, Loss 5.0\n",
      "    Params: tensor([  4.5842, -12.8693])\n",
      "    Grad: tensor([-0.1333,  0.7548])\n",
      "Epoch 814, Loss 5.0\n",
      "    Params: tensor([  4.5855, -12.8769])\n",
      "    Grad: tensor([-0.1331,  0.7535])\n",
      "Epoch 815, Loss 5.0\n",
      "    Params: tensor([  4.5868, -12.8844])\n",
      "    Grad: tensor([-0.1329,  0.7522])\n",
      "Epoch 816, Loss 5.0\n",
      "    Params: tensor([  4.5882, -12.8919])\n",
      "    Grad: tensor([-0.1326,  0.7509])\n",
      "Epoch 817, Loss 5.0\n",
      "    Params: tensor([  4.5895, -12.8994])\n",
      "    Grad: tensor([-0.1324,  0.7496])\n",
      "Epoch 818, Loss 5.0\n",
      "    Params: tensor([  4.5908, -12.9069])\n",
      "    Grad: tensor([-0.1322,  0.7484])\n",
      "Epoch 819, Loss 5.0\n",
      "    Params: tensor([  4.5921, -12.9143])\n",
      "    Grad: tensor([-0.1320,  0.7471])\n",
      "Epoch 820, Loss 5.0\n",
      "    Params: tensor([  4.5935, -12.9218])\n",
      "    Grad: tensor([-0.1318,  0.7458])\n",
      "Epoch 821, Loss 5.0\n",
      "    Params: tensor([  4.5948, -12.9292])\n",
      "    Grad: tensor([-0.1315,  0.7446])\n",
      "Epoch 822, Loss 5.0\n",
      "    Params: tensor([  4.5961, -12.9367])\n",
      "    Grad: tensor([-0.1313,  0.7433])\n",
      "Epoch 823, Loss 5.0\n",
      "    Params: tensor([  4.5974, -12.9441])\n",
      "    Grad: tensor([-0.1311,  0.7420])\n",
      "Epoch 824, Loss 5.0\n",
      "    Params: tensor([  4.5987, -12.9515])\n",
      "    Grad: tensor([-0.1309,  0.7408])\n",
      "Epoch 825, Loss 5.0\n",
      "    Params: tensor([  4.6000, -12.9589])\n",
      "    Grad: tensor([-0.1307,  0.7395])\n",
      "Epoch 826, Loss 5.0\n",
      "    Params: tensor([  4.6013, -12.9663])\n",
      "    Grad: tensor([-0.1304,  0.7383])\n",
      "Epoch 827, Loss 5.0\n",
      "    Params: tensor([  4.6026, -12.9737])\n",
      "    Grad: tensor([-0.1302,  0.7370])\n",
      "Epoch 828, Loss 5.0\n",
      "    Params: tensor([  4.6039, -12.9810])\n",
      "    Grad: tensor([-0.1300,  0.7358])\n",
      "Epoch 829, Loss 5.0\n",
      "    Params: tensor([  4.6052, -12.9884])\n",
      "    Grad: tensor([-0.1298,  0.7345])\n",
      "Epoch 830, Loss 5.0\n",
      "    Params: tensor([  4.6065, -12.9957])\n",
      "    Grad: tensor([-0.1295,  0.7333])\n",
      "Epoch 831, Loss 5.0\n",
      "    Params: tensor([  4.6078, -13.0030])\n",
      "    Grad: tensor([-0.1293,  0.7320])\n",
      "Epoch 832, Loss 5.0\n",
      "    Params: tensor([  4.6091, -13.0103])\n",
      "    Grad: tensor([-0.1291,  0.7308])\n",
      "Epoch 833, Loss 5.0\n",
      "    Params: tensor([  4.6104, -13.0176])\n",
      "    Grad: tensor([-0.1289,  0.7295])\n",
      "Epoch 834, Loss 5.0\n",
      "    Params: tensor([  4.6117, -13.0249])\n",
      "    Grad: tensor([-0.1287,  0.7283])\n",
      "Epoch 835, Loss 5.0\n",
      "    Params: tensor([  4.6129, -13.0322])\n",
      "    Grad: tensor([-0.1284,  0.7270])\n",
      "Epoch 836, Loss 5.0\n",
      "    Params: tensor([  4.6142, -13.0394])\n",
      "    Grad: tensor([-0.1282,  0.7258])\n",
      "Epoch 837, Loss 5.0\n",
      "    Params: tensor([  4.6155, -13.0467])\n",
      "    Grad: tensor([-0.1280,  0.7246])\n",
      "Epoch 838, Loss 5.0\n",
      "    Params: tensor([  4.6168, -13.0539])\n",
      "    Grad: tensor([-0.1278,  0.7234])\n",
      "Epoch 839, Loss 5.0\n",
      "    Params: tensor([  4.6181, -13.0611])\n",
      "    Grad: tensor([-0.1276,  0.7221])\n",
      "Epoch 840, Loss 5.0\n",
      "    Params: tensor([  4.6193, -13.0683])\n",
      "    Grad: tensor([-0.1274,  0.7209])\n",
      "Epoch 841, Loss 4.0\n",
      "    Params: tensor([  4.6206, -13.0755])\n",
      "    Grad: tensor([-0.1271,  0.7197])\n",
      "Epoch 842, Loss 4.0\n",
      "    Params: tensor([  4.6219, -13.0827])\n",
      "    Grad: tensor([-0.1269,  0.7184])\n",
      "Epoch 843, Loss 4.0\n",
      "    Params: tensor([  4.6231, -13.0899])\n",
      "    Grad: tensor([-0.1267,  0.7172])\n",
      "Epoch 844, Loss 4.0\n",
      "    Params: tensor([  4.6244, -13.0970])\n",
      "    Grad: tensor([-0.1265,  0.7160])\n",
      "Epoch 845, Loss 4.0\n",
      "    Params: tensor([  4.6257, -13.1042])\n",
      "    Grad: tensor([-0.1263,  0.7148])\n",
      "Epoch 846, Loss 4.0\n",
      "    Params: tensor([  4.6269, -13.1113])\n",
      "    Grad: tensor([-0.1260,  0.7136])\n",
      "Epoch 847, Loss 4.0\n",
      "    Params: tensor([  4.6282, -13.1185])\n",
      "    Grad: tensor([-0.1258,  0.7124])\n",
      "Epoch 848, Loss 4.0\n",
      "    Params: tensor([  4.6294, -13.1256])\n",
      "    Grad: tensor([-0.1256,  0.7112])\n",
      "Epoch 849, Loss 4.0\n",
      "    Params: tensor([  4.6307, -13.1327])\n",
      "    Grad: tensor([-0.1254,  0.7100])\n",
      "Epoch 850, Loss 4.0\n",
      "    Params: tensor([  4.6320, -13.1398])\n",
      "    Grad: tensor([-0.1252,  0.7087])\n",
      "Epoch 851, Loss 4.0\n",
      "    Params: tensor([  4.6332, -13.1468])\n",
      "    Grad: tensor([-0.1250,  0.7075])\n",
      "Epoch 852, Loss 4.0\n",
      "    Params: tensor([  4.6345, -13.1539])\n",
      "    Grad: tensor([-0.1248,  0.7063])\n",
      "Epoch 853, Loss 4.0\n",
      "    Params: tensor([  4.6357, -13.1609])\n",
      "    Grad: tensor([-0.1246,  0.7051])\n",
      "Epoch 854, Loss 4.0\n",
      "    Params: tensor([  4.6369, -13.1680])\n",
      "    Grad: tensor([-0.1243,  0.7039])\n",
      "Epoch 855, Loss 4.0\n",
      "    Params: tensor([  4.6382, -13.1750])\n",
      "    Grad: tensor([-0.1241,  0.7027])\n",
      "Epoch 856, Loss 4.0\n",
      "    Params: tensor([  4.6394, -13.1820])\n",
      "    Grad: tensor([-0.1239,  0.7016])\n",
      "Epoch 857, Loss 4.0\n",
      "    Params: tensor([  4.6407, -13.1890])\n",
      "    Grad: tensor([-0.1237,  0.7004])\n",
      "Epoch 858, Loss 4.0\n",
      "    Params: tensor([  4.6419, -13.1960])\n",
      "    Grad: tensor([-0.1235,  0.6992])\n",
      "Epoch 859, Loss 4.0\n",
      "    Params: tensor([  4.6431, -13.2030])\n",
      "    Grad: tensor([-0.1233,  0.6980])\n",
      "Epoch 860, Loss 4.0\n",
      "    Params: tensor([  4.6444, -13.2100])\n",
      "    Grad: tensor([-0.1231,  0.6968])\n",
      "Epoch 861, Loss 4.0\n",
      "    Params: tensor([  4.6456, -13.2169])\n",
      "    Grad: tensor([-0.1229,  0.6956])\n",
      "Epoch 862, Loss 4.0\n",
      "    Params: tensor([  4.6468, -13.2239])\n",
      "    Grad: tensor([-0.1227,  0.6944])\n",
      "Epoch 863, Loss 4.0\n",
      "    Params: tensor([  4.6480, -13.2308])\n",
      "    Grad: tensor([-0.1225,  0.6932])\n",
      "Epoch 864, Loss 4.0\n",
      "    Params: tensor([  4.6493, -13.2377])\n",
      "    Grad: tensor([-0.1223,  0.6921])\n",
      "Epoch 865, Loss 4.0\n",
      "    Params: tensor([  4.6505, -13.2446])\n",
      "    Grad: tensor([-0.1221,  0.6909])\n",
      "Epoch 866, Loss 4.0\n",
      "    Params: tensor([  4.6517, -13.2515])\n",
      "    Grad: tensor([-0.1218,  0.6897])\n",
      "Epoch 867, Loss 4.0\n",
      "    Params: tensor([  4.6529, -13.2584])\n",
      "    Grad: tensor([-0.1216,  0.6886])\n",
      "Epoch 868, Loss 4.0\n",
      "    Params: tensor([  4.6541, -13.2653])\n",
      "    Grad: tensor([-0.1214,  0.6874])\n",
      "Epoch 869, Loss 4.0\n",
      "    Params: tensor([  4.6553, -13.2721])\n",
      "    Grad: tensor([-0.1212,  0.6862])\n",
      "Epoch 870, Loss 4.0\n",
      "    Params: tensor([  4.6566, -13.2790])\n",
      "    Grad: tensor([-0.1210,  0.6850])\n",
      "Epoch 871, Loss 4.0\n",
      "    Params: tensor([  4.6578, -13.2858])\n",
      "    Grad: tensor([-0.1208,  0.6839])\n",
      "Epoch 872, Loss 4.0\n",
      "    Params: tensor([  4.6590, -13.2927])\n",
      "    Grad: tensor([-0.1206,  0.6827])\n",
      "Epoch 873, Loss 4.0\n",
      "    Params: tensor([  4.6602, -13.2995])\n",
      "    Grad: tensor([-0.1204,  0.6816])\n",
      "Epoch 874, Loss 4.0\n",
      "    Params: tensor([  4.6614, -13.3063])\n",
      "    Grad: tensor([-0.1202,  0.6804])\n",
      "Epoch 875, Loss 4.0\n",
      "    Params: tensor([  4.6626, -13.3131])\n",
      "    Grad: tensor([-0.1200,  0.6792])\n",
      "Epoch 876, Loss 4.0\n",
      "    Params: tensor([  4.6638, -13.3199])\n",
      "    Grad: tensor([-0.1198,  0.6781])\n",
      "Epoch 877, Loss 4.0\n",
      "    Params: tensor([  4.6650, -13.3266])\n",
      "    Grad: tensor([-0.1196,  0.6769])\n",
      "Epoch 878, Loss 4.0\n",
      "    Params: tensor([  4.6662, -13.3334])\n",
      "    Grad: tensor([-0.1194,  0.6758])\n",
      "Epoch 879, Loss 4.0\n",
      "    Params: tensor([  4.6674, -13.3401])\n",
      "    Grad: tensor([-0.1192,  0.6746])\n",
      "Epoch 880, Loss 4.0\n",
      "    Params: tensor([  4.6685, -13.3469])\n",
      "    Grad: tensor([-0.1190,  0.6735])\n",
      "Epoch 881, Loss 4.0\n",
      "    Params: tensor([  4.6697, -13.3536])\n",
      "    Grad: tensor([-0.1188,  0.6724])\n",
      "Epoch 882, Loss 4.0\n",
      "    Params: tensor([  4.6709, -13.3603])\n",
      "    Grad: tensor([-0.1186,  0.6712])\n",
      "Epoch 883, Loss 4.0\n",
      "    Params: tensor([  4.6721, -13.3670])\n",
      "    Grad: tensor([-0.1184,  0.6701])\n",
      "Epoch 884, Loss 4.0\n",
      "    Params: tensor([  4.6733, -13.3737])\n",
      "    Grad: tensor([-0.1182,  0.6689])\n",
      "Epoch 885, Loss 4.0\n",
      "    Params: tensor([  4.6745, -13.3804])\n",
      "    Grad: tensor([-0.1180,  0.6678])\n",
      "Epoch 886, Loss 4.0\n",
      "    Params: tensor([  4.6756, -13.3870])\n",
      "    Grad: tensor([-0.1178,  0.6667])\n",
      "Epoch 887, Loss 4.0\n",
      "    Params: tensor([  4.6768, -13.3937])\n",
      "    Grad: tensor([-0.1176,  0.6655])\n",
      "Epoch 888, Loss 4.0\n",
      "    Params: tensor([  4.6780, -13.4003])\n",
      "    Grad: tensor([-0.1174,  0.6644])\n",
      "Epoch 889, Loss 4.0\n",
      "    Params: tensor([  4.6792, -13.4070])\n",
      "    Grad: tensor([-0.1172,  0.6633])\n",
      "Epoch 890, Loss 4.0\n",
      "    Params: tensor([  4.6803, -13.4136])\n",
      "    Grad: tensor([-0.1170,  0.6621])\n",
      "Epoch 891, Loss 4.0\n",
      "    Params: tensor([  4.6815, -13.4202])\n",
      "    Grad: tensor([-0.1168,  0.6610])\n",
      "Epoch 892, Loss 4.0\n",
      "    Params: tensor([  4.6827, -13.4268])\n",
      "    Grad: tensor([-0.1166,  0.6599])\n",
      "Epoch 893, Loss 4.0\n",
      "    Params: tensor([  4.6838, -13.4334])\n",
      "    Grad: tensor([-0.1164,  0.6588])\n",
      "Epoch 894, Loss 4.0\n",
      "    Params: tensor([  4.6850, -13.4400])\n",
      "    Grad: tensor([-0.1162,  0.6577])\n",
      "Epoch 895, Loss 4.0\n",
      "    Params: tensor([  4.6861, -13.4465])\n",
      "    Grad: tensor([-0.1160,  0.6565])\n",
      "Epoch 896, Loss 4.0\n",
      "    Params: tensor([  4.6873, -13.4531])\n",
      "    Grad: tensor([-0.1158,  0.6554])\n",
      "Epoch 897, Loss 4.0\n",
      "    Params: tensor([  4.6885, -13.4596])\n",
      "    Grad: tensor([-0.1156,  0.6543])\n",
      "Epoch 898, Loss 4.0\n",
      "    Params: tensor([  4.6896, -13.4662])\n",
      "    Grad: tensor([-0.1154,  0.6532])\n",
      "Epoch 899, Loss 4.0\n",
      "    Params: tensor([  4.6908, -13.4727])\n",
      "    Grad: tensor([-0.1152,  0.6521])\n",
      "Epoch 900, Loss 4.0\n",
      "    Params: tensor([  4.6919, -13.4792])\n",
      "    Grad: tensor([-0.1150,  0.6510])\n",
      "Epoch 901, Loss 4.0\n",
      "    Params: tensor([  4.6931, -13.4857])\n",
      "    Grad: tensor([-0.1148,  0.6499])\n",
      "Epoch 902, Loss 4.0\n",
      "    Params: tensor([  4.6942, -13.4922])\n",
      "    Grad: tensor([-0.1146,  0.6488])\n",
      "Epoch 903, Loss 4.0\n",
      "    Params: tensor([  4.6954, -13.4987])\n",
      "    Grad: tensor([-0.1144,  0.6477])\n",
      "Epoch 904, Loss 4.0\n",
      "    Params: tensor([  4.6965, -13.5051])\n",
      "    Grad: tensor([-0.1142,  0.6466])\n",
      "Epoch 905, Loss 4.0\n",
      "    Params: tensor([  4.6976, -13.5116])\n",
      "    Grad: tensor([-0.1140,  0.6455])\n",
      "Epoch 906, Loss 4.0\n",
      "    Params: tensor([  4.6988, -13.5180])\n",
      "    Grad: tensor([-0.1138,  0.6444])\n",
      "Epoch 907, Loss 4.0\n",
      "    Params: tensor([  4.6999, -13.5244])\n",
      "    Grad: tensor([-0.1136,  0.6433])\n",
      "Epoch 908, Loss 4.0\n",
      "    Params: tensor([  4.7010, -13.5309])\n",
      "    Grad: tensor([-0.1134,  0.6422])\n",
      "Epoch 909, Loss 4.0\n",
      "    Params: tensor([  4.7022, -13.5373])\n",
      "    Grad: tensor([-0.1133,  0.6411])\n",
      "Epoch 910, Loss 4.0\n",
      "    Params: tensor([  4.7033, -13.5437])\n",
      "    Grad: tensor([-0.1131,  0.6400])\n",
      "Epoch 911, Loss 4.0\n",
      "    Params: tensor([  4.7044, -13.5501])\n",
      "    Grad: tensor([-0.1129,  0.6389])\n",
      "Epoch 912, Loss 4.0\n",
      "    Params: tensor([  4.7056, -13.5564])\n",
      "    Grad: tensor([-0.1127,  0.6378])\n",
      "Epoch 913, Loss 4.0\n",
      "    Params: tensor([  4.7067, -13.5628])\n",
      "    Grad: tensor([-0.1125,  0.6368])\n",
      "Epoch 914, Loss 4.0\n",
      "    Params: tensor([  4.7078, -13.5692])\n",
      "    Grad: tensor([-0.1123,  0.6357])\n",
      "Epoch 915, Loss 4.0\n",
      "    Params: tensor([  4.7089, -13.5755])\n",
      "    Grad: tensor([-0.1121,  0.6346])\n",
      "Epoch 916, Loss 4.0\n",
      "    Params: tensor([  4.7101, -13.5819])\n",
      "    Grad: tensor([-0.1119,  0.6335])\n",
      "Epoch 917, Loss 4.0\n",
      "    Params: tensor([  4.7112, -13.5882])\n",
      "    Grad: tensor([-0.1117,  0.6324])\n",
      "Epoch 918, Loss 4.0\n",
      "    Params: tensor([  4.7123, -13.5945])\n",
      "    Grad: tensor([-0.1115,  0.6314])\n",
      "Epoch 919, Loss 4.0\n",
      "    Params: tensor([  4.7134, -13.6008])\n",
      "    Grad: tensor([-0.1113,  0.6303])\n",
      "Epoch 920, Loss 4.0\n",
      "    Params: tensor([  4.7145, -13.6071])\n",
      "    Grad: tensor([-0.1111,  0.6292])\n",
      "Epoch 921, Loss 4.0\n",
      "    Params: tensor([  4.7156, -13.6134])\n",
      "    Grad: tensor([-0.1110,  0.6282])\n",
      "Epoch 922, Loss 4.0\n",
      "    Params: tensor([  4.7167, -13.6196])\n",
      "    Grad: tensor([-0.1108,  0.6271])\n",
      "Epoch 923, Loss 4.0\n",
      "    Params: tensor([  4.7178, -13.6259])\n",
      "    Grad: tensor([-0.1106,  0.6260])\n",
      "Epoch 924, Loss 4.0\n",
      "    Params: tensor([  4.7189, -13.6321])\n",
      "    Grad: tensor([-0.1104,  0.6250])\n",
      "Epoch 925, Loss 4.0\n",
      "    Params: tensor([  4.7200, -13.6384])\n",
      "    Grad: tensor([-0.1102,  0.6239])\n",
      "Epoch 926, Loss 4.0\n",
      "    Params: tensor([  4.7211, -13.6446])\n",
      "    Grad: tensor([-0.1100,  0.6228])\n",
      "Epoch 927, Loss 4.0\n",
      "    Params: tensor([  4.7222, -13.6508])\n",
      "    Grad: tensor([-0.1098,  0.6218])\n",
      "Epoch 928, Loss 4.0\n",
      "    Params: tensor([  4.7233, -13.6570])\n",
      "    Grad: tensor([-0.1096,  0.6207])\n",
      "Epoch 929, Loss 4.0\n",
      "    Params: tensor([  4.7244, -13.6632])\n",
      "    Grad: tensor([-0.1095,  0.6197])\n",
      "Epoch 930, Loss 4.0\n",
      "    Params: tensor([  4.7255, -13.6694])\n",
      "    Grad: tensor([-0.1093,  0.6186])\n",
      "Epoch 931, Loss 4.0\n",
      "    Params: tensor([  4.7266, -13.6756])\n",
      "    Grad: tensor([-0.1091,  0.6176])\n",
      "Epoch 932, Loss 4.0\n",
      "    Params: tensor([  4.7277, -13.6818])\n",
      "    Grad: tensor([-0.1089,  0.6165])\n",
      "Epoch 933, Loss 4.0\n",
      "    Params: tensor([  4.7288, -13.6879])\n",
      "    Grad: tensor([-0.1087,  0.6155])\n",
      "Epoch 934, Loss 4.0\n",
      "    Params: tensor([  4.7299, -13.6941])\n",
      "    Grad: tensor([-0.1086,  0.6144])\n",
      "Epoch 935, Loss 4.0\n",
      "    Params: tensor([  4.7310, -13.7002])\n",
      "    Grad: tensor([-0.1084,  0.6134])\n",
      "Epoch 936, Loss 4.0\n",
      "    Params: tensor([  4.7320, -13.7063])\n",
      "    Grad: tensor([-0.1082,  0.6123])\n",
      "Epoch 937, Loss 4.0\n",
      "    Params: tensor([  4.7331, -13.7124])\n",
      "    Grad: tensor([-0.1080,  0.6113])\n",
      "Epoch 938, Loss 4.0\n",
      "    Params: tensor([  4.7342, -13.7185])\n",
      "    Grad: tensor([-0.1078,  0.6103])\n",
      "Epoch 939, Loss 4.0\n",
      "    Params: tensor([  4.7353, -13.7246])\n",
      "    Grad: tensor([-0.1076,  0.6092])\n",
      "Epoch 940, Loss 4.0\n",
      "    Params: tensor([  4.7363, -13.7307])\n",
      "    Grad: tensor([-0.1074,  0.6082])\n",
      "Epoch 941, Loss 4.0\n",
      "    Params: tensor([  4.7374, -13.7368])\n",
      "    Grad: tensor([-0.1072,  0.6072])\n",
      "Epoch 942, Loss 4.0\n",
      "    Params: tensor([  4.7385, -13.7428])\n",
      "    Grad: tensor([-0.1071,  0.6061])\n",
      "Epoch 943, Loss 4.0\n",
      "    Params: tensor([  4.7396, -13.7489])\n",
      "    Grad: tensor([-0.1069,  0.6051])\n",
      "Epoch 944, Loss 4.0\n",
      "    Params: tensor([  4.7406, -13.7549])\n",
      "    Grad: tensor([-0.1067,  0.6041])\n",
      "Epoch 945, Loss 4.0\n",
      "    Params: tensor([  4.7417, -13.7610])\n",
      "    Grad: tensor([-0.1065,  0.6030])\n",
      "Epoch 946, Loss 4.0\n",
      "    Params: tensor([  4.7428, -13.7670])\n",
      "    Grad: tensor([-0.1063,  0.6020])\n",
      "Epoch 947, Loss 4.0\n",
      "    Params: tensor([  4.7438, -13.7730])\n",
      "    Grad: tensor([-0.1062,  0.6010])\n",
      "Epoch 948, Loss 4.0\n",
      "    Params: tensor([  4.7449, -13.7790])\n",
      "    Grad: tensor([-0.1060,  0.6000])\n",
      "Epoch 949, Loss 4.0\n",
      "    Params: tensor([  4.7459, -13.7850])\n",
      "    Grad: tensor([-0.1058,  0.5989])\n",
      "Epoch 950, Loss 4.0\n",
      "    Params: tensor([  4.7470, -13.7910])\n",
      "    Grad: tensor([-0.1056,  0.5979])\n",
      "Epoch 951, Loss 4.0\n",
      "    Params: tensor([  4.7480, -13.7969])\n",
      "    Grad: tensor([-0.1055,  0.5969])\n",
      "Epoch 952, Loss 4.0\n",
      "    Params: tensor([  4.7491, -13.8029])\n",
      "    Grad: tensor([-0.1053,  0.5959])\n",
      "Epoch 953, Loss 4.0\n",
      "    Params: tensor([  4.7502, -13.8088])\n",
      "    Grad: tensor([-0.1051,  0.5949])\n",
      "Epoch 954, Loss 4.0\n",
      "    Params: tensor([  4.7512, -13.8148])\n",
      "    Grad: tensor([-0.1049,  0.5939])\n",
      "Epoch 955, Loss 4.0\n",
      "    Params: tensor([  4.7522, -13.8207])\n",
      "    Grad: tensor([-0.1047,  0.5929])\n",
      "Epoch 956, Loss 4.0\n",
      "    Params: tensor([  4.7533, -13.8266])\n",
      "    Grad: tensor([-0.1046,  0.5919])\n",
      "Epoch 957, Loss 4.0\n",
      "    Params: tensor([  4.7543, -13.8325])\n",
      "    Grad: tensor([-0.1044,  0.5909])\n",
      "Epoch 958, Loss 4.0\n",
      "    Params: tensor([  4.7554, -13.8384])\n",
      "    Grad: tensor([-0.1042,  0.5899])\n",
      "Epoch 959, Loss 4.0\n",
      "    Params: tensor([  4.7564, -13.8443])\n",
      "    Grad: tensor([-0.1040,  0.5888])\n",
      "Epoch 960, Loss 4.0\n",
      "    Params: tensor([  4.7575, -13.8502])\n",
      "    Grad: tensor([-0.1039,  0.5878])\n",
      "Epoch 961, Loss 4.0\n",
      "    Params: tensor([  4.7585, -13.8561])\n",
      "    Grad: tensor([-0.1037,  0.5869])\n",
      "Epoch 962, Loss 4.0\n",
      "    Params: tensor([  4.7595, -13.8619])\n",
      "    Grad: tensor([-0.1035,  0.5859])\n",
      "Epoch 963, Loss 4.0\n",
      "    Params: tensor([  4.7606, -13.8678])\n",
      "    Grad: tensor([-0.1033,  0.5849])\n",
      "Epoch 964, Loss 4.0\n",
      "    Params: tensor([  4.7616, -13.8736])\n",
      "    Grad: tensor([-0.1031,  0.5839])\n",
      "Epoch 965, Loss 4.0\n",
      "    Params: tensor([  4.7626, -13.8794])\n",
      "    Grad: tensor([-0.1030,  0.5829])\n",
      "Epoch 966, Loss 4.0\n",
      "    Params: tensor([  4.7637, -13.8853])\n",
      "    Grad: tensor([-0.1028,  0.5819])\n",
      "Epoch 967, Loss 4.0\n",
      "    Params: tensor([  4.7647, -13.8911])\n",
      "    Grad: tensor([-0.1026,  0.5809])\n",
      "Epoch 968, Loss 4.0\n",
      "    Params: tensor([  4.7657, -13.8969])\n",
      "    Grad: tensor([-0.1024,  0.5799])\n",
      "Epoch 969, Loss 4.0\n",
      "    Params: tensor([  4.7667, -13.9027])\n",
      "    Grad: tensor([-0.1023,  0.5789])\n",
      "Epoch 970, Loss 4.0\n",
      "    Params: tensor([  4.7677, -13.9084])\n",
      "    Grad: tensor([-0.1021,  0.5779])\n",
      "Epoch 971, Loss 4.0\n",
      "    Params: tensor([  4.7688, -13.9142])\n",
      "    Grad: tensor([-0.1019,  0.5770])\n",
      "Epoch 972, Loss 4.0\n",
      "    Params: tensor([  4.7698, -13.9200])\n",
      "    Grad: tensor([-0.1017,  0.5760])\n",
      "Epoch 973, Loss 4.0\n",
      "    Params: tensor([  4.7708, -13.9257])\n",
      "    Grad: tensor([-0.1016,  0.5750])\n",
      "Epoch 974, Loss 4.0\n",
      "    Params: tensor([  4.7718, -13.9315])\n",
      "    Grad: tensor([-0.1014,  0.5740])\n",
      "Epoch 975, Loss 4.0\n",
      "    Params: tensor([  4.7728, -13.9372])\n",
      "    Grad: tensor([-0.1012,  0.5730])\n",
      "Epoch 976, Loss 4.0\n",
      "    Params: tensor([  4.7738, -13.9429])\n",
      "    Grad: tensor([-0.1011,  0.5721])\n",
      "Epoch 977, Loss 4.0\n",
      "    Params: tensor([  4.7748, -13.9486])\n",
      "    Grad: tensor([-0.1009,  0.5711])\n",
      "Epoch 978, Loss 4.0\n",
      "    Params: tensor([  4.7759, -13.9543])\n",
      "    Grad: tensor([-0.1007,  0.5701])\n",
      "Epoch 979, Loss 4.0\n",
      "    Params: tensor([  4.7769, -13.9600])\n",
      "    Grad: tensor([-0.1005,  0.5692])\n",
      "Epoch 980, Loss 4.0\n",
      "    Params: tensor([  4.7779, -13.9657])\n",
      "    Grad: tensor([-0.1004,  0.5682])\n",
      "Epoch 981, Loss 4.0\n",
      "    Params: tensor([  4.7789, -13.9714])\n",
      "    Grad: tensor([-0.1002,  0.5672])\n",
      "Epoch 982, Loss 4.0\n",
      "    Params: tensor([  4.7799, -13.9770])\n",
      "    Grad: tensor([-0.1000,  0.5663])\n",
      "Epoch 983, Loss 4.0\n",
      "    Params: tensor([  4.7809, -13.9827])\n",
      "    Grad: tensor([-0.0999,  0.5653])\n",
      "Epoch 984, Loss 4.0\n",
      "    Params: tensor([  4.7819, -13.9883])\n",
      "    Grad: tensor([-0.0997,  0.5643])\n",
      "Epoch 985, Loss 4.0\n",
      "    Params: tensor([  4.7829, -13.9940])\n",
      "    Grad: tensor([-0.0995,  0.5634])\n",
      "Epoch 986, Loss 4.0\n",
      "    Params: tensor([  4.7838, -13.9996])\n",
      "    Grad: tensor([-0.0994,  0.5624])\n",
      "Epoch 987, Loss 4.0\n",
      "    Params: tensor([  4.7848, -14.0052])\n",
      "    Grad: tensor([-0.0992,  0.5615])\n",
      "Epoch 988, Loss 4.0\n",
      "    Params: tensor([  4.7858, -14.0108])\n",
      "    Grad: tensor([-0.0990,  0.5605])\n",
      "Epoch 989, Loss 4.0\n",
      "    Params: tensor([  4.7868, -14.0164])\n",
      "    Grad: tensor([-0.0989,  0.5596])\n",
      "Epoch 990, Loss 4.0\n",
      "    Params: tensor([  4.7878, -14.0220])\n",
      "    Grad: tensor([-0.0987,  0.5586])\n",
      "Epoch 991, Loss 4.0\n",
      "    Params: tensor([  4.7888, -14.0276])\n",
      "    Grad: tensor([-0.0985,  0.5577])\n",
      "Epoch 992, Loss 4.0\n",
      "    Params: tensor([  4.7898, -14.0331])\n",
      "    Grad: tensor([-0.0983,  0.5567])\n",
      "Epoch 993, Loss 4.0\n",
      "    Params: tensor([  4.7908, -14.0387])\n",
      "    Grad: tensor([-0.0982,  0.5558])\n",
      "Epoch 994, Loss 4.0\n",
      "    Params: tensor([  4.7917, -14.0442])\n",
      "    Grad: tensor([-0.0980,  0.5548])\n",
      "Epoch 995, Loss 4.0\n",
      "    Params: tensor([  4.7927, -14.0498])\n",
      "    Grad: tensor([-0.0979,  0.5539])\n",
      "Epoch 996, Loss 4.0\n",
      "    Params: tensor([  4.7937, -14.0553])\n",
      "    Grad: tensor([-0.0977,  0.5529])\n",
      "Epoch 997, Loss 4.0\n",
      "    Params: tensor([  4.7947, -14.0608])\n",
      "    Grad: tensor([-0.0975,  0.5520])\n",
      "Epoch 998, Loss 4.0\n",
      "    Params: tensor([  4.7956, -14.0663])\n",
      "    Grad: tensor([-0.0973,  0.5511])\n",
      "Epoch 999, Loss 4.0\n",
      "    Params: tensor([  4.7966, -14.0718])\n",
      "    Grad: tensor([-0.0972,  0.5501])\n",
      "Epoch 1000, Loss 4.0\n",
      "    Params: tensor([  4.7976, -14.0773])\n",
      "    Grad: tensor([-0.0970,  0.5492])\n",
      "Epoch 1001, Loss 4.0\n",
      "    Params: tensor([  4.7985, -14.0828])\n",
      "    Grad: tensor([-0.0968,  0.5483])\n",
      "Epoch 1002, Loss 4.0\n",
      "    Params: tensor([  4.7995, -14.0883])\n",
      "    Grad: tensor([-0.0967,  0.5473])\n",
      "Epoch 1003, Loss 4.0\n",
      "    Params: tensor([  4.8005, -14.0938])\n",
      "    Grad: tensor([-0.0965,  0.5464])\n",
      "Epoch 1004, Loss 4.0\n",
      "    Params: tensor([  4.8014, -14.0992])\n",
      "    Grad: tensor([-0.0964,  0.5455])\n",
      "Epoch 1005, Loss 4.0\n",
      "    Params: tensor([  4.8024, -14.1047])\n",
      "    Grad: tensor([-0.0962,  0.5446])\n",
      "Epoch 1006, Loss 4.0\n",
      "    Params: tensor([  4.8034, -14.1101])\n",
      "    Grad: tensor([-0.0960,  0.5436])\n",
      "Epoch 1007, Loss 4.0\n",
      "    Params: tensor([  4.8043, -14.1155])\n",
      "    Grad: tensor([-0.0959,  0.5427])\n",
      "Epoch 1008, Loss 4.0\n",
      "    Params: tensor([  4.8053, -14.1209])\n",
      "    Grad: tensor([-0.0957,  0.5418])\n",
      "Epoch 1009, Loss 4.0\n",
      "    Params: tensor([  4.8062, -14.1263])\n",
      "    Grad: tensor([-0.0955,  0.5409])\n",
      "Epoch 1010, Loss 4.0\n",
      "    Params: tensor([  4.8072, -14.1317])\n",
      "    Grad: tensor([-0.0954,  0.5399])\n",
      "Epoch 1011, Loss 4.0\n",
      "    Params: tensor([  4.8081, -14.1371])\n",
      "    Grad: tensor([-0.0952,  0.5390])\n",
      "Epoch 1012, Loss 4.0\n",
      "    Params: tensor([  4.8091, -14.1425])\n",
      "    Grad: tensor([-0.0950,  0.5381])\n",
      "Epoch 1013, Loss 4.0\n",
      "    Params: tensor([  4.8100, -14.1479])\n",
      "    Grad: tensor([-0.0949,  0.5372])\n",
      "Epoch 1014, Loss 4.0\n",
      "    Params: tensor([  4.8110, -14.1533])\n",
      "    Grad: tensor([-0.0947,  0.5363])\n",
      "Epoch 1015, Loss 4.0\n",
      "    Params: tensor([  4.8119, -14.1586])\n",
      "    Grad: tensor([-0.0946,  0.5354])\n",
      "Epoch 1016, Loss 4.0\n",
      "    Params: tensor([  4.8129, -14.1639])\n",
      "    Grad: tensor([-0.0944,  0.5345])\n",
      "Epoch 1017, Loss 4.0\n",
      "    Params: tensor([  4.8138, -14.1693])\n",
      "    Grad: tensor([-0.0942,  0.5336])\n",
      "Epoch 1018, Loss 4.0\n",
      "    Params: tensor([  4.8148, -14.1746])\n",
      "    Grad: tensor([-0.0941,  0.5326])\n",
      "Epoch 1019, Loss 4.0\n",
      "    Params: tensor([  4.8157, -14.1799])\n",
      "    Grad: tensor([-0.0939,  0.5317])\n",
      "Epoch 1020, Loss 4.0\n",
      "    Params: tensor([  4.8166, -14.1852])\n",
      "    Grad: tensor([-0.0938,  0.5308])\n",
      "Epoch 1021, Loss 4.0\n",
      "    Params: tensor([  4.8176, -14.1905])\n",
      "    Grad: tensor([-0.0936,  0.5299])\n",
      "Epoch 1022, Loss 4.0\n",
      "    Params: tensor([  4.8185, -14.1958])\n",
      "    Grad: tensor([-0.0935,  0.5290])\n",
      "Epoch 1023, Loss 4.0\n",
      "    Params: tensor([  4.8194, -14.2011])\n",
      "    Grad: tensor([-0.0933,  0.5281])\n",
      "Epoch 1024, Loss 4.0\n",
      "    Params: tensor([  4.8204, -14.2064])\n",
      "    Grad: tensor([-0.0931,  0.5272])\n",
      "Epoch 1025, Loss 4.0\n",
      "    Params: tensor([  4.8213, -14.2116])\n",
      "    Grad: tensor([-0.0930,  0.5263])\n",
      "Epoch 1026, Loss 4.0\n",
      "    Params: tensor([  4.8222, -14.2169])\n",
      "    Grad: tensor([-0.0928,  0.5255])\n",
      "Epoch 1027, Loss 4.0\n",
      "    Params: tensor([  4.8232, -14.2221])\n",
      "    Grad: tensor([-0.0927,  0.5246])\n",
      "Epoch 1028, Loss 4.0\n",
      "    Params: tensor([  4.8241, -14.2274])\n",
      "    Grad: tensor([-0.0925,  0.5237])\n",
      "Epoch 1029, Loss 4.0\n",
      "    Params: tensor([  4.8250, -14.2326])\n",
      "    Grad: tensor([-0.0923,  0.5228])\n",
      "Epoch 1030, Loss 4.0\n",
      "    Params: tensor([  4.8259, -14.2378])\n",
      "    Grad: tensor([-0.0922,  0.5219])\n",
      "Epoch 1031, Loss 4.0\n",
      "    Params: tensor([  4.8269, -14.2430])\n",
      "    Grad: tensor([-0.0920,  0.5210])\n",
      "Epoch 1032, Loss 4.0\n",
      "    Params: tensor([  4.8278, -14.2482])\n",
      "    Grad: tensor([-0.0919,  0.5201])\n",
      "Epoch 1033, Loss 4.0\n",
      "    Params: tensor([  4.8287, -14.2534])\n",
      "    Grad: tensor([-0.0917,  0.5192])\n",
      "Epoch 1034, Loss 4.0\n",
      "    Params: tensor([  4.8296, -14.2586])\n",
      "    Grad: tensor([-0.0916,  0.5183])\n",
      "Epoch 1035, Loss 4.0\n",
      "    Params: tensor([  4.8305, -14.2638])\n",
      "    Grad: tensor([-0.0914,  0.5175])\n",
      "Epoch 1036, Loss 4.0\n",
      "    Params: tensor([  4.8314, -14.2690])\n",
      "    Grad: tensor([-0.0913,  0.5166])\n",
      "Epoch 1037, Loss 4.0\n",
      "    Params: tensor([  4.8323, -14.2741])\n",
      "    Grad: tensor([-0.0911,  0.5157])\n",
      "Epoch 1038, Loss 4.0\n",
      "    Params: tensor([  4.8333, -14.2793])\n",
      "    Grad: tensor([-0.0909,  0.5148])\n",
      "Epoch 1039, Loss 4.0\n",
      "    Params: tensor([  4.8342, -14.2844])\n",
      "    Grad: tensor([-0.0908,  0.5140])\n",
      "Epoch 1040, Loss 4.0\n",
      "    Params: tensor([  4.8351, -14.2895])\n",
      "    Grad: tensor([-0.0906,  0.5131])\n",
      "Epoch 1041, Loss 4.0\n",
      "    Params: tensor([  4.8360, -14.2947])\n",
      "    Grad: tensor([-0.0905,  0.5122])\n",
      "Epoch 1042, Loss 4.0\n",
      "    Params: tensor([  4.8369, -14.2998])\n",
      "    Grad: tensor([-0.0903,  0.5113])\n",
      "Epoch 1043, Loss 4.0\n",
      "    Params: tensor([  4.8378, -14.3049])\n",
      "    Grad: tensor([-0.0902,  0.5105])\n",
      "Epoch 1044, Loss 4.0\n",
      "    Params: tensor([  4.8387, -14.3100])\n",
      "    Grad: tensor([-0.0900,  0.5096])\n",
      "Epoch 1045, Loss 4.0\n",
      "    Params: tensor([  4.8396, -14.3151])\n",
      "    Grad: tensor([-0.0899,  0.5087])\n",
      "Epoch 1046, Loss 4.0\n",
      "    Params: tensor([  4.8405, -14.3201])\n",
      "    Grad: tensor([-0.0897,  0.5079])\n",
      "Epoch 1047, Loss 4.0\n",
      "    Params: tensor([  4.8414, -14.3252])\n",
      "    Grad: tensor([-0.0896,  0.5070])\n",
      "Epoch 1048, Loss 4.0\n",
      "    Params: tensor([  4.8423, -14.3303])\n",
      "    Grad: tensor([-0.0894,  0.5062])\n",
      "Epoch 1049, Loss 4.0\n",
      "    Params: tensor([  4.8432, -14.3353])\n",
      "    Grad: tensor([-0.0893,  0.5053])\n",
      "Epoch 1050, Loss 4.0\n",
      "    Params: tensor([  4.8440, -14.3404])\n",
      "    Grad: tensor([-0.0891,  0.5044])\n",
      "Epoch 1051, Loss 4.0\n",
      "    Params: tensor([  4.8449, -14.3454])\n",
      "    Grad: tensor([-0.0889,  0.5036])\n",
      "Epoch 1052, Loss 4.0\n",
      "    Params: tensor([  4.8458, -14.3504])\n",
      "    Grad: tensor([-0.0888,  0.5027])\n",
      "Epoch 1053, Loss 4.0\n",
      "    Params: tensor([  4.8467, -14.3554])\n",
      "    Grad: tensor([-0.0886,  0.5019])\n",
      "Epoch 1054, Loss 4.0\n",
      "    Params: tensor([  4.8476, -14.3605])\n",
      "    Grad: tensor([-0.0885,  0.5010])\n",
      "Epoch 1055, Loss 4.0\n",
      "    Params: tensor([  4.8485, -14.3655])\n",
      "    Grad: tensor([-0.0884,  0.5002])\n",
      "Epoch 1056, Loss 4.0\n",
      "    Params: tensor([  4.8494, -14.3705])\n",
      "    Grad: tensor([-0.0882,  0.4993])\n",
      "Epoch 1057, Loss 4.0\n",
      "    Params: tensor([  4.8502, -14.3754])\n",
      "    Grad: tensor([-0.0881,  0.4985])\n",
      "Epoch 1058, Loss 4.0\n",
      "    Params: tensor([  4.8511, -14.3804])\n",
      "    Grad: tensor([-0.0879,  0.4976])\n",
      "Epoch 1059, Loss 4.0\n",
      "    Params: tensor([  4.8520, -14.3854])\n",
      "    Grad: tensor([-0.0878,  0.4968])\n",
      "Epoch 1060, Loss 4.0\n",
      "    Params: tensor([  4.8529, -14.3903])\n",
      "    Grad: tensor([-0.0876,  0.4959])\n",
      "Epoch 1061, Loss 4.0\n",
      "    Params: tensor([  4.8537, -14.3953])\n",
      "    Grad: tensor([-0.0875,  0.4951])\n",
      "Epoch 1062, Loss 4.0\n",
      "    Params: tensor([  4.8546, -14.4002])\n",
      "    Grad: tensor([-0.0873,  0.4943])\n",
      "Epoch 1063, Loss 4.0\n",
      "    Params: tensor([  4.8555, -14.4052])\n",
      "    Grad: tensor([-0.0872,  0.4934])\n",
      "Epoch 1064, Loss 4.0\n",
      "    Params: tensor([  4.8564, -14.4101])\n",
      "    Grad: tensor([-0.0870,  0.4926])\n",
      "Epoch 1065, Loss 4.0\n",
      "    Params: tensor([  4.8572, -14.4150])\n",
      "    Grad: tensor([-0.0869,  0.4917])\n",
      "Epoch 1066, Loss 4.0\n",
      "    Params: tensor([  4.8581, -14.4199])\n",
      "    Grad: tensor([-0.0867,  0.4909])\n",
      "Epoch 1067, Loss 4.0\n",
      "    Params: tensor([  4.8590, -14.4248])\n",
      "    Grad: tensor([-0.0866,  0.4901])\n",
      "Epoch 1068, Loss 4.0\n",
      "    Params: tensor([  4.8598, -14.4297])\n",
      "    Grad: tensor([-0.0864,  0.4892])\n",
      "Epoch 1069, Loss 4.0\n",
      "    Params: tensor([  4.8607, -14.4346])\n",
      "    Grad: tensor([-0.0863,  0.4884])\n",
      "Epoch 1070, Loss 4.0\n",
      "    Params: tensor([  4.8616, -14.4395])\n",
      "    Grad: tensor([-0.0861,  0.4876])\n",
      "Epoch 1071, Loss 4.0\n",
      "    Params: tensor([  4.8624, -14.4443])\n",
      "    Grad: tensor([-0.0860,  0.4867])\n",
      "Epoch 1072, Loss 4.0\n",
      "    Params: tensor([  4.8633, -14.4492])\n",
      "    Grad: tensor([-0.0859,  0.4859])\n",
      "Epoch 1073, Loss 4.0\n",
      "    Params: tensor([  4.8641, -14.4541])\n",
      "    Grad: tensor([-0.0857,  0.4851])\n",
      "Epoch 1074, Loss 4.0\n",
      "    Params: tensor([  4.8650, -14.4589])\n",
      "    Grad: tensor([-0.0855,  0.4843])\n",
      "Epoch 1075, Loss 4.0\n",
      "    Params: tensor([  4.8658, -14.4637])\n",
      "    Grad: tensor([-0.0854,  0.4834])\n",
      "Epoch 1076, Loss 4.0\n",
      "    Params: tensor([  4.8667, -14.4686])\n",
      "    Grad: tensor([-0.0853,  0.4826])\n",
      "Epoch 1077, Loss 4.0\n",
      "    Params: tensor([  4.8675, -14.4734])\n",
      "    Grad: tensor([-0.0851,  0.4818])\n",
      "Epoch 1078, Loss 4.0\n",
      "    Params: tensor([  4.8684, -14.4782])\n",
      "    Grad: tensor([-0.0850,  0.4810])\n",
      "Epoch 1079, Loss 4.0\n",
      "    Params: tensor([  4.8692, -14.4830])\n",
      "    Grad: tensor([-0.0848,  0.4802])\n",
      "Epoch 1080, Loss 4.0\n",
      "    Params: tensor([  4.8701, -14.4878])\n",
      "    Grad: tensor([-0.0847,  0.4794])\n",
      "Epoch 1081, Loss 4.0\n",
      "    Params: tensor([  4.8709, -14.4926])\n",
      "    Grad: tensor([-0.0845,  0.4785])\n",
      "Epoch 1082, Loss 4.0\n",
      "    Params: tensor([  4.8718, -14.4973])\n",
      "    Grad: tensor([-0.0844,  0.4777])\n",
      "Epoch 1083, Loss 4.0\n",
      "    Params: tensor([  4.8726, -14.5021])\n",
      "    Grad: tensor([-0.0842,  0.4769])\n",
      "Epoch 1084, Loss 4.0\n",
      "    Params: tensor([  4.8735, -14.5069])\n",
      "    Grad: tensor([-0.0841,  0.4761])\n",
      "Epoch 1085, Loss 4.0\n",
      "    Params: tensor([  4.8743, -14.5116])\n",
      "    Grad: tensor([-0.0840,  0.4753])\n",
      "Epoch 1086, Loss 4.0\n",
      "    Params: tensor([  4.8751, -14.5164])\n",
      "    Grad: tensor([-0.0838,  0.4745])\n",
      "Epoch 1087, Loss 4.0\n",
      "    Params: tensor([  4.8760, -14.5211])\n",
      "    Grad: tensor([-0.0837,  0.4737])\n",
      "Epoch 1088, Loss 4.0\n",
      "    Params: tensor([  4.8768, -14.5258])\n",
      "    Grad: tensor([-0.0835,  0.4729])\n",
      "Epoch 1089, Loss 4.0\n",
      "    Params: tensor([  4.8776, -14.5306])\n",
      "    Grad: tensor([-0.0834,  0.4721])\n",
      "Epoch 1090, Loss 4.0\n",
      "    Params: tensor([  4.8785, -14.5353])\n",
      "    Grad: tensor([-0.0833,  0.4713])\n",
      "Epoch 1091, Loss 4.0\n",
      "    Params: tensor([  4.8793, -14.5400])\n",
      "    Grad: tensor([-0.0831,  0.4705])\n",
      "Epoch 1092, Loss 4.0\n",
      "    Params: tensor([  4.8801, -14.5447])\n",
      "    Grad: tensor([-0.0830,  0.4697])\n",
      "Epoch 1093, Loss 4.0\n",
      "    Params: tensor([  4.8810, -14.5494])\n",
      "    Grad: tensor([-0.0828,  0.4689])\n",
      "Epoch 1094, Loss 4.0\n",
      "    Params: tensor([  4.8818, -14.5540])\n",
      "    Grad: tensor([-0.0827,  0.4681])\n",
      "Epoch 1095, Loss 4.0\n",
      "    Params: tensor([  4.8826, -14.5587])\n",
      "    Grad: tensor([-0.0826,  0.4673])\n",
      "Epoch 1096, Loss 4.0\n",
      "    Params: tensor([  4.8834, -14.5634])\n",
      "    Grad: tensor([-0.0824,  0.4665])\n",
      "Epoch 1097, Loss 4.0\n",
      "    Params: tensor([  4.8843, -14.5680])\n",
      "    Grad: tensor([-0.0823,  0.4657])\n",
      "Epoch 1098, Loss 4.0\n",
      "    Params: tensor([  4.8851, -14.5727])\n",
      "    Grad: tensor([-0.0821,  0.4649])\n",
      "Epoch 1099, Loss 4.0\n",
      "    Params: tensor([  4.8859, -14.5773])\n",
      "    Grad: tensor([-0.0820,  0.4641])\n",
      "Epoch 1100, Loss 4.0\n",
      "    Params: tensor([  4.8867, -14.5820])\n",
      "    Grad: tensor([-0.0818,  0.4633])\n",
      "Epoch 1101, Loss 4.0\n",
      "    Params: tensor([  4.8875, -14.5866])\n",
      "    Grad: tensor([-0.0817,  0.4625])\n",
      "Epoch 1102, Loss 4.0\n",
      "    Params: tensor([  4.8884, -14.5912])\n",
      "    Grad: tensor([-0.0816,  0.4618])\n",
      "Epoch 1103, Loss 4.0\n",
      "    Params: tensor([  4.8892, -14.5958])\n",
      "    Grad: tensor([-0.0814,  0.4610])\n",
      "Epoch 1104, Loss 4.0\n",
      "    Params: tensor([  4.8900, -14.6004])\n",
      "    Grad: tensor([-0.0813,  0.4602])\n",
      "Epoch 1105, Loss 4.0\n",
      "    Params: tensor([  4.8908, -14.6050])\n",
      "    Grad: tensor([-0.0812,  0.4594])\n",
      "Epoch 1106, Loss 4.0\n",
      "    Params: tensor([  4.8916, -14.6096])\n",
      "    Grad: tensor([-0.0810,  0.4586])\n",
      "Epoch 1107, Loss 4.0\n",
      "    Params: tensor([  4.8924, -14.6142])\n",
      "    Grad: tensor([-0.0809,  0.4578])\n",
      "Epoch 1108, Loss 4.0\n",
      "    Params: tensor([  4.8932, -14.6187])\n",
      "    Grad: tensor([-0.0808,  0.4571])\n",
      "Epoch 1109, Loss 4.0\n",
      "    Params: tensor([  4.8940, -14.6233])\n",
      "    Grad: tensor([-0.0806,  0.4563])\n",
      "Epoch 1110, Loss 4.0\n",
      "    Params: tensor([  4.8948, -14.6279])\n",
      "    Grad: tensor([-0.0805,  0.4555])\n",
      "Epoch 1111, Loss 4.0\n",
      "    Params: tensor([  4.8956, -14.6324])\n",
      "    Grad: tensor([-0.0803,  0.4547])\n",
      "Epoch 1112, Loss 4.0\n",
      "    Params: tensor([  4.8964, -14.6369])\n",
      "    Grad: tensor([-0.0802,  0.4540])\n",
      "Epoch 1113, Loss 4.0\n",
      "    Params: tensor([  4.8972, -14.6415])\n",
      "    Grad: tensor([-0.0801,  0.4532])\n",
      "Epoch 1114, Loss 4.0\n",
      "    Params: tensor([  4.8980, -14.6460])\n",
      "    Grad: tensor([-0.0799,  0.4524])\n",
      "Epoch 1115, Loss 4.0\n",
      "    Params: tensor([  4.8988, -14.6505])\n",
      "    Grad: tensor([-0.0798,  0.4517])\n",
      "Epoch 1116, Loss 4.0\n",
      "    Params: tensor([  4.8996, -14.6550])\n",
      "    Grad: tensor([-0.0797,  0.4509])\n",
      "Epoch 1117, Loss 4.0\n",
      "    Params: tensor([  4.9004, -14.6595])\n",
      "    Grad: tensor([-0.0795,  0.4501])\n",
      "Epoch 1118, Loss 4.0\n",
      "    Params: tensor([  4.9012, -14.6640])\n",
      "    Grad: tensor([-0.0794,  0.4494])\n",
      "Epoch 1119, Loss 4.0\n",
      "    Params: tensor([  4.9020, -14.6685])\n",
      "    Grad: tensor([-0.0792,  0.4486])\n",
      "Epoch 1120, Loss 4.0\n",
      "    Params: tensor([  4.9028, -14.6730])\n",
      "    Grad: tensor([-0.0791,  0.4478])\n",
      "Epoch 1121, Loss 4.0\n",
      "    Params: tensor([  4.9036, -14.6775])\n",
      "    Grad: tensor([-0.0790,  0.4471])\n",
      "Epoch 1122, Loss 4.0\n",
      "    Params: tensor([  4.9044, -14.6819])\n",
      "    Grad: tensor([-0.0789,  0.4463])\n",
      "Epoch 1123, Loss 4.0\n",
      "    Params: tensor([  4.9052, -14.6864])\n",
      "    Grad: tensor([-0.0787,  0.4456])\n",
      "Epoch 1124, Loss 4.0\n",
      "    Params: tensor([  4.9060, -14.6908])\n",
      "    Grad: tensor([-0.0786,  0.4448])\n",
      "Epoch 1125, Loss 4.0\n",
      "    Params: tensor([  4.9067, -14.6953])\n",
      "    Grad: tensor([-0.0784,  0.4441])\n",
      "Epoch 1126, Loss 4.0\n",
      "    Params: tensor([  4.9075, -14.6997])\n",
      "    Grad: tensor([-0.0783,  0.4433])\n",
      "Epoch 1127, Loss 4.0\n",
      "    Params: tensor([  4.9083, -14.7041])\n",
      "    Grad: tensor([-0.0782,  0.4425])\n",
      "Epoch 1128, Loss 4.0\n",
      "    Params: tensor([  4.9091, -14.7085])\n",
      "    Grad: tensor([-0.0780,  0.4418])\n",
      "Epoch 1129, Loss 4.0\n",
      "    Params: tensor([  4.9099, -14.7130])\n",
      "    Grad: tensor([-0.0779,  0.4410])\n",
      "Epoch 1130, Loss 4.0\n",
      "    Params: tensor([  4.9106, -14.7174])\n",
      "    Grad: tensor([-0.0778,  0.4403])\n",
      "Epoch 1131, Loss 4.0\n",
      "    Params: tensor([  4.9114, -14.7218])\n",
      "    Grad: tensor([-0.0776,  0.4395])\n",
      "Epoch 1132, Loss 4.0\n",
      "    Params: tensor([  4.9122, -14.7261])\n",
      "    Grad: tensor([-0.0775,  0.4388])\n",
      "Epoch 1133, Loss 4.0\n",
      "    Params: tensor([  4.9130, -14.7305])\n",
      "    Grad: tensor([-0.0774,  0.4381])\n",
      "Epoch 1134, Loss 4.0\n",
      "    Params: tensor([  4.9137, -14.7349])\n",
      "    Grad: tensor([-0.0772,  0.4373])\n",
      "Epoch 1135, Loss 4.0\n",
      "    Params: tensor([  4.9145, -14.7393])\n",
      "    Grad: tensor([-0.0771,  0.4366])\n",
      "Epoch 1136, Loss 4.0\n",
      "    Params: tensor([  4.9153, -14.7436])\n",
      "    Grad: tensor([-0.0770,  0.4358])\n",
      "Epoch 1137, Loss 4.0\n",
      "    Params: tensor([  4.9160, -14.7480])\n",
      "    Grad: tensor([-0.0769,  0.4351])\n",
      "Epoch 1138, Loss 4.0\n",
      "    Params: tensor([  4.9168, -14.7523])\n",
      "    Grad: tensor([-0.0767,  0.4343])\n",
      "Epoch 1139, Loss 3.0\n",
      "    Params: tensor([  4.9176, -14.7566])\n",
      "    Grad: tensor([-0.0766,  0.4336])\n",
      "Epoch 1140, Loss 3.0\n",
      "    Params: tensor([  4.9183, -14.7610])\n",
      "    Grad: tensor([-0.0765,  0.4329])\n",
      "Epoch 1141, Loss 3.0\n",
      "    Params: tensor([  4.9191, -14.7653])\n",
      "    Grad: tensor([-0.0763,  0.4321])\n",
      "Epoch 1142, Loss 3.0\n",
      "    Params: tensor([  4.9199, -14.7696])\n",
      "    Grad: tensor([-0.0762,  0.4314])\n",
      "Epoch 1143, Loss 3.0\n",
      "    Params: tensor([  4.9206, -14.7739])\n",
      "    Grad: tensor([-0.0761,  0.4307])\n",
      "Epoch 1144, Loss 3.0\n",
      "    Params: tensor([  4.9214, -14.7782])\n",
      "    Grad: tensor([-0.0760,  0.4299])\n",
      "Epoch 1145, Loss 3.0\n",
      "    Params: tensor([  4.9222, -14.7825])\n",
      "    Grad: tensor([-0.0758,  0.4292])\n",
      "Epoch 1146, Loss 3.0\n",
      "    Params: tensor([  4.9229, -14.7868])\n",
      "    Grad: tensor([-0.0757,  0.4285])\n",
      "Epoch 1147, Loss 3.0\n",
      "    Params: tensor([  4.9237, -14.7911])\n",
      "    Grad: tensor([-0.0756,  0.4277])\n",
      "Epoch 1148, Loss 3.0\n",
      "    Params: tensor([  4.9244, -14.7953])\n",
      "    Grad: tensor([-0.0754,  0.4270])\n",
      "Epoch 1149, Loss 3.0\n",
      "    Params: tensor([  4.9252, -14.7996])\n",
      "    Grad: tensor([-0.0753,  0.4263])\n",
      "Epoch 1150, Loss 3.0\n",
      "    Params: tensor([  4.9259, -14.8039])\n",
      "    Grad: tensor([-0.0752,  0.4256])\n",
      "Epoch 1151, Loss 3.0\n",
      "    Params: tensor([  4.9267, -14.8081])\n",
      "    Grad: tensor([-0.0750,  0.4249])\n",
      "Epoch 1152, Loss 3.0\n",
      "    Params: tensor([  4.9274, -14.8124])\n",
      "    Grad: tensor([-0.0749,  0.4241])\n",
      "Epoch 1153, Loss 3.0\n",
      "    Params: tensor([  4.9282, -14.8166])\n",
      "    Grad: tensor([-0.0748,  0.4234])\n",
      "Epoch 1154, Loss 3.0\n",
      "    Params: tensor([  4.9289, -14.8208])\n",
      "    Grad: tensor([-0.0747,  0.4227])\n",
      "Epoch 1155, Loss 3.0\n",
      "    Params: tensor([  4.9297, -14.8250])\n",
      "    Grad: tensor([-0.0745,  0.4220])\n",
      "Epoch 1156, Loss 3.0\n",
      "    Params: tensor([  4.9304, -14.8292])\n",
      "    Grad: tensor([-0.0744,  0.4213])\n",
      "Epoch 1157, Loss 3.0\n",
      "    Params: tensor([  4.9312, -14.8334])\n",
      "    Grad: tensor([-0.0743,  0.4205])\n",
      "Epoch 1158, Loss 3.0\n",
      "    Params: tensor([  4.9319, -14.8376])\n",
      "    Grad: tensor([-0.0742,  0.4198])\n",
      "Epoch 1159, Loss 3.0\n",
      "    Params: tensor([  4.9326, -14.8418])\n",
      "    Grad: tensor([-0.0740,  0.4191])\n",
      "Epoch 1160, Loss 3.0\n",
      "    Params: tensor([  4.9334, -14.8460])\n",
      "    Grad: tensor([-0.0739,  0.4184])\n",
      "Epoch 1161, Loss 3.0\n",
      "    Params: tensor([  4.9341, -14.8502])\n",
      "    Grad: tensor([-0.0738,  0.4177])\n",
      "Epoch 1162, Loss 3.0\n",
      "    Params: tensor([  4.9348, -14.8544])\n",
      "    Grad: tensor([-0.0737,  0.4170])\n",
      "Epoch 1163, Loss 3.0\n",
      "    Params: tensor([  4.9356, -14.8585])\n",
      "    Grad: tensor([-0.0735,  0.4163])\n",
      "Epoch 1164, Loss 3.0\n",
      "    Params: tensor([  4.9363, -14.8627])\n",
      "    Grad: tensor([-0.0734,  0.4156])\n",
      "Epoch 1165, Loss 3.0\n",
      "    Params: tensor([  4.9370, -14.8668])\n",
      "    Grad: tensor([-0.0733,  0.4149])\n",
      "Epoch 1166, Loss 3.0\n",
      "    Params: tensor([  4.9378, -14.8710])\n",
      "    Grad: tensor([-0.0731,  0.4142])\n",
      "Epoch 1167, Loss 3.0\n",
      "    Params: tensor([  4.9385, -14.8751])\n",
      "    Grad: tensor([-0.0730,  0.4134])\n",
      "Epoch 1168, Loss 3.0\n",
      "    Params: tensor([  4.9392, -14.8792])\n",
      "    Grad: tensor([-0.0729,  0.4127])\n",
      "Epoch 1169, Loss 3.0\n",
      "    Params: tensor([  4.9400, -14.8834])\n",
      "    Grad: tensor([-0.0728,  0.4120])\n",
      "Epoch 1170, Loss 3.0\n",
      "    Params: tensor([  4.9407, -14.8875])\n",
      "    Grad: tensor([-0.0727,  0.4113])\n",
      "Epoch 1171, Loss 3.0\n",
      "    Params: tensor([  4.9414, -14.8916])\n",
      "    Grad: tensor([-0.0725,  0.4106])\n",
      "Epoch 1172, Loss 3.0\n",
      "    Params: tensor([  4.9421, -14.8957])\n",
      "    Grad: tensor([-0.0724,  0.4099])\n",
      "Epoch 1173, Loss 3.0\n",
      "    Params: tensor([  4.9429, -14.8998])\n",
      "    Grad: tensor([-0.0723,  0.4092])\n",
      "Epoch 1174, Loss 3.0\n",
      "    Params: tensor([  4.9436, -14.9039])\n",
      "    Grad: tensor([-0.0722,  0.4086])\n",
      "Epoch 1175, Loss 3.0\n",
      "    Params: tensor([  4.9443, -14.9079])\n",
      "    Grad: tensor([-0.0720,  0.4079])\n",
      "Epoch 1176, Loss 3.0\n",
      "    Params: tensor([  4.9450, -14.9120])\n",
      "    Grad: tensor([-0.0719,  0.4072])\n",
      "Epoch 1177, Loss 3.0\n",
      "    Params: tensor([  4.9457, -14.9161])\n",
      "    Grad: tensor([-0.0718,  0.4065])\n",
      "Epoch 1178, Loss 3.0\n",
      "    Params: tensor([  4.9465, -14.9201])\n",
      "    Grad: tensor([-0.0717,  0.4058])\n",
      "Epoch 1179, Loss 3.0\n",
      "    Params: tensor([  4.9472, -14.9242])\n",
      "    Grad: tensor([-0.0716,  0.4051])\n",
      "Epoch 1180, Loss 3.0\n",
      "    Params: tensor([  4.9479, -14.9282])\n",
      "    Grad: tensor([-0.0714,  0.4044])\n",
      "Epoch 1181, Loss 3.0\n",
      "    Params: tensor([  4.9486, -14.9323])\n",
      "    Grad: tensor([-0.0713,  0.4037])\n",
      "Epoch 1182, Loss 3.0\n",
      "    Params: tensor([  4.9493, -14.9363])\n",
      "    Grad: tensor([-0.0712,  0.4030])\n",
      "Epoch 1183, Loss 3.0\n",
      "    Params: tensor([  4.9500, -14.9403])\n",
      "    Grad: tensor([-0.0711,  0.4024])\n",
      "Epoch 1184, Loss 3.0\n",
      "    Params: tensor([  4.9507, -14.9443])\n",
      "    Grad: tensor([-0.0709,  0.4017])\n",
      "Epoch 1185, Loss 3.0\n",
      "    Params: tensor([  4.9514, -14.9483])\n",
      "    Grad: tensor([-0.0708,  0.4010])\n",
      "Epoch 1186, Loss 3.0\n",
      "    Params: tensor([  4.9522, -14.9523])\n",
      "    Grad: tensor([-0.0707,  0.4003])\n",
      "Epoch 1187, Loss 3.0\n",
      "    Params: tensor([  4.9529, -14.9563])\n",
      "    Grad: tensor([-0.0706,  0.3996])\n",
      "Epoch 1188, Loss 3.0\n",
      "    Params: tensor([  4.9536, -14.9603])\n",
      "    Grad: tensor([-0.0705,  0.3989])\n",
      "Epoch 1189, Loss 3.0\n",
      "    Params: tensor([  4.9543, -14.9643])\n",
      "    Grad: tensor([-0.0703,  0.3983])\n",
      "Epoch 1190, Loss 3.0\n",
      "    Params: tensor([  4.9550, -14.9683])\n",
      "    Grad: tensor([-0.0702,  0.3976])\n",
      "Epoch 1191, Loss 3.0\n",
      "    Params: tensor([  4.9557, -14.9723])\n",
      "    Grad: tensor([-0.0701,  0.3969])\n",
      "Epoch 1192, Loss 3.0\n",
      "    Params: tensor([  4.9564, -14.9762])\n",
      "    Grad: tensor([-0.0700,  0.3962])\n",
      "Epoch 1193, Loss 3.0\n",
      "    Params: tensor([  4.9571, -14.9802])\n",
      "    Grad: tensor([-0.0699,  0.3956])\n",
      "Epoch 1194, Loss 3.0\n",
      "    Params: tensor([  4.9578, -14.9841])\n",
      "    Grad: tensor([-0.0698,  0.3949])\n",
      "Epoch 1195, Loss 3.0\n",
      "    Params: tensor([  4.9585, -14.9881])\n",
      "    Grad: tensor([-0.0696,  0.3942])\n",
      "Epoch 1196, Loss 3.0\n",
      "    Params: tensor([  4.9592, -14.9920])\n",
      "    Grad: tensor([-0.0695,  0.3936])\n",
      "Epoch 1197, Loss 3.0\n",
      "    Params: tensor([  4.9599, -14.9959])\n",
      "    Grad: tensor([-0.0694,  0.3929])\n",
      "Epoch 1198, Loss 3.0\n",
      "    Params: tensor([  4.9605, -14.9999])\n",
      "    Grad: tensor([-0.0693,  0.3922])\n",
      "Epoch 1199, Loss 3.0\n",
      "    Params: tensor([  4.9612, -15.0038])\n",
      "    Grad: tensor([-0.0692,  0.3916])\n",
      "Epoch 1200, Loss 3.0\n",
      "    Params: tensor([  4.9619, -15.0077])\n",
      "    Grad: tensor([-0.0690,  0.3909])\n",
      "Epoch 1201, Loss 3.0\n",
      "    Params: tensor([  4.9626, -15.0116])\n",
      "    Grad: tensor([-0.0689,  0.3902])\n",
      "Epoch 1202, Loss 3.0\n",
      "    Params: tensor([  4.9633, -15.0155])\n",
      "    Grad: tensor([-0.0688,  0.3896])\n",
      "Epoch 1203, Loss 3.0\n",
      "    Params: tensor([  4.9640, -15.0194])\n",
      "    Grad: tensor([-0.0687,  0.3889])\n",
      "Epoch 1204, Loss 3.0\n",
      "    Params: tensor([  4.9647, -15.0233])\n",
      "    Grad: tensor([-0.0686,  0.3882])\n",
      "Epoch 1205, Loss 3.0\n",
      "    Params: tensor([  4.9654, -15.0271])\n",
      "    Grad: tensor([-0.0685,  0.3876])\n",
      "Epoch 1206, Loss 3.0\n",
      "    Params: tensor([  4.9660, -15.0310])\n",
      "    Grad: tensor([-0.0684,  0.3869])\n",
      "Epoch 1207, Loss 3.0\n",
      "    Params: tensor([  4.9667, -15.0349])\n",
      "    Grad: tensor([-0.0682,  0.3863])\n",
      "Epoch 1208, Loss 3.0\n",
      "    Params: tensor([  4.9674, -15.0387])\n",
      "    Grad: tensor([-0.0681,  0.3856])\n",
      "Epoch 1209, Loss 3.0\n",
      "    Params: tensor([  4.9681, -15.0426])\n",
      "    Grad: tensor([-0.0680,  0.3850])\n",
      "Epoch 1210, Loss 3.0\n",
      "    Params: tensor([  4.9688, -15.0464])\n",
      "    Grad: tensor([-0.0679,  0.3843])\n",
      "Epoch 1211, Loss 3.0\n",
      "    Params: tensor([  4.9694, -15.0502])\n",
      "    Grad: tensor([-0.0678,  0.3836])\n",
      "Epoch 1212, Loss 3.0\n",
      "    Params: tensor([  4.9701, -15.0541])\n",
      "    Grad: tensor([-0.0677,  0.3830])\n",
      "Epoch 1213, Loss 3.0\n",
      "    Params: tensor([  4.9708, -15.0579])\n",
      "    Grad: tensor([-0.0675,  0.3823])\n",
      "Epoch 1214, Loss 3.0\n",
      "    Params: tensor([  4.9715, -15.0617])\n",
      "    Grad: tensor([-0.0674,  0.3817])\n",
      "Epoch 1215, Loss 3.0\n",
      "    Params: tensor([  4.9721, -15.0655])\n",
      "    Grad: tensor([-0.0673,  0.3810])\n",
      "Epoch 1216, Loss 3.0\n",
      "    Params: tensor([  4.9728, -15.0693])\n",
      "    Grad: tensor([-0.0672,  0.3804])\n",
      "Epoch 1217, Loss 3.0\n",
      "    Params: tensor([  4.9735, -15.0731])\n",
      "    Grad: tensor([-0.0671,  0.3797])\n",
      "Epoch 1218, Loss 3.0\n",
      "    Params: tensor([  4.9742, -15.0769])\n",
      "    Grad: tensor([-0.0670,  0.3791])\n",
      "Epoch 1219, Loss 3.0\n",
      "    Params: tensor([  4.9748, -15.0807])\n",
      "    Grad: tensor([-0.0668,  0.3785])\n",
      "Epoch 1220, Loss 3.0\n",
      "    Params: tensor([  4.9755, -15.0845])\n",
      "    Grad: tensor([-0.0667,  0.3778])\n",
      "Epoch 1221, Loss 3.0\n",
      "    Params: tensor([  4.9762, -15.0883])\n",
      "    Grad: tensor([-0.0666,  0.3772])\n",
      "Epoch 1222, Loss 3.0\n",
      "    Params: tensor([  4.9768, -15.0920])\n",
      "    Grad: tensor([-0.0665,  0.3765])\n",
      "Epoch 1223, Loss 3.0\n",
      "    Params: tensor([  4.9775, -15.0958])\n",
      "    Grad: tensor([-0.0664,  0.3759])\n",
      "Epoch 1224, Loss 3.0\n",
      "    Params: tensor([  4.9782, -15.0995])\n",
      "    Grad: tensor([-0.0663,  0.3753])\n",
      "Epoch 1225, Loss 3.0\n",
      "    Params: tensor([  4.9788, -15.1033])\n",
      "    Grad: tensor([-0.0662,  0.3746])\n",
      "Epoch 1226, Loss 3.0\n",
      "    Params: tensor([  4.9795, -15.1070])\n",
      "    Grad: tensor([-0.0661,  0.3740])\n",
      "Epoch 1227, Loss 3.0\n",
      "    Params: tensor([  4.9801, -15.1107])\n",
      "    Grad: tensor([-0.0659,  0.3734])\n",
      "Epoch 1228, Loss 3.0\n",
      "    Params: tensor([  4.9808, -15.1145])\n",
      "    Grad: tensor([-0.0658,  0.3727])\n",
      "Epoch 1229, Loss 3.0\n",
      "    Params: tensor([  4.9815, -15.1182])\n",
      "    Grad: tensor([-0.0657,  0.3721])\n",
      "Epoch 1230, Loss 3.0\n",
      "    Params: tensor([  4.9821, -15.1219])\n",
      "    Grad: tensor([-0.0656,  0.3714])\n",
      "Epoch 1231, Loss 3.0\n",
      "    Params: tensor([  4.9828, -15.1256])\n",
      "    Grad: tensor([-0.0655,  0.3708])\n",
      "Epoch 1232, Loss 3.0\n",
      "    Params: tensor([  4.9834, -15.1293])\n",
      "    Grad: tensor([-0.0654,  0.3702])\n",
      "Epoch 1233, Loss 3.0\n",
      "    Params: tensor([  4.9841, -15.1330])\n",
      "    Grad: tensor([-0.0653,  0.3696])\n",
      "Epoch 1234, Loss 3.0\n",
      "    Params: tensor([  4.9847, -15.1367])\n",
      "    Grad: tensor([-0.0652,  0.3689])\n",
      "Epoch 1235, Loss 3.0\n",
      "    Params: tensor([  4.9854, -15.1404])\n",
      "    Grad: tensor([-0.0651,  0.3683])\n",
      "Epoch 1236, Loss 3.0\n",
      "    Params: tensor([  4.9860, -15.1441])\n",
      "    Grad: tensor([-0.0650,  0.3677])\n",
      "Epoch 1237, Loss 3.0\n",
      "    Params: tensor([  4.9867, -15.1477])\n",
      "    Grad: tensor([-0.0648,  0.3671])\n",
      "Epoch 1238, Loss 3.0\n",
      "    Params: tensor([  4.9873, -15.1514])\n",
      "    Grad: tensor([-0.0647,  0.3664])\n",
      "Epoch 1239, Loss 3.0\n",
      "    Params: tensor([  4.9880, -15.1551])\n",
      "    Grad: tensor([-0.0646,  0.3658])\n",
      "Epoch 1240, Loss 3.0\n",
      "    Params: tensor([  4.9886, -15.1587])\n",
      "    Grad: tensor([-0.0645,  0.3652])\n",
      "Epoch 1241, Loss 3.0\n",
      "    Params: tensor([  4.9893, -15.1624])\n",
      "    Grad: tensor([-0.0644,  0.3646])\n",
      "Epoch 1242, Loss 3.0\n",
      "    Params: tensor([  4.9899, -15.1660])\n",
      "    Grad: tensor([-0.0643,  0.3639])\n",
      "Epoch 1243, Loss 3.0\n",
      "    Params: tensor([  4.9905, -15.1696])\n",
      "    Grad: tensor([-0.0642,  0.3633])\n",
      "Epoch 1244, Loss 3.0\n",
      "    Params: tensor([  4.9912, -15.1733])\n",
      "    Grad: tensor([-0.0641,  0.3627])\n",
      "Epoch 1245, Loss 3.0\n",
      "    Params: tensor([  4.9918, -15.1769])\n",
      "    Grad: tensor([-0.0640,  0.3621])\n",
      "Epoch 1246, Loss 3.0\n",
      "    Params: tensor([  4.9925, -15.1805])\n",
      "    Grad: tensor([-0.0639,  0.3615])\n",
      "Epoch 1247, Loss 3.0\n",
      "    Params: tensor([  4.9931, -15.1841])\n",
      "    Grad: tensor([-0.0638,  0.3609])\n",
      "Epoch 1248, Loss 3.0\n",
      "    Params: tensor([  4.9937, -15.1877])\n",
      "    Grad: tensor([-0.0636,  0.3603])\n",
      "Epoch 1249, Loss 3.0\n",
      "    Params: tensor([  4.9944, -15.1913])\n",
      "    Grad: tensor([-0.0635,  0.3596])\n",
      "Epoch 1250, Loss 3.0\n",
      "    Params: tensor([  4.9950, -15.1949])\n",
      "    Grad: tensor([-0.0634,  0.3590])\n",
      "Epoch 1251, Loss 3.0\n",
      "    Params: tensor([  4.9956, -15.1985])\n",
      "    Grad: tensor([-0.0633,  0.3584])\n",
      "Epoch 1252, Loss 3.0\n",
      "    Params: tensor([  4.9963, -15.2021])\n",
      "    Grad: tensor([-0.0632,  0.3578])\n",
      "Epoch 1253, Loss 3.0\n",
      "    Params: tensor([  4.9969, -15.2056])\n",
      "    Grad: tensor([-0.0631,  0.3572])\n",
      "Epoch 1254, Loss 3.0\n",
      "    Params: tensor([  4.9975, -15.2092])\n",
      "    Grad: tensor([-0.0630,  0.3566])\n",
      "Epoch 1255, Loss 3.0\n",
      "    Params: tensor([  4.9982, -15.2127])\n",
      "    Grad: tensor([-0.0629,  0.3560])\n",
      "Epoch 1256, Loss 3.0\n",
      "    Params: tensor([  4.9988, -15.2163])\n",
      "    Grad: tensor([-0.0628,  0.3554])\n",
      "Epoch 1257, Loss 3.0\n",
      "    Params: tensor([  4.9994, -15.2199])\n",
      "    Grad: tensor([-0.0627,  0.3548])\n",
      "Epoch 1258, Loss 3.0\n",
      "    Params: tensor([  5.0000, -15.2234])\n",
      "    Grad: tensor([-0.0626,  0.3542])\n",
      "Epoch 1259, Loss 3.0\n",
      "    Params: tensor([  5.0007, -15.2269])\n",
      "    Grad: tensor([-0.0625,  0.3536])\n",
      "Epoch 1260, Loss 3.0\n",
      "    Params: tensor([  5.0013, -15.2305])\n",
      "    Grad: tensor([-0.0624,  0.3530])\n",
      "Epoch 1261, Loss 3.0\n",
      "    Params: tensor([  5.0019, -15.2340])\n",
      "    Grad: tensor([-0.0622,  0.3524])\n",
      "Epoch 1262, Loss 3.0\n",
      "    Params: tensor([  5.0025, -15.2375])\n",
      "    Grad: tensor([-0.0622,  0.3518])\n",
      "Epoch 1263, Loss 3.0\n",
      "    Params: tensor([  5.0031, -15.2410])\n",
      "    Grad: tensor([-0.0621,  0.3512])\n",
      "Epoch 1264, Loss 3.0\n",
      "    Params: tensor([  5.0038, -15.2445])\n",
      "    Grad: tensor([-0.0620,  0.3506])\n",
      "Epoch 1265, Loss 3.0\n",
      "    Params: tensor([  5.0044, -15.2480])\n",
      "    Grad: tensor([-0.0618,  0.3500])\n",
      "Epoch 1266, Loss 3.0\n",
      "    Params: tensor([  5.0050, -15.2515])\n",
      "    Grad: tensor([-0.0617,  0.3494])\n",
      "Epoch 1267, Loss 3.0\n",
      "    Params: tensor([  5.0056, -15.2550])\n",
      "    Grad: tensor([-0.0616,  0.3488])\n",
      "Epoch 1268, Loss 3.0\n",
      "    Params: tensor([  5.0062, -15.2585])\n",
      "    Grad: tensor([-0.0615,  0.3482])\n",
      "Epoch 1269, Loss 3.0\n",
      "    Params: tensor([  5.0068, -15.2620])\n",
      "    Grad: tensor([-0.0614,  0.3476])\n",
      "Epoch 1270, Loss 3.0\n",
      "    Params: tensor([  5.0075, -15.2654])\n",
      "    Grad: tensor([-0.0613,  0.3470])\n",
      "Epoch 1271, Loss 3.0\n",
      "    Params: tensor([  5.0081, -15.2689])\n",
      "    Grad: tensor([-0.0612,  0.3464])\n",
      "Epoch 1272, Loss 3.0\n",
      "    Params: tensor([  5.0087, -15.2724])\n",
      "    Grad: tensor([-0.0611,  0.3458])\n",
      "Epoch 1273, Loss 3.0\n",
      "    Params: tensor([  5.0093, -15.2758])\n",
      "    Grad: tensor([-0.0610,  0.3453])\n",
      "Epoch 1274, Loss 3.0\n",
      "    Params: tensor([  5.0099, -15.2792])\n",
      "    Grad: tensor([-0.0609,  0.3447])\n",
      "Epoch 1275, Loss 3.0\n",
      "    Params: tensor([  5.0105, -15.2827])\n",
      "    Grad: tensor([-0.0608,  0.3441])\n",
      "Epoch 1276, Loss 3.0\n",
      "    Params: tensor([  5.0111, -15.2861])\n",
      "    Grad: tensor([-0.0607,  0.3435])\n",
      "Epoch 1277, Loss 3.0\n",
      "    Params: tensor([  5.0117, -15.2896])\n",
      "    Grad: tensor([-0.0606,  0.3429])\n",
      "Epoch 1278, Loss 3.0\n",
      "    Params: tensor([  5.0123, -15.2930])\n",
      "    Grad: tensor([-0.0605,  0.3423])\n",
      "Epoch 1279, Loss 3.0\n",
      "    Params: tensor([  5.0129, -15.2964])\n",
      "    Grad: tensor([-0.0604,  0.3418])\n",
      "Epoch 1280, Loss 3.0\n",
      "    Params: tensor([  5.0135, -15.2998])\n",
      "    Grad: tensor([-0.0603,  0.3412])\n",
      "Epoch 1281, Loss 3.0\n",
      "    Params: tensor([  5.0141, -15.3032])\n",
      "    Grad: tensor([-0.0602,  0.3406])\n",
      "Epoch 1282, Loss 3.0\n",
      "    Params: tensor([  5.0147, -15.3066])\n",
      "    Grad: tensor([-0.0601,  0.3400])\n",
      "Epoch 1283, Loss 3.0\n",
      "    Params: tensor([  5.0153, -15.3100])\n",
      "    Grad: tensor([-0.0600,  0.3394])\n",
      "Epoch 1284, Loss 3.0\n",
      "    Params: tensor([  5.0159, -15.3134])\n",
      "    Grad: tensor([-0.0598,  0.3389])\n",
      "Epoch 1285, Loss 3.0\n",
      "    Params: tensor([  5.0165, -15.3168])\n",
      "    Grad: tensor([-0.0598,  0.3383])\n",
      "Epoch 1286, Loss 3.0\n",
      "    Params: tensor([  5.0171, -15.3202])\n",
      "    Grad: tensor([-0.0597,  0.3377])\n",
      "Epoch 1287, Loss 3.0\n",
      "    Params: tensor([  5.0177, -15.3235])\n",
      "    Grad: tensor([-0.0596,  0.3371])\n",
      "Epoch 1288, Loss 3.0\n",
      "    Params: tensor([  5.0183, -15.3269])\n",
      "    Grad: tensor([-0.0595,  0.3366])\n",
      "Epoch 1289, Loss 3.0\n",
      "    Params: tensor([  5.0189, -15.3303])\n",
      "    Grad: tensor([-0.0593,  0.3360])\n",
      "Epoch 1290, Loss 3.0\n",
      "    Params: tensor([  5.0195, -15.3336])\n",
      "    Grad: tensor([-0.0592,  0.3354])\n",
      "Epoch 1291, Loss 3.0\n",
      "    Params: tensor([  5.0201, -15.3370])\n",
      "    Grad: tensor([-0.0591,  0.3349])\n",
      "Epoch 1292, Loss 3.0\n",
      "    Params: tensor([  5.0207, -15.3403])\n",
      "    Grad: tensor([-0.0590,  0.3343])\n",
      "Epoch 1293, Loss 3.0\n",
      "    Params: tensor([  5.0213, -15.3436])\n",
      "    Grad: tensor([-0.0590,  0.3337])\n",
      "Epoch 1294, Loss 3.0\n",
      "    Params: tensor([  5.0219, -15.3470])\n",
      "    Grad: tensor([-0.0589,  0.3332])\n",
      "Epoch 1295, Loss 3.0\n",
      "    Params: tensor([  5.0225, -15.3503])\n",
      "    Grad: tensor([-0.0588,  0.3326])\n",
      "Epoch 1296, Loss 3.0\n",
      "    Params: tensor([  5.0230, -15.3536])\n",
      "    Grad: tensor([-0.0587,  0.3320])\n",
      "Epoch 1297, Loss 3.0\n",
      "    Params: tensor([  5.0236, -15.3569])\n",
      "    Grad: tensor([-0.0586,  0.3315])\n",
      "Epoch 1298, Loss 3.0\n",
      "    Params: tensor([  5.0242, -15.3602])\n",
      "    Grad: tensor([-0.0585,  0.3309])\n",
      "Epoch 1299, Loss 3.0\n",
      "    Params: tensor([  5.0248, -15.3635])\n",
      "    Grad: tensor([-0.0584,  0.3303])\n",
      "Epoch 1300, Loss 3.0\n",
      "    Params: tensor([  5.0254, -15.3668])\n",
      "    Grad: tensor([-0.0583,  0.3298])\n",
      "Epoch 1301, Loss 3.0\n",
      "    Params: tensor([  5.0260, -15.3701])\n",
      "    Grad: tensor([-0.0581,  0.3292])\n",
      "Epoch 1302, Loss 3.0\n",
      "    Params: tensor([  5.0265, -15.3734])\n",
      "    Grad: tensor([-0.0581,  0.3287])\n",
      "Epoch 1303, Loss 3.0\n",
      "    Params: tensor([  5.0271, -15.3767])\n",
      "    Grad: tensor([-0.0580,  0.3281])\n",
      "Epoch 1304, Loss 3.0\n",
      "    Params: tensor([  5.0277, -15.3800])\n",
      "    Grad: tensor([-0.0579,  0.3275])\n",
      "Epoch 1305, Loss 3.0\n",
      "    Params: tensor([  5.0283, -15.3832])\n",
      "    Grad: tensor([-0.0577,  0.3270])\n",
      "Epoch 1306, Loss 3.0\n",
      "    Params: tensor([  5.0288, -15.3865])\n",
      "    Grad: tensor([-0.0577,  0.3264])\n",
      "Epoch 1307, Loss 3.0\n",
      "    Params: tensor([  5.0294, -15.3898])\n",
      "    Grad: tensor([-0.0576,  0.3259])\n",
      "Epoch 1308, Loss 3.0\n",
      "    Params: tensor([  5.0300, -15.3930])\n",
      "    Grad: tensor([-0.0575,  0.3253])\n",
      "Epoch 1309, Loss 3.0\n",
      "    Params: tensor([  5.0306, -15.3963])\n",
      "    Grad: tensor([-0.0574,  0.3248])\n",
      "Epoch 1310, Loss 3.0\n",
      "    Params: tensor([  5.0311, -15.3995])\n",
      "    Grad: tensor([-0.0573,  0.3242])\n",
      "Epoch 1311, Loss 3.0\n",
      "    Params: tensor([  5.0317, -15.4027])\n",
      "    Grad: tensor([-0.0572,  0.3237])\n",
      "Epoch 1312, Loss 3.0\n",
      "    Params: tensor([  5.0323, -15.4060])\n",
      "    Grad: tensor([-0.0571,  0.3231])\n",
      "Epoch 1313, Loss 3.0\n",
      "    Params: tensor([  5.0329, -15.4092])\n",
      "    Grad: tensor([-0.0570,  0.3226])\n",
      "Epoch 1314, Loss 3.0\n",
      "    Params: tensor([  5.0334, -15.4124])\n",
      "    Grad: tensor([-0.0569,  0.3220])\n",
      "Epoch 1315, Loss 3.0\n",
      "    Params: tensor([  5.0340, -15.4156])\n",
      "    Grad: tensor([-0.0568,  0.3215])\n",
      "Epoch 1316, Loss 3.0\n",
      "    Params: tensor([  5.0346, -15.4188])\n",
      "    Grad: tensor([-0.0567,  0.3209])\n",
      "Epoch 1317, Loss 3.0\n",
      "    Params: tensor([  5.0351, -15.4220])\n",
      "    Grad: tensor([-0.0566,  0.3204])\n",
      "Epoch 1318, Loss 3.0\n",
      "    Params: tensor([  5.0357, -15.4252])\n",
      "    Grad: tensor([-0.0565,  0.3198])\n",
      "Epoch 1319, Loss 3.0\n",
      "    Params: tensor([  5.0363, -15.4284])\n",
      "    Grad: tensor([-0.0564,  0.3193])\n",
      "Epoch 1320, Loss 3.0\n",
      "    Params: tensor([  5.0368, -15.4316])\n",
      "    Grad: tensor([-0.0563,  0.3187])\n",
      "Epoch 1321, Loss 3.0\n",
      "    Params: tensor([  5.0374, -15.4348])\n",
      "    Grad: tensor([-0.0562,  0.3182])\n",
      "Epoch 1322, Loss 3.0\n",
      "    Params: tensor([  5.0379, -15.4380])\n",
      "    Grad: tensor([-0.0561,  0.3177])\n",
      "Epoch 1323, Loss 3.0\n",
      "    Params: tensor([  5.0385, -15.4412])\n",
      "    Grad: tensor([-0.0560,  0.3171])\n",
      "Epoch 1324, Loss 3.0\n",
      "    Params: tensor([  5.0391, -15.4443])\n",
      "    Grad: tensor([-0.0559,  0.3166])\n",
      "Epoch 1325, Loss 3.0\n",
      "    Params: tensor([  5.0396, -15.4475])\n",
      "    Grad: tensor([-0.0558,  0.3160])\n",
      "Epoch 1326, Loss 3.0\n",
      "    Params: tensor([  5.0402, -15.4506])\n",
      "    Grad: tensor([-0.0557,  0.3155])\n",
      "Epoch 1327, Loss 3.0\n",
      "    Params: tensor([  5.0407, -15.4538])\n",
      "    Grad: tensor([-0.0556,  0.3150])\n",
      "Epoch 1328, Loss 3.0\n",
      "    Params: tensor([  5.0413, -15.4569])\n",
      "    Grad: tensor([-0.0556,  0.3144])\n",
      "Epoch 1329, Loss 3.0\n",
      "    Params: tensor([  5.0418, -15.4601])\n",
      "    Grad: tensor([-0.0555,  0.3139])\n",
      "Epoch 1330, Loss 3.0\n",
      "    Params: tensor([  5.0424, -15.4632])\n",
      "    Grad: tensor([-0.0554,  0.3134])\n",
      "Epoch 1331, Loss 3.0\n",
      "    Params: tensor([  5.0430, -15.4663])\n",
      "    Grad: tensor([-0.0553,  0.3128])\n",
      "Epoch 1332, Loss 3.0\n",
      "    Params: tensor([  5.0435, -15.4695])\n",
      "    Grad: tensor([-0.0552,  0.3123])\n",
      "Epoch 1333, Loss 3.0\n",
      "    Params: tensor([  5.0441, -15.4726])\n",
      "    Grad: tensor([-0.0551,  0.3118])\n",
      "Epoch 1334, Loss 3.0\n",
      "    Params: tensor([  5.0446, -15.4757])\n",
      "    Grad: tensor([-0.0550,  0.3112])\n",
      "Epoch 1335, Loss 3.0\n",
      "    Params: tensor([  5.0452, -15.4788])\n",
      "    Grad: tensor([-0.0549,  0.3107])\n",
      "Epoch 1336, Loss 3.0\n",
      "    Params: tensor([  5.0457, -15.4819])\n",
      "    Grad: tensor([-0.0548,  0.3102])\n",
      "Epoch 1337, Loss 3.0\n",
      "    Params: tensor([  5.0462, -15.4850])\n",
      "    Grad: tensor([-0.0547,  0.3097])\n",
      "Epoch 1338, Loss 3.0\n",
      "    Params: tensor([  5.0468, -15.4881])\n",
      "    Grad: tensor([-0.0546,  0.3091])\n",
      "Epoch 1339, Loss 3.0\n",
      "    Params: tensor([  5.0473, -15.4912])\n",
      "    Grad: tensor([-0.0545,  0.3086])\n",
      "Epoch 1340, Loss 3.0\n",
      "    Params: tensor([  5.0479, -15.4943])\n",
      "    Grad: tensor([-0.0544,  0.3081])\n",
      "Epoch 1341, Loss 3.0\n",
      "    Params: tensor([  5.0484, -15.4973])\n",
      "    Grad: tensor([-0.0543,  0.3076])\n",
      "Epoch 1342, Loss 3.0\n",
      "    Params: tensor([  5.0490, -15.5004])\n",
      "    Grad: tensor([-0.0542,  0.3070])\n",
      "Epoch 1343, Loss 3.0\n",
      "    Params: tensor([  5.0495, -15.5035])\n",
      "    Grad: tensor([-0.0542,  0.3065])\n",
      "Epoch 1344, Loss 3.0\n",
      "    Params: tensor([  5.0501, -15.5065])\n",
      "    Grad: tensor([-0.0540,  0.3060])\n",
      "Epoch 1345, Loss 3.0\n",
      "    Params: tensor([  5.0506, -15.5096])\n",
      "    Grad: tensor([-0.0540,  0.3055])\n",
      "Epoch 1346, Loss 3.0\n",
      "    Params: tensor([  5.0511, -15.5126])\n",
      "    Grad: tensor([-0.0539,  0.3050])\n",
      "Epoch 1347, Loss 3.0\n",
      "    Params: tensor([  5.0517, -15.5157])\n",
      "    Grad: tensor([-0.0538,  0.3044])\n",
      "Epoch 1348, Loss 3.0\n",
      "    Params: tensor([  5.0522, -15.5187])\n",
      "    Grad: tensor([-0.0537,  0.3039])\n",
      "Epoch 1349, Loss 3.0\n",
      "    Params: tensor([  5.0527, -15.5217])\n",
      "    Grad: tensor([-0.0536,  0.3034])\n",
      "Epoch 1350, Loss 3.0\n",
      "    Params: tensor([  5.0533, -15.5248])\n",
      "    Grad: tensor([-0.0535,  0.3029])\n",
      "Epoch 1351, Loss 3.0\n",
      "    Params: tensor([  5.0538, -15.5278])\n",
      "    Grad: tensor([-0.0534,  0.3024])\n",
      "Epoch 1352, Loss 3.0\n",
      "    Params: tensor([  5.0543, -15.5308])\n",
      "    Grad: tensor([-0.0533,  0.3019])\n",
      "Epoch 1353, Loss 3.0\n",
      "    Params: tensor([  5.0549, -15.5338])\n",
      "    Grad: tensor([-0.0532,  0.3014])\n",
      "Epoch 1354, Loss 3.0\n",
      "    Params: tensor([  5.0554, -15.5368])\n",
      "    Grad: tensor([-0.0531,  0.3008])\n",
      "Epoch 1355, Loss 3.0\n",
      "    Params: tensor([  5.0559, -15.5398])\n",
      "    Grad: tensor([-0.0530,  0.3003])\n",
      "Epoch 1356, Loss 3.0\n",
      "    Params: tensor([  5.0565, -15.5428])\n",
      "    Grad: tensor([-0.0530,  0.2998])\n",
      "Epoch 1357, Loss 3.0\n",
      "    Params: tensor([  5.0570, -15.5458])\n",
      "    Grad: tensor([-0.0529,  0.2993])\n",
      "Epoch 1358, Loss 3.0\n",
      "    Params: tensor([  5.0575, -15.5488])\n",
      "    Grad: tensor([-0.0528,  0.2988])\n",
      "Epoch 1359, Loss 3.0\n",
      "    Params: tensor([  5.0581, -15.5518])\n",
      "    Grad: tensor([-0.0527,  0.2983])\n",
      "Epoch 1360, Loss 3.0\n",
      "    Params: tensor([  5.0586, -15.5548])\n",
      "    Grad: tensor([-0.0526,  0.2978])\n",
      "Epoch 1361, Loss 3.0\n",
      "    Params: tensor([  5.0591, -15.5578])\n",
      "    Grad: tensor([-0.0525,  0.2973])\n",
      "Epoch 1362, Loss 3.0\n",
      "    Params: tensor([  5.0596, -15.5607])\n",
      "    Grad: tensor([-0.0524,  0.2968])\n",
      "Epoch 1363, Loss 3.0\n",
      "    Params: tensor([  5.0601, -15.5637])\n",
      "    Grad: tensor([-0.0523,  0.2963])\n",
      "Epoch 1364, Loss 3.0\n",
      "    Params: tensor([  5.0607, -15.5666])\n",
      "    Grad: tensor([-0.0523,  0.2958])\n",
      "Epoch 1365, Loss 3.0\n",
      "    Params: tensor([  5.0612, -15.5696])\n",
      "    Grad: tensor([-0.0522,  0.2953])\n",
      "Epoch 1366, Loss 3.0\n",
      "    Params: tensor([  5.0617, -15.5725])\n",
      "    Grad: tensor([-0.0521,  0.2948])\n",
      "Epoch 1367, Loss 3.0\n",
      "    Params: tensor([  5.0622, -15.5755])\n",
      "    Grad: tensor([-0.0520,  0.2943])\n",
      "Epoch 1368, Loss 3.0\n",
      "    Params: tensor([  5.0628, -15.5784])\n",
      "    Grad: tensor([-0.0519,  0.2938])\n",
      "Epoch 1369, Loss 3.0\n",
      "    Params: tensor([  5.0633, -15.5814])\n",
      "    Grad: tensor([-0.0518,  0.2933])\n",
      "Epoch 1370, Loss 3.0\n",
      "    Params: tensor([  5.0638, -15.5843])\n",
      "    Grad: tensor([-0.0517,  0.2928])\n",
      "Epoch 1371, Loss 3.0\n",
      "    Params: tensor([  5.0643, -15.5872])\n",
      "    Grad: tensor([-0.0516,  0.2923])\n",
      "Epoch 1372, Loss 3.0\n",
      "    Params: tensor([  5.0648, -15.5901])\n",
      "    Grad: tensor([-0.0515,  0.2918])\n",
      "Epoch 1373, Loss 3.0\n",
      "    Params: tensor([  5.0653, -15.5930])\n",
      "    Grad: tensor([-0.0514,  0.2913])\n",
      "Epoch 1374, Loss 3.0\n",
      "    Params: tensor([  5.0658, -15.5959])\n",
      "    Grad: tensor([-0.0514,  0.2908])\n",
      "Epoch 1375, Loss 3.0\n",
      "    Params: tensor([  5.0664, -15.5989])\n",
      "    Grad: tensor([-0.0513,  0.2903])\n",
      "Epoch 1376, Loss 3.0\n",
      "    Params: tensor([  5.0669, -15.6017])\n",
      "    Grad: tensor([-0.0512,  0.2898])\n",
      "Epoch 1377, Loss 3.0\n",
      "    Params: tensor([  5.0674, -15.6046])\n",
      "    Grad: tensor([-0.0511,  0.2893])\n",
      "Epoch 1378, Loss 3.0\n",
      "    Params: tensor([  5.0679, -15.6075])\n",
      "    Grad: tensor([-0.0510,  0.2888])\n",
      "Epoch 1379, Loss 3.0\n",
      "    Params: tensor([  5.0684, -15.6104])\n",
      "    Grad: tensor([-0.0509,  0.2883])\n",
      "Epoch 1380, Loss 3.0\n",
      "    Params: tensor([  5.0689, -15.6133])\n",
      "    Grad: tensor([-0.0508,  0.2878])\n",
      "Epoch 1381, Loss 3.0\n",
      "    Params: tensor([  5.0694, -15.6162])\n",
      "    Grad: tensor([-0.0508,  0.2873])\n",
      "Epoch 1382, Loss 3.0\n",
      "    Params: tensor([  5.0699, -15.6190])\n",
      "    Grad: tensor([-0.0507,  0.2869])\n",
      "Epoch 1383, Loss 3.0\n",
      "    Params: tensor([  5.0704, -15.6219])\n",
      "    Grad: tensor([-0.0506,  0.2864])\n",
      "Epoch 1384, Loss 3.0\n",
      "    Params: tensor([  5.0709, -15.6248])\n",
      "    Grad: tensor([-0.0505,  0.2859])\n",
      "Epoch 1385, Loss 3.0\n",
      "    Params: tensor([  5.0714, -15.6276])\n",
      "    Grad: tensor([-0.0504,  0.2854])\n",
      "Epoch 1386, Loss 3.0\n",
      "    Params: tensor([  5.0719, -15.6305])\n",
      "    Grad: tensor([-0.0503,  0.2849])\n",
      "Epoch 1387, Loss 3.0\n",
      "    Params: tensor([  5.0724, -15.6333])\n",
      "    Grad: tensor([-0.0503,  0.2844])\n",
      "Epoch 1388, Loss 3.0\n",
      "    Params: tensor([  5.0729, -15.6361])\n",
      "    Grad: tensor([-0.0502,  0.2839])\n",
      "Epoch 1389, Loss 3.0\n",
      "    Params: tensor([  5.0734, -15.6390])\n",
      "    Grad: tensor([-0.0501,  0.2835])\n",
      "Epoch 1390, Loss 3.0\n",
      "    Params: tensor([  5.0739, -15.6418])\n",
      "    Grad: tensor([-0.0500,  0.2830])\n",
      "Epoch 1391, Loss 3.0\n",
      "    Params: tensor([  5.0744, -15.6446])\n",
      "    Grad: tensor([-0.0499,  0.2825])\n",
      "Epoch 1392, Loss 3.0\n",
      "    Params: tensor([  5.0749, -15.6475])\n",
      "    Grad: tensor([-0.0498,  0.2820])\n",
      "Epoch 1393, Loss 3.0\n",
      "    Params: tensor([  5.0754, -15.6503])\n",
      "    Grad: tensor([-0.0497,  0.2815])\n",
      "Epoch 1394, Loss 3.0\n",
      "    Params: tensor([  5.0759, -15.6531])\n",
      "    Grad: tensor([-0.0496,  0.2811])\n",
      "Epoch 1395, Loss 3.0\n",
      "    Params: tensor([  5.0764, -15.6559])\n",
      "    Grad: tensor([-0.0496,  0.2806])\n",
      "Epoch 1396, Loss 3.0\n",
      "    Params: tensor([  5.0769, -15.6587])\n",
      "    Grad: tensor([-0.0495,  0.2801])\n",
      "Epoch 1397, Loss 3.0\n",
      "    Params: tensor([  5.0774, -15.6615])\n",
      "    Grad: tensor([-0.0494,  0.2796])\n",
      "Epoch 1398, Loss 3.0\n",
      "    Params: tensor([  5.0779, -15.6643])\n",
      "    Grad: tensor([-0.0493,  0.2792])\n",
      "Epoch 1399, Loss 3.0\n",
      "    Params: tensor([  5.0784, -15.6671])\n",
      "    Grad: tensor([-0.0492,  0.2787])\n",
      "Epoch 1400, Loss 3.0\n",
      "    Params: tensor([  5.0789, -15.6698])\n",
      "    Grad: tensor([-0.0491,  0.2782])\n",
      "Epoch 1401, Loss 3.0\n",
      "    Params: tensor([  5.0794, -15.6726])\n",
      "    Grad: tensor([-0.0491,  0.2777])\n",
      "Epoch 1402, Loss 3.0\n",
      "    Params: tensor([  5.0799, -15.6754])\n",
      "    Grad: tensor([-0.0490,  0.2773])\n",
      "Epoch 1403, Loss 3.0\n",
      "    Params: tensor([  5.0804, -15.6782])\n",
      "    Grad: tensor([-0.0489,  0.2768])\n",
      "Epoch 1404, Loss 3.0\n",
      "    Params: tensor([  5.0809, -15.6809])\n",
      "    Grad: tensor([-0.0488,  0.2763])\n",
      "Epoch 1405, Loss 3.0\n",
      "    Params: tensor([  5.0813, -15.6837])\n",
      "    Grad: tensor([-0.0487,  0.2759])\n",
      "Epoch 1406, Loss 3.0\n",
      "    Params: tensor([  5.0818, -15.6864])\n",
      "    Grad: tensor([-0.0486,  0.2754])\n",
      "Epoch 1407, Loss 3.0\n",
      "    Params: tensor([  5.0823, -15.6892])\n",
      "    Grad: tensor([-0.0486,  0.2749])\n",
      "Epoch 1408, Loss 3.0\n",
      "    Params: tensor([  5.0828, -15.6919])\n",
      "    Grad: tensor([-0.0485,  0.2745])\n",
      "Epoch 1409, Loss 3.0\n",
      "    Params: tensor([  5.0833, -15.6947])\n",
      "    Grad: tensor([-0.0484,  0.2740])\n",
      "Epoch 1410, Loss 3.0\n",
      "    Params: tensor([  5.0838, -15.6974])\n",
      "    Grad: tensor([-0.0483,  0.2735])\n",
      "Epoch 1411, Loss 3.0\n",
      "    Params: tensor([  5.0843, -15.7001])\n",
      "    Grad: tensor([-0.0483,  0.2731])\n",
      "Epoch 1412, Loss 3.0\n",
      "    Params: tensor([  5.0847, -15.7029])\n",
      "    Grad: tensor([-0.0482,  0.2726])\n",
      "Epoch 1413, Loss 3.0\n",
      "    Params: tensor([  5.0852, -15.7056])\n",
      "    Grad: tensor([-0.0481,  0.2721])\n",
      "Epoch 1414, Loss 3.0\n",
      "    Params: tensor([  5.0857, -15.7083])\n",
      "    Grad: tensor([-0.0480,  0.2717])\n",
      "Epoch 1415, Loss 3.0\n",
      "    Params: tensor([  5.0862, -15.7110])\n",
      "    Grad: tensor([-0.0479,  0.2712])\n",
      "Epoch 1416, Loss 3.0\n",
      "    Params: tensor([  5.0867, -15.7137])\n",
      "    Grad: tensor([-0.0478,  0.2707])\n",
      "Epoch 1417, Loss 3.0\n",
      "    Params: tensor([  5.0871, -15.7164])\n",
      "    Grad: tensor([-0.0477,  0.2703])\n",
      "Epoch 1418, Loss 3.0\n",
      "    Params: tensor([  5.0876, -15.7191])\n",
      "    Grad: tensor([-0.0477,  0.2698])\n",
      "Epoch 1419, Loss 3.0\n",
      "    Params: tensor([  5.0881, -15.7218])\n",
      "    Grad: tensor([-0.0476,  0.2694])\n",
      "Epoch 1420, Loss 3.0\n",
      "    Params: tensor([  5.0886, -15.7245])\n",
      "    Grad: tensor([-0.0475,  0.2689])\n",
      "Epoch 1421, Loss 3.0\n",
      "    Params: tensor([  5.0890, -15.7272])\n",
      "    Grad: tensor([-0.0474,  0.2685])\n",
      "Epoch 1422, Loss 3.0\n",
      "    Params: tensor([  5.0895, -15.7299])\n",
      "    Grad: tensor([-0.0473,  0.2680])\n",
      "Epoch 1423, Loss 3.0\n",
      "    Params: tensor([  5.0900, -15.7325])\n",
      "    Grad: tensor([-0.0473,  0.2675])\n",
      "Epoch 1424, Loss 3.0\n",
      "    Params: tensor([  5.0904, -15.7352])\n",
      "    Grad: tensor([-0.0472,  0.2671])\n",
      "Epoch 1425, Loss 3.0\n",
      "    Params: tensor([  5.0909, -15.7379])\n",
      "    Grad: tensor([-0.0471,  0.2666])\n",
      "Epoch 1426, Loss 3.0\n",
      "    Params: tensor([  5.0914, -15.7405])\n",
      "    Grad: tensor([-0.0470,  0.2662])\n",
      "Epoch 1427, Loss 3.0\n",
      "    Params: tensor([  5.0919, -15.7432])\n",
      "    Grad: tensor([-0.0470,  0.2657])\n",
      "Epoch 1428, Loss 3.0\n",
      "    Params: tensor([  5.0923, -15.7458])\n",
      "    Grad: tensor([-0.0469,  0.2653])\n",
      "Epoch 1429, Loss 3.0\n",
      "    Params: tensor([  5.0928, -15.7485])\n",
      "    Grad: tensor([-0.0468,  0.2648])\n",
      "Epoch 1430, Loss 3.0\n",
      "    Params: tensor([  5.0933, -15.7511])\n",
      "    Grad: tensor([-0.0467,  0.2644])\n",
      "Epoch 1431, Loss 3.0\n",
      "    Params: tensor([  5.0937, -15.7538])\n",
      "    Grad: tensor([-0.0466,  0.2639])\n",
      "Epoch 1432, Loss 3.0\n",
      "    Params: tensor([  5.0942, -15.7564])\n",
      "    Grad: tensor([-0.0465,  0.2635])\n",
      "Epoch 1433, Loss 3.0\n",
      "    Params: tensor([  5.0947, -15.7590])\n",
      "    Grad: tensor([-0.0465,  0.2630])\n",
      "Epoch 1434, Loss 3.0\n",
      "    Params: tensor([  5.0951, -15.7617])\n",
      "    Grad: tensor([-0.0464,  0.2626])\n",
      "Epoch 1435, Loss 3.0\n",
      "    Params: tensor([  5.0956, -15.7643])\n",
      "    Grad: tensor([-0.0463,  0.2621])\n",
      "Epoch 1436, Loss 3.0\n",
      "    Params: tensor([  5.0960, -15.7669])\n",
      "    Grad: tensor([-0.0462,  0.2617])\n",
      "Epoch 1437, Loss 3.0\n",
      "    Params: tensor([  5.0965, -15.7695])\n",
      "    Grad: tensor([-0.0462,  0.2612])\n",
      "Epoch 1438, Loss 3.0\n",
      "    Params: tensor([  5.0970, -15.7721])\n",
      "    Grad: tensor([-0.0461,  0.2608])\n",
      "Epoch 1439, Loss 3.0\n",
      "    Params: tensor([  5.0974, -15.7747])\n",
      "    Grad: tensor([-0.0460,  0.2604])\n",
      "Epoch 1440, Loss 3.0\n",
      "    Params: tensor([  5.0979, -15.7773])\n",
      "    Grad: tensor([-0.0459,  0.2599])\n",
      "Epoch 1441, Loss 3.0\n",
      "    Params: tensor([  5.0983, -15.7799])\n",
      "    Grad: tensor([-0.0458,  0.2595])\n",
      "Epoch 1442, Loss 3.0\n",
      "    Params: tensor([  5.0988, -15.7825])\n",
      "    Grad: tensor([-0.0457,  0.2590])\n",
      "Epoch 1443, Loss 3.0\n",
      "    Params: tensor([  5.0993, -15.7851])\n",
      "    Grad: tensor([-0.0457,  0.2586])\n",
      "Epoch 1444, Loss 3.0\n",
      "    Params: tensor([  5.0997, -15.7877])\n",
      "    Grad: tensor([-0.0456,  0.2582])\n",
      "Epoch 1445, Loss 3.0\n",
      "    Params: tensor([  5.1002, -15.7903])\n",
      "    Grad: tensor([-0.0455,  0.2577])\n",
      "Epoch 1446, Loss 3.0\n",
      "    Params: tensor([  5.1006, -15.7928])\n",
      "    Grad: tensor([-0.0454,  0.2573])\n",
      "Epoch 1447, Loss 3.0\n",
      "    Params: tensor([  5.1011, -15.7954])\n",
      "    Grad: tensor([-0.0454,  0.2568])\n",
      "Epoch 1448, Loss 3.0\n",
      "    Params: tensor([  5.1015, -15.7980])\n",
      "    Grad: tensor([-0.0453,  0.2564])\n",
      "Epoch 1449, Loss 3.0\n",
      "    Params: tensor([  5.1020, -15.8005])\n",
      "    Grad: tensor([-0.0452,  0.2560])\n",
      "Epoch 1450, Loss 3.0\n",
      "    Params: tensor([  5.1024, -15.8031])\n",
      "    Grad: tensor([-0.0452,  0.2555])\n",
      "Epoch 1451, Loss 3.0\n",
      "    Params: tensor([  5.1029, -15.8056])\n",
      "    Grad: tensor([-0.0451,  0.2551])\n",
      "Epoch 1452, Loss 3.0\n",
      "    Params: tensor([  5.1033, -15.8082])\n",
      "    Grad: tensor([-0.0450,  0.2547])\n",
      "Epoch 1453, Loss 3.0\n",
      "    Params: tensor([  5.1038, -15.8107])\n",
      "    Grad: tensor([-0.0449,  0.2542])\n",
      "Epoch 1454, Loss 3.0\n",
      "    Params: tensor([  5.1042, -15.8133])\n",
      "    Grad: tensor([-0.0448,  0.2538])\n",
      "Epoch 1455, Loss 3.0\n",
      "    Params: tensor([  5.1047, -15.8158])\n",
      "    Grad: tensor([-0.0448,  0.2534])\n",
      "Epoch 1456, Loss 3.0\n",
      "    Params: tensor([  5.1051, -15.8183])\n",
      "    Grad: tensor([-0.0447,  0.2529])\n",
      "Epoch 1457, Loss 3.0\n",
      "    Params: tensor([  5.1056, -15.8208])\n",
      "    Grad: tensor([-0.0446,  0.2525])\n",
      "Epoch 1458, Loss 3.0\n",
      "    Params: tensor([  5.1060, -15.8234])\n",
      "    Grad: tensor([-0.0446,  0.2521])\n",
      "Epoch 1459, Loss 3.0\n",
      "    Params: tensor([  5.1065, -15.8259])\n",
      "    Grad: tensor([-0.0445,  0.2517])\n",
      "Epoch 1460, Loss 3.0\n",
      "    Params: tensor([  5.1069, -15.8284])\n",
      "    Grad: tensor([-0.0444,  0.2512])\n",
      "Epoch 1461, Loss 3.0\n",
      "    Params: tensor([  5.1074, -15.8309])\n",
      "    Grad: tensor([-0.0443,  0.2508])\n",
      "Epoch 1462, Loss 3.0\n",
      "    Params: tensor([  5.1078, -15.8334])\n",
      "    Grad: tensor([-0.0442,  0.2504])\n",
      "Epoch 1463, Loss 3.0\n",
      "    Params: tensor([  5.1082, -15.8359])\n",
      "    Grad: tensor([-0.0441,  0.2500])\n",
      "Epoch 1464, Loss 3.0\n",
      "    Params: tensor([  5.1087, -15.8384])\n",
      "    Grad: tensor([-0.0441,  0.2495])\n",
      "Epoch 1465, Loss 3.0\n",
      "    Params: tensor([  5.1091, -15.8409])\n",
      "    Grad: tensor([-0.0440,  0.2491])\n",
      "Epoch 1466, Loss 3.0\n",
      "    Params: tensor([  5.1096, -15.8434])\n",
      "    Grad: tensor([-0.0439,  0.2487])\n",
      "Epoch 1467, Loss 3.0\n",
      "    Params: tensor([  5.1100, -15.8459])\n",
      "    Grad: tensor([-0.0439,  0.2483])\n",
      "Epoch 1468, Loss 3.0\n",
      "    Params: tensor([  5.1104, -15.8483])\n",
      "    Grad: tensor([-0.0438,  0.2478])\n",
      "Epoch 1469, Loss 3.0\n",
      "    Params: tensor([  5.1109, -15.8508])\n",
      "    Grad: tensor([-0.0437,  0.2474])\n",
      "Epoch 1470, Loss 3.0\n",
      "    Params: tensor([  5.1113, -15.8533])\n",
      "    Grad: tensor([-0.0436,  0.2470])\n",
      "Epoch 1471, Loss 3.0\n",
      "    Params: tensor([  5.1117, -15.8558])\n",
      "    Grad: tensor([-0.0436,  0.2466])\n",
      "Epoch 1472, Loss 3.0\n",
      "    Params: tensor([  5.1122, -15.8582])\n",
      "    Grad: tensor([-0.0435,  0.2462])\n",
      "Epoch 1473, Loss 3.0\n",
      "    Params: tensor([  5.1126, -15.8607])\n",
      "    Grad: tensor([-0.0434,  0.2457])\n",
      "Epoch 1474, Loss 3.0\n",
      "    Params: tensor([  5.1130, -15.8631])\n",
      "    Grad: tensor([-0.0433,  0.2453])\n",
      "Epoch 1475, Loss 3.0\n",
      "    Params: tensor([  5.1135, -15.8656])\n",
      "    Grad: tensor([-0.0433,  0.2449])\n",
      "Epoch 1476, Loss 3.0\n",
      "    Params: tensor([  5.1139, -15.8680])\n",
      "    Grad: tensor([-0.0432,  0.2445])\n",
      "Epoch 1477, Loss 3.0\n",
      "    Params: tensor([  5.1143, -15.8705])\n",
      "    Grad: tensor([-0.0431,  0.2441])\n",
      "Epoch 1478, Loss 3.0\n",
      "    Params: tensor([  5.1148, -15.8729])\n",
      "    Grad: tensor([-0.0430,  0.2437])\n",
      "Epoch 1479, Loss 3.0\n",
      "    Params: tensor([  5.1152, -15.8753])\n",
      "    Grad: tensor([-0.0430,  0.2432])\n",
      "Epoch 1480, Loss 3.0\n",
      "    Params: tensor([  5.1156, -15.8778])\n",
      "    Grad: tensor([-0.0429,  0.2428])\n",
      "Epoch 1481, Loss 3.0\n",
      "    Params: tensor([  5.1161, -15.8802])\n",
      "    Grad: tensor([-0.0428,  0.2424])\n",
      "Epoch 1482, Loss 3.0\n",
      "    Params: tensor([  5.1165, -15.8826])\n",
      "    Grad: tensor([-0.0427,  0.2420])\n",
      "Epoch 1483, Loss 3.0\n",
      "    Params: tensor([  5.1169, -15.8850])\n",
      "    Grad: tensor([-0.0427,  0.2416])\n",
      "Epoch 1484, Loss 3.0\n",
      "    Params: tensor([  5.1173, -15.8874])\n",
      "    Grad: tensor([-0.0426,  0.2412])\n",
      "Epoch 1485, Loss 3.0\n",
      "    Params: tensor([  5.1178, -15.8898])\n",
      "    Grad: tensor([-0.0425,  0.2408])\n",
      "Epoch 1486, Loss 3.0\n",
      "    Params: tensor([  5.1182, -15.8922])\n",
      "    Grad: tensor([-0.0425,  0.2404])\n",
      "Epoch 1487, Loss 3.0\n",
      "    Params: tensor([  5.1186, -15.8946])\n",
      "    Grad: tensor([-0.0424,  0.2400])\n",
      "Epoch 1488, Loss 3.0\n",
      "    Params: tensor([  5.1190, -15.8970])\n",
      "    Grad: tensor([-0.0423,  0.2396])\n",
      "Epoch 1489, Loss 3.0\n",
      "    Params: tensor([  5.1195, -15.8994])\n",
      "    Grad: tensor([-0.0423,  0.2391])\n",
      "Epoch 1490, Loss 3.0\n",
      "    Params: tensor([  5.1199, -15.9018])\n",
      "    Grad: tensor([-0.0422,  0.2387])\n",
      "Epoch 1491, Loss 3.0\n",
      "    Params: tensor([  5.1203, -15.9042])\n",
      "    Grad: tensor([-0.0421,  0.2383])\n",
      "Epoch 1492, Loss 3.0\n",
      "    Params: tensor([  5.1207, -15.9066])\n",
      "    Grad: tensor([-0.0420,  0.2379])\n",
      "Epoch 1493, Loss 3.0\n",
      "    Params: tensor([  5.1211, -15.9090])\n",
      "    Grad: tensor([-0.0420,  0.2375])\n",
      "Epoch 1494, Loss 3.0\n",
      "    Params: tensor([  5.1216, -15.9113])\n",
      "    Grad: tensor([-0.0419,  0.2371])\n",
      "Epoch 1495, Loss 3.0\n",
      "    Params: tensor([  5.1220, -15.9137])\n",
      "    Grad: tensor([-0.0418,  0.2367])\n",
      "Epoch 1496, Loss 3.0\n",
      "    Params: tensor([  5.1224, -15.9161])\n",
      "    Grad: tensor([-0.0417,  0.2363])\n",
      "Epoch 1497, Loss 3.0\n",
      "    Params: tensor([  5.1228, -15.9184])\n",
      "    Grad: tensor([-0.0417,  0.2359])\n",
      "Epoch 1498, Loss 3.0\n",
      "    Params: tensor([  5.1232, -15.9208])\n",
      "    Grad: tensor([-0.0416,  0.2355])\n",
      "Epoch 1499, Loss 3.0\n",
      "    Params: tensor([  5.1236, -15.9231])\n",
      "    Grad: tensor([-0.0415,  0.2351])\n",
      "Epoch 1500, Loss 3.0\n",
      "    Params: tensor([  5.1241, -15.9255])\n",
      "    Grad: tensor([-0.0414,  0.2347])\n",
      "Epoch 1501, Loss 3.0\n",
      "    Params: tensor([  5.1245, -15.9278])\n",
      "    Grad: tensor([-0.0414,  0.2343])\n",
      "Epoch 1502, Loss 3.0\n",
      "    Params: tensor([  5.1249, -15.9301])\n",
      "    Grad: tensor([-0.0413,  0.2339])\n",
      "Epoch 1503, Loss 3.0\n",
      "    Params: tensor([  5.1253, -15.9325])\n",
      "    Grad: tensor([-0.0412,  0.2335])\n",
      "Epoch 1504, Loss 3.0\n",
      "    Params: tensor([  5.1257, -15.9348])\n",
      "    Grad: tensor([-0.0412,  0.2331])\n",
      "Epoch 1505, Loss 3.0\n",
      "    Params: tensor([  5.1261, -15.9371])\n",
      "    Grad: tensor([-0.0411,  0.2327])\n",
      "Epoch 1506, Loss 3.0\n",
      "    Params: tensor([  5.1265, -15.9395])\n",
      "    Grad: tensor([-0.0410,  0.2323])\n",
      "Epoch 1507, Loss 3.0\n",
      "    Params: tensor([  5.1269, -15.9418])\n",
      "    Grad: tensor([-0.0410,  0.2319])\n",
      "Epoch 1508, Loss 3.0\n",
      "    Params: tensor([  5.1274, -15.9441])\n",
      "    Grad: tensor([-0.0409,  0.2315])\n",
      "Epoch 1509, Loss 3.0\n",
      "    Params: tensor([  5.1278, -15.9464])\n",
      "    Grad: tensor([-0.0408,  0.2312])\n",
      "Epoch 1510, Loss 3.0\n",
      "    Params: tensor([  5.1282, -15.9487])\n",
      "    Grad: tensor([-0.0408,  0.2308])\n",
      "Epoch 1511, Loss 3.0\n",
      "    Params: tensor([  5.1286, -15.9510])\n",
      "    Grad: tensor([-0.0407,  0.2304])\n",
      "Epoch 1512, Loss 3.0\n",
      "    Params: tensor([  5.1290, -15.9533])\n",
      "    Grad: tensor([-0.0406,  0.2300])\n",
      "Epoch 1513, Loss 3.0\n",
      "    Params: tensor([  5.1294, -15.9556])\n",
      "    Grad: tensor([-0.0406,  0.2296])\n",
      "Epoch 1514, Loss 3.0\n",
      "    Params: tensor([  5.1298, -15.9579])\n",
      "    Grad: tensor([-0.0405,  0.2292])\n",
      "Epoch 1515, Loss 3.0\n",
      "    Params: tensor([  5.1302, -15.9602])\n",
      "    Grad: tensor([-0.0404,  0.2288])\n",
      "Epoch 1516, Loss 3.0\n",
      "    Params: tensor([  5.1306, -15.9625])\n",
      "    Grad: tensor([-0.0404,  0.2284])\n",
      "Epoch 1517, Loss 3.0\n",
      "    Params: tensor([  5.1310, -15.9648])\n",
      "    Grad: tensor([-0.0403,  0.2280])\n",
      "Epoch 1518, Loss 3.0\n",
      "    Params: tensor([  5.1314, -15.9670])\n",
      "    Grad: tensor([-0.0402,  0.2276])\n",
      "Epoch 1519, Loss 3.0\n",
      "    Params: tensor([  5.1318, -15.9693])\n",
      "    Grad: tensor([-0.0402,  0.2272])\n",
      "Epoch 1520, Loss 3.0\n",
      "    Params: tensor([  5.1322, -15.9716])\n",
      "    Grad: tensor([-0.0401,  0.2269])\n",
      "Epoch 1521, Loss 3.0\n",
      "    Params: tensor([  5.1326, -15.9738])\n",
      "    Grad: tensor([-0.0400,  0.2265])\n",
      "Epoch 1522, Loss 3.0\n",
      "    Params: tensor([  5.1330, -15.9761])\n",
      "    Grad: tensor([-0.0399,  0.2261])\n",
      "Epoch 1523, Loss 3.0\n",
      "    Params: tensor([  5.1334, -15.9784])\n",
      "    Grad: tensor([-0.0399,  0.2257])\n",
      "Epoch 1524, Loss 3.0\n",
      "    Params: tensor([  5.1338, -15.9806])\n",
      "    Grad: tensor([-0.0398,  0.2253])\n",
      "Epoch 1525, Loss 3.0\n",
      "    Params: tensor([  5.1342, -15.9829])\n",
      "    Grad: tensor([-0.0397,  0.2249])\n",
      "Epoch 1526, Loss 3.0\n",
      "    Params: tensor([  5.1346, -15.9851])\n",
      "    Grad: tensor([-0.0397,  0.2246])\n",
      "Epoch 1527, Loss 3.0\n",
      "    Params: tensor([  5.1350, -15.9874])\n",
      "    Grad: tensor([-0.0396,  0.2242])\n",
      "Epoch 1528, Loss 3.0\n",
      "    Params: tensor([  5.1354, -15.9896])\n",
      "    Grad: tensor([-0.0395,  0.2238])\n",
      "Epoch 1529, Loss 3.0\n",
      "    Params: tensor([  5.1358, -15.9918])\n",
      "    Grad: tensor([-0.0395,  0.2234])\n",
      "Epoch 1530, Loss 3.0\n",
      "    Params: tensor([  5.1362, -15.9941])\n",
      "    Grad: tensor([-0.0394,  0.2230])\n",
      "Epoch 1531, Loss 3.0\n",
      "    Params: tensor([  5.1366, -15.9963])\n",
      "    Grad: tensor([-0.0393,  0.2227])\n",
      "Epoch 1532, Loss 3.0\n",
      "    Params: tensor([  5.1370, -15.9985])\n",
      "    Grad: tensor([-0.0393,  0.2223])\n",
      "Epoch 1533, Loss 3.0\n",
      "    Params: tensor([  5.1374, -16.0007])\n",
      "    Grad: tensor([-0.0392,  0.2219])\n",
      "Epoch 1534, Loss 3.0\n",
      "    Params: tensor([  5.1377, -16.0029])\n",
      "    Grad: tensor([-0.0391,  0.2215])\n",
      "Epoch 1535, Loss 3.0\n",
      "    Params: tensor([  5.1381, -16.0052])\n",
      "    Grad: tensor([-0.0391,  0.2212])\n",
      "Epoch 1536, Loss 3.0\n",
      "    Params: tensor([  5.1385, -16.0074])\n",
      "    Grad: tensor([-0.0390,  0.2208])\n",
      "Epoch 1537, Loss 3.0\n",
      "    Params: tensor([  5.1389, -16.0096])\n",
      "    Grad: tensor([-0.0389,  0.2204])\n",
      "Epoch 1538, Loss 3.0\n",
      "    Params: tensor([  5.1393, -16.0118])\n",
      "    Grad: tensor([-0.0389,  0.2200])\n",
      "Epoch 1539, Loss 3.0\n",
      "    Params: tensor([  5.1397, -16.0140])\n",
      "    Grad: tensor([-0.0388,  0.2197])\n",
      "Epoch 1540, Loss 3.0\n",
      "    Params: tensor([  5.1401, -16.0162])\n",
      "    Grad: tensor([-0.0388,  0.2193])\n",
      "Epoch 1541, Loss 3.0\n",
      "    Params: tensor([  5.1405, -16.0183])\n",
      "    Grad: tensor([-0.0387,  0.2189])\n",
      "Epoch 1542, Loss 3.0\n",
      "    Params: tensor([  5.1409, -16.0205])\n",
      "    Grad: tensor([-0.0386,  0.2185])\n",
      "Epoch 1543, Loss 3.0\n",
      "    Params: tensor([  5.1412, -16.0227])\n",
      "    Grad: tensor([-0.0385,  0.2182])\n",
      "Epoch 1544, Loss 3.0\n",
      "    Params: tensor([  5.1416, -16.0249])\n",
      "    Grad: tensor([-0.0385,  0.2178])\n",
      "Epoch 1545, Loss 3.0\n",
      "    Params: tensor([  5.1420, -16.0271])\n",
      "    Grad: tensor([-0.0384,  0.2174])\n",
      "Epoch 1546, Loss 3.0\n",
      "    Params: tensor([  5.1424, -16.0292])\n",
      "    Grad: tensor([-0.0383,  0.2171])\n",
      "Epoch 1547, Loss 3.0\n",
      "    Params: tensor([  5.1428, -16.0314])\n",
      "    Grad: tensor([-0.0383,  0.2167])\n",
      "Epoch 1548, Loss 3.0\n",
      "    Params: tensor([  5.1432, -16.0336])\n",
      "    Grad: tensor([-0.0382,  0.2163])\n",
      "Epoch 1549, Loss 3.0\n",
      "    Params: tensor([  5.1435, -16.0357])\n",
      "    Grad: tensor([-0.0381,  0.2159])\n",
      "Epoch 1550, Loss 3.0\n",
      "    Params: tensor([  5.1439, -16.0379])\n",
      "    Grad: tensor([-0.0381,  0.2156])\n",
      "Epoch 1551, Loss 3.0\n",
      "    Params: tensor([  5.1443, -16.0400])\n",
      "    Grad: tensor([-0.0380,  0.2152])\n",
      "Epoch 1552, Loss 3.0\n",
      "    Params: tensor([  5.1447, -16.0422])\n",
      "    Grad: tensor([-0.0379,  0.2149])\n",
      "Epoch 1553, Loss 3.0\n",
      "    Params: tensor([  5.1451, -16.0443])\n",
      "    Grad: tensor([-0.0379,  0.2145])\n",
      "Epoch 1554, Loss 3.0\n",
      "    Params: tensor([  5.1454, -16.0465])\n",
      "    Grad: tensor([-0.0378,  0.2141])\n",
      "Epoch 1555, Loss 3.0\n",
      "    Params: tensor([  5.1458, -16.0486])\n",
      "    Grad: tensor([-0.0378,  0.2138])\n",
      "Epoch 1556, Loss 3.0\n",
      "    Params: tensor([  5.1462, -16.0507])\n",
      "    Grad: tensor([-0.0377,  0.2134])\n",
      "Epoch 1557, Loss 3.0\n",
      "    Params: tensor([  5.1466, -16.0529])\n",
      "    Grad: tensor([-0.0376,  0.2130])\n",
      "Epoch 1558, Loss 3.0\n",
      "    Params: tensor([  5.1469, -16.0550])\n",
      "    Grad: tensor([-0.0376,  0.2127])\n",
      "Epoch 1559, Loss 3.0\n",
      "    Params: tensor([  5.1473, -16.0571])\n",
      "    Grad: tensor([-0.0375,  0.2123])\n",
      "Epoch 1560, Loss 3.0\n",
      "    Params: tensor([  5.1477, -16.0592])\n",
      "    Grad: tensor([-0.0374,  0.2119])\n",
      "Epoch 1561, Loss 3.0\n",
      "    Params: tensor([  5.1481, -16.0614])\n",
      "    Grad: tensor([-0.0374,  0.2116])\n",
      "Epoch 1562, Loss 3.0\n",
      "    Params: tensor([  5.1484, -16.0635])\n",
      "    Grad: tensor([-0.0373,  0.2112])\n",
      "Epoch 1563, Loss 3.0\n",
      "    Params: tensor([  5.1488, -16.0656])\n",
      "    Grad: tensor([-0.0372,  0.2109])\n",
      "Epoch 1564, Loss 3.0\n",
      "    Params: tensor([  5.1492, -16.0677])\n",
      "    Grad: tensor([-0.0372,  0.2105])\n",
      "Epoch 1565, Loss 3.0\n",
      "    Params: tensor([  5.1496, -16.0698])\n",
      "    Grad: tensor([-0.0371,  0.2102])\n",
      "Epoch 1566, Loss 3.0\n",
      "    Params: tensor([  5.1499, -16.0719])\n",
      "    Grad: tensor([-0.0371,  0.2098])\n",
      "Epoch 1567, Loss 3.0\n",
      "    Params: tensor([  5.1503, -16.0740])\n",
      "    Grad: tensor([-0.0370,  0.2094])\n",
      "Epoch 1568, Loss 3.0\n",
      "    Params: tensor([  5.1507, -16.0761])\n",
      "    Grad: tensor([-0.0369,  0.2091])\n",
      "Epoch 1569, Loss 3.0\n",
      "    Params: tensor([  5.1510, -16.0782])\n",
      "    Grad: tensor([-0.0369,  0.2087])\n",
      "Epoch 1570, Loss 3.0\n",
      "    Params: tensor([  5.1514, -16.0802])\n",
      "    Grad: tensor([-0.0368,  0.2084])\n",
      "Epoch 1571, Loss 3.0\n",
      "    Params: tensor([  5.1518, -16.0823])\n",
      "    Grad: tensor([-0.0367,  0.2080])\n",
      "Epoch 1572, Loss 3.0\n",
      "    Params: tensor([  5.1521, -16.0844])\n",
      "    Grad: tensor([-0.0367,  0.2077])\n",
      "Epoch 1573, Loss 3.0\n",
      "    Params: tensor([  5.1525, -16.0865])\n",
      "    Grad: tensor([-0.0366,  0.2073])\n",
      "Epoch 1574, Loss 3.0\n",
      "    Params: tensor([  5.1529, -16.0885])\n",
      "    Grad: tensor([-0.0366,  0.2070])\n",
      "Epoch 1575, Loss 3.0\n",
      "    Params: tensor([  5.1532, -16.0906])\n",
      "    Grad: tensor([-0.0365,  0.2066])\n",
      "Epoch 1576, Loss 3.0\n",
      "    Params: tensor([  5.1536, -16.0927])\n",
      "    Grad: tensor([-0.0364,  0.2063])\n",
      "Epoch 1577, Loss 3.0\n",
      "    Params: tensor([  5.1540, -16.0947])\n",
      "    Grad: tensor([-0.0364,  0.2059])\n",
      "Epoch 1578, Loss 3.0\n",
      "    Params: tensor([  5.1543, -16.0968])\n",
      "    Grad: tensor([-0.0363,  0.2056])\n",
      "Epoch 1579, Loss 3.0\n",
      "    Params: tensor([  5.1547, -16.0988])\n",
      "    Grad: tensor([-0.0363,  0.2052])\n",
      "Epoch 1580, Loss 3.0\n",
      "    Params: tensor([  5.1550, -16.1009])\n",
      "    Grad: tensor([-0.0362,  0.2049])\n",
      "Epoch 1581, Loss 3.0\n",
      "    Params: tensor([  5.1554, -16.1029])\n",
      "    Grad: tensor([-0.0361,  0.2045])\n",
      "Epoch 1582, Loss 3.0\n",
      "    Params: tensor([  5.1558, -16.1050])\n",
      "    Grad: tensor([-0.0361,  0.2042])\n",
      "Epoch 1583, Loss 3.0\n",
      "    Params: tensor([  5.1561, -16.1070])\n",
      "    Grad: tensor([-0.0360,  0.2038])\n",
      "Epoch 1584, Loss 3.0\n",
      "    Params: tensor([  5.1565, -16.1090])\n",
      "    Grad: tensor([-0.0360,  0.2035])\n",
      "Epoch 1585, Loss 3.0\n",
      "    Params: tensor([  5.1568, -16.1111])\n",
      "    Grad: tensor([-0.0359,  0.2031])\n",
      "Epoch 1586, Loss 3.0\n",
      "    Params: tensor([  5.1572, -16.1131])\n",
      "    Grad: tensor([-0.0358,  0.2028])\n",
      "Epoch 1587, Loss 3.0\n",
      "    Params: tensor([  5.1576, -16.1151])\n",
      "    Grad: tensor([-0.0358,  0.2024])\n",
      "Epoch 1588, Loss 3.0\n",
      "    Params: tensor([  5.1579, -16.1171])\n",
      "    Grad: tensor([-0.0357,  0.2021])\n",
      "Epoch 1589, Loss 3.0\n",
      "    Params: tensor([  5.1583, -16.1192])\n",
      "    Grad: tensor([-0.0356,  0.2018])\n",
      "Epoch 1590, Loss 3.0\n",
      "    Params: tensor([  5.1586, -16.1212])\n",
      "    Grad: tensor([-0.0356,  0.2014])\n",
      "Epoch 1591, Loss 3.0\n",
      "    Params: tensor([  5.1590, -16.1232])\n",
      "    Grad: tensor([-0.0355,  0.2011])\n",
      "Epoch 1592, Loss 3.0\n",
      "    Params: tensor([  5.1593, -16.1252])\n",
      "    Grad: tensor([-0.0355,  0.2007])\n",
      "Epoch 1593, Loss 3.0\n",
      "    Params: tensor([  5.1597, -16.1272])\n",
      "    Grad: tensor([-0.0354,  0.2004])\n",
      "Epoch 1594, Loss 3.0\n",
      "    Params: tensor([  5.1600, -16.1292])\n",
      "    Grad: tensor([-0.0354,  0.2000])\n",
      "Epoch 1595, Loss 3.0\n",
      "    Params: tensor([  5.1604, -16.1312])\n",
      "    Grad: tensor([-0.0353,  0.1997])\n",
      "Epoch 1596, Loss 3.0\n",
      "    Params: tensor([  5.1608, -16.1332])\n",
      "    Grad: tensor([-0.0352,  0.1994])\n",
      "Epoch 1597, Loss 3.0\n",
      "    Params: tensor([  5.1611, -16.1352])\n",
      "    Grad: tensor([-0.0352,  0.1990])\n",
      "Epoch 1598, Loss 3.0\n",
      "    Params: tensor([  5.1615, -16.1372])\n",
      "    Grad: tensor([-0.0351,  0.1987])\n",
      "Epoch 1599, Loss 3.0\n",
      "    Params: tensor([  5.1618, -16.1392])\n",
      "    Grad: tensor([-0.0351,  0.1983])\n",
      "Epoch 1600, Loss 3.0\n",
      "    Params: tensor([  5.1622, -16.1411])\n",
      "    Grad: tensor([-0.0350,  0.1980])\n",
      "Epoch 1601, Loss 3.0\n",
      "    Params: tensor([  5.1625, -16.1431])\n",
      "    Grad: tensor([-0.0349,  0.1977])\n",
      "Epoch 1602, Loss 3.0\n",
      "    Params: tensor([  5.1629, -16.1451])\n",
      "    Grad: tensor([-0.0349,  0.1973])\n",
      "Epoch 1603, Loss 3.0\n",
      "    Params: tensor([  5.1632, -16.1471])\n",
      "    Grad: tensor([-0.0348,  0.1970])\n",
      "Epoch 1604, Loss 3.0\n",
      "    Params: tensor([  5.1635, -16.1490])\n",
      "    Grad: tensor([-0.0347,  0.1967])\n",
      "Epoch 1605, Loss 3.0\n",
      "    Params: tensor([  5.1639, -16.1510])\n",
      "    Grad: tensor([-0.0347,  0.1963])\n",
      "Epoch 1606, Loss 3.0\n",
      "    Params: tensor([  5.1642, -16.1529])\n",
      "    Grad: tensor([-0.0346,  0.1960])\n",
      "Epoch 1607, Loss 3.0\n",
      "    Params: tensor([  5.1646, -16.1549])\n",
      "    Grad: tensor([-0.0346,  0.1957])\n",
      "Epoch 1608, Loss 3.0\n",
      "    Params: tensor([  5.1649, -16.1569])\n",
      "    Grad: tensor([-0.0345,  0.1953])\n",
      "Epoch 1609, Loss 3.0\n",
      "    Params: tensor([  5.1653, -16.1588])\n",
      "    Grad: tensor([-0.0344,  0.1950])\n",
      "Epoch 1610, Loss 3.0\n",
      "    Params: tensor([  5.1656, -16.1607])\n",
      "    Grad: tensor([-0.0344,  0.1947])\n",
      "Epoch 1611, Loss 3.0\n",
      "    Params: tensor([  5.1660, -16.1627])\n",
      "    Grad: tensor([-0.0343,  0.1943])\n",
      "Epoch 1612, Loss 3.0\n",
      "    Params: tensor([  5.1663, -16.1646])\n",
      "    Grad: tensor([-0.0343,  0.1940])\n",
      "Epoch 1613, Loss 3.0\n",
      "    Params: tensor([  5.1666, -16.1666])\n",
      "    Grad: tensor([-0.0342,  0.1937])\n",
      "Epoch 1614, Loss 3.0\n",
      "    Params: tensor([  5.1670, -16.1685])\n",
      "    Grad: tensor([-0.0342,  0.1934])\n",
      "Epoch 1615, Loss 3.0\n",
      "    Params: tensor([  5.1673, -16.1704])\n",
      "    Grad: tensor([-0.0341,  0.1930])\n",
      "Epoch 1616, Loss 3.0\n",
      "    Params: tensor([  5.1677, -16.1724])\n",
      "    Grad: tensor([-0.0341,  0.1927])\n",
      "Epoch 1617, Loss 3.0\n",
      "    Params: tensor([  5.1680, -16.1743])\n",
      "    Grad: tensor([-0.0340,  0.1924])\n",
      "Epoch 1618, Loss 3.0\n",
      "    Params: tensor([  5.1684, -16.1762])\n",
      "    Grad: tensor([-0.0339,  0.1920])\n",
      "Epoch 1619, Loss 3.0\n",
      "    Params: tensor([  5.1687, -16.1781])\n",
      "    Grad: tensor([-0.0339,  0.1917])\n",
      "Epoch 1620, Loss 3.0\n",
      "    Params: tensor([  5.1690, -16.1800])\n",
      "    Grad: tensor([-0.0338,  0.1914])\n",
      "Epoch 1621, Loss 3.0\n",
      "    Params: tensor([  5.1694, -16.1819])\n",
      "    Grad: tensor([-0.0337,  0.1911])\n",
      "Epoch 1622, Loss 3.0\n",
      "    Params: tensor([  5.1697, -16.1839])\n",
      "    Grad: tensor([-0.0337,  0.1907])\n",
      "Epoch 1623, Loss 3.0\n",
      "    Params: tensor([  5.1700, -16.1858])\n",
      "    Grad: tensor([-0.0336,  0.1904])\n",
      "Epoch 1624, Loss 3.0\n",
      "    Params: tensor([  5.1704, -16.1877])\n",
      "    Grad: tensor([-0.0336,  0.1901])\n",
      "Epoch 1625, Loss 3.0\n",
      "    Params: tensor([  5.1707, -16.1896])\n",
      "    Grad: tensor([-0.0335,  0.1898])\n",
      "Epoch 1626, Loss 3.0\n",
      "    Params: tensor([  5.1710, -16.1914])\n",
      "    Grad: tensor([-0.0335,  0.1895])\n",
      "Epoch 1627, Loss 3.0\n",
      "    Params: tensor([  5.1714, -16.1933])\n",
      "    Grad: tensor([-0.0334,  0.1891])\n",
      "Epoch 1628, Loss 3.0\n",
      "    Params: tensor([  5.1717, -16.1952])\n",
      "    Grad: tensor([-0.0333,  0.1888])\n",
      "Epoch 1629, Loss 3.0\n",
      "    Params: tensor([  5.1720, -16.1971])\n",
      "    Grad: tensor([-0.0333,  0.1885])\n",
      "Epoch 1630, Loss 3.0\n",
      "    Params: tensor([  5.1724, -16.1990])\n",
      "    Grad: tensor([-0.0332,  0.1882])\n",
      "Epoch 1631, Loss 3.0\n",
      "    Params: tensor([  5.1727, -16.2009])\n",
      "    Grad: tensor([-0.0332,  0.1878])\n",
      "Epoch 1632, Loss 3.0\n",
      "    Params: tensor([  5.1730, -16.2027])\n",
      "    Grad: tensor([-0.0331,  0.1875])\n",
      "Epoch 1633, Loss 3.0\n",
      "    Params: tensor([  5.1734, -16.2046])\n",
      "    Grad: tensor([-0.0331,  0.1872])\n",
      "Epoch 1634, Loss 3.0\n",
      "    Params: tensor([  5.1737, -16.2065])\n",
      "    Grad: tensor([-0.0330,  0.1869])\n",
      "Epoch 1635, Loss 3.0\n",
      "    Params: tensor([  5.1740, -16.2084])\n",
      "    Grad: tensor([-0.0330,  0.1866])\n",
      "Epoch 1636, Loss 3.0\n",
      "    Params: tensor([  5.1744, -16.2102])\n",
      "    Grad: tensor([-0.0329,  0.1863])\n",
      "Epoch 1637, Loss 3.0\n",
      "    Params: tensor([  5.1747, -16.2121])\n",
      "    Grad: tensor([-0.0329,  0.1859])\n",
      "Epoch 1638, Loss 3.0\n",
      "    Params: tensor([  5.1750, -16.2139])\n",
      "    Grad: tensor([-0.0328,  0.1856])\n",
      "Epoch 1639, Loss 3.0\n",
      "    Params: tensor([  5.1753, -16.2158])\n",
      "    Grad: tensor([-0.0327,  0.1853])\n",
      "Epoch 1640, Loss 3.0\n",
      "    Params: tensor([  5.1757, -16.2176])\n",
      "    Grad: tensor([-0.0327,  0.1850])\n",
      "Epoch 1641, Loss 3.0\n",
      "    Params: tensor([  5.1760, -16.2195])\n",
      "    Grad: tensor([-0.0326,  0.1847])\n",
      "Epoch 1642, Loss 3.0\n",
      "    Params: tensor([  5.1763, -16.2213])\n",
      "    Grad: tensor([-0.0326,  0.1844])\n",
      "Epoch 1643, Loss 3.0\n",
      "    Params: tensor([  5.1766, -16.2232])\n",
      "    Grad: tensor([-0.0325,  0.1841])\n",
      "Epoch 1644, Loss 3.0\n",
      "    Params: tensor([  5.1770, -16.2250])\n",
      "    Grad: tensor([-0.0325,  0.1837])\n",
      "Epoch 1645, Loss 3.0\n",
      "    Params: tensor([  5.1773, -16.2268])\n",
      "    Grad: tensor([-0.0324,  0.1834])\n",
      "Epoch 1646, Loss 3.0\n",
      "    Params: tensor([  5.1776, -16.2287])\n",
      "    Grad: tensor([-0.0324,  0.1831])\n",
      "Epoch 1647, Loss 3.0\n",
      "    Params: tensor([  5.1779, -16.2305])\n",
      "    Grad: tensor([-0.0323,  0.1828])\n",
      "Epoch 1648, Loss 3.0\n",
      "    Params: tensor([  5.1783, -16.2323])\n",
      "    Grad: tensor([-0.0322,  0.1825])\n",
      "Epoch 1649, Loss 3.0\n",
      "    Params: tensor([  5.1786, -16.2341])\n",
      "    Grad: tensor([-0.0322,  0.1822])\n",
      "Epoch 1650, Loss 3.0\n",
      "    Params: tensor([  5.1789, -16.2360])\n",
      "    Grad: tensor([-0.0321,  0.1819])\n",
      "Epoch 1651, Loss 3.0\n",
      "    Params: tensor([  5.1792, -16.2378])\n",
      "    Grad: tensor([-0.0321,  0.1816])\n",
      "Epoch 1652, Loss 3.0\n",
      "    Params: tensor([  5.1796, -16.2396])\n",
      "    Grad: tensor([-0.0320,  0.1813])\n",
      "Epoch 1653, Loss 3.0\n",
      "    Params: tensor([  5.1799, -16.2414])\n",
      "    Grad: tensor([-0.0320,  0.1810])\n",
      "Epoch 1654, Loss 3.0\n",
      "    Params: tensor([  5.1802, -16.2432])\n",
      "    Grad: tensor([-0.0319,  0.1806])\n",
      "Epoch 1655, Loss 3.0\n",
      "    Params: tensor([  5.1805, -16.2450])\n",
      "    Grad: tensor([-0.0319,  0.1803])\n",
      "Epoch 1656, Loss 3.0\n",
      "    Params: tensor([  5.1808, -16.2468])\n",
      "    Grad: tensor([-0.0318,  0.1800])\n",
      "Epoch 1657, Loss 3.0\n",
      "    Params: tensor([  5.1811, -16.2486])\n",
      "    Grad: tensor([-0.0318,  0.1797])\n",
      "Epoch 1658, Loss 3.0\n",
      "    Params: tensor([  5.1815, -16.2504])\n",
      "    Grad: tensor([-0.0317,  0.1794])\n",
      "Epoch 1659, Loss 3.0\n",
      "    Params: tensor([  5.1818, -16.2522])\n",
      "    Grad: tensor([-0.0316,  0.1791])\n",
      "Epoch 1660, Loss 3.0\n",
      "    Params: tensor([  5.1821, -16.2540])\n",
      "    Grad: tensor([-0.0316,  0.1788])\n",
      "Epoch 1661, Loss 3.0\n",
      "    Params: tensor([  5.1824, -16.2558])\n",
      "    Grad: tensor([-0.0315,  0.1785])\n",
      "Epoch 1662, Loss 3.0\n",
      "    Params: tensor([  5.1827, -16.2576])\n",
      "    Grad: tensor([-0.0315,  0.1782])\n",
      "Epoch 1663, Loss 3.0\n",
      "    Params: tensor([  5.1830, -16.2593])\n",
      "    Grad: tensor([-0.0314,  0.1779])\n",
      "Epoch 1664, Loss 3.0\n",
      "    Params: tensor([  5.1834, -16.2611])\n",
      "    Grad: tensor([-0.0314,  0.1776])\n",
      "Epoch 1665, Loss 3.0\n",
      "    Params: tensor([  5.1837, -16.2629])\n",
      "    Grad: tensor([-0.0313,  0.1773])\n",
      "Epoch 1666, Loss 3.0\n",
      "    Params: tensor([  5.1840, -16.2647])\n",
      "    Grad: tensor([-0.0313,  0.1770])\n",
      "Epoch 1667, Loss 3.0\n",
      "    Params: tensor([  5.1843, -16.2664])\n",
      "    Grad: tensor([-0.0312,  0.1767])\n",
      "Epoch 1668, Loss 3.0\n",
      "    Params: tensor([  5.1846, -16.2682])\n",
      "    Grad: tensor([-0.0311,  0.1764])\n",
      "Epoch 1669, Loss 3.0\n",
      "    Params: tensor([  5.1849, -16.2699])\n",
      "    Grad: tensor([-0.0311,  0.1761])\n",
      "Epoch 1670, Loss 3.0\n",
      "    Params: tensor([  5.1852, -16.2717])\n",
      "    Grad: tensor([-0.0311,  0.1758])\n",
      "Epoch 1671, Loss 3.0\n",
      "    Params: tensor([  5.1855, -16.2735])\n",
      "    Grad: tensor([-0.0310,  0.1755])\n",
      "Epoch 1672, Loss 3.0\n",
      "    Params: tensor([  5.1858, -16.2752])\n",
      "    Grad: tensor([-0.0310,  0.1752])\n",
      "Epoch 1673, Loss 3.0\n",
      "    Params: tensor([  5.1862, -16.2770])\n",
      "    Grad: tensor([-0.0309,  0.1749])\n",
      "Epoch 1674, Loss 3.0\n",
      "    Params: tensor([  5.1865, -16.2787])\n",
      "    Grad: tensor([-0.0308,  0.1746])\n",
      "Epoch 1675, Loss 3.0\n",
      "    Params: tensor([  5.1868, -16.2804])\n",
      "    Grad: tensor([-0.0308,  0.1743])\n",
      "Epoch 1676, Loss 3.0\n",
      "    Params: tensor([  5.1871, -16.2822])\n",
      "    Grad: tensor([-0.0307,  0.1740])\n",
      "Epoch 1677, Loss 3.0\n",
      "    Params: tensor([  5.1874, -16.2839])\n",
      "    Grad: tensor([-0.0307,  0.1737])\n",
      "Epoch 1678, Loss 3.0\n",
      "    Params: tensor([  5.1877, -16.2857])\n",
      "    Grad: tensor([-0.0306,  0.1734])\n",
      "Epoch 1679, Loss 3.0\n",
      "    Params: tensor([  5.1880, -16.2874])\n",
      "    Grad: tensor([-0.0306,  0.1731])\n",
      "Epoch 1680, Loss 3.0\n",
      "    Params: tensor([  5.1883, -16.2891])\n",
      "    Grad: tensor([-0.0305,  0.1728])\n",
      "Epoch 1681, Loss 3.0\n",
      "    Params: tensor([  5.1886, -16.2908])\n",
      "    Grad: tensor([-0.0305,  0.1725])\n",
      "Epoch 1682, Loss 3.0\n",
      "    Params: tensor([  5.1889, -16.2926])\n",
      "    Grad: tensor([-0.0304,  0.1722])\n",
      "Epoch 1683, Loss 3.0\n",
      "    Params: tensor([  5.1892, -16.2943])\n",
      "    Grad: tensor([-0.0304,  0.1720])\n",
      "Epoch 1684, Loss 3.0\n",
      "    Params: tensor([  5.1895, -16.2960])\n",
      "    Grad: tensor([-0.0303,  0.1717])\n",
      "Epoch 1685, Loss 3.0\n",
      "    Params: tensor([  5.1898, -16.2977])\n",
      "    Grad: tensor([-0.0303,  0.1714])\n",
      "Epoch 1686, Loss 3.0\n",
      "    Params: tensor([  5.1901, -16.2994])\n",
      "    Grad: tensor([-0.0302,  0.1711])\n",
      "Epoch 1687, Loss 3.0\n",
      "    Params: tensor([  5.1904, -16.3011])\n",
      "    Grad: tensor([-0.0302,  0.1708])\n",
      "Epoch 1688, Loss 3.0\n",
      "    Params: tensor([  5.1907, -16.3028])\n",
      "    Grad: tensor([-0.0301,  0.1705])\n",
      "Epoch 1689, Loss 3.0\n",
      "    Params: tensor([  5.1910, -16.3045])\n",
      "    Grad: tensor([-0.0301,  0.1702])\n",
      "Epoch 1690, Loss 3.0\n",
      "    Params: tensor([  5.1913, -16.3062])\n",
      "    Grad: tensor([-0.0300,  0.1699])\n",
      "Epoch 1691, Loss 3.0\n",
      "    Params: tensor([  5.1916, -16.3079])\n",
      "    Grad: tensor([-0.0300,  0.1696])\n",
      "Epoch 1692, Loss 3.0\n",
      "    Params: tensor([  5.1919, -16.3096])\n",
      "    Grad: tensor([-0.0299,  0.1693])\n",
      "Epoch 1693, Loss 3.0\n",
      "    Params: tensor([  5.1922, -16.3113])\n",
      "    Grad: tensor([-0.0299,  0.1691])\n",
      "Epoch 1694, Loss 3.0\n",
      "    Params: tensor([  5.1925, -16.3130])\n",
      "    Grad: tensor([-0.0298,  0.1688])\n",
      "Epoch 1695, Loss 3.0\n",
      "    Params: tensor([  5.1928, -16.3147])\n",
      "    Grad: tensor([-0.0298,  0.1685])\n",
      "Epoch 1696, Loss 3.0\n",
      "    Params: tensor([  5.1931, -16.3164])\n",
      "    Grad: tensor([-0.0297,  0.1682])\n",
      "Epoch 1697, Loss 3.0\n",
      "    Params: tensor([  5.1934, -16.3181])\n",
      "    Grad: tensor([-0.0297,  0.1679])\n",
      "Epoch 1698, Loss 3.0\n",
      "    Params: tensor([  5.1937, -16.3197])\n",
      "    Grad: tensor([-0.0296,  0.1676])\n",
      "Epoch 1699, Loss 3.0\n",
      "    Params: tensor([  5.1940, -16.3214])\n",
      "    Grad: tensor([-0.0296,  0.1673])\n",
      "Epoch 1700, Loss 3.0\n",
      "    Params: tensor([  5.1943, -16.3231])\n",
      "    Grad: tensor([-0.0295,  0.1671])\n",
      "Epoch 1701, Loss 3.0\n",
      "    Params: tensor([  5.1946, -16.3247])\n",
      "    Grad: tensor([-0.0295,  0.1668])\n",
      "Epoch 1702, Loss 3.0\n",
      "    Params: tensor([  5.1949, -16.3264])\n",
      "    Grad: tensor([-0.0294,  0.1665])\n",
      "Epoch 1703, Loss 3.0\n",
      "    Params: tensor([  5.1952, -16.3281])\n",
      "    Grad: tensor([-0.0294,  0.1662])\n",
      "Epoch 1704, Loss 3.0\n",
      "    Params: tensor([  5.1955, -16.3297])\n",
      "    Grad: tensor([-0.0293,  0.1659])\n",
      "Epoch 1705, Loss 3.0\n",
      "    Params: tensor([  5.1958, -16.3314])\n",
      "    Grad: tensor([-0.0293,  0.1656])\n",
      "Epoch 1706, Loss 3.0\n",
      "    Params: tensor([  5.1961, -16.3330])\n",
      "    Grad: tensor([-0.0292,  0.1654])\n",
      "Epoch 1707, Loss 3.0\n",
      "    Params: tensor([  5.1963, -16.3347])\n",
      "    Grad: tensor([-0.0292,  0.1651])\n",
      "Epoch 1708, Loss 3.0\n",
      "    Params: tensor([  5.1966, -16.3363])\n",
      "    Grad: tensor([-0.0291,  0.1648])\n",
      "Epoch 1709, Loss 3.0\n",
      "    Params: tensor([  5.1969, -16.3380])\n",
      "    Grad: tensor([-0.0291,  0.1645])\n",
      "Epoch 1710, Loss 3.0\n",
      "    Params: tensor([  5.1972, -16.3396])\n",
      "    Grad: tensor([-0.0290,  0.1642])\n",
      "Epoch 1711, Loss 3.0\n",
      "    Params: tensor([  5.1975, -16.3413])\n",
      "    Grad: tensor([-0.0290,  0.1640])\n",
      "Epoch 1712, Loss 3.0\n",
      "    Params: tensor([  5.1978, -16.3429])\n",
      "    Grad: tensor([-0.0289,  0.1637])\n",
      "Epoch 1713, Loss 3.0\n",
      "    Params: tensor([  5.1981, -16.3445])\n",
      "    Grad: tensor([-0.0289,  0.1634])\n",
      "Epoch 1714, Loss 3.0\n",
      "    Params: tensor([  5.1984, -16.3462])\n",
      "    Grad: tensor([-0.0288,  0.1631])\n",
      "Epoch 1715, Loss 3.0\n",
      "    Params: tensor([  5.1987, -16.3478])\n",
      "    Grad: tensor([-0.0288,  0.1628])\n",
      "Epoch 1716, Loss 3.0\n",
      "    Params: tensor([  5.1990, -16.3494])\n",
      "    Grad: tensor([-0.0287,  0.1626])\n",
      "Epoch 1717, Loss 3.0\n",
      "    Params: tensor([  5.1992, -16.3510])\n",
      "    Grad: tensor([-0.0287,  0.1623])\n",
      "Epoch 1718, Loss 3.0\n",
      "    Params: tensor([  5.1995, -16.3527])\n",
      "    Grad: tensor([-0.0286,  0.1620])\n",
      "Epoch 1719, Loss 3.0\n",
      "    Params: tensor([  5.1998, -16.3543])\n",
      "    Grad: tensor([-0.0286,  0.1617])\n",
      "Epoch 1720, Loss 3.0\n",
      "    Params: tensor([  5.2001, -16.3559])\n",
      "    Grad: tensor([-0.0285,  0.1615])\n",
      "Epoch 1721, Loss 3.0\n",
      "    Params: tensor([  5.2004, -16.3575])\n",
      "    Grad: tensor([-0.0285,  0.1612])\n",
      "Epoch 1722, Loss 3.0\n",
      "    Params: tensor([  5.2007, -16.3591])\n",
      "    Grad: tensor([-0.0284,  0.1609])\n",
      "Epoch 1723, Loss 3.0\n",
      "    Params: tensor([  5.2009, -16.3607])\n",
      "    Grad: tensor([-0.0284,  0.1606])\n",
      "Epoch 1724, Loss 3.0\n",
      "    Params: tensor([  5.2012, -16.3623])\n",
      "    Grad: tensor([-0.0283,  0.1604])\n",
      "Epoch 1725, Loss 3.0\n",
      "    Params: tensor([  5.2015, -16.3639])\n",
      "    Grad: tensor([-0.0283,  0.1601])\n",
      "Epoch 1726, Loss 3.0\n",
      "    Params: tensor([  5.2018, -16.3655])\n",
      "    Grad: tensor([-0.0282,  0.1598])\n",
      "Epoch 1727, Loss 3.0\n",
      "    Params: tensor([  5.2021, -16.3671])\n",
      "    Grad: tensor([-0.0282,  0.1596])\n",
      "Epoch 1728, Loss 3.0\n",
      "    Params: tensor([  5.2024, -16.3687])\n",
      "    Grad: tensor([-0.0282,  0.1593])\n",
      "Epoch 1729, Loss 3.0\n",
      "    Params: tensor([  5.2026, -16.3703])\n",
      "    Grad: tensor([-0.0281,  0.1590])\n",
      "Epoch 1730, Loss 3.0\n",
      "    Params: tensor([  5.2029, -16.3719])\n",
      "    Grad: tensor([-0.0281,  0.1587])\n",
      "Epoch 1731, Loss 3.0\n",
      "    Params: tensor([  5.2032, -16.3735])\n",
      "    Grad: tensor([-0.0280,  0.1585])\n",
      "Epoch 1732, Loss 3.0\n",
      "    Params: tensor([  5.2035, -16.3751])\n",
      "    Grad: tensor([-0.0279,  0.1582])\n",
      "Epoch 1733, Loss 3.0\n",
      "    Params: tensor([  5.2038, -16.3766])\n",
      "    Grad: tensor([-0.0279,  0.1579])\n",
      "Epoch 1734, Loss 3.0\n",
      "    Params: tensor([  5.2040, -16.3782])\n",
      "    Grad: tensor([-0.0278,  0.1577])\n",
      "Epoch 1735, Loss 3.0\n",
      "    Params: tensor([  5.2043, -16.3798])\n",
      "    Grad: tensor([-0.0278,  0.1574])\n",
      "Epoch 1736, Loss 3.0\n",
      "    Params: tensor([  5.2046, -16.3814])\n",
      "    Grad: tensor([-0.0278,  0.1571])\n",
      "Epoch 1737, Loss 3.0\n",
      "    Params: tensor([  5.2049, -16.3829])\n",
      "    Grad: tensor([-0.0277,  0.1569])\n",
      "Epoch 1738, Loss 3.0\n",
      "    Params: tensor([  5.2051, -16.3845])\n",
      "    Grad: tensor([-0.0277,  0.1566])\n",
      "Epoch 1739, Loss 3.0\n",
      "    Params: tensor([  5.2054, -16.3861])\n",
      "    Grad: tensor([-0.0276,  0.1563])\n",
      "Epoch 1740, Loss 3.0\n",
      "    Params: tensor([  5.2057, -16.3876])\n",
      "    Grad: tensor([-0.0276,  0.1561])\n",
      "Epoch 1741, Loss 3.0\n",
      "    Params: tensor([  5.2060, -16.3892])\n",
      "    Grad: tensor([-0.0275,  0.1558])\n",
      "Epoch 1742, Loss 3.0\n",
      "    Params: tensor([  5.2062, -16.3907])\n",
      "    Grad: tensor([-0.0275,  0.1555])\n",
      "Epoch 1743, Loss 3.0\n",
      "    Params: tensor([  5.2065, -16.3923])\n",
      "    Grad: tensor([-0.0274,  0.1553])\n",
      "Epoch 1744, Loss 3.0\n",
      "    Params: tensor([  5.2068, -16.3938])\n",
      "    Grad: tensor([-0.0274,  0.1550])\n",
      "Epoch 1745, Loss 3.0\n",
      "    Params: tensor([  5.2071, -16.3954])\n",
      "    Grad: tensor([-0.0274,  0.1547])\n",
      "Epoch 1746, Loss 3.0\n",
      "    Params: tensor([  5.2073, -16.3969])\n",
      "    Grad: tensor([-0.0273,  0.1545])\n",
      "Epoch 1747, Loss 3.0\n",
      "    Params: tensor([  5.2076, -16.3985])\n",
      "    Grad: tensor([-0.0272,  0.1542])\n",
      "Epoch 1748, Loss 3.0\n",
      "    Params: tensor([  5.2079, -16.4000])\n",
      "    Grad: tensor([-0.0272,  0.1540])\n",
      "Epoch 1749, Loss 3.0\n",
      "    Params: tensor([  5.2082, -16.4015])\n",
      "    Grad: tensor([-0.0271,  0.1537])\n",
      "Epoch 1750, Loss 3.0\n",
      "    Params: tensor([  5.2084, -16.4031])\n",
      "    Grad: tensor([-0.0271,  0.1534])\n",
      "Epoch 1751, Loss 3.0\n",
      "    Params: tensor([  5.2087, -16.4046])\n",
      "    Grad: tensor([-0.0270,  0.1532])\n",
      "Epoch 1752, Loss 3.0\n",
      "    Params: tensor([  5.2090, -16.4061])\n",
      "    Grad: tensor([-0.0270,  0.1529])\n",
      "Epoch 1753, Loss 3.0\n",
      "    Params: tensor([  5.2092, -16.4077])\n",
      "    Grad: tensor([-0.0270,  0.1527])\n",
      "Epoch 1754, Loss 3.0\n",
      "    Params: tensor([  5.2095, -16.4092])\n",
      "    Grad: tensor([-0.0269,  0.1524])\n",
      "Epoch 1755, Loss 3.0\n",
      "    Params: tensor([  5.2098, -16.4107])\n",
      "    Grad: tensor([-0.0269,  0.1521])\n",
      "Epoch 1756, Loss 3.0\n",
      "    Params: tensor([  5.2100, -16.4122])\n",
      "    Grad: tensor([-0.0268,  0.1519])\n",
      "Epoch 1757, Loss 3.0\n",
      "    Params: tensor([  5.2103, -16.4137])\n",
      "    Grad: tensor([-0.0268,  0.1516])\n",
      "Epoch 1758, Loss 3.0\n",
      "    Params: tensor([  5.2106, -16.4153])\n",
      "    Grad: tensor([-0.0267,  0.1514])\n",
      "Epoch 1759, Loss 3.0\n",
      "    Params: tensor([  5.2108, -16.4168])\n",
      "    Grad: tensor([-0.0267,  0.1511])\n",
      "Epoch 1760, Loss 3.0\n",
      "    Params: tensor([  5.2111, -16.4183])\n",
      "    Grad: tensor([-0.0266,  0.1509])\n",
      "Epoch 1761, Loss 3.0\n",
      "    Params: tensor([  5.2114, -16.4198])\n",
      "    Grad: tensor([-0.0266,  0.1506])\n",
      "Epoch 1762, Loss 3.0\n",
      "    Params: tensor([  5.2116, -16.4213])\n",
      "    Grad: tensor([-0.0266,  0.1503])\n",
      "Epoch 1763, Loss 3.0\n",
      "    Params: tensor([  5.2119, -16.4228])\n",
      "    Grad: tensor([-0.0265,  0.1501])\n",
      "Epoch 1764, Loss 3.0\n",
      "    Params: tensor([  5.2122, -16.4243])\n",
      "    Grad: tensor([-0.0265,  0.1498])\n",
      "Epoch 1765, Loss 3.0\n",
      "    Params: tensor([  5.2124, -16.4258])\n",
      "    Grad: tensor([-0.0264,  0.1496])\n",
      "Epoch 1766, Loss 3.0\n",
      "    Params: tensor([  5.2127, -16.4273])\n",
      "    Grad: tensor([-0.0264,  0.1493])\n",
      "Epoch 1767, Loss 3.0\n",
      "    Params: tensor([  5.2130, -16.4288])\n",
      "    Grad: tensor([-0.0263,  0.1491])\n",
      "Epoch 1768, Loss 3.0\n",
      "    Params: tensor([  5.2132, -16.4303])\n",
      "    Grad: tensor([-0.0263,  0.1488])\n",
      "Epoch 1769, Loss 3.0\n",
      "    Params: tensor([  5.2135, -16.4317])\n",
      "    Grad: tensor([-0.0262,  0.1486])\n",
      "Epoch 1770, Loss 3.0\n",
      "    Params: tensor([  5.2138, -16.4332])\n",
      "    Grad: tensor([-0.0262,  0.1483])\n",
      "Epoch 1771, Loss 3.0\n",
      "    Params: tensor([  5.2140, -16.4347])\n",
      "    Grad: tensor([-0.0262,  0.1481])\n",
      "Epoch 1772, Loss 3.0\n",
      "    Params: tensor([  5.2143, -16.4362])\n",
      "    Grad: tensor([-0.0261,  0.1478])\n",
      "Epoch 1773, Loss 3.0\n",
      "    Params: tensor([  5.2145, -16.4377])\n",
      "    Grad: tensor([-0.0261,  0.1476])\n",
      "Epoch 1774, Loss 3.0\n",
      "    Params: tensor([  5.2148, -16.4391])\n",
      "    Grad: tensor([-0.0260,  0.1473])\n",
      "Epoch 1775, Loss 3.0\n",
      "    Params: tensor([  5.2151, -16.4406])\n",
      "    Grad: tensor([-0.0260,  0.1471])\n",
      "Epoch 1776, Loss 3.0\n",
      "    Params: tensor([  5.2153, -16.4421])\n",
      "    Grad: tensor([-0.0259,  0.1468])\n",
      "Epoch 1777, Loss 3.0\n",
      "    Params: tensor([  5.2156, -16.4435])\n",
      "    Grad: tensor([-0.0259,  0.1466])\n",
      "Epoch 1778, Loss 3.0\n",
      "    Params: tensor([  5.2158, -16.4450])\n",
      "    Grad: tensor([-0.0258,  0.1463])\n",
      "Epoch 1779, Loss 3.0\n",
      "    Params: tensor([  5.2161, -16.4465])\n",
      "    Grad: tensor([-0.0258,  0.1461])\n",
      "Epoch 1780, Loss 3.0\n",
      "    Params: tensor([  5.2164, -16.4479])\n",
      "    Grad: tensor([-0.0258,  0.1458])\n",
      "Epoch 1781, Loss 3.0\n",
      "    Params: tensor([  5.2166, -16.4494])\n",
      "    Grad: tensor([-0.0257,  0.1456])\n",
      "Epoch 1782, Loss 3.0\n",
      "    Params: tensor([  5.2169, -16.4508])\n",
      "    Grad: tensor([-0.0257,  0.1453])\n",
      "Epoch 1783, Loss 3.0\n",
      "    Params: tensor([  5.2171, -16.4523])\n",
      "    Grad: tensor([-0.0256,  0.1451])\n",
      "Epoch 1784, Loss 3.0\n",
      "    Params: tensor([  5.2174, -16.4537])\n",
      "    Grad: tensor([-0.0256,  0.1448])\n",
      "Epoch 1785, Loss 3.0\n",
      "    Params: tensor([  5.2176, -16.4552])\n",
      "    Grad: tensor([-0.0255,  0.1446])\n",
      "Epoch 1786, Loss 3.0\n",
      "    Params: tensor([  5.2179, -16.4566])\n",
      "    Grad: tensor([-0.0255,  0.1443])\n",
      "Epoch 1787, Loss 3.0\n",
      "    Params: tensor([  5.2181, -16.4581])\n",
      "    Grad: tensor([-0.0255,  0.1441])\n",
      "Epoch 1788, Loss 3.0\n",
      "    Params: tensor([  5.2184, -16.4595])\n",
      "    Grad: tensor([-0.0254,  0.1438])\n",
      "Epoch 1789, Loss 3.0\n",
      "    Params: tensor([  5.2186, -16.4609])\n",
      "    Grad: tensor([-0.0253,  0.1436])\n",
      "Epoch 1790, Loss 3.0\n",
      "    Params: tensor([  5.2189, -16.4624])\n",
      "    Grad: tensor([-0.0253,  0.1434])\n",
      "Epoch 1791, Loss 3.0\n",
      "    Params: tensor([  5.2192, -16.4638])\n",
      "    Grad: tensor([-0.0253,  0.1431])\n",
      "Epoch 1792, Loss 3.0\n",
      "    Params: tensor([  5.2194, -16.4652])\n",
      "    Grad: tensor([-0.0252,  0.1429])\n",
      "Epoch 1793, Loss 3.0\n",
      "    Params: tensor([  5.2197, -16.4666])\n",
      "    Grad: tensor([-0.0252,  0.1426])\n",
      "Epoch 1794, Loss 3.0\n",
      "    Params: tensor([  5.2199, -16.4681])\n",
      "    Grad: tensor([-0.0252,  0.1424])\n",
      "Epoch 1795, Loss 3.0\n",
      "    Params: tensor([  5.2202, -16.4695])\n",
      "    Grad: tensor([-0.0251,  0.1421])\n",
      "Epoch 1796, Loss 3.0\n",
      "    Params: tensor([  5.2204, -16.4709])\n",
      "    Grad: tensor([-0.0251,  0.1419])\n",
      "Epoch 1797, Loss 3.0\n",
      "    Params: tensor([  5.2207, -16.4723])\n",
      "    Grad: tensor([-0.0250,  0.1417])\n",
      "Epoch 1798, Loss 3.0\n",
      "    Params: tensor([  5.2209, -16.4737])\n",
      "    Grad: tensor([-0.0250,  0.1414])\n",
      "Epoch 1799, Loss 3.0\n",
      "    Params: tensor([  5.2212, -16.4752])\n",
      "    Grad: tensor([-0.0249,  0.1412])\n",
      "Epoch 1800, Loss 3.0\n",
      "    Params: tensor([  5.2214, -16.4766])\n",
      "    Grad: tensor([-0.0249,  0.1409])\n",
      "Epoch 1801, Loss 3.0\n",
      "    Params: tensor([  5.2217, -16.4780])\n",
      "    Grad: tensor([-0.0248,  0.1407])\n",
      "Epoch 1802, Loss 3.0\n",
      "    Params: tensor([  5.2219, -16.4794])\n",
      "    Grad: tensor([-0.0248,  0.1405])\n",
      "Epoch 1803, Loss 3.0\n",
      "    Params: tensor([  5.2222, -16.4808])\n",
      "    Grad: tensor([-0.0248,  0.1402])\n",
      "Epoch 1804, Loss 3.0\n",
      "    Params: tensor([  5.2224, -16.4822])\n",
      "    Grad: tensor([-0.0247,  0.1400])\n",
      "Epoch 1805, Loss 3.0\n",
      "    Params: tensor([  5.2226, -16.4836])\n",
      "    Grad: tensor([-0.0247,  0.1397])\n",
      "Epoch 1806, Loss 3.0\n",
      "    Params: tensor([  5.2229, -16.4850])\n",
      "    Grad: tensor([-0.0246,  0.1395])\n",
      "Epoch 1807, Loss 3.0\n",
      "    Params: tensor([  5.2231, -16.4864])\n",
      "    Grad: tensor([-0.0246,  0.1393])\n",
      "Epoch 1808, Loss 3.0\n",
      "    Params: tensor([  5.2234, -16.4878])\n",
      "    Grad: tensor([-0.0245,  0.1390])\n",
      "Epoch 1809, Loss 3.0\n",
      "    Params: tensor([  5.2236, -16.4891])\n",
      "    Grad: tensor([-0.0245,  0.1388])\n",
      "Epoch 1810, Loss 3.0\n",
      "    Params: tensor([  5.2239, -16.4905])\n",
      "    Grad: tensor([-0.0245,  0.1386])\n",
      "Epoch 1811, Loss 3.0\n",
      "    Params: tensor([  5.2241, -16.4919])\n",
      "    Grad: tensor([-0.0244,  0.1383])\n",
      "Epoch 1812, Loss 3.0\n",
      "    Params: tensor([  5.2244, -16.4933])\n",
      "    Grad: tensor([-0.0244,  0.1381])\n",
      "Epoch 1813, Loss 3.0\n",
      "    Params: tensor([  5.2246, -16.4947])\n",
      "    Grad: tensor([-0.0243,  0.1379])\n",
      "Epoch 1814, Loss 3.0\n",
      "    Params: tensor([  5.2249, -16.4960])\n",
      "    Grad: tensor([-0.0243,  0.1376])\n",
      "Epoch 1815, Loss 3.0\n",
      "    Params: tensor([  5.2251, -16.4974])\n",
      "    Grad: tensor([-0.0243,  0.1374])\n",
      "Epoch 1816, Loss 3.0\n",
      "    Params: tensor([  5.2253, -16.4988])\n",
      "    Grad: tensor([-0.0242,  0.1372])\n",
      "Epoch 1817, Loss 3.0\n",
      "    Params: tensor([  5.2256, -16.5002])\n",
      "    Grad: tensor([-0.0242,  0.1369])\n",
      "Epoch 1818, Loss 3.0\n",
      "    Params: tensor([  5.2258, -16.5015])\n",
      "    Grad: tensor([-0.0241,  0.1367])\n",
      "Epoch 1819, Loss 3.0\n",
      "    Params: tensor([  5.2261, -16.5029])\n",
      "    Grad: tensor([-0.0241,  0.1365])\n",
      "Epoch 1820, Loss 3.0\n",
      "    Params: tensor([  5.2263, -16.5043])\n",
      "    Grad: tensor([-0.0241,  0.1362])\n",
      "Epoch 1821, Loss 3.0\n",
      "    Params: tensor([  5.2265, -16.5056])\n",
      "    Grad: tensor([-0.0240,  0.1360])\n",
      "Epoch 1822, Loss 3.0\n",
      "    Params: tensor([  5.2268, -16.5070])\n",
      "    Grad: tensor([-0.0240,  0.1358])\n",
      "Epoch 1823, Loss 3.0\n",
      "    Params: tensor([  5.2270, -16.5083])\n",
      "    Grad: tensor([-0.0239,  0.1355])\n",
      "Epoch 1824, Loss 3.0\n",
      "    Params: tensor([  5.2273, -16.5097])\n",
      "    Grad: tensor([-0.0239,  0.1353])\n",
      "Epoch 1825, Loss 3.0\n",
      "    Params: tensor([  5.2275, -16.5110])\n",
      "    Grad: tensor([-0.0239,  0.1351])\n",
      "Epoch 1826, Loss 3.0\n",
      "    Params: tensor([  5.2277, -16.5124])\n",
      "    Grad: tensor([-0.0238,  0.1348])\n",
      "Epoch 1827, Loss 3.0\n",
      "    Params: tensor([  5.2280, -16.5137])\n",
      "    Grad: tensor([-0.0238,  0.1346])\n",
      "Epoch 1828, Loss 3.0\n",
      "    Params: tensor([  5.2282, -16.5151])\n",
      "    Grad: tensor([-0.0238,  0.1344])\n",
      "Epoch 1829, Loss 3.0\n",
      "    Params: tensor([  5.2284, -16.5164])\n",
      "    Grad: tensor([-0.0237,  0.1342])\n",
      "Epoch 1830, Loss 3.0\n",
      "    Params: tensor([  5.2287, -16.5177])\n",
      "    Grad: tensor([-0.0237,  0.1339])\n",
      "Epoch 1831, Loss 3.0\n",
      "    Params: tensor([  5.2289, -16.5191])\n",
      "    Grad: tensor([-0.0236,  0.1337])\n",
      "Epoch 1832, Loss 3.0\n",
      "    Params: tensor([  5.2292, -16.5204])\n",
      "    Grad: tensor([-0.0236,  0.1335])\n",
      "Epoch 1833, Loss 3.0\n",
      "    Params: tensor([  5.2294, -16.5218])\n",
      "    Grad: tensor([-0.0235,  0.1332])\n",
      "Epoch 1834, Loss 3.0\n",
      "    Params: tensor([  5.2296, -16.5231])\n",
      "    Grad: tensor([-0.0235,  0.1330])\n",
      "Epoch 1835, Loss 3.0\n",
      "    Params: tensor([  5.2299, -16.5244])\n",
      "    Grad: tensor([-0.0234,  0.1328])\n",
      "Epoch 1836, Loss 3.0\n",
      "    Params: tensor([  5.2301, -16.5257])\n",
      "    Grad: tensor([-0.0234,  0.1326])\n",
      "Epoch 1837, Loss 3.0\n",
      "    Params: tensor([  5.2303, -16.5271])\n",
      "    Grad: tensor([-0.0234,  0.1323])\n",
      "Epoch 1838, Loss 3.0\n",
      "    Params: tensor([  5.2306, -16.5284])\n",
      "    Grad: tensor([-0.0233,  0.1321])\n",
      "Epoch 1839, Loss 3.0\n",
      "    Params: tensor([  5.2308, -16.5297])\n",
      "    Grad: tensor([-0.0233,  0.1319])\n",
      "Epoch 1840, Loss 3.0\n",
      "    Params: tensor([  5.2310, -16.5310])\n",
      "    Grad: tensor([-0.0232,  0.1317])\n",
      "Epoch 1841, Loss 3.0\n",
      "    Params: tensor([  5.2313, -16.5323])\n",
      "    Grad: tensor([-0.0232,  0.1314])\n",
      "Epoch 1842, Loss 3.0\n",
      "    Params: tensor([  5.2315, -16.5336])\n",
      "    Grad: tensor([-0.0232,  0.1312])\n",
      "Epoch 1843, Loss 3.0\n",
      "    Params: tensor([  5.2317, -16.5350])\n",
      "    Grad: tensor([-0.0231,  0.1310])\n",
      "Epoch 1844, Loss 3.0\n",
      "    Params: tensor([  5.2320, -16.5363])\n",
      "    Grad: tensor([-0.0231,  0.1308])\n",
      "Epoch 1845, Loss 3.0\n",
      "    Params: tensor([  5.2322, -16.5376])\n",
      "    Grad: tensor([-0.0231,  0.1306])\n",
      "Epoch 1846, Loss 3.0\n",
      "    Params: tensor([  5.2324, -16.5389])\n",
      "    Grad: tensor([-0.0230,  0.1303])\n",
      "Epoch 1847, Loss 3.0\n",
      "    Params: tensor([  5.2326, -16.5402])\n",
      "    Grad: tensor([-0.0230,  0.1301])\n",
      "Epoch 1848, Loss 3.0\n",
      "    Params: tensor([  5.2329, -16.5415])\n",
      "    Grad: tensor([-0.0229,  0.1299])\n",
      "Epoch 1849, Loss 3.0\n",
      "    Params: tensor([  5.2331, -16.5428])\n",
      "    Grad: tensor([-0.0229,  0.1297])\n",
      "Epoch 1850, Loss 3.0\n",
      "    Params: tensor([  5.2333, -16.5441])\n",
      "    Grad: tensor([-0.0229,  0.1294])\n",
      "Epoch 1851, Loss 3.0\n",
      "    Params: tensor([  5.2336, -16.5454])\n",
      "    Grad: tensor([-0.0228,  0.1292])\n",
      "Epoch 1852, Loss 3.0\n",
      "    Params: tensor([  5.2338, -16.5466])\n",
      "    Grad: tensor([-0.0228,  0.1290])\n",
      "Epoch 1853, Loss 3.0\n",
      "    Params: tensor([  5.2340, -16.5479])\n",
      "    Grad: tensor([-0.0227,  0.1288])\n",
      "Epoch 1854, Loss 3.0\n",
      "    Params: tensor([  5.2342, -16.5492])\n",
      "    Grad: tensor([-0.0227,  0.1286])\n",
      "Epoch 1855, Loss 3.0\n",
      "    Params: tensor([  5.2345, -16.5505])\n",
      "    Grad: tensor([-0.0227,  0.1284])\n",
      "Epoch 1856, Loss 3.0\n",
      "    Params: tensor([  5.2347, -16.5518])\n",
      "    Grad: tensor([-0.0226,  0.1281])\n",
      "Epoch 1857, Loss 3.0\n",
      "    Params: tensor([  5.2349, -16.5531])\n",
      "    Grad: tensor([-0.0226,  0.1279])\n",
      "Epoch 1858, Loss 3.0\n",
      "    Params: tensor([  5.2351, -16.5543])\n",
      "    Grad: tensor([-0.0226,  0.1277])\n",
      "Epoch 1859, Loss 3.0\n",
      "    Params: tensor([  5.2354, -16.5556])\n",
      "    Grad: tensor([-0.0225,  0.1275])\n",
      "Epoch 1860, Loss 3.0\n",
      "    Params: tensor([  5.2356, -16.5569])\n",
      "    Grad: tensor([-0.0225,  0.1273])\n",
      "Epoch 1861, Loss 3.0\n",
      "    Params: tensor([  5.2358, -16.5582])\n",
      "    Grad: tensor([-0.0224,  0.1271])\n",
      "Epoch 1862, Loss 3.0\n",
      "    Params: tensor([  5.2360, -16.5594])\n",
      "    Grad: tensor([-0.0224,  0.1268])\n",
      "Epoch 1863, Loss 3.0\n",
      "    Params: tensor([  5.2363, -16.5607])\n",
      "    Grad: tensor([-0.0224,  0.1266])\n",
      "Epoch 1864, Loss 3.0\n",
      "    Params: tensor([  5.2365, -16.5620])\n",
      "    Grad: tensor([-0.0223,  0.1264])\n",
      "Epoch 1865, Loss 3.0\n",
      "    Params: tensor([  5.2367, -16.5632])\n",
      "    Grad: tensor([-0.0223,  0.1262])\n",
      "Epoch 1866, Loss 3.0\n",
      "    Params: tensor([  5.2369, -16.5645])\n",
      "    Grad: tensor([-0.0223,  0.1260])\n",
      "Epoch 1867, Loss 3.0\n",
      "    Params: tensor([  5.2372, -16.5657])\n",
      "    Grad: tensor([-0.0222,  0.1258])\n",
      "Epoch 1868, Loss 3.0\n",
      "    Params: tensor([  5.2374, -16.5670])\n",
      "    Grad: tensor([-0.0222,  0.1255])\n",
      "Epoch 1869, Loss 3.0\n",
      "    Params: tensor([  5.2376, -16.5682])\n",
      "    Grad: tensor([-0.0221,  0.1253])\n",
      "Epoch 1870, Loss 3.0\n",
      "    Params: tensor([  5.2378, -16.5695])\n",
      "    Grad: tensor([-0.0221,  0.1251])\n",
      "Epoch 1871, Loss 3.0\n",
      "    Params: tensor([  5.2380, -16.5707])\n",
      "    Grad: tensor([-0.0221,  0.1249])\n",
      "Epoch 1872, Loss 3.0\n",
      "    Params: tensor([  5.2383, -16.5720])\n",
      "    Grad: tensor([-0.0220,  0.1247])\n",
      "Epoch 1873, Loss 3.0\n",
      "    Params: tensor([  5.2385, -16.5732])\n",
      "    Grad: tensor([-0.0220,  0.1245])\n",
      "Epoch 1874, Loss 3.0\n",
      "    Params: tensor([  5.2387, -16.5745])\n",
      "    Grad: tensor([-0.0220,  0.1243])\n",
      "Epoch 1875, Loss 3.0\n",
      "    Params: tensor([  5.2389, -16.5757])\n",
      "    Grad: tensor([-0.0219,  0.1241])\n",
      "Epoch 1876, Loss 3.0\n",
      "    Params: tensor([  5.2391, -16.5770])\n",
      "    Grad: tensor([-0.0219,  0.1239])\n",
      "Epoch 1877, Loss 3.0\n",
      "    Params: tensor([  5.2394, -16.5782])\n",
      "    Grad: tensor([-0.0218,  0.1236])\n",
      "Epoch 1878, Loss 3.0\n",
      "    Params: tensor([  5.2396, -16.5794])\n",
      "    Grad: tensor([-0.0218,  0.1234])\n",
      "Epoch 1879, Loss 3.0\n",
      "    Params: tensor([  5.2398, -16.5807])\n",
      "    Grad: tensor([-0.0218,  0.1232])\n",
      "Epoch 1880, Loss 3.0\n",
      "    Params: tensor([  5.2400, -16.5819])\n",
      "    Grad: tensor([-0.0217,  0.1230])\n",
      "Epoch 1881, Loss 3.0\n",
      "    Params: tensor([  5.2402, -16.5831])\n",
      "    Grad: tensor([-0.0217,  0.1228])\n",
      "Epoch 1882, Loss 3.0\n",
      "    Params: tensor([  5.2405, -16.5843])\n",
      "    Grad: tensor([-0.0217,  0.1226])\n",
      "Epoch 1883, Loss 3.0\n",
      "    Params: tensor([  5.2407, -16.5856])\n",
      "    Grad: tensor([-0.0216,  0.1224])\n",
      "Epoch 1884, Loss 3.0\n",
      "    Params: tensor([  5.2409, -16.5868])\n",
      "    Grad: tensor([-0.0216,  0.1222])\n",
      "Epoch 1885, Loss 3.0\n",
      "    Params: tensor([  5.2411, -16.5880])\n",
      "    Grad: tensor([-0.0216,  0.1220])\n",
      "Epoch 1886, Loss 3.0\n",
      "    Params: tensor([  5.2413, -16.5892])\n",
      "    Grad: tensor([-0.0215,  0.1218])\n",
      "Epoch 1887, Loss 3.0\n",
      "    Params: tensor([  5.2415, -16.5904])\n",
      "    Grad: tensor([-0.0215,  0.1216])\n",
      "Epoch 1888, Loss 3.0\n",
      "    Params: tensor([  5.2417, -16.5917])\n",
      "    Grad: tensor([-0.0214,  0.1214])\n",
      "Epoch 1889, Loss 3.0\n",
      "    Params: tensor([  5.2420, -16.5929])\n",
      "    Grad: tensor([-0.0214,  0.1211])\n",
      "Epoch 1890, Loss 3.0\n",
      "    Params: tensor([  5.2422, -16.5941])\n",
      "    Grad: tensor([-0.0214,  0.1209])\n",
      "Epoch 1891, Loss 3.0\n",
      "    Params: tensor([  5.2424, -16.5953])\n",
      "    Grad: tensor([-0.0213,  0.1207])\n",
      "Epoch 1892, Loss 3.0\n",
      "    Params: tensor([  5.2426, -16.5965])\n",
      "    Grad: tensor([-0.0213,  0.1205])\n",
      "Epoch 1893, Loss 3.0\n",
      "    Params: tensor([  5.2428, -16.5977])\n",
      "    Grad: tensor([-0.0213,  0.1203])\n",
      "Epoch 1894, Loss 3.0\n",
      "    Params: tensor([  5.2430, -16.5989])\n",
      "    Grad: tensor([-0.0212,  0.1201])\n",
      "Epoch 1895, Loss 3.0\n",
      "    Params: tensor([  5.2432, -16.6001])\n",
      "    Grad: tensor([-0.0212,  0.1199])\n",
      "Epoch 1896, Loss 3.0\n",
      "    Params: tensor([  5.2434, -16.6013])\n",
      "    Grad: tensor([-0.0212,  0.1197])\n",
      "Epoch 1897, Loss 3.0\n",
      "    Params: tensor([  5.2437, -16.6025])\n",
      "    Grad: tensor([-0.0211,  0.1195])\n",
      "Epoch 1898, Loss 3.0\n",
      "    Params: tensor([  5.2439, -16.6037])\n",
      "    Grad: tensor([-0.0211,  0.1193])\n",
      "Epoch 1899, Loss 3.0\n",
      "    Params: tensor([  5.2441, -16.6049])\n",
      "    Grad: tensor([-0.0210,  0.1191])\n",
      "Epoch 1900, Loss 3.0\n",
      "    Params: tensor([  5.2443, -16.6061])\n",
      "    Grad: tensor([-0.0210,  0.1189])\n",
      "Epoch 1901, Loss 3.0\n",
      "    Params: tensor([  5.2445, -16.6072])\n",
      "    Grad: tensor([-0.0210,  0.1187])\n",
      "Epoch 1902, Loss 3.0\n",
      "    Params: tensor([  5.2447, -16.6084])\n",
      "    Grad: tensor([-0.0209,  0.1185])\n",
      "Epoch 1903, Loss 3.0\n",
      "    Params: tensor([  5.2449, -16.6096])\n",
      "    Grad: tensor([-0.0209,  0.1183])\n",
      "Epoch 1904, Loss 3.0\n",
      "    Params: tensor([  5.2451, -16.6108])\n",
      "    Grad: tensor([-0.0208,  0.1181])\n",
      "Epoch 1905, Loss 3.0\n",
      "    Params: tensor([  5.2453, -16.6120])\n",
      "    Grad: tensor([-0.0208,  0.1179])\n",
      "Epoch 1906, Loss 3.0\n",
      "    Params: tensor([  5.2455, -16.6131])\n",
      "    Grad: tensor([-0.0208,  0.1177])\n",
      "Epoch 1907, Loss 3.0\n",
      "    Params: tensor([  5.2457, -16.6143])\n",
      "    Grad: tensor([-0.0207,  0.1175])\n",
      "Epoch 1908, Loss 3.0\n",
      "    Params: tensor([  5.2460, -16.6155])\n",
      "    Grad: tensor([-0.0207,  0.1173])\n",
      "Epoch 1909, Loss 3.0\n",
      "    Params: tensor([  5.2462, -16.6167])\n",
      "    Grad: tensor([-0.0207,  0.1171])\n",
      "Epoch 1910, Loss 3.0\n",
      "    Params: tensor([  5.2464, -16.6178])\n",
      "    Grad: tensor([-0.0207,  0.1169])\n",
      "Epoch 1911, Loss 3.0\n",
      "    Params: tensor([  5.2466, -16.6190])\n",
      "    Grad: tensor([-0.0206,  0.1167])\n",
      "Epoch 1912, Loss 3.0\n",
      "    Params: tensor([  5.2468, -16.6202])\n",
      "    Grad: tensor([-0.0206,  0.1165])\n",
      "Epoch 1913, Loss 3.0\n",
      "    Params: tensor([  5.2470, -16.6213])\n",
      "    Grad: tensor([-0.0205,  0.1163])\n",
      "Epoch 1914, Loss 3.0\n",
      "    Params: tensor([  5.2472, -16.6225])\n",
      "    Grad: tensor([-0.0205,  0.1161])\n",
      "Epoch 1915, Loss 3.0\n",
      "    Params: tensor([  5.2474, -16.6236])\n",
      "    Grad: tensor([-0.0205,  0.1159])\n",
      "Epoch 1916, Loss 3.0\n",
      "    Params: tensor([  5.2476, -16.6248])\n",
      "    Grad: tensor([-0.0205,  0.1157])\n",
      "Epoch 1917, Loss 3.0\n",
      "    Params: tensor([  5.2478, -16.6260])\n",
      "    Grad: tensor([-0.0204,  0.1155])\n",
      "Epoch 1918, Loss 3.0\n",
      "    Params: tensor([  5.2480, -16.6271])\n",
      "    Grad: tensor([-0.0204,  0.1153])\n",
      "Epoch 1919, Loss 3.0\n",
      "    Params: tensor([  5.2482, -16.6283])\n",
      "    Grad: tensor([-0.0203,  0.1151])\n",
      "Epoch 1920, Loss 3.0\n",
      "    Params: tensor([  5.2484, -16.6294])\n",
      "    Grad: tensor([-0.0203,  0.1149])\n",
      "Epoch 1921, Loss 3.0\n",
      "    Params: tensor([  5.2486, -16.6306])\n",
      "    Grad: tensor([-0.0203,  0.1147])\n",
      "Epoch 1922, Loss 3.0\n",
      "    Params: tensor([  5.2488, -16.6317])\n",
      "    Grad: tensor([-0.0202,  0.1145])\n",
      "Epoch 1923, Loss 3.0\n",
      "    Params: tensor([  5.2490, -16.6329])\n",
      "    Grad: tensor([-0.0202,  0.1143])\n",
      "Epoch 1924, Loss 3.0\n",
      "    Params: tensor([  5.2492, -16.6340])\n",
      "    Grad: tensor([-0.0202,  0.1141])\n",
      "Epoch 1925, Loss 3.0\n",
      "    Params: tensor([  5.2494, -16.6351])\n",
      "    Grad: tensor([-0.0201,  0.1140])\n",
      "Epoch 1926, Loss 3.0\n",
      "    Params: tensor([  5.2496, -16.6363])\n",
      "    Grad: tensor([-0.0201,  0.1138])\n",
      "Epoch 1927, Loss 3.0\n",
      "    Params: tensor([  5.2498, -16.6374])\n",
      "    Grad: tensor([-0.0200,  0.1136])\n",
      "Epoch 1928, Loss 3.0\n",
      "    Params: tensor([  5.2500, -16.6385])\n",
      "    Grad: tensor([-0.0200,  0.1134])\n",
      "Epoch 1929, Loss 3.0\n",
      "    Params: tensor([  5.2502, -16.6397])\n",
      "    Grad: tensor([-0.0200,  0.1132])\n",
      "Epoch 1930, Loss 3.0\n",
      "    Params: tensor([  5.2504, -16.6408])\n",
      "    Grad: tensor([-0.0199,  0.1130])\n",
      "Epoch 1931, Loss 3.0\n",
      "    Params: tensor([  5.2506, -16.6419])\n",
      "    Grad: tensor([-0.0199,  0.1128])\n",
      "Epoch 1932, Loss 3.0\n",
      "    Params: tensor([  5.2508, -16.6431])\n",
      "    Grad: tensor([-0.0199,  0.1126])\n",
      "Epoch 1933, Loss 3.0\n",
      "    Params: tensor([  5.2510, -16.6442])\n",
      "    Grad: tensor([-0.0198,  0.1124])\n",
      "Epoch 1934, Loss 3.0\n",
      "    Params: tensor([  5.2512, -16.6453])\n",
      "    Grad: tensor([-0.0198,  0.1122])\n",
      "Epoch 1935, Loss 3.0\n",
      "    Params: tensor([  5.2514, -16.6464])\n",
      "    Grad: tensor([-0.0198,  0.1120])\n",
      "Epoch 1936, Loss 3.0\n",
      "    Params: tensor([  5.2516, -16.6475])\n",
      "    Grad: tensor([-0.0197,  0.1118])\n",
      "Epoch 1937, Loss 3.0\n",
      "    Params: tensor([  5.2518, -16.6486])\n",
      "    Grad: tensor([-0.0197,  0.1117])\n",
      "Epoch 1938, Loss 3.0\n",
      "    Params: tensor([  5.2520, -16.6498])\n",
      "    Grad: tensor([-0.0197,  0.1115])\n",
      "Epoch 1939, Loss 3.0\n",
      "    Params: tensor([  5.2522, -16.6509])\n",
      "    Grad: tensor([-0.0197,  0.1113])\n",
      "Epoch 1940, Loss 3.0\n",
      "    Params: tensor([  5.2524, -16.6520])\n",
      "    Grad: tensor([-0.0196,  0.1111])\n",
      "Epoch 1941, Loss 3.0\n",
      "    Params: tensor([  5.2526, -16.6531])\n",
      "    Grad: tensor([-0.0196,  0.1109])\n",
      "Epoch 1942, Loss 3.0\n",
      "    Params: tensor([  5.2528, -16.6542])\n",
      "    Grad: tensor([-0.0195,  0.1107])\n",
      "Epoch 1943, Loss 3.0\n",
      "    Params: tensor([  5.2530, -16.6553])\n",
      "    Grad: tensor([-0.0195,  0.1105])\n",
      "Epoch 1944, Loss 3.0\n",
      "    Params: tensor([  5.2532, -16.6564])\n",
      "    Grad: tensor([-0.0195,  0.1103])\n",
      "Epoch 1945, Loss 3.0\n",
      "    Params: tensor([  5.2534, -16.6575])\n",
      "    Grad: tensor([-0.0195,  0.1101])\n",
      "Epoch 1946, Loss 3.0\n",
      "    Params: tensor([  5.2536, -16.6586])\n",
      "    Grad: tensor([-0.0194,  0.1100])\n",
      "Epoch 1947, Loss 3.0\n",
      "    Params: tensor([  5.2538, -16.6597])\n",
      "    Grad: tensor([-0.0194,  0.1098])\n",
      "Epoch 1948, Loss 3.0\n",
      "    Params: tensor([  5.2540, -16.6608])\n",
      "    Grad: tensor([-0.0194,  0.1096])\n",
      "Epoch 1949, Loss 3.0\n",
      "    Params: tensor([  5.2542, -16.6619])\n",
      "    Grad: tensor([-0.0193,  0.1094])\n",
      "Epoch 1950, Loss 3.0\n",
      "    Params: tensor([  5.2543, -16.6630])\n",
      "    Grad: tensor([-0.0193,  0.1092])\n",
      "Epoch 1951, Loss 3.0\n",
      "    Params: tensor([  5.2545, -16.6641])\n",
      "    Grad: tensor([-0.0193,  0.1090])\n",
      "Epoch 1952, Loss 3.0\n",
      "    Params: tensor([  5.2547, -16.6652])\n",
      "    Grad: tensor([-0.0192,  0.1088])\n",
      "Epoch 1953, Loss 3.0\n",
      "    Params: tensor([  5.2549, -16.6663])\n",
      "    Grad: tensor([-0.0192,  0.1087])\n",
      "Epoch 1954, Loss 3.0\n",
      "    Params: tensor([  5.2551, -16.6673])\n",
      "    Grad: tensor([-0.0192,  0.1085])\n",
      "Epoch 1955, Loss 3.0\n",
      "    Params: tensor([  5.2553, -16.6684])\n",
      "    Grad: tensor([-0.0191,  0.1083])\n",
      "Epoch 1956, Loss 3.0\n",
      "    Params: tensor([  5.2555, -16.6695])\n",
      "    Grad: tensor([-0.0191,  0.1081])\n",
      "Epoch 1957, Loss 3.0\n",
      "    Params: tensor([  5.2557, -16.6706])\n",
      "    Grad: tensor([-0.0191,  0.1079])\n",
      "Epoch 1958, Loss 3.0\n",
      "    Params: tensor([  5.2559, -16.6717])\n",
      "    Grad: tensor([-0.0190,  0.1077])\n",
      "Epoch 1959, Loss 3.0\n",
      "    Params: tensor([  5.2561, -16.6727])\n",
      "    Grad: tensor([-0.0190,  0.1075])\n",
      "Epoch 1960, Loss 3.0\n",
      "    Params: tensor([  5.2563, -16.6738])\n",
      "    Grad: tensor([-0.0190,  0.1074])\n",
      "Epoch 1961, Loss 3.0\n",
      "    Params: tensor([  5.2564, -16.6749])\n",
      "    Grad: tensor([-0.0189,  0.1072])\n",
      "Epoch 1962, Loss 3.0\n",
      "    Params: tensor([  5.2566, -16.6760])\n",
      "    Grad: tensor([-0.0189,  0.1070])\n",
      "Epoch 1963, Loss 3.0\n",
      "    Params: tensor([  5.2568, -16.6770])\n",
      "    Grad: tensor([-0.0189,  0.1068])\n",
      "Epoch 1964, Loss 3.0\n",
      "    Params: tensor([  5.2570, -16.6781])\n",
      "    Grad: tensor([-0.0188,  0.1066])\n",
      "Epoch 1965, Loss 3.0\n",
      "    Params: tensor([  5.2572, -16.6792])\n",
      "    Grad: tensor([-0.0188,  0.1065])\n",
      "Epoch 1966, Loss 3.0\n",
      "    Params: tensor([  5.2574, -16.6802])\n",
      "    Grad: tensor([-0.0188,  0.1063])\n",
      "Epoch 1967, Loss 3.0\n",
      "    Params: tensor([  5.2576, -16.6813])\n",
      "    Grad: tensor([-0.0187,  0.1061])\n",
      "Epoch 1968, Loss 3.0\n",
      "    Params: tensor([  5.2578, -16.6823])\n",
      "    Grad: tensor([-0.0187,  0.1059])\n",
      "Epoch 1969, Loss 3.0\n",
      "    Params: tensor([  5.2579, -16.6834])\n",
      "    Grad: tensor([-0.0187,  0.1057])\n",
      "Epoch 1970, Loss 3.0\n",
      "    Params: tensor([  5.2581, -16.6844])\n",
      "    Grad: tensor([-0.0186,  0.1056])\n",
      "Epoch 1971, Loss 3.0\n",
      "    Params: tensor([  5.2583, -16.6855])\n",
      "    Grad: tensor([-0.0186,  0.1054])\n",
      "Epoch 1972, Loss 3.0\n",
      "    Params: tensor([  5.2585, -16.6866])\n",
      "    Grad: tensor([-0.0186,  0.1052])\n",
      "Epoch 1973, Loss 3.0\n",
      "    Params: tensor([  5.2587, -16.6876])\n",
      "    Grad: tensor([-0.0186,  0.1050])\n",
      "Epoch 1974, Loss 3.0\n",
      "    Params: tensor([  5.2589, -16.6887])\n",
      "    Grad: tensor([-0.0185,  0.1048])\n",
      "Epoch 1975, Loss 3.0\n",
      "    Params: tensor([  5.2591, -16.6897])\n",
      "    Grad: tensor([-0.0185,  0.1047])\n",
      "Epoch 1976, Loss 3.0\n",
      "    Params: tensor([  5.2592, -16.6907])\n",
      "    Grad: tensor([-0.0185,  0.1045])\n",
      "Epoch 1977, Loss 3.0\n",
      "    Params: tensor([  5.2594, -16.6918])\n",
      "    Grad: tensor([-0.0184,  0.1043])\n",
      "Epoch 1978, Loss 3.0\n",
      "    Params: tensor([  5.2596, -16.6928])\n",
      "    Grad: tensor([-0.0184,  0.1041])\n",
      "Epoch 1979, Loss 3.0\n",
      "    Params: tensor([  5.2598, -16.6939])\n",
      "    Grad: tensor([-0.0184,  0.1040])\n",
      "Epoch 1980, Loss 3.0\n",
      "    Params: tensor([  5.2600, -16.6949])\n",
      "    Grad: tensor([-0.0183,  0.1038])\n",
      "Epoch 1981, Loss 3.0\n",
      "    Params: tensor([  5.2602, -16.6959])\n",
      "    Grad: tensor([-0.0183,  0.1036])\n",
      "Epoch 1982, Loss 3.0\n",
      "    Params: tensor([  5.2603, -16.6970])\n",
      "    Grad: tensor([-0.0183,  0.1034])\n",
      "Epoch 1983, Loss 3.0\n",
      "    Params: tensor([  5.2605, -16.6980])\n",
      "    Grad: tensor([-0.0182,  0.1033])\n",
      "Epoch 1984, Loss 3.0\n",
      "    Params: tensor([  5.2607, -16.6990])\n",
      "    Grad: tensor([-0.0182,  0.1031])\n",
      "Epoch 1985, Loss 3.0\n",
      "    Params: tensor([  5.2609, -16.7001])\n",
      "    Grad: tensor([-0.0182,  0.1029])\n",
      "Epoch 1986, Loss 3.0\n",
      "    Params: tensor([  5.2611, -16.7011])\n",
      "    Grad: tensor([-0.0182,  0.1027])\n",
      "Epoch 1987, Loss 3.0\n",
      "    Params: tensor([  5.2613, -16.7021])\n",
      "    Grad: tensor([-0.0181,  0.1026])\n",
      "Epoch 1988, Loss 3.0\n",
      "    Params: tensor([  5.2614, -16.7031])\n",
      "    Grad: tensor([-0.0181,  0.1024])\n",
      "Epoch 1989, Loss 3.0\n",
      "    Params: tensor([  5.2616, -16.7042])\n",
      "    Grad: tensor([-0.0180,  0.1022])\n",
      "Epoch 1990, Loss 3.0\n",
      "    Params: tensor([  5.2618, -16.7052])\n",
      "    Grad: tensor([-0.0180,  0.1020])\n",
      "Epoch 1991, Loss 3.0\n",
      "    Params: tensor([  5.2620, -16.7062])\n",
      "    Grad: tensor([-0.0180,  0.1019])\n",
      "Epoch 1992, Loss 3.0\n",
      "    Params: tensor([  5.2622, -16.7072])\n",
      "    Grad: tensor([-0.0180,  0.1017])\n",
      "Epoch 1993, Loss 3.0\n",
      "    Params: tensor([  5.2623, -16.7082])\n",
      "    Grad: tensor([-0.0179,  0.1015])\n",
      "Epoch 1994, Loss 3.0\n",
      "    Params: tensor([  5.2625, -16.7093])\n",
      "    Grad: tensor([-0.0179,  0.1013])\n",
      "Epoch 1995, Loss 3.0\n",
      "    Params: tensor([  5.2627, -16.7103])\n",
      "    Grad: tensor([-0.0179,  0.1012])\n",
      "Epoch 1996, Loss 3.0\n",
      "    Params: tensor([  5.2629, -16.7113])\n",
      "    Grad: tensor([-0.0178,  0.1010])\n",
      "Epoch 1997, Loss 3.0\n",
      "    Params: tensor([  5.2631, -16.7123])\n",
      "    Grad: tensor([-0.0178,  0.1008])\n",
      "Epoch 1998, Loss 3.0\n",
      "    Params: tensor([  5.2632, -16.7133])\n",
      "    Grad: tensor([-0.0178,  0.1006])\n",
      "Epoch 1999, Loss 3.0\n",
      "    Params: tensor([  5.2634, -16.7143])\n",
      "    Grad: tensor([-0.0178,  0.1005])\n",
      "Epoch 2000, Loss 3.0\n",
      "    Params: tensor([  5.2636, -16.7153])\n",
      "    Grad: tensor([-0.0177,  0.1003])\n",
      "Epoch 2001, Loss 3.0\n",
      "    Params: tensor([  5.2638, -16.7163])\n",
      "    Grad: tensor([-0.0177,  0.1001])\n",
      "Epoch 2002, Loss 3.0\n",
      "    Params: tensor([  5.2639, -16.7173])\n",
      "    Grad: tensor([-0.0176,  0.1000])\n",
      "Epoch 2003, Loss 3.0\n",
      "    Params: tensor([  5.2641, -16.7183])\n",
      "    Grad: tensor([-0.0176,  0.0998])\n",
      "Epoch 2004, Loss 3.0\n",
      "    Params: tensor([  5.2643, -16.7193])\n",
      "    Grad: tensor([-0.0176,  0.0996])\n",
      "Epoch 2005, Loss 3.0\n",
      "    Params: tensor([  5.2645, -16.7203])\n",
      "    Grad: tensor([-0.0175,  0.0995])\n",
      "Epoch 2006, Loss 3.0\n",
      "    Params: tensor([  5.2646, -16.7213])\n",
      "    Grad: tensor([-0.0175,  0.0993])\n",
      "Epoch 2007, Loss 3.0\n",
      "    Params: tensor([  5.2648, -16.7223])\n",
      "    Grad: tensor([-0.0175,  0.0991])\n",
      "Epoch 2008, Loss 3.0\n",
      "    Params: tensor([  5.2650, -16.7233])\n",
      "    Grad: tensor([-0.0175,  0.0990])\n",
      "Epoch 2009, Loss 3.0\n",
      "    Params: tensor([  5.2652, -16.7243])\n",
      "    Grad: tensor([-0.0174,  0.0988])\n",
      "Epoch 2010, Loss 3.0\n",
      "    Params: tensor([  5.2653, -16.7252])\n",
      "    Grad: tensor([-0.0174,  0.0986])\n",
      "Epoch 2011, Loss 3.0\n",
      "    Params: tensor([  5.2655, -16.7262])\n",
      "    Grad: tensor([-0.0174,  0.0984])\n",
      "Epoch 2012, Loss 3.0\n",
      "    Params: tensor([  5.2657, -16.7272])\n",
      "    Grad: tensor([-0.0174,  0.0983])\n",
      "Epoch 2013, Loss 3.0\n",
      "    Params: tensor([  5.2659, -16.7282])\n",
      "    Grad: tensor([-0.0173,  0.0981])\n",
      "Epoch 2014, Loss 3.0\n",
      "    Params: tensor([  5.2660, -16.7292])\n",
      "    Grad: tensor([-0.0173,  0.0980])\n",
      "Epoch 2015, Loss 3.0\n",
      "    Params: tensor([  5.2662, -16.7301])\n",
      "    Grad: tensor([-0.0173,  0.0978])\n",
      "Epoch 2016, Loss 3.0\n",
      "    Params: tensor([  5.2664, -16.7311])\n",
      "    Grad: tensor([-0.0173,  0.0976])\n",
      "Epoch 2017, Loss 3.0\n",
      "    Params: tensor([  5.2666, -16.7321])\n",
      "    Grad: tensor([-0.0172,  0.0975])\n",
      "Epoch 2018, Loss 3.0\n",
      "    Params: tensor([  5.2667, -16.7331])\n",
      "    Grad: tensor([-0.0172,  0.0973])\n",
      "Epoch 2019, Loss 3.0\n",
      "    Params: tensor([  5.2669, -16.7340])\n",
      "    Grad: tensor([-0.0172,  0.0971])\n",
      "Epoch 2020, Loss 3.0\n",
      "    Params: tensor([  5.2671, -16.7350])\n",
      "    Grad: tensor([-0.0171,  0.0970])\n",
      "Epoch 2021, Loss 3.0\n",
      "    Params: tensor([  5.2672, -16.7360])\n",
      "    Grad: tensor([-0.0171,  0.0968])\n",
      "Epoch 2022, Loss 3.0\n",
      "    Params: tensor([  5.2674, -16.7369])\n",
      "    Grad: tensor([-0.0171,  0.0966])\n",
      "Epoch 2023, Loss 3.0\n",
      "    Params: tensor([  5.2676, -16.7379])\n",
      "    Grad: tensor([-0.0170,  0.0965])\n",
      "Epoch 2024, Loss 3.0\n",
      "    Params: tensor([  5.2677, -16.7389])\n",
      "    Grad: tensor([-0.0170,  0.0963])\n",
      "Epoch 2025, Loss 3.0\n",
      "    Params: tensor([  5.2679, -16.7398])\n",
      "    Grad: tensor([-0.0170,  0.0961])\n",
      "Epoch 2026, Loss 3.0\n",
      "    Params: tensor([  5.2681, -16.7408])\n",
      "    Grad: tensor([-0.0170,  0.0960])\n",
      "Epoch 2027, Loss 3.0\n",
      "    Params: tensor([  5.2683, -16.7417])\n",
      "    Grad: tensor([-0.0169,  0.0958])\n",
      "Epoch 2028, Loss 3.0\n",
      "    Params: tensor([  5.2684, -16.7427])\n",
      "    Grad: tensor([-0.0169,  0.0956])\n",
      "Epoch 2029, Loss 3.0\n",
      "    Params: tensor([  5.2686, -16.7437])\n",
      "    Grad: tensor([-0.0169,  0.0955])\n",
      "Epoch 2030, Loss 3.0\n",
      "    Params: tensor([  5.2688, -16.7446])\n",
      "    Grad: tensor([-0.0168,  0.0953])\n",
      "Epoch 2031, Loss 3.0\n",
      "    Params: tensor([  5.2689, -16.7456])\n",
      "    Grad: tensor([-0.0168,  0.0952])\n",
      "Epoch 2032, Loss 3.0\n",
      "    Params: tensor([  5.2691, -16.7465])\n",
      "    Grad: tensor([-0.0168,  0.0950])\n",
      "Epoch 2033, Loss 3.0\n",
      "    Params: tensor([  5.2693, -16.7475])\n",
      "    Grad: tensor([-0.0168,  0.0948])\n",
      "Epoch 2034, Loss 3.0\n",
      "    Params: tensor([  5.2694, -16.7484])\n",
      "    Grad: tensor([-0.0167,  0.0947])\n",
      "Epoch 2035, Loss 3.0\n",
      "    Params: tensor([  5.2696, -16.7494])\n",
      "    Grad: tensor([-0.0167,  0.0945])\n",
      "Epoch 2036, Loss 3.0\n",
      "    Params: tensor([  5.2698, -16.7503])\n",
      "    Grad: tensor([-0.0167,  0.0944])\n",
      "Epoch 2037, Loss 3.0\n",
      "    Params: tensor([  5.2699, -16.7512])\n",
      "    Grad: tensor([-0.0166,  0.0942])\n",
      "Epoch 2038, Loss 3.0\n",
      "    Params: tensor([  5.2701, -16.7522])\n",
      "    Grad: tensor([-0.0166,  0.0940])\n",
      "Epoch 2039, Loss 3.0\n",
      "    Params: tensor([  5.2703, -16.7531])\n",
      "    Grad: tensor([-0.0166,  0.0939])\n",
      "Epoch 2040, Loss 3.0\n",
      "    Params: tensor([  5.2704, -16.7541])\n",
      "    Grad: tensor([-0.0165,  0.0937])\n",
      "Epoch 2041, Loss 3.0\n",
      "    Params: tensor([  5.2706, -16.7550])\n",
      "    Grad: tensor([-0.0165,  0.0936])\n",
      "Epoch 2042, Loss 3.0\n",
      "    Params: tensor([  5.2708, -16.7559])\n",
      "    Grad: tensor([-0.0165,  0.0934])\n",
      "Epoch 2043, Loss 3.0\n",
      "    Params: tensor([  5.2709, -16.7569])\n",
      "    Grad: tensor([-0.0165,  0.0932])\n",
      "Epoch 2044, Loss 3.0\n",
      "    Params: tensor([  5.2711, -16.7578])\n",
      "    Grad: tensor([-0.0164,  0.0931])\n",
      "Epoch 2045, Loss 3.0\n",
      "    Params: tensor([  5.2713, -16.7587])\n",
      "    Grad: tensor([-0.0164,  0.0929])\n",
      "Epoch 2046, Loss 3.0\n",
      "    Params: tensor([  5.2714, -16.7596])\n",
      "    Grad: tensor([-0.0164,  0.0928])\n",
      "Epoch 2047, Loss 3.0\n",
      "    Params: tensor([  5.2716, -16.7606])\n",
      "    Grad: tensor([-0.0163,  0.0926])\n",
      "Epoch 2048, Loss 3.0\n",
      "    Params: tensor([  5.2717, -16.7615])\n",
      "    Grad: tensor([-0.0163,  0.0924])\n",
      "Epoch 2049, Loss 3.0\n",
      "    Params: tensor([  5.2719, -16.7624])\n",
      "    Grad: tensor([-0.0163,  0.0923])\n",
      "Epoch 2050, Loss 3.0\n",
      "    Params: tensor([  5.2721, -16.7633])\n",
      "    Grad: tensor([-0.0163,  0.0921])\n",
      "Epoch 2051, Loss 3.0\n",
      "    Params: tensor([  5.2722, -16.7643])\n",
      "    Grad: tensor([-0.0162,  0.0920])\n",
      "Epoch 2052, Loss 3.0\n",
      "    Params: tensor([  5.2724, -16.7652])\n",
      "    Grad: tensor([-0.0162,  0.0918])\n",
      "Epoch 2053, Loss 3.0\n",
      "    Params: tensor([  5.2726, -16.7661])\n",
      "    Grad: tensor([-0.0162,  0.0917])\n",
      "Epoch 2054, Loss 3.0\n",
      "    Params: tensor([  5.2727, -16.7670])\n",
      "    Grad: tensor([-0.0162,  0.0915])\n",
      "Epoch 2055, Loss 3.0\n",
      "    Params: tensor([  5.2729, -16.7679])\n",
      "    Grad: tensor([-0.0161,  0.0914])\n",
      "Epoch 2056, Loss 3.0\n",
      "    Params: tensor([  5.2730, -16.7688])\n",
      "    Grad: tensor([-0.0161,  0.0912])\n",
      "Epoch 2057, Loss 3.0\n",
      "    Params: tensor([  5.2732, -16.7697])\n",
      "    Grad: tensor([-0.0161,  0.0910])\n",
      "Epoch 2058, Loss 3.0\n",
      "    Params: tensor([  5.2734, -16.7707])\n",
      "    Grad: tensor([-0.0160,  0.0909])\n",
      "Epoch 2059, Loss 3.0\n",
      "    Params: tensor([  5.2735, -16.7716])\n",
      "    Grad: tensor([-0.0160,  0.0907])\n",
      "Epoch 2060, Loss 3.0\n",
      "    Params: tensor([  5.2737, -16.7725])\n",
      "    Grad: tensor([-0.0160,  0.0906])\n",
      "Epoch 2061, Loss 3.0\n",
      "    Params: tensor([  5.2738, -16.7734])\n",
      "    Grad: tensor([-0.0160,  0.0904])\n",
      "Epoch 2062, Loss 3.0\n",
      "    Params: tensor([  5.2740, -16.7743])\n",
      "    Grad: tensor([-0.0159,  0.0903])\n",
      "Epoch 2063, Loss 3.0\n",
      "    Params: tensor([  5.2742, -16.7752])\n",
      "    Grad: tensor([-0.0159,  0.0901])\n",
      "Epoch 2064, Loss 3.0\n",
      "    Params: tensor([  5.2743, -16.7761])\n",
      "    Grad: tensor([-0.0159,  0.0900])\n",
      "Epoch 2065, Loss 3.0\n",
      "    Params: tensor([  5.2745, -16.7770])\n",
      "    Grad: tensor([-0.0159,  0.0898])\n",
      "Epoch 2066, Loss 3.0\n",
      "    Params: tensor([  5.2746, -16.7779])\n",
      "    Grad: tensor([-0.0158,  0.0897])\n",
      "Epoch 2067, Loss 3.0\n",
      "    Params: tensor([  5.2748, -16.7788])\n",
      "    Grad: tensor([-0.0158,  0.0895])\n",
      "Epoch 2068, Loss 3.0\n",
      "    Params: tensor([  5.2750, -16.7797])\n",
      "    Grad: tensor([-0.0158,  0.0894])\n",
      "Epoch 2069, Loss 3.0\n",
      "    Params: tensor([  5.2751, -16.7806])\n",
      "    Grad: tensor([-0.0158,  0.0892])\n",
      "Epoch 2070, Loss 3.0\n",
      "    Params: tensor([  5.2753, -16.7814])\n",
      "    Grad: tensor([-0.0157,  0.0891])\n",
      "Epoch 2071, Loss 3.0\n",
      "    Params: tensor([  5.2754, -16.7823])\n",
      "    Grad: tensor([-0.0157,  0.0889])\n",
      "Epoch 2072, Loss 3.0\n",
      "    Params: tensor([  5.2756, -16.7832])\n",
      "    Grad: tensor([-0.0157,  0.0888])\n",
      "Epoch 2073, Loss 3.0\n",
      "    Params: tensor([  5.2757, -16.7841])\n",
      "    Grad: tensor([-0.0156,  0.0886])\n",
      "Epoch 2074, Loss 3.0\n",
      "    Params: tensor([  5.2759, -16.7850])\n",
      "    Grad: tensor([-0.0156,  0.0885])\n",
      "Epoch 2075, Loss 3.0\n",
      "    Params: tensor([  5.2761, -16.7859])\n",
      "    Grad: tensor([-0.0156,  0.0883])\n",
      "Epoch 2076, Loss 3.0\n",
      "    Params: tensor([  5.2762, -16.7868])\n",
      "    Grad: tensor([-0.0156,  0.0882])\n",
      "Epoch 2077, Loss 3.0\n",
      "    Params: tensor([  5.2764, -16.7876])\n",
      "    Grad: tensor([-0.0155,  0.0880])\n",
      "Epoch 2078, Loss 3.0\n",
      "    Params: tensor([  5.2765, -16.7885])\n",
      "    Grad: tensor([-0.0155,  0.0879])\n",
      "Epoch 2079, Loss 3.0\n",
      "    Params: tensor([  5.2767, -16.7894])\n",
      "    Grad: tensor([-0.0155,  0.0877])\n",
      "Epoch 2080, Loss 3.0\n",
      "    Params: tensor([  5.2768, -16.7903])\n",
      "    Grad: tensor([-0.0155,  0.0876])\n",
      "Epoch 2081, Loss 3.0\n",
      "    Params: tensor([  5.2770, -16.7911])\n",
      "    Grad: tensor([-0.0154,  0.0874])\n",
      "Epoch 2082, Loss 3.0\n",
      "    Params: tensor([  5.2771, -16.7920])\n",
      "    Grad: tensor([-0.0154,  0.0873])\n",
      "Epoch 2083, Loss 3.0\n",
      "    Params: tensor([  5.2773, -16.7929])\n",
      "    Grad: tensor([-0.0154,  0.0871])\n",
      "Epoch 2084, Loss 3.0\n",
      "    Params: tensor([  5.2774, -16.7938])\n",
      "    Grad: tensor([-0.0154,  0.0870])\n",
      "Epoch 2085, Loss 3.0\n",
      "    Params: tensor([  5.2776, -16.7946])\n",
      "    Grad: tensor([-0.0153,  0.0868])\n",
      "Epoch 2086, Loss 3.0\n",
      "    Params: tensor([  5.2778, -16.7955])\n",
      "    Grad: tensor([-0.0153,  0.0867])\n",
      "Epoch 2087, Loss 3.0\n",
      "    Params: tensor([  5.2779, -16.7964])\n",
      "    Grad: tensor([-0.0153,  0.0865])\n",
      "Epoch 2088, Loss 3.0\n",
      "    Params: tensor([  5.2781, -16.7972])\n",
      "    Grad: tensor([-0.0153,  0.0864])\n",
      "Epoch 2089, Loss 3.0\n",
      "    Params: tensor([  5.2782, -16.7981])\n",
      "    Grad: tensor([-0.0152,  0.0862])\n",
      "Epoch 2090, Loss 3.0\n",
      "    Params: tensor([  5.2784, -16.7989])\n",
      "    Grad: tensor([-0.0152,  0.0861])\n",
      "Epoch 2091, Loss 3.0\n",
      "    Params: tensor([  5.2785, -16.7998])\n",
      "    Grad: tensor([-0.0152,  0.0859])\n",
      "Epoch 2092, Loss 3.0\n",
      "    Params: tensor([  5.2787, -16.8007])\n",
      "    Grad: tensor([-0.0152,  0.0858])\n",
      "Epoch 2093, Loss 3.0\n",
      "    Params: tensor([  5.2788, -16.8015])\n",
      "    Grad: tensor([-0.0151,  0.0856])\n",
      "Epoch 2094, Loss 3.0\n",
      "    Params: tensor([  5.2790, -16.8024])\n",
      "    Grad: tensor([-0.0151,  0.0855])\n",
      "Epoch 2095, Loss 3.0\n",
      "    Params: tensor([  5.2791, -16.8032])\n",
      "    Grad: tensor([-0.0151,  0.0853])\n",
      "Epoch 2096, Loss 3.0\n",
      "    Params: tensor([  5.2793, -16.8041])\n",
      "    Grad: tensor([-0.0150,  0.0852])\n",
      "Epoch 2097, Loss 3.0\n",
      "    Params: tensor([  5.2794, -16.8049])\n",
      "    Grad: tensor([-0.0150,  0.0851])\n",
      "Epoch 2098, Loss 3.0\n",
      "    Params: tensor([  5.2796, -16.8058])\n",
      "    Grad: tensor([-0.0150,  0.0849])\n",
      "Epoch 2099, Loss 3.0\n",
      "    Params: tensor([  5.2797, -16.8066])\n",
      "    Grad: tensor([-0.0150,  0.0848])\n",
      "Epoch 2100, Loss 3.0\n",
      "    Params: tensor([  5.2799, -16.8075])\n",
      "    Grad: tensor([-0.0149,  0.0846])\n",
      "Epoch 2101, Loss 3.0\n",
      "    Params: tensor([  5.2800, -16.8083])\n",
      "    Grad: tensor([-0.0149,  0.0845])\n",
      "Epoch 2102, Loss 3.0\n",
      "    Params: tensor([  5.2802, -16.8092])\n",
      "    Grad: tensor([-0.0149,  0.0843])\n",
      "Epoch 2103, Loss 3.0\n",
      "    Params: tensor([  5.2803, -16.8100])\n",
      "    Grad: tensor([-0.0149,  0.0842])\n",
      "Epoch 2104, Loss 3.0\n",
      "    Params: tensor([  5.2805, -16.8108])\n",
      "    Grad: tensor([-0.0148,  0.0841])\n",
      "Epoch 2105, Loss 3.0\n",
      "    Params: tensor([  5.2806, -16.8117])\n",
      "    Grad: tensor([-0.0148,  0.0839])\n",
      "Epoch 2106, Loss 3.0\n",
      "    Params: tensor([  5.2808, -16.8125])\n",
      "    Grad: tensor([-0.0148,  0.0838])\n",
      "Epoch 2107, Loss 3.0\n",
      "    Params: tensor([  5.2809, -16.8134])\n",
      "    Grad: tensor([-0.0148,  0.0836])\n",
      "Epoch 2108, Loss 3.0\n",
      "    Params: tensor([  5.2811, -16.8142])\n",
      "    Grad: tensor([-0.0147,  0.0835])\n",
      "Epoch 2109, Loss 3.0\n",
      "    Params: tensor([  5.2812, -16.8150])\n",
      "    Grad: tensor([-0.0147,  0.0833])\n",
      "Epoch 2110, Loss 3.0\n",
      "    Params: tensor([  5.2813, -16.8159])\n",
      "    Grad: tensor([-0.0147,  0.0832])\n",
      "Epoch 2111, Loss 3.0\n",
      "    Params: tensor([  5.2815, -16.8167])\n",
      "    Grad: tensor([-0.0147,  0.0831])\n",
      "Epoch 2112, Loss 3.0\n",
      "    Params: tensor([  5.2816, -16.8175])\n",
      "    Grad: tensor([-0.0146,  0.0829])\n",
      "Epoch 2113, Loss 3.0\n",
      "    Params: tensor([  5.2818, -16.8183])\n",
      "    Grad: tensor([-0.0146,  0.0828])\n",
      "Epoch 2114, Loss 3.0\n",
      "    Params: tensor([  5.2819, -16.8192])\n",
      "    Grad: tensor([-0.0146,  0.0826])\n",
      "Epoch 2115, Loss 3.0\n",
      "    Params: tensor([  5.2821, -16.8200])\n",
      "    Grad: tensor([-0.0146,  0.0825])\n",
      "Epoch 2116, Loss 3.0\n",
      "    Params: tensor([  5.2822, -16.8208])\n",
      "    Grad: tensor([-0.0146,  0.0824])\n",
      "Epoch 2117, Loss 3.0\n",
      "    Params: tensor([  5.2824, -16.8216])\n",
      "    Grad: tensor([-0.0145,  0.0822])\n",
      "Epoch 2118, Loss 3.0\n",
      "    Params: tensor([  5.2825, -16.8225])\n",
      "    Grad: tensor([-0.0145,  0.0821])\n",
      "Epoch 2119, Loss 3.0\n",
      "    Params: tensor([  5.2827, -16.8233])\n",
      "    Grad: tensor([-0.0145,  0.0819])\n",
      "Epoch 2120, Loss 3.0\n",
      "    Params: tensor([  5.2828, -16.8241])\n",
      "    Grad: tensor([-0.0144,  0.0818])\n",
      "Epoch 2121, Loss 3.0\n",
      "    Params: tensor([  5.2829, -16.8249])\n",
      "    Grad: tensor([-0.0144,  0.0817])\n",
      "Epoch 2122, Loss 3.0\n",
      "    Params: tensor([  5.2831, -16.8257])\n",
      "    Grad: tensor([-0.0144,  0.0815])\n",
      "Epoch 2123, Loss 3.0\n",
      "    Params: tensor([  5.2832, -16.8265])\n",
      "    Grad: tensor([-0.0144,  0.0814])\n",
      "Epoch 2124, Loss 3.0\n",
      "    Params: tensor([  5.2834, -16.8274])\n",
      "    Grad: tensor([-0.0143,  0.0812])\n",
      "Epoch 2125, Loss 3.0\n",
      "    Params: tensor([  5.2835, -16.8282])\n",
      "    Grad: tensor([-0.0143,  0.0811])\n",
      "Epoch 2126, Loss 3.0\n",
      "    Params: tensor([  5.2837, -16.8290])\n",
      "    Grad: tensor([-0.0143,  0.0810])\n",
      "Epoch 2127, Loss 3.0\n",
      "    Params: tensor([  5.2838, -16.8298])\n",
      "    Grad: tensor([-0.0143,  0.0808])\n",
      "Epoch 2128, Loss 3.0\n",
      "    Params: tensor([  5.2840, -16.8306])\n",
      "    Grad: tensor([-0.0143,  0.0807])\n",
      "Epoch 2129, Loss 3.0\n",
      "    Params: tensor([  5.2841, -16.8314])\n",
      "    Grad: tensor([-0.0142,  0.0806])\n",
      "Epoch 2130, Loss 3.0\n",
      "    Params: tensor([  5.2842, -16.8322])\n",
      "    Grad: tensor([-0.0142,  0.0804])\n",
      "Epoch 2131, Loss 3.0\n",
      "    Params: tensor([  5.2844, -16.8330])\n",
      "    Grad: tensor([-0.0142,  0.0803])\n",
      "Epoch 2132, Loss 3.0\n",
      "    Params: tensor([  5.2845, -16.8338])\n",
      "    Grad: tensor([-0.0142,  0.0801])\n",
      "Epoch 2133, Loss 3.0\n",
      "    Params: tensor([  5.2847, -16.8346])\n",
      "    Grad: tensor([-0.0141,  0.0800])\n",
      "Epoch 2134, Loss 3.0\n",
      "    Params: tensor([  5.2848, -16.8354])\n",
      "    Grad: tensor([-0.0141,  0.0799])\n",
      "Epoch 2135, Loss 3.0\n",
      "    Params: tensor([  5.2849, -16.8362])\n",
      "    Grad: tensor([-0.0141,  0.0797])\n",
      "Epoch 2136, Loss 3.0\n",
      "    Params: tensor([  5.2851, -16.8370])\n",
      "    Grad: tensor([-0.0141,  0.0796])\n",
      "Epoch 2137, Loss 3.0\n",
      "    Params: tensor([  5.2852, -16.8378])\n",
      "    Grad: tensor([-0.0140,  0.0795])\n",
      "Epoch 2138, Loss 3.0\n",
      "    Params: tensor([  5.2854, -16.8386])\n",
      "    Grad: tensor([-0.0140,  0.0793])\n",
      "Epoch 2139, Loss 3.0\n",
      "    Params: tensor([  5.2855, -16.8394])\n",
      "    Grad: tensor([-0.0140,  0.0792])\n",
      "Epoch 2140, Loss 3.0\n",
      "    Params: tensor([  5.2856, -16.8402])\n",
      "    Grad: tensor([-0.0140,  0.0791])\n",
      "Epoch 2141, Loss 3.0\n",
      "    Params: tensor([  5.2858, -16.8410])\n",
      "    Grad: tensor([-0.0139,  0.0789])\n",
      "Epoch 2142, Loss 3.0\n",
      "    Params: tensor([  5.2859, -16.8417])\n",
      "    Grad: tensor([-0.0139,  0.0788])\n",
      "Epoch 2143, Loss 3.0\n",
      "    Params: tensor([  5.2861, -16.8425])\n",
      "    Grad: tensor([-0.0139,  0.0787])\n",
      "Epoch 2144, Loss 3.0\n",
      "    Params: tensor([  5.2862, -16.8433])\n",
      "    Grad: tensor([-0.0139,  0.0785])\n",
      "Epoch 2145, Loss 3.0\n",
      "    Params: tensor([  5.2863, -16.8441])\n",
      "    Grad: tensor([-0.0138,  0.0784])\n",
      "Epoch 2146, Loss 3.0\n",
      "    Params: tensor([  5.2865, -16.8449])\n",
      "    Grad: tensor([-0.0138,  0.0783])\n",
      "Epoch 2147, Loss 3.0\n",
      "    Params: tensor([  5.2866, -16.8457])\n",
      "    Grad: tensor([-0.0138,  0.0781])\n",
      "Epoch 2148, Loss 3.0\n",
      "    Params: tensor([  5.2868, -16.8464])\n",
      "    Grad: tensor([-0.0138,  0.0780])\n",
      "Epoch 2149, Loss 3.0\n",
      "    Params: tensor([  5.2869, -16.8472])\n",
      "    Grad: tensor([-0.0138,  0.0779])\n",
      "Epoch 2150, Loss 3.0\n",
      "    Params: tensor([  5.2870, -16.8480])\n",
      "    Grad: tensor([-0.0137,  0.0777])\n",
      "Epoch 2151, Loss 3.0\n",
      "    Params: tensor([  5.2872, -16.8488])\n",
      "    Grad: tensor([-0.0137,  0.0776])\n",
      "Epoch 2152, Loss 3.0\n",
      "    Params: tensor([  5.2873, -16.8495])\n",
      "    Grad: tensor([-0.0137,  0.0775])\n",
      "Epoch 2153, Loss 3.0\n",
      "    Params: tensor([  5.2874, -16.8503])\n",
      "    Grad: tensor([-0.0137,  0.0773])\n",
      "Epoch 2154, Loss 3.0\n",
      "    Params: tensor([  5.2876, -16.8511])\n",
      "    Grad: tensor([-0.0136,  0.0772])\n",
      "Epoch 2155, Loss 3.0\n",
      "    Params: tensor([  5.2877, -16.8519])\n",
      "    Grad: tensor([-0.0136,  0.0771])\n",
      "Epoch 2156, Loss 3.0\n",
      "    Params: tensor([  5.2878, -16.8526])\n",
      "    Grad: tensor([-0.0136,  0.0769])\n",
      "Epoch 2157, Loss 3.0\n",
      "    Params: tensor([  5.2880, -16.8534])\n",
      "    Grad: tensor([-0.0136,  0.0768])\n",
      "Epoch 2158, Loss 3.0\n",
      "    Params: tensor([  5.2881, -16.8542])\n",
      "    Grad: tensor([-0.0135,  0.0767])\n",
      "Epoch 2159, Loss 3.0\n",
      "    Params: tensor([  5.2883, -16.8549])\n",
      "    Grad: tensor([-0.0135,  0.0765])\n",
      "Epoch 2160, Loss 3.0\n",
      "    Params: tensor([  5.2884, -16.8557])\n",
      "    Grad: tensor([-0.0135,  0.0764])\n",
      "Epoch 2161, Loss 3.0\n",
      "    Params: tensor([  5.2885, -16.8565])\n",
      "    Grad: tensor([-0.0135,  0.0763])\n",
      "Epoch 2162, Loss 3.0\n",
      "    Params: tensor([  5.2887, -16.8572])\n",
      "    Grad: tensor([-0.0134,  0.0762])\n",
      "Epoch 2163, Loss 3.0\n",
      "    Params: tensor([  5.2888, -16.8580])\n",
      "    Grad: tensor([-0.0134,  0.0760])\n",
      "Epoch 2164, Loss 3.0\n",
      "    Params: tensor([  5.2889, -16.8587])\n",
      "    Grad: tensor([-0.0134,  0.0759])\n",
      "Epoch 2165, Loss 3.0\n",
      "    Params: tensor([  5.2891, -16.8595])\n",
      "    Grad: tensor([-0.0134,  0.0758])\n",
      "Epoch 2166, Loss 3.0\n",
      "    Params: tensor([  5.2892, -16.8603])\n",
      "    Grad: tensor([-0.0133,  0.0756])\n",
      "Epoch 2167, Loss 3.0\n",
      "    Params: tensor([  5.2893, -16.8610])\n",
      "    Grad: tensor([-0.0133,  0.0755])\n",
      "Epoch 2168, Loss 3.0\n",
      "    Params: tensor([  5.2895, -16.8618])\n",
      "    Grad: tensor([-0.0133,  0.0754])\n",
      "Epoch 2169, Loss 3.0\n",
      "    Params: tensor([  5.2896, -16.8625])\n",
      "    Grad: tensor([-0.0133,  0.0753])\n",
      "Epoch 2170, Loss 3.0\n",
      "    Params: tensor([  5.2897, -16.8633])\n",
      "    Grad: tensor([-0.0133,  0.0751])\n",
      "Epoch 2171, Loss 3.0\n",
      "    Params: tensor([  5.2899, -16.8640])\n",
      "    Grad: tensor([-0.0133,  0.0750])\n",
      "Epoch 2172, Loss 3.0\n",
      "    Params: tensor([  5.2900, -16.8648])\n",
      "    Grad: tensor([-0.0132,  0.0749])\n",
      "Epoch 2173, Loss 3.0\n",
      "    Params: tensor([  5.2901, -16.8655])\n",
      "    Grad: tensor([-0.0132,  0.0747])\n",
      "Epoch 2174, Loss 3.0\n",
      "    Params: tensor([  5.2903, -16.8663])\n",
      "    Grad: tensor([-0.0132,  0.0746])\n",
      "Epoch 2175, Loss 3.0\n",
      "    Params: tensor([  5.2904, -16.8670])\n",
      "    Grad: tensor([-0.0132,  0.0745])\n",
      "Epoch 2176, Loss 3.0\n",
      "    Params: tensor([  5.2905, -16.8678])\n",
      "    Grad: tensor([-0.0131,  0.0744])\n",
      "Epoch 2177, Loss 3.0\n",
      "    Params: tensor([  5.2906, -16.8685])\n",
      "    Grad: tensor([-0.0131,  0.0742])\n",
      "Epoch 2178, Loss 3.0\n",
      "    Params: tensor([  5.2908, -16.8692])\n",
      "    Grad: tensor([-0.0131,  0.0741])\n",
      "Epoch 2179, Loss 3.0\n",
      "    Params: tensor([  5.2909, -16.8700])\n",
      "    Grad: tensor([-0.0131,  0.0740])\n",
      "Epoch 2180, Loss 3.0\n",
      "    Params: tensor([  5.2910, -16.8707])\n",
      "    Grad: tensor([-0.0131,  0.0739])\n",
      "Epoch 2181, Loss 3.0\n",
      "    Params: tensor([  5.2912, -16.8715])\n",
      "    Grad: tensor([-0.0130,  0.0737])\n",
      "Epoch 2182, Loss 3.0\n",
      "    Params: tensor([  5.2913, -16.8722])\n",
      "    Grad: tensor([-0.0130,  0.0736])\n",
      "Epoch 2183, Loss 3.0\n",
      "    Params: tensor([  5.2914, -16.8729])\n",
      "    Grad: tensor([-0.0130,  0.0735])\n",
      "Epoch 2184, Loss 3.0\n",
      "    Params: tensor([  5.2916, -16.8737])\n",
      "    Grad: tensor([-0.0130,  0.0734])\n",
      "Epoch 2185, Loss 3.0\n",
      "    Params: tensor([  5.2917, -16.8744])\n",
      "    Grad: tensor([-0.0129,  0.0732])\n",
      "Epoch 2186, Loss 3.0\n",
      "    Params: tensor([  5.2918, -16.8751])\n",
      "    Grad: tensor([-0.0129,  0.0731])\n",
      "Epoch 2187, Loss 3.0\n",
      "    Params: tensor([  5.2919, -16.8759])\n",
      "    Grad: tensor([-0.0129,  0.0730])\n",
      "Epoch 2188, Loss 3.0\n",
      "    Params: tensor([  5.2921, -16.8766])\n",
      "    Grad: tensor([-0.0129,  0.0729])\n",
      "Epoch 2189, Loss 3.0\n",
      "    Params: tensor([  5.2922, -16.8773])\n",
      "    Grad: tensor([-0.0128,  0.0727])\n",
      "Epoch 2190, Loss 3.0\n",
      "    Params: tensor([  5.2923, -16.8780])\n",
      "    Grad: tensor([-0.0128,  0.0726])\n",
      "Epoch 2191, Loss 3.0\n",
      "    Params: tensor([  5.2925, -16.8788])\n",
      "    Grad: tensor([-0.0128,  0.0725])\n",
      "Epoch 2192, Loss 3.0\n",
      "    Params: tensor([  5.2926, -16.8795])\n",
      "    Grad: tensor([-0.0128,  0.0724])\n",
      "Epoch 2193, Loss 3.0\n",
      "    Params: tensor([  5.2927, -16.8802])\n",
      "    Grad: tensor([-0.0128,  0.0723])\n",
      "Epoch 2194, Loss 3.0\n",
      "    Params: tensor([  5.2928, -16.8809])\n",
      "    Grad: tensor([-0.0128,  0.0721])\n",
      "Epoch 2195, Loss 3.0\n",
      "    Params: tensor([  5.2930, -16.8816])\n",
      "    Grad: tensor([-0.0127,  0.0720])\n",
      "Epoch 2196, Loss 3.0\n",
      "    Params: tensor([  5.2931, -16.8824])\n",
      "    Grad: tensor([-0.0127,  0.0719])\n",
      "Epoch 2197, Loss 3.0\n",
      "    Params: tensor([  5.2932, -16.8831])\n",
      "    Grad: tensor([-0.0127,  0.0718])\n",
      "Epoch 2198, Loss 3.0\n",
      "    Params: tensor([  5.2934, -16.8838])\n",
      "    Grad: tensor([-0.0126,  0.0716])\n",
      "Epoch 2199, Loss 3.0\n",
      "    Params: tensor([  5.2935, -16.8845])\n",
      "    Grad: tensor([-0.0126,  0.0715])\n",
      "Epoch 2200, Loss 3.0\n",
      "    Params: tensor([  5.2936, -16.8852])\n",
      "    Grad: tensor([-0.0126,  0.0714])\n",
      "Epoch 2201, Loss 3.0\n",
      "    Params: tensor([  5.2937, -16.8859])\n",
      "    Grad: tensor([-0.0126,  0.0713])\n",
      "Epoch 2202, Loss 3.0\n",
      "    Params: tensor([  5.2939, -16.8867])\n",
      "    Grad: tensor([-0.0126,  0.0712])\n",
      "Epoch 2203, Loss 3.0\n",
      "    Params: tensor([  5.2940, -16.8874])\n",
      "    Grad: tensor([-0.0125,  0.0710])\n",
      "Epoch 2204, Loss 3.0\n",
      "    Params: tensor([  5.2941, -16.8881])\n",
      "    Grad: tensor([-0.0125,  0.0709])\n",
      "Epoch 2205, Loss 3.0\n",
      "    Params: tensor([  5.2942, -16.8888])\n",
      "    Grad: tensor([-0.0125,  0.0708])\n",
      "Epoch 2206, Loss 3.0\n",
      "    Params: tensor([  5.2944, -16.8895])\n",
      "    Grad: tensor([-0.0125,  0.0707])\n",
      "Epoch 2207, Loss 3.0\n",
      "    Params: tensor([  5.2945, -16.8902])\n",
      "    Grad: tensor([-0.0125,  0.0706])\n",
      "Epoch 2208, Loss 3.0\n",
      "    Params: tensor([  5.2946, -16.8909])\n",
      "    Grad: tensor([-0.0124,  0.0704])\n",
      "Epoch 2209, Loss 3.0\n",
      "    Params: tensor([  5.2947, -16.8916])\n",
      "    Grad: tensor([-0.0124,  0.0703])\n",
      "Epoch 2210, Loss 3.0\n",
      "    Params: tensor([  5.2949, -16.8923])\n",
      "    Grad: tensor([-0.0124,  0.0702])\n",
      "Epoch 2211, Loss 3.0\n",
      "    Params: tensor([  5.2950, -16.8930])\n",
      "    Grad: tensor([-0.0124,  0.0701])\n",
      "Epoch 2212, Loss 3.0\n",
      "    Params: tensor([  5.2951, -16.8937])\n",
      "    Grad: tensor([-0.0123,  0.0700])\n",
      "Epoch 2213, Loss 3.0\n",
      "    Params: tensor([  5.2952, -16.8944])\n",
      "    Grad: tensor([-0.0123,  0.0698])\n",
      "Epoch 2214, Loss 3.0\n",
      "    Params: tensor([  5.2953, -16.8951])\n",
      "    Grad: tensor([-0.0123,  0.0697])\n",
      "Epoch 2215, Loss 3.0\n",
      "    Params: tensor([  5.2955, -16.8958])\n",
      "    Grad: tensor([-0.0123,  0.0696])\n",
      "Epoch 2216, Loss 3.0\n",
      "    Params: tensor([  5.2956, -16.8965])\n",
      "    Grad: tensor([-0.0123,  0.0695])\n",
      "Epoch 2217, Loss 3.0\n",
      "    Params: tensor([  5.2957, -16.8972])\n",
      "    Grad: tensor([-0.0123,  0.0694])\n",
      "Epoch 2218, Loss 3.0\n",
      "    Params: tensor([  5.2958, -16.8979])\n",
      "    Grad: tensor([-0.0122,  0.0692])\n",
      "Epoch 2219, Loss 3.0\n",
      "    Params: tensor([  5.2960, -16.8986])\n",
      "    Grad: tensor([-0.0122,  0.0691])\n",
      "Epoch 2220, Loss 3.0\n",
      "    Params: tensor([  5.2961, -16.8993])\n",
      "    Grad: tensor([-0.0122,  0.0690])\n",
      "Epoch 2221, Loss 3.0\n",
      "    Params: tensor([  5.2962, -16.8999])\n",
      "    Grad: tensor([-0.0122,  0.0689])\n",
      "Epoch 2222, Loss 3.0\n",
      "    Params: tensor([  5.2963, -16.9006])\n",
      "    Grad: tensor([-0.0122,  0.0688])\n",
      "Epoch 2223, Loss 3.0\n",
      "    Params: tensor([  5.2964, -16.9013])\n",
      "    Grad: tensor([-0.0121,  0.0687])\n",
      "Epoch 2224, Loss 3.0\n",
      "    Params: tensor([  5.2966, -16.9020])\n",
      "    Grad: tensor([-0.0121,  0.0685])\n",
      "Epoch 2225, Loss 3.0\n",
      "    Params: tensor([  5.2967, -16.9027])\n",
      "    Grad: tensor([-0.0121,  0.0684])\n",
      "Epoch 2226, Loss 3.0\n",
      "    Params: tensor([  5.2968, -16.9034])\n",
      "    Grad: tensor([-0.0121,  0.0683])\n",
      "Epoch 2227, Loss 3.0\n",
      "    Params: tensor([  5.2969, -16.9041])\n",
      "    Grad: tensor([-0.0120,  0.0682])\n",
      "Epoch 2228, Loss 3.0\n",
      "    Params: tensor([  5.2970, -16.9047])\n",
      "    Grad: tensor([-0.0120,  0.0681])\n",
      "Epoch 2229, Loss 3.0\n",
      "    Params: tensor([  5.2972, -16.9054])\n",
      "    Grad: tensor([-0.0120,  0.0680])\n",
      "Epoch 2230, Loss 3.0\n",
      "    Params: tensor([  5.2973, -16.9061])\n",
      "    Grad: tensor([-0.0120,  0.0678])\n",
      "Epoch 2231, Loss 3.0\n",
      "    Params: tensor([  5.2974, -16.9068])\n",
      "    Grad: tensor([-0.0120,  0.0677])\n",
      "Epoch 2232, Loss 3.0\n",
      "    Params: tensor([  5.2975, -16.9074])\n",
      "    Grad: tensor([-0.0119,  0.0676])\n",
      "Epoch 2233, Loss 3.0\n",
      "    Params: tensor([  5.2976, -16.9081])\n",
      "    Grad: tensor([-0.0119,  0.0675])\n",
      "Epoch 2234, Loss 3.0\n",
      "    Params: tensor([  5.2978, -16.9088])\n",
      "    Grad: tensor([-0.0119,  0.0674])\n",
      "Epoch 2235, Loss 3.0\n",
      "    Params: tensor([  5.2979, -16.9095])\n",
      "    Grad: tensor([-0.0119,  0.0673])\n",
      "Epoch 2236, Loss 3.0\n",
      "    Params: tensor([  5.2980, -16.9101])\n",
      "    Grad: tensor([-0.0119,  0.0672])\n",
      "Epoch 2237, Loss 3.0\n",
      "    Params: tensor([  5.2981, -16.9108])\n",
      "    Grad: tensor([-0.0118,  0.0670])\n",
      "Epoch 2238, Loss 3.0\n",
      "    Params: tensor([  5.2982, -16.9115])\n",
      "    Grad: tensor([-0.0118,  0.0669])\n",
      "Epoch 2239, Loss 3.0\n",
      "    Params: tensor([  5.2984, -16.9121])\n",
      "    Grad: tensor([-0.0118,  0.0668])\n",
      "Epoch 2240, Loss 3.0\n",
      "    Params: tensor([  5.2985, -16.9128])\n",
      "    Grad: tensor([-0.0118,  0.0667])\n",
      "Epoch 2241, Loss 3.0\n",
      "    Params: tensor([  5.2986, -16.9135])\n",
      "    Grad: tensor([-0.0118,  0.0666])\n",
      "Epoch 2242, Loss 3.0\n",
      "    Params: tensor([  5.2987, -16.9141])\n",
      "    Grad: tensor([-0.0117,  0.0665])\n",
      "Epoch 2243, Loss 3.0\n",
      "    Params: tensor([  5.2988, -16.9148])\n",
      "    Grad: tensor([-0.0117,  0.0664])\n",
      "Epoch 2244, Loss 3.0\n",
      "    Params: tensor([  5.2989, -16.9155])\n",
      "    Grad: tensor([-0.0117,  0.0662])\n",
      "Epoch 2245, Loss 3.0\n",
      "    Params: tensor([  5.2991, -16.9161])\n",
      "    Grad: tensor([-0.0117,  0.0661])\n",
      "Epoch 2246, Loss 3.0\n",
      "    Params: tensor([  5.2992, -16.9168])\n",
      "    Grad: tensor([-0.0117,  0.0660])\n",
      "Epoch 2247, Loss 3.0\n",
      "    Params: tensor([  5.2993, -16.9174])\n",
      "    Grad: tensor([-0.0116,  0.0659])\n",
      "Epoch 2248, Loss 3.0\n",
      "    Params: tensor([  5.2994, -16.9181])\n",
      "    Grad: tensor([-0.0116,  0.0658])\n",
      "Epoch 2249, Loss 3.0\n",
      "    Params: tensor([  5.2995, -16.9188])\n",
      "    Grad: tensor([-0.0116,  0.0657])\n",
      "Epoch 2250, Loss 3.0\n",
      "    Params: tensor([  5.2996, -16.9194])\n",
      "    Grad: tensor([-0.0116,  0.0656])\n",
      "Epoch 2251, Loss 3.0\n",
      "    Params: tensor([  5.2998, -16.9201])\n",
      "    Grad: tensor([-0.0116,  0.0655])\n",
      "Epoch 2252, Loss 3.0\n",
      "    Params: tensor([  5.2999, -16.9207])\n",
      "    Grad: tensor([-0.0115,  0.0654])\n",
      "Epoch 2253, Loss 3.0\n",
      "    Params: tensor([  5.3000, -16.9214])\n",
      "    Grad: tensor([-0.0115,  0.0652])\n",
      "Epoch 2254, Loss 3.0\n",
      "    Params: tensor([  5.3001, -16.9220])\n",
      "    Grad: tensor([-0.0115,  0.0651])\n",
      "Epoch 2255, Loss 3.0\n",
      "    Params: tensor([  5.3002, -16.9227])\n",
      "    Grad: tensor([-0.0115,  0.0650])\n",
      "Epoch 2256, Loss 3.0\n",
      "    Params: tensor([  5.3003, -16.9233])\n",
      "    Grad: tensor([-0.0114,  0.0649])\n",
      "Epoch 2257, Loss 3.0\n",
      "    Params: tensor([  5.3004, -16.9240])\n",
      "    Grad: tensor([-0.0114,  0.0648])\n",
      "Epoch 2258, Loss 3.0\n",
      "    Params: tensor([  5.3006, -16.9246])\n",
      "    Grad: tensor([-0.0114,  0.0647])\n",
      "Epoch 2259, Loss 3.0\n",
      "    Params: tensor([  5.3007, -16.9253])\n",
      "    Grad: tensor([-0.0114,  0.0646])\n",
      "Epoch 2260, Loss 3.0\n",
      "    Params: tensor([  5.3008, -16.9259])\n",
      "    Grad: tensor([-0.0114,  0.0645])\n",
      "Epoch 2261, Loss 3.0\n",
      "    Params: tensor([  5.3009, -16.9266])\n",
      "    Grad: tensor([-0.0114,  0.0644])\n",
      "Epoch 2262, Loss 3.0\n",
      "    Params: tensor([  5.3010, -16.9272])\n",
      "    Grad: tensor([-0.0113,  0.0643])\n",
      "Epoch 2263, Loss 3.0\n",
      "    Params: tensor([  5.3011, -16.9278])\n",
      "    Grad: tensor([-0.0113,  0.0641])\n",
      "Epoch 2264, Loss 3.0\n",
      "    Params: tensor([  5.3012, -16.9285])\n",
      "    Grad: tensor([-0.0113,  0.0640])\n",
      "Epoch 2265, Loss 3.0\n",
      "    Params: tensor([  5.3014, -16.9291])\n",
      "    Grad: tensor([-0.0113,  0.0639])\n",
      "Epoch 2266, Loss 3.0\n",
      "    Params: tensor([  5.3015, -16.9298])\n",
      "    Grad: tensor([-0.0113,  0.0638])\n",
      "Epoch 2267, Loss 3.0\n",
      "    Params: tensor([  5.3016, -16.9304])\n",
      "    Grad: tensor([-0.0113,  0.0637])\n",
      "Epoch 2268, Loss 3.0\n",
      "    Params: tensor([  5.3017, -16.9310])\n",
      "    Grad: tensor([-0.0112,  0.0636])\n",
      "Epoch 2269, Loss 3.0\n",
      "    Params: tensor([  5.3018, -16.9317])\n",
      "    Grad: tensor([-0.0112,  0.0635])\n",
      "Epoch 2270, Loss 3.0\n",
      "    Params: tensor([  5.3019, -16.9323])\n",
      "    Grad: tensor([-0.0112,  0.0634])\n",
      "Epoch 2271, Loss 3.0\n",
      "    Params: tensor([  5.3020, -16.9329])\n",
      "    Grad: tensor([-0.0112,  0.0633])\n",
      "Epoch 2272, Loss 3.0\n",
      "    Params: tensor([  5.3021, -16.9336])\n",
      "    Grad: tensor([-0.0112,  0.0632])\n",
      "Epoch 2273, Loss 3.0\n",
      "    Params: tensor([  5.3023, -16.9342])\n",
      "    Grad: tensor([-0.0111,  0.0631])\n",
      "Epoch 2274, Loss 3.0\n",
      "    Params: tensor([  5.3024, -16.9348])\n",
      "    Grad: tensor([-0.0111,  0.0630])\n",
      "Epoch 2275, Loss 3.0\n",
      "    Params: tensor([  5.3025, -16.9355])\n",
      "    Grad: tensor([-0.0111,  0.0628])\n",
      "Epoch 2276, Loss 3.0\n",
      "    Params: tensor([  5.3026, -16.9361])\n",
      "    Grad: tensor([-0.0111,  0.0627])\n",
      "Epoch 2277, Loss 3.0\n",
      "    Params: tensor([  5.3027, -16.9367])\n",
      "    Grad: tensor([-0.0111,  0.0626])\n",
      "Epoch 2278, Loss 3.0\n",
      "    Params: tensor([  5.3028, -16.9373])\n",
      "    Grad: tensor([-0.0110,  0.0625])\n",
      "Epoch 2279, Loss 3.0\n",
      "    Params: tensor([  5.3029, -16.9380])\n",
      "    Grad: tensor([-0.0110,  0.0624])\n",
      "Epoch 2280, Loss 3.0\n",
      "    Params: tensor([  5.3030, -16.9386])\n",
      "    Grad: tensor([-0.0110,  0.0623])\n",
      "Epoch 2281, Loss 3.0\n",
      "    Params: tensor([  5.3031, -16.9392])\n",
      "    Grad: tensor([-0.0110,  0.0622])\n",
      "Epoch 2282, Loss 3.0\n",
      "    Params: tensor([  5.3032, -16.9398])\n",
      "    Grad: tensor([-0.0110,  0.0621])\n",
      "Epoch 2283, Loss 3.0\n",
      "    Params: tensor([  5.3034, -16.9404])\n",
      "    Grad: tensor([-0.0110,  0.0620])\n",
      "Epoch 2284, Loss 3.0\n",
      "    Params: tensor([  5.3035, -16.9411])\n",
      "    Grad: tensor([-0.0109,  0.0619])\n",
      "Epoch 2285, Loss 3.0\n",
      "    Params: tensor([  5.3036, -16.9417])\n",
      "    Grad: tensor([-0.0109,  0.0618])\n",
      "Epoch 2286, Loss 3.0\n",
      "    Params: tensor([  5.3037, -16.9423])\n",
      "    Grad: tensor([-0.0109,  0.0617])\n",
      "Epoch 2287, Loss 3.0\n",
      "    Params: tensor([  5.3038, -16.9429])\n",
      "    Grad: tensor([-0.0109,  0.0616])\n",
      "Epoch 2288, Loss 3.0\n",
      "    Params: tensor([  5.3039, -16.9435])\n",
      "    Grad: tensor([-0.0109,  0.0615])\n",
      "Epoch 2289, Loss 3.0\n",
      "    Params: tensor([  5.3040, -16.9441])\n",
      "    Grad: tensor([-0.0108,  0.0614])\n",
      "Epoch 2290, Loss 3.0\n",
      "    Params: tensor([  5.3041, -16.9448])\n",
      "    Grad: tensor([-0.0108,  0.0613])\n",
      "Epoch 2291, Loss 3.0\n",
      "    Params: tensor([  5.3042, -16.9454])\n",
      "    Grad: tensor([-0.0108,  0.0612])\n",
      "Epoch 2292, Loss 3.0\n",
      "    Params: tensor([  5.3043, -16.9460])\n",
      "    Grad: tensor([-0.0108,  0.0611])\n",
      "Epoch 2293, Loss 3.0\n",
      "    Params: tensor([  5.3044, -16.9466])\n",
      "    Grad: tensor([-0.0108,  0.0610])\n",
      "Epoch 2294, Loss 3.0\n",
      "    Params: tensor([  5.3045, -16.9472])\n",
      "    Grad: tensor([-0.0108,  0.0608])\n",
      "Epoch 2295, Loss 3.0\n",
      "    Params: tensor([  5.3047, -16.9478])\n",
      "    Grad: tensor([-0.0107,  0.0607])\n",
      "Epoch 2296, Loss 3.0\n",
      "    Params: tensor([  5.3048, -16.9484])\n",
      "    Grad: tensor([-0.0107,  0.0606])\n",
      "Epoch 2297, Loss 3.0\n",
      "    Params: tensor([  5.3049, -16.9490])\n",
      "    Grad: tensor([-0.0107,  0.0605])\n",
      "Epoch 2298, Loss 3.0\n",
      "    Params: tensor([  5.3050, -16.9496])\n",
      "    Grad: tensor([-0.0107,  0.0604])\n",
      "Epoch 2299, Loss 3.0\n",
      "    Params: tensor([  5.3051, -16.9502])\n",
      "    Grad: tensor([-0.0107,  0.0603])\n",
      "Epoch 2300, Loss 3.0\n",
      "    Params: tensor([  5.3052, -16.9508])\n",
      "    Grad: tensor([-0.0106,  0.0602])\n",
      "Epoch 2301, Loss 3.0\n",
      "    Params: tensor([  5.3053, -16.9514])\n",
      "    Grad: tensor([-0.0106,  0.0601])\n",
      "Epoch 2302, Loss 3.0\n",
      "    Params: tensor([  5.3054, -16.9520])\n",
      "    Grad: tensor([-0.0106,  0.0600])\n",
      "Epoch 2303, Loss 3.0\n",
      "    Params: tensor([  5.3055, -16.9526])\n",
      "    Grad: tensor([-0.0106,  0.0599])\n",
      "Epoch 2304, Loss 3.0\n",
      "    Params: tensor([  5.3056, -16.9532])\n",
      "    Grad: tensor([-0.0106,  0.0598])\n",
      "Epoch 2305, Loss 3.0\n",
      "    Params: tensor([  5.3057, -16.9538])\n",
      "    Grad: tensor([-0.0105,  0.0597])\n",
      "Epoch 2306, Loss 3.0\n",
      "    Params: tensor([  5.3058, -16.9544])\n",
      "    Grad: tensor([-0.0105,  0.0596])\n",
      "Epoch 2307, Loss 3.0\n",
      "    Params: tensor([  5.3059, -16.9550])\n",
      "    Grad: tensor([-0.0105,  0.0595])\n",
      "Epoch 2308, Loss 3.0\n",
      "    Params: tensor([  5.3060, -16.9556])\n",
      "    Grad: tensor([-0.0105,  0.0594])\n",
      "Epoch 2309, Loss 3.0\n",
      "    Params: tensor([  5.3061, -16.9562])\n",
      "    Grad: tensor([-0.0105,  0.0593])\n",
      "Epoch 2310, Loss 3.0\n",
      "    Params: tensor([  5.3062, -16.9568])\n",
      "    Grad: tensor([-0.0105,  0.0592])\n",
      "Epoch 2311, Loss 3.0\n",
      "    Params: tensor([  5.3063, -16.9574])\n",
      "    Grad: tensor([-0.0104,  0.0591])\n",
      "Epoch 2312, Loss 3.0\n",
      "    Params: tensor([  5.3065, -16.9580])\n",
      "    Grad: tensor([-0.0104,  0.0590])\n",
      "Epoch 2313, Loss 3.0\n",
      "    Params: tensor([  5.3066, -16.9586])\n",
      "    Grad: tensor([-0.0104,  0.0589])\n",
      "Epoch 2314, Loss 3.0\n",
      "    Params: tensor([  5.3067, -16.9591])\n",
      "    Grad: tensor([-0.0104,  0.0588])\n",
      "Epoch 2315, Loss 3.0\n",
      "    Params: tensor([  5.3068, -16.9597])\n",
      "    Grad: tensor([-0.0103,  0.0587])\n",
      "Epoch 2316, Loss 3.0\n",
      "    Params: tensor([  5.3069, -16.9603])\n",
      "    Grad: tensor([-0.0103,  0.0586])\n",
      "Epoch 2317, Loss 3.0\n",
      "    Params: tensor([  5.3070, -16.9609])\n",
      "    Grad: tensor([-0.0103,  0.0585])\n",
      "Epoch 2318, Loss 3.0\n",
      "    Params: tensor([  5.3071, -16.9615])\n",
      "    Grad: tensor([-0.0103,  0.0584])\n",
      "Epoch 2319, Loss 3.0\n",
      "    Params: tensor([  5.3072, -16.9621])\n",
      "    Grad: tensor([-0.0103,  0.0583])\n",
      "Epoch 2320, Loss 3.0\n",
      "    Params: tensor([  5.3073, -16.9627])\n",
      "    Grad: tensor([-0.0103,  0.0582])\n",
      "Epoch 2321, Loss 3.0\n",
      "    Params: tensor([  5.3074, -16.9632])\n",
      "    Grad: tensor([-0.0103,  0.0581])\n",
      "Epoch 2322, Loss 3.0\n",
      "    Params: tensor([  5.3075, -16.9638])\n",
      "    Grad: tensor([-0.0102,  0.0580])\n",
      "Epoch 2323, Loss 3.0\n",
      "    Params: tensor([  5.3076, -16.9644])\n",
      "    Grad: tensor([-0.0102,  0.0579])\n",
      "Epoch 2324, Loss 3.0\n",
      "    Params: tensor([  5.3077, -16.9650])\n",
      "    Grad: tensor([-0.0102,  0.0578])\n",
      "Epoch 2325, Loss 3.0\n",
      "    Params: tensor([  5.3078, -16.9656])\n",
      "    Grad: tensor([-0.0102,  0.0577])\n",
      "Epoch 2326, Loss 3.0\n",
      "    Params: tensor([  5.3079, -16.9661])\n",
      "    Grad: tensor([-0.0102,  0.0576])\n",
      "Epoch 2327, Loss 3.0\n",
      "    Params: tensor([  5.3080, -16.9667])\n",
      "    Grad: tensor([-0.0102,  0.0575])\n",
      "Epoch 2328, Loss 3.0\n",
      "    Params: tensor([  5.3081, -16.9673])\n",
      "    Grad: tensor([-0.0102,  0.0574])\n",
      "Epoch 2329, Loss 3.0\n",
      "    Params: tensor([  5.3082, -16.9679])\n",
      "    Grad: tensor([-0.0101,  0.0573])\n",
      "Epoch 2330, Loss 3.0\n",
      "    Params: tensor([  5.3083, -16.9684])\n",
      "    Grad: tensor([-0.0101,  0.0572])\n",
      "Epoch 2331, Loss 3.0\n",
      "    Params: tensor([  5.3084, -16.9690])\n",
      "    Grad: tensor([-0.0101,  0.0571])\n",
      "Epoch 2332, Loss 3.0\n",
      "    Params: tensor([  5.3085, -16.9696])\n",
      "    Grad: tensor([-0.0101,  0.0570])\n",
      "Epoch 2333, Loss 3.0\n",
      "    Params: tensor([  5.3086, -16.9701])\n",
      "    Grad: tensor([-0.0101,  0.0569])\n",
      "Epoch 2334, Loss 3.0\n",
      "    Params: tensor([  5.3087, -16.9707])\n",
      "    Grad: tensor([-0.0101,  0.0568])\n",
      "Epoch 2335, Loss 3.0\n",
      "    Params: tensor([  5.3088, -16.9713])\n",
      "    Grad: tensor([-0.0100,  0.0568])\n",
      "Epoch 2336, Loss 3.0\n",
      "    Params: tensor([  5.3089, -16.9718])\n",
      "    Grad: tensor([-0.0100,  0.0567])\n",
      "Epoch 2337, Loss 3.0\n",
      "    Params: tensor([  5.3090, -16.9724])\n",
      "    Grad: tensor([-0.0100,  0.0566])\n",
      "Epoch 2338, Loss 3.0\n",
      "    Params: tensor([  5.3091, -16.9730])\n",
      "    Grad: tensor([-0.0100,  0.0565])\n",
      "Epoch 2339, Loss 3.0\n",
      "    Params: tensor([  5.3092, -16.9735])\n",
      "    Grad: tensor([-0.0100,  0.0564])\n",
      "Epoch 2340, Loss 3.0\n",
      "    Params: tensor([  5.3093, -16.9741])\n",
      "    Grad: tensor([-0.0100,  0.0563])\n",
      "Epoch 2341, Loss 3.0\n",
      "    Params: tensor([  5.3094, -16.9747])\n",
      "    Grad: tensor([-0.0099,  0.0562])\n",
      "Epoch 2342, Loss 3.0\n",
      "    Params: tensor([  5.3095, -16.9752])\n",
      "    Grad: tensor([-0.0099,  0.0561])\n",
      "Epoch 2343, Loss 3.0\n",
      "    Params: tensor([  5.3096, -16.9758])\n",
      "    Grad: tensor([-0.0099,  0.0560])\n",
      "Epoch 2344, Loss 3.0\n",
      "    Params: tensor([  5.3097, -16.9763])\n",
      "    Grad: tensor([-0.0099,  0.0559])\n",
      "Epoch 2345, Loss 3.0\n",
      "    Params: tensor([  5.3098, -16.9769])\n",
      "    Grad: tensor([-0.0099,  0.0558])\n",
      "Epoch 2346, Loss 3.0\n",
      "    Params: tensor([  5.3099, -16.9775])\n",
      "    Grad: tensor([-0.0098,  0.0557])\n",
      "Epoch 2347, Loss 3.0\n",
      "    Params: tensor([  5.3100, -16.9780])\n",
      "    Grad: tensor([-0.0098,  0.0556])\n",
      "Epoch 2348, Loss 3.0\n",
      "    Params: tensor([  5.3101, -16.9786])\n",
      "    Grad: tensor([-0.0098,  0.0555])\n",
      "Epoch 2349, Loss 3.0\n",
      "    Params: tensor([  5.3102, -16.9791])\n",
      "    Grad: tensor([-0.0098,  0.0554])\n",
      "Epoch 2350, Loss 3.0\n",
      "    Params: tensor([  5.3103, -16.9797])\n",
      "    Grad: tensor([-0.0098,  0.0553])\n",
      "Epoch 2351, Loss 3.0\n",
      "    Params: tensor([  5.3104, -16.9802])\n",
      "    Grad: tensor([-0.0098,  0.0552])\n",
      "Epoch 2352, Loss 3.0\n",
      "    Params: tensor([  5.3105, -16.9808])\n",
      "    Grad: tensor([-0.0097,  0.0551])\n",
      "Epoch 2353, Loss 3.0\n",
      "    Params: tensor([  5.3106, -16.9813])\n",
      "    Grad: tensor([-0.0097,  0.0550])\n",
      "Epoch 2354, Loss 3.0\n",
      "    Params: tensor([  5.3107, -16.9819])\n",
      "    Grad: tensor([-0.0097,  0.0549])\n",
      "Epoch 2355, Loss 3.0\n",
      "    Params: tensor([  5.3108, -16.9824])\n",
      "    Grad: tensor([-0.0097,  0.0549])\n",
      "Epoch 2356, Loss 3.0\n",
      "    Params: tensor([  5.3109, -16.9830])\n",
      "    Grad: tensor([-0.0097,  0.0548])\n",
      "Epoch 2357, Loss 3.0\n",
      "    Params: tensor([  5.3110, -16.9835])\n",
      "    Grad: tensor([-0.0097,  0.0547])\n",
      "Epoch 2358, Loss 3.0\n",
      "    Params: tensor([  5.3111, -16.9841])\n",
      "    Grad: tensor([-0.0096,  0.0546])\n",
      "Epoch 2359, Loss 3.0\n",
      "    Params: tensor([  5.3112, -16.9846])\n",
      "    Grad: tensor([-0.0096,  0.0545])\n",
      "Epoch 2360, Loss 3.0\n",
      "    Params: tensor([  5.3113, -16.9852])\n",
      "    Grad: tensor([-0.0096,  0.0544])\n",
      "Epoch 2361, Loss 3.0\n",
      "    Params: tensor([  5.3114, -16.9857])\n",
      "    Grad: tensor([-0.0096,  0.0543])\n",
      "Epoch 2362, Loss 3.0\n",
      "    Params: tensor([  5.3114, -16.9862])\n",
      "    Grad: tensor([-0.0096,  0.0542])\n",
      "Epoch 2363, Loss 3.0\n",
      "    Params: tensor([  5.3115, -16.9868])\n",
      "    Grad: tensor([-0.0095,  0.0541])\n",
      "Epoch 2364, Loss 3.0\n",
      "    Params: tensor([  5.3116, -16.9873])\n",
      "    Grad: tensor([-0.0095,  0.0540])\n",
      "Epoch 2365, Loss 3.0\n",
      "    Params: tensor([  5.3117, -16.9879])\n",
      "    Grad: tensor([-0.0095,  0.0539])\n",
      "Epoch 2366, Loss 3.0\n",
      "    Params: tensor([  5.3118, -16.9884])\n",
      "    Grad: tensor([-0.0095,  0.0538])\n",
      "Epoch 2367, Loss 3.0\n",
      "    Params: tensor([  5.3119, -16.9889])\n",
      "    Grad: tensor([-0.0095,  0.0537])\n",
      "Epoch 2368, Loss 3.0\n",
      "    Params: tensor([  5.3120, -16.9895])\n",
      "    Grad: tensor([-0.0095,  0.0537])\n",
      "Epoch 2369, Loss 3.0\n",
      "    Params: tensor([  5.3121, -16.9900])\n",
      "    Grad: tensor([-0.0094,  0.0536])\n",
      "Epoch 2370, Loss 3.0\n",
      "    Params: tensor([  5.3122, -16.9906])\n",
      "    Grad: tensor([-0.0094,  0.0535])\n",
      "Epoch 2371, Loss 3.0\n",
      "    Params: tensor([  5.3123, -16.9911])\n",
      "    Grad: tensor([-0.0094,  0.0534])\n",
      "Epoch 2372, Loss 3.0\n",
      "    Params: tensor([  5.3124, -16.9916])\n",
      "    Grad: tensor([-0.0094,  0.0533])\n",
      "Epoch 2373, Loss 3.0\n",
      "    Params: tensor([  5.3125, -16.9921])\n",
      "    Grad: tensor([-0.0094,  0.0532])\n",
      "Epoch 2374, Loss 3.0\n",
      "    Params: tensor([  5.3126, -16.9927])\n",
      "    Grad: tensor([-0.0094,  0.0531])\n",
      "Epoch 2375, Loss 3.0\n",
      "    Params: tensor([  5.3127, -16.9932])\n",
      "    Grad: tensor([-0.0093,  0.0530])\n",
      "Epoch 2376, Loss 3.0\n",
      "    Params: tensor([  5.3128, -16.9937])\n",
      "    Grad: tensor([-0.0093,  0.0529])\n",
      "Epoch 2377, Loss 3.0\n",
      "    Params: tensor([  5.3129, -16.9943])\n",
      "    Grad: tensor([-0.0093,  0.0528])\n",
      "Epoch 2378, Loss 3.0\n",
      "    Params: tensor([  5.3130, -16.9948])\n",
      "    Grad: tensor([-0.0093,  0.0528])\n",
      "Epoch 2379, Loss 3.0\n",
      "    Params: tensor([  5.3131, -16.9953])\n",
      "    Grad: tensor([-0.0093,  0.0527])\n",
      "Epoch 2380, Loss 3.0\n",
      "    Params: tensor([  5.3131, -16.9958])\n",
      "    Grad: tensor([-0.0093,  0.0526])\n",
      "Epoch 2381, Loss 3.0\n",
      "    Params: tensor([  5.3132, -16.9964])\n",
      "    Grad: tensor([-0.0093,  0.0525])\n",
      "Epoch 2382, Loss 3.0\n",
      "    Params: tensor([  5.3133, -16.9969])\n",
      "    Grad: tensor([-0.0093,  0.0524])\n",
      "Epoch 2383, Loss 3.0\n",
      "    Params: tensor([  5.3134, -16.9974])\n",
      "    Grad: tensor([-0.0092,  0.0523])\n",
      "Epoch 2384, Loss 3.0\n",
      "    Params: tensor([  5.3135, -16.9979])\n",
      "    Grad: tensor([-0.0092,  0.0522])\n",
      "Epoch 2385, Loss 3.0\n",
      "    Params: tensor([  5.3136, -16.9985])\n",
      "    Grad: tensor([-0.0092,  0.0521])\n",
      "Epoch 2386, Loss 3.0\n",
      "    Params: tensor([  5.3137, -16.9990])\n",
      "    Grad: tensor([-0.0092,  0.0520])\n",
      "Epoch 2387, Loss 3.0\n",
      "    Params: tensor([  5.3138, -16.9995])\n",
      "    Grad: tensor([-0.0092,  0.0519])\n",
      "Epoch 2388, Loss 3.0\n",
      "    Params: tensor([  5.3139, -17.0000])\n",
      "    Grad: tensor([-0.0092,  0.0519])\n",
      "Epoch 2389, Loss 3.0\n",
      "    Params: tensor([  5.3140, -17.0005])\n",
      "    Grad: tensor([-0.0091,  0.0518])\n",
      "Epoch 2390, Loss 3.0\n",
      "    Params: tensor([  5.3141, -17.0011])\n",
      "    Grad: tensor([-0.0091,  0.0517])\n",
      "Epoch 2391, Loss 3.0\n",
      "    Params: tensor([  5.3142, -17.0016])\n",
      "    Grad: tensor([-0.0091,  0.0516])\n",
      "Epoch 2392, Loss 3.0\n",
      "    Params: tensor([  5.3142, -17.0021])\n",
      "    Grad: tensor([-0.0091,  0.0515])\n",
      "Epoch 2393, Loss 3.0\n",
      "    Params: tensor([  5.3143, -17.0026])\n",
      "    Grad: tensor([-0.0091,  0.0514])\n",
      "Epoch 2394, Loss 3.0\n",
      "    Params: tensor([  5.3144, -17.0031])\n",
      "    Grad: tensor([-0.0091,  0.0513])\n",
      "Epoch 2395, Loss 3.0\n",
      "    Params: tensor([  5.3145, -17.0036])\n",
      "    Grad: tensor([-0.0091,  0.0512])\n",
      "Epoch 2396, Loss 3.0\n",
      "    Params: tensor([  5.3146, -17.0041])\n",
      "    Grad: tensor([-0.0090,  0.0512])\n",
      "Epoch 2397, Loss 3.0\n",
      "    Params: tensor([  5.3147, -17.0047])\n",
      "    Grad: tensor([-0.0090,  0.0511])\n",
      "Epoch 2398, Loss 3.0\n",
      "    Params: tensor([  5.3148, -17.0052])\n",
      "    Grad: tensor([-0.0090,  0.0510])\n",
      "Epoch 2399, Loss 3.0\n",
      "    Params: tensor([  5.3149, -17.0057])\n",
      "    Grad: tensor([-0.0090,  0.0509])\n",
      "Epoch 2400, Loss 3.0\n",
      "    Params: tensor([  5.3150, -17.0062])\n",
      "    Grad: tensor([-0.0090,  0.0508])\n",
      "Epoch 2401, Loss 3.0\n",
      "    Params: tensor([  5.3151, -17.0067])\n",
      "    Grad: tensor([-0.0090,  0.0507])\n",
      "Epoch 2402, Loss 3.0\n",
      "    Params: tensor([  5.3151, -17.0072])\n",
      "    Grad: tensor([-0.0089,  0.0506])\n",
      "Epoch 2403, Loss 3.0\n",
      "    Params: tensor([  5.3152, -17.0077])\n",
      "    Grad: tensor([-0.0089,  0.0506])\n",
      "Epoch 2404, Loss 3.0\n",
      "    Params: tensor([  5.3153, -17.0082])\n",
      "    Grad: tensor([-0.0089,  0.0505])\n",
      "Epoch 2405, Loss 3.0\n",
      "    Params: tensor([  5.3154, -17.0087])\n",
      "    Grad: tensor([-0.0089,  0.0504])\n",
      "Epoch 2406, Loss 3.0\n",
      "    Params: tensor([  5.3155, -17.0092])\n",
      "    Grad: tensor([-0.0089,  0.0503])\n",
      "Epoch 2407, Loss 3.0\n",
      "    Params: tensor([  5.3156, -17.0097])\n",
      "    Grad: tensor([-0.0089,  0.0502])\n",
      "Epoch 2408, Loss 3.0\n",
      "    Params: tensor([  5.3157, -17.0102])\n",
      "    Grad: tensor([-0.0089,  0.0501])\n",
      "Epoch 2409, Loss 3.0\n",
      "    Params: tensor([  5.3158, -17.0107])\n",
      "    Grad: tensor([-0.0088,  0.0500])\n",
      "Epoch 2410, Loss 3.0\n",
      "    Params: tensor([  5.3159, -17.0112])\n",
      "    Grad: tensor([-0.0088,  0.0500])\n",
      "Epoch 2411, Loss 3.0\n",
      "    Params: tensor([  5.3159, -17.0117])\n",
      "    Grad: tensor([-0.0088,  0.0499])\n",
      "Epoch 2412, Loss 3.0\n",
      "    Params: tensor([  5.3160, -17.0122])\n",
      "    Grad: tensor([-0.0088,  0.0498])\n",
      "Epoch 2413, Loss 3.0\n",
      "    Params: tensor([  5.3161, -17.0127])\n",
      "    Grad: tensor([-0.0088,  0.0497])\n",
      "Epoch 2414, Loss 3.0\n",
      "    Params: tensor([  5.3162, -17.0132])\n",
      "    Grad: tensor([-0.0088,  0.0496])\n",
      "Epoch 2415, Loss 3.0\n",
      "    Params: tensor([  5.3163, -17.0137])\n",
      "    Grad: tensor([-0.0087,  0.0495])\n",
      "Epoch 2416, Loss 3.0\n",
      "    Params: tensor([  5.3164, -17.0142])\n",
      "    Grad: tensor([-0.0087,  0.0494])\n",
      "Epoch 2417, Loss 3.0\n",
      "    Params: tensor([  5.3165, -17.0147])\n",
      "    Grad: tensor([-0.0087,  0.0494])\n",
      "Epoch 2418, Loss 3.0\n",
      "    Params: tensor([  5.3166, -17.0152])\n",
      "    Grad: tensor([-0.0087,  0.0493])\n",
      "Epoch 2419, Loss 3.0\n",
      "    Params: tensor([  5.3166, -17.0157])\n",
      "    Grad: tensor([-0.0087,  0.0492])\n",
      "Epoch 2420, Loss 3.0\n",
      "    Params: tensor([  5.3167, -17.0162])\n",
      "    Grad: tensor([-0.0087,  0.0491])\n",
      "Epoch 2421, Loss 3.0\n",
      "    Params: tensor([  5.3168, -17.0167])\n",
      "    Grad: tensor([-0.0087,  0.0490])\n",
      "Epoch 2422, Loss 3.0\n",
      "    Params: tensor([  5.3169, -17.0171])\n",
      "    Grad: tensor([-0.0086,  0.0489])\n",
      "Epoch 2423, Loss 3.0\n",
      "    Params: tensor([  5.3170, -17.0176])\n",
      "    Grad: tensor([-0.0086,  0.0489])\n",
      "Epoch 2424, Loss 3.0\n",
      "    Params: tensor([  5.3171, -17.0181])\n",
      "    Grad: tensor([-0.0086,  0.0488])\n",
      "Epoch 2425, Loss 3.0\n",
      "    Params: tensor([  5.3172, -17.0186])\n",
      "    Grad: tensor([-0.0086,  0.0487])\n",
      "Epoch 2426, Loss 3.0\n",
      "    Params: tensor([  5.3173, -17.0191])\n",
      "    Grad: tensor([-0.0086,  0.0486])\n",
      "Epoch 2427, Loss 3.0\n",
      "    Params: tensor([  5.3173, -17.0196])\n",
      "    Grad: tensor([-0.0086,  0.0485])\n",
      "Epoch 2428, Loss 3.0\n",
      "    Params: tensor([  5.3174, -17.0201])\n",
      "    Grad: tensor([-0.0086,  0.0484])\n",
      "Epoch 2429, Loss 3.0\n",
      "    Params: tensor([  5.3175, -17.0205])\n",
      "    Grad: tensor([-0.0085,  0.0484])\n",
      "Epoch 2430, Loss 3.0\n",
      "    Params: tensor([  5.3176, -17.0210])\n",
      "    Grad: tensor([-0.0085,  0.0483])\n",
      "Epoch 2431, Loss 3.0\n",
      "    Params: tensor([  5.3177, -17.0215])\n",
      "    Grad: tensor([-0.0085,  0.0482])\n",
      "Epoch 2432, Loss 3.0\n",
      "    Params: tensor([  5.3178, -17.0220])\n",
      "    Grad: tensor([-0.0085,  0.0481])\n",
      "Epoch 2433, Loss 3.0\n",
      "    Params: tensor([  5.3178, -17.0225])\n",
      "    Grad: tensor([-0.0085,  0.0480])\n",
      "Epoch 2434, Loss 3.0\n",
      "    Params: tensor([  5.3179, -17.0230])\n",
      "    Grad: tensor([-0.0085,  0.0480])\n",
      "Epoch 2435, Loss 3.0\n",
      "    Params: tensor([  5.3180, -17.0234])\n",
      "    Grad: tensor([-0.0085,  0.0479])\n",
      "Epoch 2436, Loss 3.0\n",
      "    Params: tensor([  5.3181, -17.0239])\n",
      "    Grad: tensor([-0.0085,  0.0478])\n",
      "Epoch 2437, Loss 3.0\n",
      "    Params: tensor([  5.3182, -17.0244])\n",
      "    Grad: tensor([-0.0085,  0.0477])\n",
      "Epoch 2438, Loss 3.0\n",
      "    Params: tensor([  5.3183, -17.0249])\n",
      "    Grad: tensor([-0.0084,  0.0476])\n",
      "Epoch 2439, Loss 3.0\n",
      "    Params: tensor([  5.3184, -17.0253])\n",
      "    Grad: tensor([-0.0084,  0.0476])\n",
      "Epoch 2440, Loss 3.0\n",
      "    Params: tensor([  5.3184, -17.0258])\n",
      "    Grad: tensor([-0.0084,  0.0475])\n",
      "Epoch 2441, Loss 3.0\n",
      "    Params: tensor([  5.3185, -17.0263])\n",
      "    Grad: tensor([-0.0084,  0.0474])\n",
      "Epoch 2442, Loss 3.0\n",
      "    Params: tensor([  5.3186, -17.0268])\n",
      "    Grad: tensor([-0.0083,  0.0473])\n",
      "Epoch 2443, Loss 3.0\n",
      "    Params: tensor([  5.3187, -17.0272])\n",
      "    Grad: tensor([-0.0083,  0.0472])\n",
      "Epoch 2444, Loss 3.0\n",
      "    Params: tensor([  5.3188, -17.0277])\n",
      "    Grad: tensor([-0.0083,  0.0472])\n",
      "Epoch 2445, Loss 3.0\n",
      "    Params: tensor([  5.3189, -17.0282])\n",
      "    Grad: tensor([-0.0083,  0.0471])\n",
      "Epoch 2446, Loss 3.0\n",
      "    Params: tensor([  5.3189, -17.0286])\n",
      "    Grad: tensor([-0.0083,  0.0470])\n",
      "Epoch 2447, Loss 3.0\n",
      "    Params: tensor([  5.3190, -17.0291])\n",
      "    Grad: tensor([-0.0083,  0.0469])\n",
      "Epoch 2448, Loss 3.0\n",
      "    Params: tensor([  5.3191, -17.0296])\n",
      "    Grad: tensor([-0.0083,  0.0468])\n",
      "Epoch 2449, Loss 3.0\n",
      "    Params: tensor([  5.3192, -17.0300])\n",
      "    Grad: tensor([-0.0083,  0.0467])\n",
      "Epoch 2450, Loss 3.0\n",
      "    Params: tensor([  5.3193, -17.0305])\n",
      "    Grad: tensor([-0.0083,  0.0467])\n",
      "Epoch 2451, Loss 3.0\n",
      "    Params: tensor([  5.3194, -17.0310])\n",
      "    Grad: tensor([-0.0082,  0.0466])\n",
      "Epoch 2452, Loss 3.0\n",
      "    Params: tensor([  5.3194, -17.0314])\n",
      "    Grad: tensor([-0.0082,  0.0465])\n",
      "Epoch 2453, Loss 3.0\n",
      "    Params: tensor([  5.3195, -17.0319])\n",
      "    Grad: tensor([-0.0082,  0.0464])\n",
      "Epoch 2454, Loss 3.0\n",
      "    Params: tensor([  5.3196, -17.0324])\n",
      "    Grad: tensor([-0.0082,  0.0464])\n",
      "Epoch 2455, Loss 3.0\n",
      "    Params: tensor([  5.3197, -17.0328])\n",
      "    Grad: tensor([-0.0082,  0.0463])\n",
      "Epoch 2456, Loss 3.0\n",
      "    Params: tensor([  5.3198, -17.0333])\n",
      "    Grad: tensor([-0.0082,  0.0462])\n",
      "Epoch 2457, Loss 3.0\n",
      "    Params: tensor([  5.3198, -17.0338])\n",
      "    Grad: tensor([-0.0082,  0.0461])\n",
      "Epoch 2458, Loss 3.0\n",
      "    Params: tensor([  5.3199, -17.0342])\n",
      "    Grad: tensor([-0.0081,  0.0460])\n",
      "Epoch 2459, Loss 3.0\n",
      "    Params: tensor([  5.3200, -17.0347])\n",
      "    Grad: tensor([-0.0081,  0.0460])\n",
      "Epoch 2460, Loss 3.0\n",
      "    Params: tensor([  5.3201, -17.0351])\n",
      "    Grad: tensor([-0.0081,  0.0459])\n",
      "Epoch 2461, Loss 3.0\n",
      "    Params: tensor([  5.3202, -17.0356])\n",
      "    Grad: tensor([-0.0081,  0.0458])\n",
      "Epoch 2462, Loss 3.0\n",
      "    Params: tensor([  5.3202, -17.0361])\n",
      "    Grad: tensor([-0.0081,  0.0457])\n",
      "Epoch 2463, Loss 3.0\n",
      "    Params: tensor([  5.3203, -17.0365])\n",
      "    Grad: tensor([-0.0081,  0.0456])\n",
      "Epoch 2464, Loss 3.0\n",
      "    Params: tensor([  5.3204, -17.0370])\n",
      "    Grad: tensor([-0.0081,  0.0456])\n",
      "Epoch 2465, Loss 3.0\n",
      "    Params: tensor([  5.3205, -17.0374])\n",
      "    Grad: tensor([-0.0080,  0.0455])\n",
      "Epoch 2466, Loss 3.0\n",
      "    Params: tensor([  5.3206, -17.0379])\n",
      "    Grad: tensor([-0.0080,  0.0454])\n",
      "Epoch 2467, Loss 3.0\n",
      "    Params: tensor([  5.3206, -17.0383])\n",
      "    Grad: tensor([-0.0080,  0.0453])\n",
      "Epoch 2468, Loss 3.0\n",
      "    Params: tensor([  5.3207, -17.0388])\n",
      "    Grad: tensor([-0.0080,  0.0453])\n",
      "Epoch 2469, Loss 3.0\n",
      "    Params: tensor([  5.3208, -17.0392])\n",
      "    Grad: tensor([-0.0080,  0.0452])\n",
      "Epoch 2470, Loss 3.0\n",
      "    Params: tensor([  5.3209, -17.0397])\n",
      "    Grad: tensor([-0.0080,  0.0451])\n",
      "Epoch 2471, Loss 3.0\n",
      "    Params: tensor([  5.3210, -17.0401])\n",
      "    Grad: tensor([-0.0080,  0.0450])\n",
      "Epoch 2472, Loss 3.0\n",
      "    Params: tensor([  5.3210, -17.0406])\n",
      "    Grad: tensor([-0.0079,  0.0450])\n",
      "Epoch 2473, Loss 3.0\n",
      "    Params: tensor([  5.3211, -17.0410])\n",
      "    Grad: tensor([-0.0079,  0.0449])\n",
      "Epoch 2474, Loss 3.0\n",
      "    Params: tensor([  5.3212, -17.0415])\n",
      "    Grad: tensor([-0.0079,  0.0448])\n",
      "Epoch 2475, Loss 3.0\n",
      "    Params: tensor([  5.3213, -17.0419])\n",
      "    Grad: tensor([-0.0079,  0.0447])\n",
      "Epoch 2476, Loss 3.0\n",
      "    Params: tensor([  5.3214, -17.0424])\n",
      "    Grad: tensor([-0.0079,  0.0447])\n",
      "Epoch 2477, Loss 3.0\n",
      "    Params: tensor([  5.3214, -17.0428])\n",
      "    Grad: tensor([-0.0079,  0.0446])\n",
      "Epoch 2478, Loss 3.0\n",
      "    Params: tensor([  5.3215, -17.0433])\n",
      "    Grad: tensor([-0.0079,  0.0445])\n",
      "Epoch 2479, Loss 3.0\n",
      "    Params: tensor([  5.3216, -17.0437])\n",
      "    Grad: tensor([-0.0078,  0.0444])\n",
      "Epoch 2480, Loss 3.0\n",
      "    Params: tensor([  5.3217, -17.0442])\n",
      "    Grad: tensor([-0.0078,  0.0444])\n",
      "Epoch 2481, Loss 3.0\n",
      "    Params: tensor([  5.3218, -17.0446])\n",
      "    Grad: tensor([-0.0078,  0.0443])\n",
      "Epoch 2482, Loss 3.0\n",
      "    Params: tensor([  5.3218, -17.0450])\n",
      "    Grad: tensor([-0.0078,  0.0442])\n",
      "Epoch 2483, Loss 3.0\n",
      "    Params: tensor([  5.3219, -17.0455])\n",
      "    Grad: tensor([-0.0078,  0.0441])\n",
      "Epoch 2484, Loss 3.0\n",
      "    Params: tensor([  5.3220, -17.0459])\n",
      "    Grad: tensor([-0.0078,  0.0441])\n",
      "Epoch 2485, Loss 3.0\n",
      "    Params: tensor([  5.3221, -17.0464])\n",
      "    Grad: tensor([-0.0078,  0.0440])\n",
      "Epoch 2486, Loss 3.0\n",
      "    Params: tensor([  5.3221, -17.0468])\n",
      "    Grad: tensor([-0.0078,  0.0439])\n",
      "Epoch 2487, Loss 3.0\n",
      "    Params: tensor([  5.3222, -17.0472])\n",
      "    Grad: tensor([-0.0077,  0.0438])\n",
      "Epoch 2488, Loss 3.0\n",
      "    Params: tensor([  5.3223, -17.0477])\n",
      "    Grad: tensor([-0.0077,  0.0438])\n",
      "Epoch 2489, Loss 3.0\n",
      "    Params: tensor([  5.3224, -17.0481])\n",
      "    Grad: tensor([-0.0077,  0.0437])\n",
      "Epoch 2490, Loss 3.0\n",
      "    Params: tensor([  5.3225, -17.0485])\n",
      "    Grad: tensor([-0.0077,  0.0436])\n",
      "Epoch 2491, Loss 3.0\n",
      "    Params: tensor([  5.3225, -17.0490])\n",
      "    Grad: tensor([-0.0077,  0.0435])\n",
      "Epoch 2492, Loss 3.0\n",
      "    Params: tensor([  5.3226, -17.0494])\n",
      "    Grad: tensor([-0.0077,  0.0435])\n",
      "Epoch 2493, Loss 3.0\n",
      "    Params: tensor([  5.3227, -17.0499])\n",
      "    Grad: tensor([-0.0077,  0.0434])\n",
      "Epoch 2494, Loss 3.0\n",
      "    Params: tensor([  5.3228, -17.0503])\n",
      "    Grad: tensor([-0.0076,  0.0433])\n",
      "Epoch 2495, Loss 3.0\n",
      "    Params: tensor([  5.3228, -17.0507])\n",
      "    Grad: tensor([-0.0077,  0.0432])\n",
      "Epoch 2496, Loss 3.0\n",
      "    Params: tensor([  5.3229, -17.0511])\n",
      "    Grad: tensor([-0.0076,  0.0432])\n",
      "Epoch 2497, Loss 3.0\n",
      "    Params: tensor([  5.3230, -17.0516])\n",
      "    Grad: tensor([-0.0076,  0.0431])\n",
      "Epoch 2498, Loss 3.0\n",
      "    Params: tensor([  5.3231, -17.0520])\n",
      "    Grad: tensor([-0.0076,  0.0430])\n",
      "Epoch 2499, Loss 3.0\n",
      "    Params: tensor([  5.3231, -17.0524])\n",
      "    Grad: tensor([-0.0076,  0.0429])\n",
      "Epoch 2500, Loss 3.0\n",
      "    Params: tensor([  5.3232, -17.0529])\n",
      "    Grad: tensor([-0.0076,  0.0429])\n",
      "Epoch 2501, Loss 3.0\n",
      "    Params: tensor([  5.3233, -17.0533])\n",
      "    Grad: tensor([-0.0076,  0.0428])\n",
      "Epoch 2502, Loss 3.0\n",
      "    Params: tensor([  5.3234, -17.0537])\n",
      "    Grad: tensor([-0.0075,  0.0427])\n",
      "Epoch 2503, Loss 3.0\n",
      "    Params: tensor([  5.3234, -17.0542])\n",
      "    Grad: tensor([-0.0075,  0.0426])\n",
      "Epoch 2504, Loss 3.0\n",
      "    Params: tensor([  5.3235, -17.0546])\n",
      "    Grad: tensor([-0.0075,  0.0426])\n",
      "Epoch 2505, Loss 3.0\n",
      "    Params: tensor([  5.3236, -17.0550])\n",
      "    Grad: tensor([-0.0075,  0.0425])\n",
      "Epoch 2506, Loss 3.0\n",
      "    Params: tensor([  5.3237, -17.0554])\n",
      "    Grad: tensor([-0.0075,  0.0424])\n",
      "Epoch 2507, Loss 3.0\n",
      "    Params: tensor([  5.3237, -17.0558])\n",
      "    Grad: tensor([-0.0075,  0.0424])\n",
      "Epoch 2508, Loss 3.0\n",
      "    Params: tensor([  5.3238, -17.0563])\n",
      "    Grad: tensor([-0.0075,  0.0423])\n",
      "Epoch 2509, Loss 3.0\n",
      "    Params: tensor([  5.3239, -17.0567])\n",
      "    Grad: tensor([-0.0075,  0.0422])\n",
      "Epoch 2510, Loss 3.0\n",
      "    Params: tensor([  5.3240, -17.0571])\n",
      "    Grad: tensor([-0.0074,  0.0421])\n",
      "Epoch 2511, Loss 3.0\n",
      "    Params: tensor([  5.3240, -17.0575])\n",
      "    Grad: tensor([-0.0074,  0.0421])\n",
      "Epoch 2512, Loss 3.0\n",
      "    Params: tensor([  5.3241, -17.0580])\n",
      "    Grad: tensor([-0.0074,  0.0420])\n",
      "Epoch 2513, Loss 3.0\n",
      "    Params: tensor([  5.3242, -17.0584])\n",
      "    Grad: tensor([-0.0074,  0.0419])\n",
      "Epoch 2514, Loss 3.0\n",
      "    Params: tensor([  5.3243, -17.0588])\n",
      "    Grad: tensor([-0.0074,  0.0419])\n",
      "Epoch 2515, Loss 3.0\n",
      "    Params: tensor([  5.3243, -17.0592])\n",
      "    Grad: tensor([-0.0074,  0.0418])\n",
      "Epoch 2516, Loss 3.0\n",
      "    Params: tensor([  5.3244, -17.0596])\n",
      "    Grad: tensor([-0.0074,  0.0417])\n",
      "Epoch 2517, Loss 3.0\n",
      "    Params: tensor([  5.3245, -17.0600])\n",
      "    Grad: tensor([-0.0074,  0.0416])\n",
      "Epoch 2518, Loss 3.0\n",
      "    Params: tensor([  5.3246, -17.0605])\n",
      "    Grad: tensor([-0.0074,  0.0416])\n",
      "Epoch 2519, Loss 3.0\n",
      "    Params: tensor([  5.3246, -17.0609])\n",
      "    Grad: tensor([-0.0073,  0.0415])\n",
      "Epoch 2520, Loss 3.0\n",
      "    Params: tensor([  5.3247, -17.0613])\n",
      "    Grad: tensor([-0.0073,  0.0414])\n",
      "Epoch 2521, Loss 3.0\n",
      "    Params: tensor([  5.3248, -17.0617])\n",
      "    Grad: tensor([-0.0073,  0.0414])\n",
      "Epoch 2522, Loss 3.0\n",
      "    Params: tensor([  5.3249, -17.0621])\n",
      "    Grad: tensor([-0.0073,  0.0413])\n",
      "Epoch 2523, Loss 3.0\n",
      "    Params: tensor([  5.3249, -17.0625])\n",
      "    Grad: tensor([-0.0073,  0.0412])\n",
      "Epoch 2524, Loss 3.0\n",
      "    Params: tensor([  5.3250, -17.0629])\n",
      "    Grad: tensor([-0.0073,  0.0412])\n",
      "Epoch 2525, Loss 3.0\n",
      "    Params: tensor([  5.3251, -17.0634])\n",
      "    Grad: tensor([-0.0073,  0.0411])\n",
      "Epoch 2526, Loss 3.0\n",
      "    Params: tensor([  5.3251, -17.0638])\n",
      "    Grad: tensor([-0.0072,  0.0410])\n",
      "Epoch 2527, Loss 3.0\n",
      "    Params: tensor([  5.3252, -17.0642])\n",
      "    Grad: tensor([-0.0072,  0.0409])\n",
      "Epoch 2528, Loss 3.0\n",
      "    Params: tensor([  5.3253, -17.0646])\n",
      "    Grad: tensor([-0.0072,  0.0409])\n",
      "Epoch 2529, Loss 3.0\n",
      "    Params: tensor([  5.3254, -17.0650])\n",
      "    Grad: tensor([-0.0072,  0.0408])\n",
      "Epoch 2530, Loss 3.0\n",
      "    Params: tensor([  5.3254, -17.0654])\n",
      "    Grad: tensor([-0.0072,  0.0407])\n",
      "Epoch 2531, Loss 3.0\n",
      "    Params: tensor([  5.3255, -17.0658])\n",
      "    Grad: tensor([-0.0072,  0.0407])\n",
      "Epoch 2532, Loss 3.0\n",
      "    Params: tensor([  5.3256, -17.0662])\n",
      "    Grad: tensor([-0.0072,  0.0406])\n",
      "Epoch 2533, Loss 3.0\n",
      "    Params: tensor([  5.3256, -17.0666])\n",
      "    Grad: tensor([-0.0072,  0.0405])\n",
      "Epoch 2534, Loss 3.0\n",
      "    Params: tensor([  5.3257, -17.0670])\n",
      "    Grad: tensor([-0.0071,  0.0405])\n",
      "Epoch 2535, Loss 3.0\n",
      "    Params: tensor([  5.3258, -17.0674])\n",
      "    Grad: tensor([-0.0071,  0.0404])\n",
      "Epoch 2536, Loss 3.0\n",
      "    Params: tensor([  5.3259, -17.0678])\n",
      "    Grad: tensor([-0.0071,  0.0403])\n",
      "Epoch 2537, Loss 3.0\n",
      "    Params: tensor([  5.3259, -17.0682])\n",
      "    Grad: tensor([-0.0071,  0.0403])\n",
      "Epoch 2538, Loss 3.0\n",
      "    Params: tensor([  5.3260, -17.0686])\n",
      "    Grad: tensor([-0.0071,  0.0402])\n",
      "Epoch 2539, Loss 3.0\n",
      "    Params: tensor([  5.3261, -17.0690])\n",
      "    Grad: tensor([-0.0071,  0.0401])\n",
      "Epoch 2540, Loss 3.0\n",
      "    Params: tensor([  5.3261, -17.0694])\n",
      "    Grad: tensor([-0.0071,  0.0401])\n",
      "Epoch 2541, Loss 3.0\n",
      "    Params: tensor([  5.3262, -17.0698])\n",
      "    Grad: tensor([-0.0071,  0.0400])\n",
      "Epoch 2542, Loss 3.0\n",
      "    Params: tensor([  5.3263, -17.0702])\n",
      "    Grad: tensor([-0.0071,  0.0399])\n",
      "Epoch 2543, Loss 3.0\n",
      "    Params: tensor([  5.3264, -17.0706])\n",
      "    Grad: tensor([-0.0070,  0.0398])\n",
      "Epoch 2544, Loss 3.0\n",
      "    Params: tensor([  5.3264, -17.0710])\n",
      "    Grad: tensor([-0.0070,  0.0398])\n",
      "Epoch 2545, Loss 3.0\n",
      "    Params: tensor([  5.3265, -17.0714])\n",
      "    Grad: tensor([-0.0070,  0.0397])\n",
      "Epoch 2546, Loss 3.0\n",
      "    Params: tensor([  5.3266, -17.0718])\n",
      "    Grad: tensor([-0.0070,  0.0396])\n",
      "Epoch 2547, Loss 3.0\n",
      "    Params: tensor([  5.3266, -17.0722])\n",
      "    Grad: tensor([-0.0070,  0.0396])\n",
      "Epoch 2548, Loss 3.0\n",
      "    Params: tensor([  5.3267, -17.0726])\n",
      "    Grad: tensor([-0.0070,  0.0395])\n",
      "Epoch 2549, Loss 3.0\n",
      "    Params: tensor([  5.3268, -17.0730])\n",
      "    Grad: tensor([-0.0070,  0.0394])\n",
      "Epoch 2550, Loss 3.0\n",
      "    Params: tensor([  5.3268, -17.0734])\n",
      "    Grad: tensor([-0.0070,  0.0394])\n",
      "Epoch 2551, Loss 3.0\n",
      "    Params: tensor([  5.3269, -17.0738])\n",
      "    Grad: tensor([-0.0069,  0.0393])\n",
      "Epoch 2552, Loss 3.0\n",
      "    Params: tensor([  5.3270, -17.0742])\n",
      "    Grad: tensor([-0.0069,  0.0392])\n",
      "Epoch 2553, Loss 3.0\n",
      "    Params: tensor([  5.3271, -17.0746])\n",
      "    Grad: tensor([-0.0069,  0.0392])\n",
      "Epoch 2554, Loss 3.0\n",
      "    Params: tensor([  5.3271, -17.0750])\n",
      "    Grad: tensor([-0.0069,  0.0391])\n",
      "Epoch 2555, Loss 3.0\n",
      "    Params: tensor([  5.3272, -17.0754])\n",
      "    Grad: tensor([-0.0069,  0.0390])\n",
      "Epoch 2556, Loss 3.0\n",
      "    Params: tensor([  5.3273, -17.0757])\n",
      "    Grad: tensor([-0.0069,  0.0390])\n",
      "Epoch 2557, Loss 3.0\n",
      "    Params: tensor([  5.3273, -17.0761])\n",
      "    Grad: tensor([-0.0069,  0.0389])\n",
      "Epoch 2558, Loss 3.0\n",
      "    Params: tensor([  5.3274, -17.0765])\n",
      "    Grad: tensor([-0.0069,  0.0388])\n",
      "Epoch 2559, Loss 3.0\n",
      "    Params: tensor([  5.3275, -17.0769])\n",
      "    Grad: tensor([-0.0069,  0.0388])\n",
      "Epoch 2560, Loss 3.0\n",
      "    Params: tensor([  5.3275, -17.0773])\n",
      "    Grad: tensor([-0.0068,  0.0387])\n",
      "Epoch 2561, Loss 3.0\n",
      "    Params: tensor([  5.3276, -17.0777])\n",
      "    Grad: tensor([-0.0068,  0.0386])\n",
      "Epoch 2562, Loss 3.0\n",
      "    Params: tensor([  5.3277, -17.0781])\n",
      "    Grad: tensor([-0.0068,  0.0386])\n",
      "Epoch 2563, Loss 3.0\n",
      "    Params: tensor([  5.3277, -17.0785])\n",
      "    Grad: tensor([-0.0068,  0.0385])\n",
      "Epoch 2564, Loss 3.0\n",
      "    Params: tensor([  5.3278, -17.0788])\n",
      "    Grad: tensor([-0.0068,  0.0384])\n",
      "Epoch 2565, Loss 3.0\n",
      "    Params: tensor([  5.3279, -17.0792])\n",
      "    Grad: tensor([-0.0068,  0.0384])\n",
      "Epoch 2566, Loss 3.0\n",
      "    Params: tensor([  5.3279, -17.0796])\n",
      "    Grad: tensor([-0.0068,  0.0383])\n",
      "Epoch 2567, Loss 3.0\n",
      "    Params: tensor([  5.3280, -17.0800])\n",
      "    Grad: tensor([-0.0068,  0.0383])\n",
      "Epoch 2568, Loss 3.0\n",
      "    Params: tensor([  5.3281, -17.0804])\n",
      "    Grad: tensor([-0.0067,  0.0382])\n",
      "Epoch 2569, Loss 3.0\n",
      "    Params: tensor([  5.3281, -17.0808])\n",
      "    Grad: tensor([-0.0067,  0.0381])\n",
      "Epoch 2570, Loss 3.0\n",
      "    Params: tensor([  5.3282, -17.0811])\n",
      "    Grad: tensor([-0.0067,  0.0381])\n",
      "Epoch 2571, Loss 3.0\n",
      "    Params: tensor([  5.3283, -17.0815])\n",
      "    Grad: tensor([-0.0067,  0.0380])\n",
      "Epoch 2572, Loss 3.0\n",
      "    Params: tensor([  5.3283, -17.0819])\n",
      "    Grad: tensor([-0.0067,  0.0379])\n",
      "Epoch 2573, Loss 3.0\n",
      "    Params: tensor([  5.3284, -17.0823])\n",
      "    Grad: tensor([-0.0067,  0.0379])\n",
      "Epoch 2574, Loss 3.0\n",
      "    Params: tensor([  5.3285, -17.0827])\n",
      "    Grad: tensor([-0.0067,  0.0378])\n",
      "Epoch 2575, Loss 3.0\n",
      "    Params: tensor([  5.3285, -17.0830])\n",
      "    Grad: tensor([-0.0067,  0.0377])\n",
      "Epoch 2576, Loss 3.0\n",
      "    Params: tensor([  5.3286, -17.0834])\n",
      "    Grad: tensor([-0.0066,  0.0377])\n",
      "Epoch 2577, Loss 3.0\n",
      "    Params: tensor([  5.3287, -17.0838])\n",
      "    Grad: tensor([-0.0067,  0.0376])\n",
      "Epoch 2578, Loss 3.0\n",
      "    Params: tensor([  5.3287, -17.0842])\n",
      "    Grad: tensor([-0.0066,  0.0375])\n",
      "Epoch 2579, Loss 3.0\n",
      "    Params: tensor([  5.3288, -17.0845])\n",
      "    Grad: tensor([-0.0066,  0.0375])\n",
      "Epoch 2580, Loss 3.0\n",
      "    Params: tensor([  5.3289, -17.0849])\n",
      "    Grad: tensor([-0.0066,  0.0374])\n",
      "Epoch 2581, Loss 3.0\n",
      "    Params: tensor([  5.3289, -17.0853])\n",
      "    Grad: tensor([-0.0066,  0.0374])\n",
      "Epoch 2582, Loss 3.0\n",
      "    Params: tensor([  5.3290, -17.0857])\n",
      "    Grad: tensor([-0.0066,  0.0373])\n",
      "Epoch 2583, Loss 3.0\n",
      "    Params: tensor([  5.3291, -17.0860])\n",
      "    Grad: tensor([-0.0066,  0.0372])\n",
      "Epoch 2584, Loss 3.0\n",
      "    Params: tensor([  5.3291, -17.0864])\n",
      "    Grad: tensor([-0.0065,  0.0372])\n",
      "Epoch 2585, Loss 3.0\n",
      "    Params: tensor([  5.3292, -17.0868])\n",
      "    Grad: tensor([-0.0065,  0.0371])\n",
      "Epoch 2586, Loss 3.0\n",
      "    Params: tensor([  5.3293, -17.0871])\n",
      "    Grad: tensor([-0.0066,  0.0370])\n",
      "Epoch 2587, Loss 3.0\n",
      "    Params: tensor([  5.3293, -17.0875])\n",
      "    Grad: tensor([-0.0065,  0.0370])\n",
      "Epoch 2588, Loss 3.0\n",
      "    Params: tensor([  5.3294, -17.0879])\n",
      "    Grad: tensor([-0.0065,  0.0369])\n",
      "Epoch 2589, Loss 3.0\n",
      "    Params: tensor([  5.3295, -17.0882])\n",
      "    Grad: tensor([-0.0065,  0.0368])\n",
      "Epoch 2590, Loss 3.0\n",
      "    Params: tensor([  5.3295, -17.0886])\n",
      "    Grad: tensor([-0.0065,  0.0368])\n",
      "Epoch 2591, Loss 3.0\n",
      "    Params: tensor([  5.3296, -17.0890])\n",
      "    Grad: tensor([-0.0065,  0.0367])\n",
      "Epoch 2592, Loss 3.0\n",
      "    Params: tensor([  5.3297, -17.0893])\n",
      "    Grad: tensor([-0.0065,  0.0367])\n",
      "Epoch 2593, Loss 3.0\n",
      "    Params: tensor([  5.3297, -17.0897])\n",
      "    Grad: tensor([-0.0065,  0.0366])\n",
      "Epoch 2594, Loss 3.0\n",
      "    Params: tensor([  5.3298, -17.0901])\n",
      "    Grad: tensor([-0.0065,  0.0365])\n",
      "Epoch 2595, Loss 3.0\n",
      "    Params: tensor([  5.3299, -17.0904])\n",
      "    Grad: tensor([-0.0064,  0.0365])\n",
      "Epoch 2596, Loss 3.0\n",
      "    Params: tensor([  5.3299, -17.0908])\n",
      "    Grad: tensor([-0.0064,  0.0364])\n",
      "Epoch 2597, Loss 3.0\n",
      "    Params: tensor([  5.3300, -17.0912])\n",
      "    Grad: tensor([-0.0064,  0.0363])\n",
      "Epoch 2598, Loss 3.0\n",
      "    Params: tensor([  5.3300, -17.0915])\n",
      "    Grad: tensor([-0.0064,  0.0363])\n",
      "Epoch 2599, Loss 3.0\n",
      "    Params: tensor([  5.3301, -17.0919])\n",
      "    Grad: tensor([-0.0064,  0.0362])\n",
      "Epoch 2600, Loss 3.0\n",
      "    Params: tensor([  5.3302, -17.0923])\n",
      "    Grad: tensor([-0.0064,  0.0362])\n",
      "Epoch 2601, Loss 3.0\n",
      "    Params: tensor([  5.3302, -17.0926])\n",
      "    Grad: tensor([-0.0064,  0.0361])\n",
      "Epoch 2602, Loss 3.0\n",
      "    Params: tensor([  5.3303, -17.0930])\n",
      "    Grad: tensor([-0.0064,  0.0360])\n",
      "Epoch 2603, Loss 3.0\n",
      "    Params: tensor([  5.3304, -17.0933])\n",
      "    Grad: tensor([-0.0064,  0.0360])\n",
      "Epoch 2604, Loss 3.0\n",
      "    Params: tensor([  5.3304, -17.0937])\n",
      "    Grad: tensor([-0.0064,  0.0359])\n",
      "Epoch 2605, Loss 3.0\n",
      "    Params: tensor([  5.3305, -17.0941])\n",
      "    Grad: tensor([-0.0063,  0.0359])\n",
      "Epoch 2606, Loss 3.0\n",
      "    Params: tensor([  5.3306, -17.0944])\n",
      "    Grad: tensor([-0.0063,  0.0358])\n",
      "Epoch 2607, Loss 3.0\n",
      "    Params: tensor([  5.3306, -17.0948])\n",
      "    Grad: tensor([-0.0063,  0.0357])\n",
      "Epoch 2608, Loss 3.0\n",
      "    Params: tensor([  5.3307, -17.0951])\n",
      "    Grad: tensor([-0.0063,  0.0357])\n",
      "Epoch 2609, Loss 3.0\n",
      "    Params: tensor([  5.3307, -17.0955])\n",
      "    Grad: tensor([-0.0063,  0.0356])\n",
      "Epoch 2610, Loss 3.0\n",
      "    Params: tensor([  5.3308, -17.0958])\n",
      "    Grad: tensor([-0.0063,  0.0356])\n",
      "Epoch 2611, Loss 3.0\n",
      "    Params: tensor([  5.3309, -17.0962])\n",
      "    Grad: tensor([-0.0063,  0.0355])\n",
      "Epoch 2612, Loss 3.0\n",
      "    Params: tensor([  5.3309, -17.0966])\n",
      "    Grad: tensor([-0.0062,  0.0354])\n",
      "Epoch 2613, Loss 3.0\n",
      "    Params: tensor([  5.3310, -17.0969])\n",
      "    Grad: tensor([-0.0062,  0.0354])\n",
      "Epoch 2614, Loss 3.0\n",
      "    Params: tensor([  5.3311, -17.0973])\n",
      "    Grad: tensor([-0.0062,  0.0353])\n",
      "Epoch 2615, Loss 3.0\n",
      "    Params: tensor([  5.3311, -17.0976])\n",
      "    Grad: tensor([-0.0062,  0.0353])\n",
      "Epoch 2616, Loss 3.0\n",
      "    Params: tensor([  5.3312, -17.0980])\n",
      "    Grad: tensor([-0.0062,  0.0352])\n",
      "Epoch 2617, Loss 3.0\n",
      "    Params: tensor([  5.3312, -17.0983])\n",
      "    Grad: tensor([-0.0062,  0.0351])\n",
      "Epoch 2618, Loss 3.0\n",
      "    Params: tensor([  5.3313, -17.0987])\n",
      "    Grad: tensor([-0.0062,  0.0351])\n",
      "Epoch 2619, Loss 3.0\n",
      "    Params: tensor([  5.3314, -17.0990])\n",
      "    Grad: tensor([-0.0062,  0.0350])\n",
      "Epoch 2620, Loss 3.0\n",
      "    Params: tensor([  5.3314, -17.0994])\n",
      "    Grad: tensor([-0.0062,  0.0350])\n",
      "Epoch 2621, Loss 3.0\n",
      "    Params: tensor([  5.3315, -17.0997])\n",
      "    Grad: tensor([-0.0062,  0.0349])\n",
      "Epoch 2622, Loss 3.0\n",
      "    Params: tensor([  5.3316, -17.1001])\n",
      "    Grad: tensor([-0.0062,  0.0348])\n",
      "Epoch 2623, Loss 3.0\n",
      "    Params: tensor([  5.3316, -17.1004])\n",
      "    Grad: tensor([-0.0062,  0.0348])\n",
      "Epoch 2624, Loss 3.0\n",
      "    Params: tensor([  5.3317, -17.1008])\n",
      "    Grad: tensor([-0.0061,  0.0347])\n",
      "Epoch 2625, Loss 3.0\n",
      "    Params: tensor([  5.3317, -17.1011])\n",
      "    Grad: tensor([-0.0061,  0.0347])\n",
      "Epoch 2626, Loss 3.0\n",
      "    Params: tensor([  5.3318, -17.1014])\n",
      "    Grad: tensor([-0.0061,  0.0346])\n",
      "Epoch 2627, Loss 3.0\n",
      "    Params: tensor([  5.3319, -17.1018])\n",
      "    Grad: tensor([-0.0061,  0.0345])\n",
      "Epoch 2628, Loss 3.0\n",
      "    Params: tensor([  5.3319, -17.1021])\n",
      "    Grad: tensor([-0.0061,  0.0345])\n",
      "Epoch 2629, Loss 3.0\n",
      "    Params: tensor([  5.3320, -17.1025])\n",
      "    Grad: tensor([-0.0061,  0.0344])\n",
      "Epoch 2630, Loss 3.0\n",
      "    Params: tensor([  5.3320, -17.1028])\n",
      "    Grad: tensor([-0.0060,  0.0344])\n",
      "Epoch 2631, Loss 3.0\n",
      "    Params: tensor([  5.3321, -17.1032])\n",
      "    Grad: tensor([-0.0060,  0.0343])\n",
      "Epoch 2632, Loss 3.0\n",
      "    Params: tensor([  5.3322, -17.1035])\n",
      "    Grad: tensor([-0.0060,  0.0343])\n",
      "Epoch 2633, Loss 3.0\n",
      "    Params: tensor([  5.3322, -17.1039])\n",
      "    Grad: tensor([-0.0060,  0.0342])\n",
      "Epoch 2634, Loss 3.0\n",
      "    Params: tensor([  5.3323, -17.1042])\n",
      "    Grad: tensor([-0.0060,  0.0341])\n",
      "Epoch 2635, Loss 3.0\n",
      "    Params: tensor([  5.3323, -17.1045])\n",
      "    Grad: tensor([-0.0060,  0.0341])\n",
      "Epoch 2636, Loss 3.0\n",
      "    Params: tensor([  5.3324, -17.1049])\n",
      "    Grad: tensor([-0.0060,  0.0340])\n",
      "Epoch 2637, Loss 3.0\n",
      "    Params: tensor([  5.3325, -17.1052])\n",
      "    Grad: tensor([-0.0060,  0.0340])\n",
      "Epoch 2638, Loss 3.0\n",
      "    Params: tensor([  5.3325, -17.1056])\n",
      "    Grad: tensor([-0.0060,  0.0339])\n",
      "Epoch 2639, Loss 3.0\n",
      "    Params: tensor([  5.3326, -17.1059])\n",
      "    Grad: tensor([-0.0060,  0.0338])\n",
      "Epoch 2640, Loss 3.0\n",
      "    Params: tensor([  5.3326, -17.1062])\n",
      "    Grad: tensor([-0.0060,  0.0338])\n",
      "Epoch 2641, Loss 3.0\n",
      "    Params: tensor([  5.3327, -17.1066])\n",
      "    Grad: tensor([-0.0059,  0.0337])\n",
      "Epoch 2642, Loss 3.0\n",
      "    Params: tensor([  5.3328, -17.1069])\n",
      "    Grad: tensor([-0.0059,  0.0337])\n",
      "Epoch 2643, Loss 3.0\n",
      "    Params: tensor([  5.3328, -17.1072])\n",
      "    Grad: tensor([-0.0059,  0.0336])\n",
      "Epoch 2644, Loss 3.0\n",
      "    Params: tensor([  5.3329, -17.1076])\n",
      "    Grad: tensor([-0.0059,  0.0336])\n",
      "Epoch 2645, Loss 3.0\n",
      "    Params: tensor([  5.3329, -17.1079])\n",
      "    Grad: tensor([-0.0059,  0.0335])\n",
      "Epoch 2646, Loss 3.0\n",
      "    Params: tensor([  5.3330, -17.1082])\n",
      "    Grad: tensor([-0.0059,  0.0334])\n",
      "Epoch 2647, Loss 3.0\n",
      "    Params: tensor([  5.3331, -17.1086])\n",
      "    Grad: tensor([-0.0059,  0.0334])\n",
      "Epoch 2648, Loss 3.0\n",
      "    Params: tensor([  5.3331, -17.1089])\n",
      "    Grad: tensor([-0.0059,  0.0333])\n",
      "Epoch 2649, Loss 3.0\n",
      "    Params: tensor([  5.3332, -17.1092])\n",
      "    Grad: tensor([-0.0059,  0.0333])\n",
      "Epoch 2650, Loss 3.0\n",
      "    Params: tensor([  5.3332, -17.1096])\n",
      "    Grad: tensor([-0.0059,  0.0332])\n",
      "Epoch 2651, Loss 3.0\n",
      "    Params: tensor([  5.3333, -17.1099])\n",
      "    Grad: tensor([-0.0059,  0.0332])\n",
      "Epoch 2652, Loss 3.0\n",
      "    Params: tensor([  5.3334, -17.1102])\n",
      "    Grad: tensor([-0.0058,  0.0331])\n",
      "Epoch 2653, Loss 3.0\n",
      "    Params: tensor([  5.3334, -17.1106])\n",
      "    Grad: tensor([-0.0058,  0.0330])\n",
      "Epoch 2654, Loss 3.0\n",
      "    Params: tensor([  5.3335, -17.1109])\n",
      "    Grad: tensor([-0.0058,  0.0330])\n",
      "Epoch 2655, Loss 3.0\n",
      "    Params: tensor([  5.3335, -17.1112])\n",
      "    Grad: tensor([-0.0058,  0.0329])\n",
      "Epoch 2656, Loss 3.0\n",
      "    Params: tensor([  5.3336, -17.1116])\n",
      "    Grad: tensor([-0.0058,  0.0329])\n",
      "Epoch 2657, Loss 3.0\n",
      "    Params: tensor([  5.3336, -17.1119])\n",
      "    Grad: tensor([-0.0058,  0.0328])\n",
      "Epoch 2658, Loss 3.0\n",
      "    Params: tensor([  5.3337, -17.1122])\n",
      "    Grad: tensor([-0.0058,  0.0328])\n",
      "Epoch 2659, Loss 3.0\n",
      "    Params: tensor([  5.3338, -17.1125])\n",
      "    Grad: tensor([-0.0058,  0.0327])\n",
      "Epoch 2660, Loss 3.0\n",
      "    Params: tensor([  5.3338, -17.1129])\n",
      "    Grad: tensor([-0.0058,  0.0327])\n",
      "Epoch 2661, Loss 3.0\n",
      "    Params: tensor([  5.3339, -17.1132])\n",
      "    Grad: tensor([-0.0058,  0.0326])\n",
      "Epoch 2662, Loss 3.0\n",
      "    Params: tensor([  5.3339, -17.1135])\n",
      "    Grad: tensor([-0.0058,  0.0325])\n",
      "Epoch 2663, Loss 3.0\n",
      "    Params: tensor([  5.3340, -17.1138])\n",
      "    Grad: tensor([-0.0057,  0.0325])\n",
      "Epoch 2664, Loss 3.0\n",
      "    Params: tensor([  5.3340, -17.1142])\n",
      "    Grad: tensor([-0.0057,  0.0324])\n",
      "Epoch 2665, Loss 3.0\n",
      "    Params: tensor([  5.3341, -17.1145])\n",
      "    Grad: tensor([-0.0057,  0.0324])\n",
      "Epoch 2666, Loss 3.0\n",
      "    Params: tensor([  5.3342, -17.1148])\n",
      "    Grad: tensor([-0.0057,  0.0323])\n",
      "Epoch 2667, Loss 3.0\n",
      "    Params: tensor([  5.3342, -17.1151])\n",
      "    Grad: tensor([-0.0057,  0.0323])\n",
      "Epoch 2668, Loss 3.0\n",
      "    Params: tensor([  5.3343, -17.1155])\n",
      "    Grad: tensor([-0.0057,  0.0322])\n",
      "Epoch 2669, Loss 3.0\n",
      "    Params: tensor([  5.3343, -17.1158])\n",
      "    Grad: tensor([-0.0057,  0.0322])\n",
      "Epoch 2670, Loss 3.0\n",
      "    Params: tensor([  5.3344, -17.1161])\n",
      "    Grad: tensor([-0.0057,  0.0321])\n",
      "Epoch 2671, Loss 3.0\n",
      "    Params: tensor([  5.3344, -17.1164])\n",
      "    Grad: tensor([-0.0057,  0.0321])\n",
      "Epoch 2672, Loss 3.0\n",
      "    Params: tensor([  5.3345, -17.1167])\n",
      "    Grad: tensor([-0.0056,  0.0320])\n",
      "Epoch 2673, Loss 3.0\n",
      "    Params: tensor([  5.3346, -17.1171])\n",
      "    Grad: tensor([-0.0057,  0.0319])\n",
      "Epoch 2674, Loss 3.0\n",
      "    Params: tensor([  5.3346, -17.1174])\n",
      "    Grad: tensor([-0.0056,  0.0319])\n",
      "Epoch 2675, Loss 3.0\n",
      "    Params: tensor([  5.3347, -17.1177])\n",
      "    Grad: tensor([-0.0056,  0.0318])\n",
      "Epoch 2676, Loss 3.0\n",
      "    Params: tensor([  5.3347, -17.1180])\n",
      "    Grad: tensor([-0.0056,  0.0318])\n",
      "Epoch 2677, Loss 3.0\n",
      "    Params: tensor([  5.3348, -17.1183])\n",
      "    Grad: tensor([-0.0056,  0.0317])\n",
      "Epoch 2678, Loss 3.0\n",
      "    Params: tensor([  5.3348, -17.1187])\n",
      "    Grad: tensor([-0.0056,  0.0317])\n",
      "Epoch 2679, Loss 3.0\n",
      "    Params: tensor([  5.3349, -17.1190])\n",
      "    Grad: tensor([-0.0056,  0.0316])\n",
      "Epoch 2680, Loss 3.0\n",
      "    Params: tensor([  5.3349, -17.1193])\n",
      "    Grad: tensor([-0.0056,  0.0316])\n",
      "Epoch 2681, Loss 3.0\n",
      "    Params: tensor([  5.3350, -17.1196])\n",
      "    Grad: tensor([-0.0056,  0.0315])\n",
      "Epoch 2682, Loss 3.0\n",
      "    Params: tensor([  5.3351, -17.1199])\n",
      "    Grad: tensor([-0.0055,  0.0315])\n",
      "Epoch 2683, Loss 3.0\n",
      "    Params: tensor([  5.3351, -17.1202])\n",
      "    Grad: tensor([-0.0055,  0.0314])\n",
      "Epoch 2684, Loss 3.0\n",
      "    Params: tensor([  5.3352, -17.1205])\n",
      "    Grad: tensor([-0.0056,  0.0313])\n",
      "Epoch 2685, Loss 3.0\n",
      "    Params: tensor([  5.3352, -17.1209])\n",
      "    Grad: tensor([-0.0055,  0.0313])\n",
      "Epoch 2686, Loss 3.0\n",
      "    Params: tensor([  5.3353, -17.1212])\n",
      "    Grad: tensor([-0.0055,  0.0312])\n",
      "Epoch 2687, Loss 3.0\n",
      "    Params: tensor([  5.3353, -17.1215])\n",
      "    Grad: tensor([-0.0055,  0.0312])\n",
      "Epoch 2688, Loss 3.0\n",
      "    Params: tensor([  5.3354, -17.1218])\n",
      "    Grad: tensor([-0.0055,  0.0311])\n",
      "Epoch 2689, Loss 3.0\n",
      "    Params: tensor([  5.3354, -17.1221])\n",
      "    Grad: tensor([-0.0055,  0.0311])\n",
      "Epoch 2690, Loss 3.0\n",
      "    Params: tensor([  5.3355, -17.1224])\n",
      "    Grad: tensor([-0.0055,  0.0310])\n",
      "Epoch 2691, Loss 3.0\n",
      "    Params: tensor([  5.3356, -17.1227])\n",
      "    Grad: tensor([-0.0055,  0.0310])\n",
      "Epoch 2692, Loss 3.0\n",
      "    Params: tensor([  5.3356, -17.1230])\n",
      "    Grad: tensor([-0.0055,  0.0309])\n",
      "Epoch 2693, Loss 3.0\n",
      "    Params: tensor([  5.3357, -17.1233])\n",
      "    Grad: tensor([-0.0054,  0.0309])\n",
      "Epoch 2694, Loss 3.0\n",
      "    Params: tensor([  5.3357, -17.1236])\n",
      "    Grad: tensor([-0.0055,  0.0308])\n",
      "Epoch 2695, Loss 3.0\n",
      "    Params: tensor([  5.3358, -17.1240])\n",
      "    Grad: tensor([-0.0055,  0.0308])\n",
      "Epoch 2696, Loss 3.0\n",
      "    Params: tensor([  5.3358, -17.1243])\n",
      "    Grad: tensor([-0.0054,  0.0307])\n",
      "Epoch 2697, Loss 3.0\n",
      "    Params: tensor([  5.3359, -17.1246])\n",
      "    Grad: tensor([-0.0054,  0.0307])\n",
      "Epoch 2698, Loss 3.0\n",
      "    Params: tensor([  5.3359, -17.1249])\n",
      "    Grad: tensor([-0.0054,  0.0306])\n",
      "Epoch 2699, Loss 3.0\n",
      "    Params: tensor([  5.3360, -17.1252])\n",
      "    Grad: tensor([-0.0054,  0.0306])\n",
      "Epoch 2700, Loss 3.0\n",
      "    Params: tensor([  5.3360, -17.1255])\n",
      "    Grad: tensor([-0.0054,  0.0305])\n",
      "Epoch 2701, Loss 3.0\n",
      "    Params: tensor([  5.3361, -17.1258])\n",
      "    Grad: tensor([-0.0054,  0.0305])\n",
      "Epoch 2702, Loss 3.0\n",
      "    Params: tensor([  5.3362, -17.1261])\n",
      "    Grad: tensor([-0.0054,  0.0304])\n",
      "Epoch 2703, Loss 3.0\n",
      "    Params: tensor([  5.3362, -17.1264])\n",
      "    Grad: tensor([-0.0054,  0.0304])\n",
      "Epoch 2704, Loss 3.0\n",
      "    Params: tensor([  5.3363, -17.1267])\n",
      "    Grad: tensor([-0.0053,  0.0303])\n",
      "Epoch 2705, Loss 3.0\n",
      "    Params: tensor([  5.3363, -17.1270])\n",
      "    Grad: tensor([-0.0053,  0.0303])\n",
      "Epoch 2706, Loss 3.0\n",
      "    Params: tensor([  5.3364, -17.1273])\n",
      "    Grad: tensor([-0.0053,  0.0302])\n",
      "Epoch 2707, Loss 3.0\n",
      "    Params: tensor([  5.3364, -17.1276])\n",
      "    Grad: tensor([-0.0053,  0.0301])\n",
      "Epoch 2708, Loss 3.0\n",
      "    Params: tensor([  5.3365, -17.1279])\n",
      "    Grad: tensor([-0.0053,  0.0301])\n",
      "Epoch 2709, Loss 3.0\n",
      "    Params: tensor([  5.3365, -17.1282])\n",
      "    Grad: tensor([-0.0053,  0.0300])\n",
      "Epoch 2710, Loss 3.0\n",
      "    Params: tensor([  5.3366, -17.1285])\n",
      "    Grad: tensor([-0.0053,  0.0300])\n",
      "Epoch 2711, Loss 3.0\n",
      "    Params: tensor([  5.3366, -17.1288])\n",
      "    Grad: tensor([-0.0053,  0.0299])\n",
      "Epoch 2712, Loss 3.0\n",
      "    Params: tensor([  5.3367, -17.1291])\n",
      "    Grad: tensor([-0.0053,  0.0299])\n",
      "Epoch 2713, Loss 3.0\n",
      "    Params: tensor([  5.3367, -17.1294])\n",
      "    Grad: tensor([-0.0053,  0.0298])\n",
      "Epoch 2714, Loss 3.0\n",
      "    Params: tensor([  5.3368, -17.1297])\n",
      "    Grad: tensor([-0.0053,  0.0298])\n",
      "Epoch 2715, Loss 3.0\n",
      "    Params: tensor([  5.3368, -17.1300])\n",
      "    Grad: tensor([-0.0053,  0.0297])\n",
      "Epoch 2716, Loss 3.0\n",
      "    Params: tensor([  5.3369, -17.1303])\n",
      "    Grad: tensor([-0.0053,  0.0297])\n",
      "Epoch 2717, Loss 3.0\n",
      "    Params: tensor([  5.3369, -17.1306])\n",
      "    Grad: tensor([-0.0053,  0.0296])\n",
      "Epoch 2718, Loss 3.0\n",
      "    Params: tensor([  5.3370, -17.1309])\n",
      "    Grad: tensor([-0.0052,  0.0296])\n",
      "Epoch 2719, Loss 3.0\n",
      "    Params: tensor([  5.3371, -17.1312])\n",
      "    Grad: tensor([-0.0052,  0.0295])\n",
      "Epoch 2720, Loss 3.0\n",
      "    Params: tensor([  5.3371, -17.1315])\n",
      "    Grad: tensor([-0.0052,  0.0295])\n",
      "Epoch 2721, Loss 3.0\n",
      "    Params: tensor([  5.3372, -17.1318])\n",
      "    Grad: tensor([-0.0052,  0.0294])\n",
      "Epoch 2722, Loss 3.0\n",
      "    Params: tensor([  5.3372, -17.1321])\n",
      "    Grad: tensor([-0.0052,  0.0294])\n",
      "Epoch 2723, Loss 3.0\n",
      "    Params: tensor([  5.3373, -17.1324])\n",
      "    Grad: tensor([-0.0052,  0.0293])\n",
      "Epoch 2724, Loss 3.0\n",
      "    Params: tensor([  5.3373, -17.1327])\n",
      "    Grad: tensor([-0.0052,  0.0293])\n",
      "Epoch 2725, Loss 3.0\n",
      "    Params: tensor([  5.3374, -17.1329])\n",
      "    Grad: tensor([-0.0052,  0.0292])\n",
      "Epoch 2726, Loss 3.0\n",
      "    Params: tensor([  5.3374, -17.1332])\n",
      "    Grad: tensor([-0.0052,  0.0292])\n",
      "Epoch 2727, Loss 3.0\n",
      "    Params: tensor([  5.3375, -17.1335])\n",
      "    Grad: tensor([-0.0052,  0.0291])\n",
      "Epoch 2728, Loss 3.0\n",
      "    Params: tensor([  5.3375, -17.1338])\n",
      "    Grad: tensor([-0.0051,  0.0291])\n",
      "Epoch 2729, Loss 3.0\n",
      "    Params: tensor([  5.3376, -17.1341])\n",
      "    Grad: tensor([-0.0051,  0.0290])\n",
      "Epoch 2730, Loss 3.0\n",
      "    Params: tensor([  5.3376, -17.1344])\n",
      "    Grad: tensor([-0.0051,  0.0290])\n",
      "Epoch 2731, Loss 3.0\n",
      "    Params: tensor([  5.3377, -17.1347])\n",
      "    Grad: tensor([-0.0051,  0.0289])\n",
      "Epoch 2732, Loss 3.0\n",
      "    Params: tensor([  5.3377, -17.1350])\n",
      "    Grad: tensor([-0.0051,  0.0289])\n",
      "Epoch 2733, Loss 3.0\n",
      "    Params: tensor([  5.3378, -17.1353])\n",
      "    Grad: tensor([-0.0051,  0.0288])\n",
      "Epoch 2734, Loss 3.0\n",
      "    Params: tensor([  5.3378, -17.1356])\n",
      "    Grad: tensor([-0.0051,  0.0288])\n",
      "Epoch 2735, Loss 3.0\n",
      "    Params: tensor([  5.3379, -17.1358])\n",
      "    Grad: tensor([-0.0051,  0.0287])\n",
      "Epoch 2736, Loss 3.0\n",
      "    Params: tensor([  5.3379, -17.1361])\n",
      "    Grad: tensor([-0.0051,  0.0287])\n",
      "Epoch 2737, Loss 3.0\n",
      "    Params: tensor([  5.3380, -17.1364])\n",
      "    Grad: tensor([-0.0050,  0.0287])\n",
      "Epoch 2738, Loss 3.0\n",
      "    Params: tensor([  5.3380, -17.1367])\n",
      "    Grad: tensor([-0.0050,  0.0286])\n",
      "Epoch 2739, Loss 3.0\n",
      "    Params: tensor([  5.3381, -17.1370])\n",
      "    Grad: tensor([-0.0050,  0.0286])\n",
      "Epoch 2740, Loss 3.0\n",
      "    Params: tensor([  5.3381, -17.1373])\n",
      "    Grad: tensor([-0.0050,  0.0285])\n",
      "Epoch 2741, Loss 3.0\n",
      "    Params: tensor([  5.3382, -17.1376])\n",
      "    Grad: tensor([-0.0050,  0.0285])\n",
      "Epoch 2742, Loss 3.0\n",
      "    Params: tensor([  5.3382, -17.1378])\n",
      "    Grad: tensor([-0.0050,  0.0284])\n",
      "Epoch 2743, Loss 3.0\n",
      "    Params: tensor([  5.3383, -17.1381])\n",
      "    Grad: tensor([-0.0050,  0.0284])\n",
      "Epoch 2744, Loss 3.0\n",
      "    Params: tensor([  5.3383, -17.1384])\n",
      "    Grad: tensor([-0.0050,  0.0283])\n",
      "Epoch 2745, Loss 3.0\n",
      "    Params: tensor([  5.3384, -17.1387])\n",
      "    Grad: tensor([-0.0050,  0.0283])\n",
      "Epoch 2746, Loss 3.0\n",
      "    Params: tensor([  5.3384, -17.1390])\n",
      "    Grad: tensor([-0.0050,  0.0282])\n",
      "Epoch 2747, Loss 3.0\n",
      "    Params: tensor([  5.3385, -17.1393])\n",
      "    Grad: tensor([-0.0050,  0.0282])\n",
      "Epoch 2748, Loss 3.0\n",
      "    Params: tensor([  5.3385, -17.1395])\n",
      "    Grad: tensor([-0.0050,  0.0281])\n",
      "Epoch 2749, Loss 3.0\n",
      "    Params: tensor([  5.3386, -17.1398])\n",
      "    Grad: tensor([-0.0049,  0.0281])\n",
      "Epoch 2750, Loss 3.0\n",
      "    Params: tensor([  5.3386, -17.1401])\n",
      "    Grad: tensor([-0.0049,  0.0280])\n",
      "Epoch 2751, Loss 3.0\n",
      "    Params: tensor([  5.3387, -17.1404])\n",
      "    Grad: tensor([-0.0049,  0.0280])\n",
      "Epoch 2752, Loss 3.0\n",
      "    Params: tensor([  5.3387, -17.1407])\n",
      "    Grad: tensor([-0.0049,  0.0279])\n",
      "Epoch 2753, Loss 3.0\n",
      "    Params: tensor([  5.3388, -17.1409])\n",
      "    Grad: tensor([-0.0049,  0.0279])\n",
      "Epoch 2754, Loss 3.0\n",
      "    Params: tensor([  5.3388, -17.1412])\n",
      "    Grad: tensor([-0.0049,  0.0278])\n",
      "Epoch 2755, Loss 3.0\n",
      "    Params: tensor([  5.3389, -17.1415])\n",
      "    Grad: tensor([-0.0049,  0.0278])\n",
      "Epoch 2756, Loss 3.0\n",
      "    Params: tensor([  5.3389, -17.1418])\n",
      "    Grad: tensor([-0.0049,  0.0277])\n",
      "Epoch 2757, Loss 3.0\n",
      "    Params: tensor([  5.3390, -17.1420])\n",
      "    Grad: tensor([-0.0049,  0.0277])\n",
      "Epoch 2758, Loss 3.0\n",
      "    Params: tensor([  5.3390, -17.1423])\n",
      "    Grad: tensor([-0.0049,  0.0276])\n",
      "Epoch 2759, Loss 3.0\n",
      "    Params: tensor([  5.3391, -17.1426])\n",
      "    Grad: tensor([-0.0049,  0.0276])\n",
      "Epoch 2760, Loss 3.0\n",
      "    Params: tensor([  5.3391, -17.1429])\n",
      "    Grad: tensor([-0.0049,  0.0275])\n",
      "Epoch 2761, Loss 3.0\n",
      "    Params: tensor([  5.3392, -17.1431])\n",
      "    Grad: tensor([-0.0049,  0.0275])\n",
      "Epoch 2762, Loss 3.0\n",
      "    Params: tensor([  5.3392, -17.1434])\n",
      "    Grad: tensor([-0.0049,  0.0275])\n",
      "Epoch 2763, Loss 3.0\n",
      "    Params: tensor([  5.3393, -17.1437])\n",
      "    Grad: tensor([-0.0048,  0.0274])\n",
      "Epoch 2764, Loss 3.0\n",
      "    Params: tensor([  5.3393, -17.1440])\n",
      "    Grad: tensor([-0.0048,  0.0274])\n",
      "Epoch 2765, Loss 3.0\n",
      "    Params: tensor([  5.3394, -17.1442])\n",
      "    Grad: tensor([-0.0048,  0.0273])\n",
      "Epoch 2766, Loss 3.0\n",
      "    Params: tensor([  5.3394, -17.1445])\n",
      "    Grad: tensor([-0.0048,  0.0273])\n",
      "Epoch 2767, Loss 3.0\n",
      "    Params: tensor([  5.3395, -17.1448])\n",
      "    Grad: tensor([-0.0048,  0.0272])\n",
      "Epoch 2768, Loss 3.0\n",
      "    Params: tensor([  5.3395, -17.1451])\n",
      "    Grad: tensor([-0.0048,  0.0272])\n",
      "Epoch 2769, Loss 3.0\n",
      "    Params: tensor([  5.3396, -17.1453])\n",
      "    Grad: tensor([-0.0048,  0.0271])\n",
      "Epoch 2770, Loss 3.0\n",
      "    Params: tensor([  5.3396, -17.1456])\n",
      "    Grad: tensor([-0.0048,  0.0271])\n",
      "Epoch 2771, Loss 3.0\n",
      "    Params: tensor([  5.3396, -17.1459])\n",
      "    Grad: tensor([-0.0048,  0.0270])\n",
      "Epoch 2772, Loss 3.0\n",
      "    Params: tensor([  5.3397, -17.1461])\n",
      "    Grad: tensor([-0.0048,  0.0270])\n",
      "Epoch 2773, Loss 3.0\n",
      "    Params: tensor([  5.3397, -17.1464])\n",
      "    Grad: tensor([-0.0048,  0.0269])\n",
      "Epoch 2774, Loss 3.0\n",
      "    Params: tensor([  5.3398, -17.1467])\n",
      "    Grad: tensor([-0.0048,  0.0269])\n",
      "Epoch 2775, Loss 3.0\n",
      "    Params: tensor([  5.3398, -17.1470])\n",
      "    Grad: tensor([-0.0047,  0.0269])\n",
      "Epoch 2776, Loss 3.0\n",
      "    Params: tensor([  5.3399, -17.1472])\n",
      "    Grad: tensor([-0.0047,  0.0268])\n",
      "Epoch 2777, Loss 3.0\n",
      "    Params: tensor([  5.3399, -17.1475])\n",
      "    Grad: tensor([-0.0048,  0.0268])\n",
      "Epoch 2778, Loss 3.0\n",
      "    Params: tensor([  5.3400, -17.1478])\n",
      "    Grad: tensor([-0.0047,  0.0267])\n",
      "Epoch 2779, Loss 3.0\n",
      "    Params: tensor([  5.3400, -17.1480])\n",
      "    Grad: tensor([-0.0047,  0.0267])\n",
      "Epoch 2780, Loss 3.0\n",
      "    Params: tensor([  5.3401, -17.1483])\n",
      "    Grad: tensor([-0.0047,  0.0266])\n",
      "Epoch 2781, Loss 3.0\n",
      "    Params: tensor([  5.3401, -17.1486])\n",
      "    Grad: tensor([-0.0047,  0.0266])\n",
      "Epoch 2782, Loss 3.0\n",
      "    Params: tensor([  5.3402, -17.1488])\n",
      "    Grad: tensor([-0.0047,  0.0265])\n",
      "Epoch 2783, Loss 3.0\n",
      "    Params: tensor([  5.3402, -17.1491])\n",
      "    Grad: tensor([-0.0047,  0.0265])\n",
      "Epoch 2784, Loss 3.0\n",
      "    Params: tensor([  5.3403, -17.1493])\n",
      "    Grad: tensor([-0.0047,  0.0264])\n",
      "Epoch 2785, Loss 3.0\n",
      "    Params: tensor([  5.3403, -17.1496])\n",
      "    Grad: tensor([-0.0047,  0.0264])\n",
      "Epoch 2786, Loss 3.0\n",
      "    Params: tensor([  5.3404, -17.1499])\n",
      "    Grad: tensor([-0.0047,  0.0264])\n",
      "Epoch 2787, Loss 3.0\n",
      "    Params: tensor([  5.3404, -17.1501])\n",
      "    Grad: tensor([-0.0046,  0.0263])\n",
      "Epoch 2788, Loss 3.0\n",
      "    Params: tensor([  5.3404, -17.1504])\n",
      "    Grad: tensor([-0.0046,  0.0263])\n",
      "Epoch 2789, Loss 3.0\n",
      "    Params: tensor([  5.3405, -17.1507])\n",
      "    Grad: tensor([-0.0046,  0.0262])\n",
      "Epoch 2790, Loss 3.0\n",
      "    Params: tensor([  5.3405, -17.1509])\n",
      "    Grad: tensor([-0.0046,  0.0262])\n",
      "Epoch 2791, Loss 3.0\n",
      "    Params: tensor([  5.3406, -17.1512])\n",
      "    Grad: tensor([-0.0046,  0.0261])\n",
      "Epoch 2792, Loss 3.0\n",
      "    Params: tensor([  5.3406, -17.1514])\n",
      "    Grad: tensor([-0.0046,  0.0261])\n",
      "Epoch 2793, Loss 3.0\n",
      "    Params: tensor([  5.3407, -17.1517])\n",
      "    Grad: tensor([-0.0046,  0.0261])\n",
      "Epoch 2794, Loss 3.0\n",
      "    Params: tensor([  5.3407, -17.1520])\n",
      "    Grad: tensor([-0.0046,  0.0260])\n",
      "Epoch 2795, Loss 3.0\n",
      "    Params: tensor([  5.3408, -17.1522])\n",
      "    Grad: tensor([-0.0046,  0.0260])\n",
      "Epoch 2796, Loss 3.0\n",
      "    Params: tensor([  5.3408, -17.1525])\n",
      "    Grad: tensor([-0.0046,  0.0259])\n",
      "Epoch 2797, Loss 3.0\n",
      "    Params: tensor([  5.3409, -17.1527])\n",
      "    Grad: tensor([-0.0046,  0.0259])\n",
      "Epoch 2798, Loss 3.0\n",
      "    Params: tensor([  5.3409, -17.1530])\n",
      "    Grad: tensor([-0.0046,  0.0258])\n",
      "Epoch 2799, Loss 3.0\n",
      "    Params: tensor([  5.3410, -17.1533])\n",
      "    Grad: tensor([-0.0045,  0.0258])\n",
      "Epoch 2800, Loss 3.0\n",
      "    Params: tensor([  5.3410, -17.1535])\n",
      "    Grad: tensor([-0.0045,  0.0257])\n",
      "Epoch 2801, Loss 3.0\n",
      "    Params: tensor([  5.3410, -17.1538])\n",
      "    Grad: tensor([-0.0045,  0.0257])\n",
      "Epoch 2802, Loss 3.0\n",
      "    Params: tensor([  5.3411, -17.1540])\n",
      "    Grad: tensor([-0.0045,  0.0256])\n",
      "Epoch 2803, Loss 3.0\n",
      "    Params: tensor([  5.3411, -17.1543])\n",
      "    Grad: tensor([-0.0045,  0.0256])\n",
      "Epoch 2804, Loss 3.0\n",
      "    Params: tensor([  5.3412, -17.1545])\n",
      "    Grad: tensor([-0.0045,  0.0256])\n",
      "Epoch 2805, Loss 3.0\n",
      "    Params: tensor([  5.3412, -17.1548])\n",
      "    Grad: tensor([-0.0045,  0.0255])\n",
      "Epoch 2806, Loss 3.0\n",
      "    Params: tensor([  5.3413, -17.1551])\n",
      "    Grad: tensor([-0.0045,  0.0255])\n",
      "Epoch 2807, Loss 3.0\n",
      "    Params: tensor([  5.3413, -17.1553])\n",
      "    Grad: tensor([-0.0045,  0.0254])\n",
      "Epoch 2808, Loss 3.0\n",
      "    Params: tensor([  5.3414, -17.1556])\n",
      "    Grad: tensor([-0.0045,  0.0254])\n",
      "Epoch 2809, Loss 3.0\n",
      "    Params: tensor([  5.3414, -17.1558])\n",
      "    Grad: tensor([-0.0045,  0.0254])\n",
      "Epoch 2810, Loss 3.0\n",
      "    Params: tensor([  5.3414, -17.1561])\n",
      "    Grad: tensor([-0.0045,  0.0253])\n",
      "Epoch 2811, Loss 3.0\n",
      "    Params: tensor([  5.3415, -17.1563])\n",
      "    Grad: tensor([-0.0045,  0.0253])\n",
      "Epoch 2812, Loss 3.0\n",
      "    Params: tensor([  5.3415, -17.1566])\n",
      "    Grad: tensor([-0.0044,  0.0252])\n",
      "Epoch 2813, Loss 3.0\n",
      "    Params: tensor([  5.3416, -17.1568])\n",
      "    Grad: tensor([-0.0044,  0.0252])\n",
      "Epoch 2814, Loss 3.0\n",
      "    Params: tensor([  5.3416, -17.1571])\n",
      "    Grad: tensor([-0.0044,  0.0251])\n",
      "Epoch 2815, Loss 3.0\n",
      "    Params: tensor([  5.3417, -17.1573])\n",
      "    Grad: tensor([-0.0044,  0.0251])\n",
      "Epoch 2816, Loss 3.0\n",
      "    Params: tensor([  5.3417, -17.1576])\n",
      "    Grad: tensor([-0.0044,  0.0250])\n",
      "Epoch 2817, Loss 3.0\n",
      "    Params: tensor([  5.3418, -17.1578])\n",
      "    Grad: tensor([-0.0044,  0.0250])\n",
      "Epoch 2818, Loss 3.0\n",
      "    Params: tensor([  5.3418, -17.1581])\n",
      "    Grad: tensor([-0.0044,  0.0250])\n",
      "Epoch 2819, Loss 3.0\n",
      "    Params: tensor([  5.3418, -17.1583])\n",
      "    Grad: tensor([-0.0044,  0.0249])\n",
      "Epoch 2820, Loss 3.0\n",
      "    Params: tensor([  5.3419, -17.1586])\n",
      "    Grad: tensor([-0.0044,  0.0249])\n",
      "Epoch 2821, Loss 3.0\n",
      "    Params: tensor([  5.3419, -17.1588])\n",
      "    Grad: tensor([-0.0044,  0.0248])\n",
      "Epoch 2822, Loss 3.0\n",
      "    Params: tensor([  5.3420, -17.1591])\n",
      "    Grad: tensor([-0.0044,  0.0248])\n",
      "Epoch 2823, Loss 3.0\n",
      "    Params: tensor([  5.3420, -17.1593])\n",
      "    Grad: tensor([-0.0044,  0.0248])\n",
      "Epoch 2824, Loss 3.0\n",
      "    Params: tensor([  5.3421, -17.1596])\n",
      "    Grad: tensor([-0.0044,  0.0247])\n",
      "Epoch 2825, Loss 3.0\n",
      "    Params: tensor([  5.3421, -17.1598])\n",
      "    Grad: tensor([-0.0044,  0.0247])\n",
      "Epoch 2826, Loss 3.0\n",
      "    Params: tensor([  5.3422, -17.1601])\n",
      "    Grad: tensor([-0.0043,  0.0246])\n",
      "Epoch 2827, Loss 3.0\n",
      "    Params: tensor([  5.3422, -17.1603])\n",
      "    Grad: tensor([-0.0043,  0.0246])\n",
      "Epoch 2828, Loss 3.0\n",
      "    Params: tensor([  5.3422, -17.1606])\n",
      "    Grad: tensor([-0.0043,  0.0245])\n",
      "Epoch 2829, Loss 3.0\n",
      "    Params: tensor([  5.3423, -17.1608])\n",
      "    Grad: tensor([-0.0043,  0.0245])\n",
      "Epoch 2830, Loss 3.0\n",
      "    Params: tensor([  5.3423, -17.1610])\n",
      "    Grad: tensor([-0.0043,  0.0245])\n",
      "Epoch 2831, Loss 3.0\n",
      "    Params: tensor([  5.3424, -17.1613])\n",
      "    Grad: tensor([-0.0043,  0.0244])\n",
      "Epoch 2832, Loss 3.0\n",
      "    Params: tensor([  5.3424, -17.1615])\n",
      "    Grad: tensor([-0.0043,  0.0244])\n",
      "Epoch 2833, Loss 3.0\n",
      "    Params: tensor([  5.3425, -17.1618])\n",
      "    Grad: tensor([-0.0043,  0.0243])\n",
      "Epoch 2834, Loss 3.0\n",
      "    Params: tensor([  5.3425, -17.1620])\n",
      "    Grad: tensor([-0.0043,  0.0243])\n",
      "Epoch 2835, Loss 3.0\n",
      "    Params: tensor([  5.3425, -17.1623])\n",
      "    Grad: tensor([-0.0043,  0.0243])\n",
      "Epoch 2836, Loss 3.0\n",
      "    Params: tensor([  5.3426, -17.1625])\n",
      "    Grad: tensor([-0.0043,  0.0242])\n",
      "Epoch 2837, Loss 3.0\n",
      "    Params: tensor([  5.3426, -17.1627])\n",
      "    Grad: tensor([-0.0043,  0.0242])\n",
      "Epoch 2838, Loss 3.0\n",
      "    Params: tensor([  5.3427, -17.1630])\n",
      "    Grad: tensor([-0.0043,  0.0241])\n",
      "Epoch 2839, Loss 3.0\n",
      "    Params: tensor([  5.3427, -17.1632])\n",
      "    Grad: tensor([-0.0042,  0.0241])\n",
      "Epoch 2840, Loss 3.0\n",
      "    Params: tensor([  5.3428, -17.1635])\n",
      "    Grad: tensor([-0.0042,  0.0241])\n",
      "Epoch 2841, Loss 3.0\n",
      "    Params: tensor([  5.3428, -17.1637])\n",
      "    Grad: tensor([-0.0042,  0.0240])\n",
      "Epoch 2842, Loss 3.0\n",
      "    Params: tensor([  5.3428, -17.1639])\n",
      "    Grad: tensor([-0.0042,  0.0240])\n",
      "Epoch 2843, Loss 3.0\n",
      "    Params: tensor([  5.3429, -17.1642])\n",
      "    Grad: tensor([-0.0042,  0.0239])\n",
      "Epoch 2844, Loss 3.0\n",
      "    Params: tensor([  5.3429, -17.1644])\n",
      "    Grad: tensor([-0.0042,  0.0239])\n",
      "Epoch 2845, Loss 3.0\n",
      "    Params: tensor([  5.3430, -17.1647])\n",
      "    Grad: tensor([-0.0042,  0.0238])\n",
      "Epoch 2846, Loss 3.0\n",
      "    Params: tensor([  5.3430, -17.1649])\n",
      "    Grad: tensor([-0.0042,  0.0238])\n",
      "Epoch 2847, Loss 3.0\n",
      "    Params: tensor([  5.3430, -17.1651])\n",
      "    Grad: tensor([-0.0042,  0.0238])\n",
      "Epoch 2848, Loss 3.0\n",
      "    Params: tensor([  5.3431, -17.1654])\n",
      "    Grad: tensor([-0.0042,  0.0237])\n",
      "Epoch 2849, Loss 3.0\n",
      "    Params: tensor([  5.3431, -17.1656])\n",
      "    Grad: tensor([-0.0042,  0.0237])\n",
      "Epoch 2850, Loss 3.0\n",
      "    Params: tensor([  5.3432, -17.1658])\n",
      "    Grad: tensor([-0.0042,  0.0236])\n",
      "Epoch 2851, Loss 3.0\n",
      "    Params: tensor([  5.3432, -17.1661])\n",
      "    Grad: tensor([-0.0042,  0.0236])\n",
      "Epoch 2852, Loss 3.0\n",
      "    Params: tensor([  5.3433, -17.1663])\n",
      "    Grad: tensor([-0.0042,  0.0236])\n",
      "Epoch 2853, Loss 3.0\n",
      "    Params: tensor([  5.3433, -17.1666])\n",
      "    Grad: tensor([-0.0042,  0.0235])\n",
      "Epoch 2854, Loss 3.0\n",
      "    Params: tensor([  5.3433, -17.1668])\n",
      "    Grad: tensor([-0.0042,  0.0235])\n",
      "Epoch 2855, Loss 3.0\n",
      "    Params: tensor([  5.3434, -17.1670])\n",
      "    Grad: tensor([-0.0041,  0.0234])\n",
      "Epoch 2856, Loss 3.0\n",
      "    Params: tensor([  5.3434, -17.1673])\n",
      "    Grad: tensor([-0.0041,  0.0234])\n",
      "Epoch 2857, Loss 3.0\n",
      "    Params: tensor([  5.3435, -17.1675])\n",
      "    Grad: tensor([-0.0041,  0.0234])\n",
      "Epoch 2858, Loss 3.0\n",
      "    Params: tensor([  5.3435, -17.1677])\n",
      "    Grad: tensor([-0.0041,  0.0233])\n",
      "Epoch 2859, Loss 3.0\n",
      "    Params: tensor([  5.3435, -17.1680])\n",
      "    Grad: tensor([-0.0041,  0.0233])\n",
      "Epoch 2860, Loss 3.0\n",
      "    Params: tensor([  5.3436, -17.1682])\n",
      "    Grad: tensor([-0.0041,  0.0232])\n",
      "Epoch 2861, Loss 3.0\n",
      "    Params: tensor([  5.3436, -17.1684])\n",
      "    Grad: tensor([-0.0041,  0.0232])\n",
      "Epoch 2862, Loss 3.0\n",
      "    Params: tensor([  5.3437, -17.1686])\n",
      "    Grad: tensor([-0.0041,  0.0232])\n",
      "Epoch 2863, Loss 3.0\n",
      "    Params: tensor([  5.3437, -17.1689])\n",
      "    Grad: tensor([-0.0041,  0.0231])\n",
      "Epoch 2864, Loss 3.0\n",
      "    Params: tensor([  5.3438, -17.1691])\n",
      "    Grad: tensor([-0.0041,  0.0231])\n",
      "Epoch 2865, Loss 3.0\n",
      "    Params: tensor([  5.3438, -17.1693])\n",
      "    Grad: tensor([-0.0041,  0.0231])\n",
      "Epoch 2866, Loss 3.0\n",
      "    Params: tensor([  5.3438, -17.1696])\n",
      "    Grad: tensor([-0.0041,  0.0230])\n",
      "Epoch 2867, Loss 3.0\n",
      "    Params: tensor([  5.3439, -17.1698])\n",
      "    Grad: tensor([-0.0041,  0.0230])\n",
      "Epoch 2868, Loss 3.0\n",
      "    Params: tensor([  5.3439, -17.1700])\n",
      "    Grad: tensor([-0.0041,  0.0229])\n",
      "Epoch 2869, Loss 3.0\n",
      "    Params: tensor([  5.3440, -17.1703])\n",
      "    Grad: tensor([-0.0041,  0.0229])\n",
      "Epoch 2870, Loss 3.0\n",
      "    Params: tensor([  5.3440, -17.1705])\n",
      "    Grad: tensor([-0.0040,  0.0229])\n",
      "Epoch 2871, Loss 3.0\n",
      "    Params: tensor([  5.3440, -17.1707])\n",
      "    Grad: tensor([-0.0040,  0.0228])\n",
      "Epoch 2872, Loss 3.0\n",
      "    Params: tensor([  5.3441, -17.1709])\n",
      "    Grad: tensor([-0.0040,  0.0228])\n",
      "Epoch 2873, Loss 3.0\n",
      "    Params: tensor([  5.3441, -17.1712])\n",
      "    Grad: tensor([-0.0040,  0.0227])\n",
      "Epoch 2874, Loss 3.0\n",
      "    Params: tensor([  5.3442, -17.1714])\n",
      "    Grad: tensor([-0.0040,  0.0227])\n",
      "Epoch 2875, Loss 3.0\n",
      "    Params: tensor([  5.3442, -17.1716])\n",
      "    Grad: tensor([-0.0040,  0.0227])\n",
      "Epoch 2876, Loss 3.0\n",
      "    Params: tensor([  5.3442, -17.1719])\n",
      "    Grad: tensor([-0.0040,  0.0226])\n",
      "Epoch 2877, Loss 3.0\n",
      "    Params: tensor([  5.3443, -17.1721])\n",
      "    Grad: tensor([-0.0040,  0.0226])\n",
      "Epoch 2878, Loss 3.0\n",
      "    Params: tensor([  5.3443, -17.1723])\n",
      "    Grad: tensor([-0.0040,  0.0225])\n",
      "Epoch 2879, Loss 3.0\n",
      "    Params: tensor([  5.3444, -17.1725])\n",
      "    Grad: tensor([-0.0040,  0.0225])\n",
      "Epoch 2880, Loss 3.0\n",
      "    Params: tensor([  5.3444, -17.1728])\n",
      "    Grad: tensor([-0.0040,  0.0225])\n",
      "Epoch 2881, Loss 3.0\n",
      "    Params: tensor([  5.3444, -17.1730])\n",
      "    Grad: tensor([-0.0040,  0.0224])\n",
      "Epoch 2882, Loss 3.0\n",
      "    Params: tensor([  5.3445, -17.1732])\n",
      "    Grad: tensor([-0.0040,  0.0224])\n",
      "Epoch 2883, Loss 3.0\n",
      "    Params: tensor([  5.3445, -17.1734])\n",
      "    Grad: tensor([-0.0039,  0.0224])\n",
      "Epoch 2884, Loss 3.0\n",
      "    Params: tensor([  5.3446, -17.1736])\n",
      "    Grad: tensor([-0.0039,  0.0223])\n",
      "Epoch 2885, Loss 3.0\n",
      "    Params: tensor([  5.3446, -17.1739])\n",
      "    Grad: tensor([-0.0039,  0.0223])\n",
      "Epoch 2886, Loss 3.0\n",
      "    Params: tensor([  5.3446, -17.1741])\n",
      "    Grad: tensor([-0.0039,  0.0222])\n",
      "Epoch 2887, Loss 3.0\n",
      "    Params: tensor([  5.3447, -17.1743])\n",
      "    Grad: tensor([-0.0039,  0.0222])\n",
      "Epoch 2888, Loss 3.0\n",
      "    Params: tensor([  5.3447, -17.1745])\n",
      "    Grad: tensor([-0.0039,  0.0222])\n",
      "Epoch 2889, Loss 3.0\n",
      "    Params: tensor([  5.3447, -17.1748])\n",
      "    Grad: tensor([-0.0039,  0.0221])\n",
      "Epoch 2890, Loss 3.0\n",
      "    Params: tensor([  5.3448, -17.1750])\n",
      "    Grad: tensor([-0.0039,  0.0221])\n",
      "Epoch 2891, Loss 3.0\n",
      "    Params: tensor([  5.3448, -17.1752])\n",
      "    Grad: tensor([-0.0039,  0.0221])\n",
      "Epoch 2892, Loss 3.0\n",
      "    Params: tensor([  5.3449, -17.1754])\n",
      "    Grad: tensor([-0.0039,  0.0220])\n",
      "Epoch 2893, Loss 3.0\n",
      "    Params: tensor([  5.3449, -17.1756])\n",
      "    Grad: tensor([-0.0039,  0.0220])\n",
      "Epoch 2894, Loss 3.0\n",
      "    Params: tensor([  5.3449, -17.1759])\n",
      "    Grad: tensor([-0.0039,  0.0219])\n",
      "Epoch 2895, Loss 3.0\n",
      "    Params: tensor([  5.3450, -17.1761])\n",
      "    Grad: tensor([-0.0039,  0.0219])\n",
      "Epoch 2896, Loss 3.0\n",
      "    Params: tensor([  5.3450, -17.1763])\n",
      "    Grad: tensor([-0.0039,  0.0219])\n",
      "Epoch 2897, Loss 3.0\n",
      "    Params: tensor([  5.3451, -17.1765])\n",
      "    Grad: tensor([-0.0039,  0.0218])\n",
      "Epoch 2898, Loss 3.0\n",
      "    Params: tensor([  5.3451, -17.1767])\n",
      "    Grad: tensor([-0.0038,  0.0218])\n",
      "Epoch 2899, Loss 3.0\n",
      "    Params: tensor([  5.3451, -17.1769])\n",
      "    Grad: tensor([-0.0038,  0.0218])\n",
      "Epoch 2900, Loss 3.0\n",
      "    Params: tensor([  5.3452, -17.1772])\n",
      "    Grad: tensor([-0.0038,  0.0217])\n",
      "Epoch 2901, Loss 3.0\n",
      "    Params: tensor([  5.3452, -17.1774])\n",
      "    Grad: tensor([-0.0038,  0.0217])\n",
      "Epoch 2902, Loss 3.0\n",
      "    Params: tensor([  5.3453, -17.1776])\n",
      "    Grad: tensor([-0.0038,  0.0216])\n",
      "Epoch 2903, Loss 3.0\n",
      "    Params: tensor([  5.3453, -17.1778])\n",
      "    Grad: tensor([-0.0038,  0.0216])\n",
      "Epoch 2904, Loss 3.0\n",
      "    Params: tensor([  5.3453, -17.1780])\n",
      "    Grad: tensor([-0.0038,  0.0216])\n",
      "Epoch 2905, Loss 3.0\n",
      "    Params: tensor([  5.3454, -17.1782])\n",
      "    Grad: tensor([-0.0038,  0.0215])\n",
      "Epoch 2906, Loss 3.0\n",
      "    Params: tensor([  5.3454, -17.1785])\n",
      "    Grad: tensor([-0.0038,  0.0215])\n",
      "Epoch 2907, Loss 3.0\n",
      "    Params: tensor([  5.3454, -17.1787])\n",
      "    Grad: tensor([-0.0038,  0.0215])\n",
      "Epoch 2908, Loss 3.0\n",
      "    Params: tensor([  5.3455, -17.1789])\n",
      "    Grad: tensor([-0.0038,  0.0214])\n",
      "Epoch 2909, Loss 3.0\n",
      "    Params: tensor([  5.3455, -17.1791])\n",
      "    Grad: tensor([-0.0038,  0.0214])\n",
      "Epoch 2910, Loss 3.0\n",
      "    Params: tensor([  5.3456, -17.1793])\n",
      "    Grad: tensor([-0.0038,  0.0214])\n",
      "Epoch 2911, Loss 3.0\n",
      "    Params: tensor([  5.3456, -17.1795])\n",
      "    Grad: tensor([-0.0038,  0.0213])\n",
      "Epoch 2912, Loss 3.0\n",
      "    Params: tensor([  5.3456, -17.1797])\n",
      "    Grad: tensor([-0.0038,  0.0213])\n",
      "Epoch 2913, Loss 3.0\n",
      "    Params: tensor([  5.3457, -17.1800])\n",
      "    Grad: tensor([-0.0038,  0.0212])\n",
      "Epoch 2914, Loss 3.0\n",
      "    Params: tensor([  5.3457, -17.1802])\n",
      "    Grad: tensor([-0.0037,  0.0212])\n",
      "Epoch 2915, Loss 3.0\n",
      "    Params: tensor([  5.3457, -17.1804])\n",
      "    Grad: tensor([-0.0037,  0.0212])\n",
      "Epoch 2916, Loss 3.0\n",
      "    Params: tensor([  5.3458, -17.1806])\n",
      "    Grad: tensor([-0.0038,  0.0211])\n",
      "Epoch 2917, Loss 3.0\n",
      "    Params: tensor([  5.3458, -17.1808])\n",
      "    Grad: tensor([-0.0037,  0.0211])\n",
      "Epoch 2918, Loss 3.0\n",
      "    Params: tensor([  5.3459, -17.1810])\n",
      "    Grad: tensor([-0.0037,  0.0211])\n",
      "Epoch 2919, Loss 3.0\n",
      "    Params: tensor([  5.3459, -17.1812])\n",
      "    Grad: tensor([-0.0037,  0.0210])\n",
      "Epoch 2920, Loss 3.0\n",
      "    Params: tensor([  5.3459, -17.1814])\n",
      "    Grad: tensor([-0.0037,  0.0210])\n",
      "Epoch 2921, Loss 3.0\n",
      "    Params: tensor([  5.3460, -17.1816])\n",
      "    Grad: tensor([-0.0037,  0.0210])\n",
      "Epoch 2922, Loss 3.0\n",
      "    Params: tensor([  5.3460, -17.1819])\n",
      "    Grad: tensor([-0.0037,  0.0209])\n",
      "Epoch 2923, Loss 3.0\n",
      "    Params: tensor([  5.3460, -17.1821])\n",
      "    Grad: tensor([-0.0037,  0.0209])\n",
      "Epoch 2924, Loss 3.0\n",
      "    Params: tensor([  5.3461, -17.1823])\n",
      "    Grad: tensor([-0.0037,  0.0208])\n",
      "Epoch 2925, Loss 3.0\n",
      "    Params: tensor([  5.3461, -17.1825])\n",
      "    Grad: tensor([-0.0037,  0.0208])\n",
      "Epoch 2926, Loss 3.0\n",
      "    Params: tensor([  5.3461, -17.1827])\n",
      "    Grad: tensor([-0.0037,  0.0208])\n",
      "Epoch 2927, Loss 3.0\n",
      "    Params: tensor([  5.3462, -17.1829])\n",
      "    Grad: tensor([-0.0037,  0.0207])\n",
      "Epoch 2928, Loss 3.0\n",
      "    Params: tensor([  5.3462, -17.1831])\n",
      "    Grad: tensor([-0.0037,  0.0207])\n",
      "Epoch 2929, Loss 3.0\n",
      "    Params: tensor([  5.3463, -17.1833])\n",
      "    Grad: tensor([-0.0037,  0.0207])\n",
      "Epoch 2930, Loss 3.0\n",
      "    Params: tensor([  5.3463, -17.1835])\n",
      "    Grad: tensor([-0.0036,  0.0206])\n",
      "Epoch 2931, Loss 3.0\n",
      "    Params: tensor([  5.3463, -17.1837])\n",
      "    Grad: tensor([-0.0036,  0.0206])\n",
      "Epoch 2932, Loss 3.0\n",
      "    Params: tensor([  5.3464, -17.1839])\n",
      "    Grad: tensor([-0.0036,  0.0206])\n",
      "Epoch 2933, Loss 3.0\n",
      "    Params: tensor([  5.3464, -17.1841])\n",
      "    Grad: tensor([-0.0036,  0.0205])\n",
      "Epoch 2934, Loss 3.0\n",
      "    Params: tensor([  5.3464, -17.1843])\n",
      "    Grad: tensor([-0.0036,  0.0205])\n",
      "Epoch 2935, Loss 3.0\n",
      "    Params: tensor([  5.3465, -17.1845])\n",
      "    Grad: tensor([-0.0036,  0.0205])\n",
      "Epoch 2936, Loss 3.0\n",
      "    Params: tensor([  5.3465, -17.1847])\n",
      "    Grad: tensor([-0.0036,  0.0204])\n",
      "Epoch 2937, Loss 3.0\n",
      "    Params: tensor([  5.3465, -17.1849])\n",
      "    Grad: tensor([-0.0036,  0.0204])\n",
      "Epoch 2938, Loss 3.0\n",
      "    Params: tensor([  5.3466, -17.1851])\n",
      "    Grad: tensor([-0.0036,  0.0204])\n",
      "Epoch 2939, Loss 3.0\n",
      "    Params: tensor([  5.3466, -17.1854])\n",
      "    Grad: tensor([-0.0036,  0.0203])\n",
      "Epoch 2940, Loss 3.0\n",
      "    Params: tensor([  5.3467, -17.1856])\n",
      "    Grad: tensor([-0.0036,  0.0203])\n",
      "Epoch 2941, Loss 3.0\n",
      "    Params: tensor([  5.3467, -17.1858])\n",
      "    Grad: tensor([-0.0036,  0.0203])\n",
      "Epoch 2942, Loss 3.0\n",
      "    Params: tensor([  5.3467, -17.1860])\n",
      "    Grad: tensor([-0.0036,  0.0202])\n",
      "Epoch 2943, Loss 3.0\n",
      "    Params: tensor([  5.3468, -17.1862])\n",
      "    Grad: tensor([-0.0036,  0.0202])\n",
      "Epoch 2944, Loss 3.0\n",
      "    Params: tensor([  5.3468, -17.1864])\n",
      "    Grad: tensor([-0.0036,  0.0202])\n",
      "Epoch 2945, Loss 3.0\n",
      "    Params: tensor([  5.3468, -17.1866])\n",
      "    Grad: tensor([-0.0035,  0.0201])\n",
      "Epoch 2946, Loss 3.0\n",
      "    Params: tensor([  5.3469, -17.1868])\n",
      "    Grad: tensor([-0.0036,  0.0201])\n",
      "Epoch 2947, Loss 3.0\n",
      "    Params: tensor([  5.3469, -17.1870])\n",
      "    Grad: tensor([-0.0035,  0.0201])\n",
      "Epoch 2948, Loss 3.0\n",
      "    Params: tensor([  5.3469, -17.1872])\n",
      "    Grad: tensor([-0.0035,  0.0200])\n",
      "Epoch 2949, Loss 3.0\n",
      "    Params: tensor([  5.3470, -17.1874])\n",
      "    Grad: tensor([-0.0035,  0.0200])\n",
      "Epoch 2950, Loss 3.0\n",
      "    Params: tensor([  5.3470, -17.1876])\n",
      "    Grad: tensor([-0.0035,  0.0199])\n",
      "Epoch 2951, Loss 3.0\n",
      "    Params: tensor([  5.3470, -17.1878])\n",
      "    Grad: tensor([-0.0035,  0.0199])\n",
      "Epoch 2952, Loss 3.0\n",
      "    Params: tensor([  5.3471, -17.1880])\n",
      "    Grad: tensor([-0.0035,  0.0199])\n",
      "Epoch 2953, Loss 3.0\n",
      "    Params: tensor([  5.3471, -17.1882])\n",
      "    Grad: tensor([-0.0035,  0.0198])\n",
      "Epoch 2954, Loss 3.0\n",
      "    Params: tensor([  5.3472, -17.1884])\n",
      "    Grad: tensor([-0.0035,  0.0198])\n",
      "Epoch 2955, Loss 3.0\n",
      "    Params: tensor([  5.3472, -17.1886])\n",
      "    Grad: tensor([-0.0035,  0.0198])\n",
      "Epoch 2956, Loss 3.0\n",
      "    Params: tensor([  5.3472, -17.1888])\n",
      "    Grad: tensor([-0.0035,  0.0197])\n",
      "Epoch 2957, Loss 3.0\n",
      "    Params: tensor([  5.3473, -17.1890])\n",
      "    Grad: tensor([-0.0035,  0.0197])\n",
      "Epoch 2958, Loss 3.0\n",
      "    Params: tensor([  5.3473, -17.1891])\n",
      "    Grad: tensor([-0.0035,  0.0197])\n",
      "Epoch 2959, Loss 3.0\n",
      "    Params: tensor([  5.3473, -17.1893])\n",
      "    Grad: tensor([-0.0035,  0.0196])\n",
      "Epoch 2960, Loss 3.0\n",
      "    Params: tensor([  5.3474, -17.1895])\n",
      "    Grad: tensor([-0.0034,  0.0196])\n",
      "Epoch 2961, Loss 3.0\n",
      "    Params: tensor([  5.3474, -17.1897])\n",
      "    Grad: tensor([-0.0035,  0.0196])\n",
      "Epoch 2962, Loss 3.0\n",
      "    Params: tensor([  5.3474, -17.1899])\n",
      "    Grad: tensor([-0.0035,  0.0195])\n",
      "Epoch 2963, Loss 3.0\n",
      "    Params: tensor([  5.3475, -17.1901])\n",
      "    Grad: tensor([-0.0034,  0.0195])\n",
      "Epoch 2964, Loss 3.0\n",
      "    Params: tensor([  5.3475, -17.1903])\n",
      "    Grad: tensor([-0.0034,  0.0195])\n",
      "Epoch 2965, Loss 3.0\n",
      "    Params: tensor([  5.3475, -17.1905])\n",
      "    Grad: tensor([-0.0034,  0.0194])\n",
      "Epoch 2966, Loss 3.0\n",
      "    Params: tensor([  5.3476, -17.1907])\n",
      "    Grad: tensor([-0.0034,  0.0194])\n",
      "Epoch 2967, Loss 3.0\n",
      "    Params: tensor([  5.3476, -17.1909])\n",
      "    Grad: tensor([-0.0034,  0.0194])\n",
      "Epoch 2968, Loss 3.0\n",
      "    Params: tensor([  5.3476, -17.1911])\n",
      "    Grad: tensor([-0.0034,  0.0193])\n",
      "Epoch 2969, Loss 3.0\n",
      "    Params: tensor([  5.3477, -17.1913])\n",
      "    Grad: tensor([-0.0034,  0.0193])\n",
      "Epoch 2970, Loss 3.0\n",
      "    Params: tensor([  5.3477, -17.1915])\n",
      "    Grad: tensor([-0.0034,  0.0193])\n",
      "Epoch 2971, Loss 3.0\n",
      "    Params: tensor([  5.3477, -17.1917])\n",
      "    Grad: tensor([-0.0034,  0.0193])\n",
      "Epoch 2972, Loss 3.0\n",
      "    Params: tensor([  5.3478, -17.1919])\n",
      "    Grad: tensor([-0.0034,  0.0192])\n",
      "Epoch 2973, Loss 3.0\n",
      "    Params: tensor([  5.3478, -17.1921])\n",
      "    Grad: tensor([-0.0034,  0.0192])\n",
      "Epoch 2974, Loss 3.0\n",
      "    Params: tensor([  5.3478, -17.1923])\n",
      "    Grad: tensor([-0.0034,  0.0191])\n",
      "Epoch 2975, Loss 3.0\n",
      "    Params: tensor([  5.3479, -17.1924])\n",
      "    Grad: tensor([-0.0034,  0.0191])\n",
      "Epoch 2976, Loss 3.0\n",
      "    Params: tensor([  5.3479, -17.1926])\n",
      "    Grad: tensor([-0.0034,  0.0191])\n",
      "Epoch 2977, Loss 3.0\n",
      "    Params: tensor([  5.3479, -17.1928])\n",
      "    Grad: tensor([-0.0034,  0.0191])\n",
      "Epoch 2978, Loss 3.0\n",
      "    Params: tensor([  5.3480, -17.1930])\n",
      "    Grad: tensor([-0.0034,  0.0190])\n",
      "Epoch 2979, Loss 3.0\n",
      "    Params: tensor([  5.3480, -17.1932])\n",
      "    Grad: tensor([-0.0034,  0.0190])\n",
      "Epoch 2980, Loss 3.0\n",
      "    Params: tensor([  5.3480, -17.1934])\n",
      "    Grad: tensor([-0.0034,  0.0190])\n",
      "Epoch 2981, Loss 3.0\n",
      "    Params: tensor([  5.3481, -17.1936])\n",
      "    Grad: tensor([-0.0033,  0.0189])\n",
      "Epoch 2982, Loss 3.0\n",
      "    Params: tensor([  5.3481, -17.1938])\n",
      "    Grad: tensor([-0.0033,  0.0189])\n",
      "Epoch 2983, Loss 3.0\n",
      "    Params: tensor([  5.3481, -17.1940])\n",
      "    Grad: tensor([-0.0033,  0.0189])\n",
      "Epoch 2984, Loss 3.0\n",
      "    Params: tensor([  5.3482, -17.1941])\n",
      "    Grad: tensor([-0.0033,  0.0188])\n",
      "Epoch 2985, Loss 3.0\n",
      "    Params: tensor([  5.3482, -17.1943])\n",
      "    Grad: tensor([-0.0033,  0.0188])\n",
      "Epoch 2986, Loss 3.0\n",
      "    Params: tensor([  5.3482, -17.1945])\n",
      "    Grad: tensor([-0.0033,  0.0188])\n",
      "Epoch 2987, Loss 3.0\n",
      "    Params: tensor([  5.3483, -17.1947])\n",
      "    Grad: tensor([-0.0033,  0.0187])\n",
      "Epoch 2988, Loss 3.0\n",
      "    Params: tensor([  5.3483, -17.1949])\n",
      "    Grad: tensor([-0.0033,  0.0187])\n",
      "Epoch 2989, Loss 3.0\n",
      "    Params: tensor([  5.3483, -17.1951])\n",
      "    Grad: tensor([-0.0033,  0.0187])\n",
      "Epoch 2990, Loss 3.0\n",
      "    Params: tensor([  5.3484, -17.1953])\n",
      "    Grad: tensor([-0.0033,  0.0186])\n",
      "Epoch 2991, Loss 3.0\n",
      "    Params: tensor([  5.3484, -17.1955])\n",
      "    Grad: tensor([-0.0033,  0.0186])\n",
      "Epoch 2992, Loss 3.0\n",
      "    Params: tensor([  5.3484, -17.1956])\n",
      "    Grad: tensor([-0.0033,  0.0186])\n",
      "Epoch 2993, Loss 3.0\n",
      "    Params: tensor([  5.3485, -17.1958])\n",
      "    Grad: tensor([-0.0033,  0.0185])\n",
      "Epoch 2994, Loss 3.0\n",
      "    Params: tensor([  5.3485, -17.1960])\n",
      "    Grad: tensor([-0.0033,  0.0185])\n",
      "Epoch 2995, Loss 3.0\n",
      "    Params: tensor([  5.3485, -17.1962])\n",
      "    Grad: tensor([-0.0032,  0.0185])\n",
      "Epoch 2996, Loss 3.0\n",
      "    Params: tensor([  5.3486, -17.1964])\n",
      "    Grad: tensor([-0.0033,  0.0184])\n",
      "Epoch 2997, Loss 3.0\n",
      "    Params: tensor([  5.3486, -17.1966])\n",
      "    Grad: tensor([-0.0033,  0.0184])\n",
      "Epoch 2998, Loss 3.0\n",
      "    Params: tensor([  5.3486, -17.1968])\n",
      "    Grad: tensor([-0.0033,  0.0184])\n",
      "Epoch 2999, Loss 3.0\n",
      "    Params: tensor([  5.3487, -17.1969])\n",
      "    Grad: tensor([-0.0032,  0.0184])\n",
      "Epoch 3000, Loss 3.0\n",
      "    Params: tensor([  5.3487, -17.1971])\n",
      "    Grad: tensor([-0.0032,  0.0183])\n",
      "Epoch 3001, Loss 3.0\n",
      "    Params: tensor([  5.3487, -17.1973])\n",
      "    Grad: tensor([-0.0032,  0.0183])\n",
      "Epoch 3002, Loss 3.0\n",
      "    Params: tensor([  5.3488, -17.1975])\n",
      "    Grad: tensor([-0.0032,  0.0183])\n",
      "Epoch 3003, Loss 3.0\n",
      "    Params: tensor([  5.3488, -17.1977])\n",
      "    Grad: tensor([-0.0032,  0.0182])\n",
      "Epoch 3004, Loss 3.0\n",
      "    Params: tensor([  5.3488, -17.1978])\n",
      "    Grad: tensor([-0.0032,  0.0182])\n",
      "Epoch 3005, Loss 3.0\n",
      "    Params: tensor([  5.3489, -17.1980])\n",
      "    Grad: tensor([-0.0032,  0.0182])\n",
      "Epoch 3006, Loss 3.0\n",
      "    Params: tensor([  5.3489, -17.1982])\n",
      "    Grad: tensor([-0.0032,  0.0181])\n",
      "Epoch 3007, Loss 3.0\n",
      "    Params: tensor([  5.3489, -17.1984])\n",
      "    Grad: tensor([-0.0032,  0.0181])\n",
      "Epoch 3008, Loss 3.0\n",
      "    Params: tensor([  5.3490, -17.1986])\n",
      "    Grad: tensor([-0.0032,  0.0181])\n",
      "Epoch 3009, Loss 3.0\n",
      "    Params: tensor([  5.3490, -17.1988])\n",
      "    Grad: tensor([-0.0032,  0.0180])\n",
      "Epoch 3010, Loss 3.0\n",
      "    Params: tensor([  5.3490, -17.1989])\n",
      "    Grad: tensor([-0.0032,  0.0180])\n",
      "Epoch 3011, Loss 3.0\n",
      "    Params: tensor([  5.3491, -17.1991])\n",
      "    Grad: tensor([-0.0032,  0.0180])\n",
      "Epoch 3012, Loss 3.0\n",
      "    Params: tensor([  5.3491, -17.1993])\n",
      "    Grad: tensor([-0.0032,  0.0180])\n",
      "Epoch 3013, Loss 3.0\n",
      "    Params: tensor([  5.3491, -17.1995])\n",
      "    Grad: tensor([-0.0032,  0.0179])\n",
      "Epoch 3014, Loss 3.0\n",
      "    Params: tensor([  5.3491, -17.1997])\n",
      "    Grad: tensor([-0.0032,  0.0179])\n",
      "Epoch 3015, Loss 3.0\n",
      "    Params: tensor([  5.3492, -17.1998])\n",
      "    Grad: tensor([-0.0032,  0.0179])\n",
      "Epoch 3016, Loss 3.0\n",
      "    Params: tensor([  5.3492, -17.2000])\n",
      "    Grad: tensor([-0.0032,  0.0178])\n",
      "Epoch 3017, Loss 3.0\n",
      "    Params: tensor([  5.3492, -17.2002])\n",
      "    Grad: tensor([-0.0031,  0.0178])\n",
      "Epoch 3018, Loss 3.0\n",
      "    Params: tensor([  5.3493, -17.2004])\n",
      "    Grad: tensor([-0.0031,  0.0178])\n",
      "Epoch 3019, Loss 3.0\n",
      "    Params: tensor([  5.3493, -17.2005])\n",
      "    Grad: tensor([-0.0031,  0.0177])\n",
      "Epoch 3020, Loss 3.0\n",
      "    Params: tensor([  5.3493, -17.2007])\n",
      "    Grad: tensor([-0.0031,  0.0177])\n",
      "Epoch 3021, Loss 3.0\n",
      "    Params: tensor([  5.3494, -17.2009])\n",
      "    Grad: tensor([-0.0031,  0.0177])\n",
      "Epoch 3022, Loss 3.0\n",
      "    Params: tensor([  5.3494, -17.2011])\n",
      "    Grad: tensor([-0.0031,  0.0176])\n",
      "Epoch 3023, Loss 3.0\n",
      "    Params: tensor([  5.3494, -17.2012])\n",
      "    Grad: tensor([-0.0031,  0.0176])\n",
      "Epoch 3024, Loss 3.0\n",
      "    Params: tensor([  5.3495, -17.2014])\n",
      "    Grad: tensor([-0.0031,  0.0176])\n",
      "Epoch 3025, Loss 3.0\n",
      "    Params: tensor([  5.3495, -17.2016])\n",
      "    Grad: tensor([-0.0031,  0.0176])\n",
      "Epoch 3026, Loss 3.0\n",
      "    Params: tensor([  5.3495, -17.2018])\n",
      "    Grad: tensor([-0.0031,  0.0175])\n",
      "Epoch 3027, Loss 3.0\n",
      "    Params: tensor([  5.3496, -17.2020])\n",
      "    Grad: tensor([-0.0031,  0.0175])\n",
      "Epoch 3028, Loss 3.0\n",
      "    Params: tensor([  5.3496, -17.2021])\n",
      "    Grad: tensor([-0.0031,  0.0175])\n",
      "Epoch 3029, Loss 3.0\n",
      "    Params: tensor([  5.3496, -17.2023])\n",
      "    Grad: tensor([-0.0031,  0.0174])\n",
      "Epoch 3030, Loss 3.0\n",
      "    Params: tensor([  5.3496, -17.2025])\n",
      "    Grad: tensor([-0.0031,  0.0174])\n",
      "Epoch 3031, Loss 3.0\n",
      "    Params: tensor([  5.3497, -17.2026])\n",
      "    Grad: tensor([-0.0031,  0.0174])\n",
      "Epoch 3032, Loss 3.0\n",
      "    Params: tensor([  5.3497, -17.2028])\n",
      "    Grad: tensor([-0.0031,  0.0173])\n",
      "Epoch 3033, Loss 3.0\n",
      "    Params: tensor([  5.3497, -17.2030])\n",
      "    Grad: tensor([-0.0031,  0.0173])\n",
      "Epoch 3034, Loss 3.0\n",
      "    Params: tensor([  5.3498, -17.2032])\n",
      "    Grad: tensor([-0.0031,  0.0173])\n",
      "Epoch 3035, Loss 3.0\n",
      "    Params: tensor([  5.3498, -17.2033])\n",
      "    Grad: tensor([-0.0031,  0.0173])\n",
      "Epoch 3036, Loss 3.0\n",
      "    Params: tensor([  5.3498, -17.2035])\n",
      "    Grad: tensor([-0.0031,  0.0172])\n",
      "Epoch 3037, Loss 3.0\n",
      "    Params: tensor([  5.3499, -17.2037])\n",
      "    Grad: tensor([-0.0030,  0.0172])\n",
      "Epoch 3038, Loss 3.0\n",
      "    Params: tensor([  5.3499, -17.2039])\n",
      "    Grad: tensor([-0.0030,  0.0172])\n",
      "Epoch 3039, Loss 3.0\n",
      "    Params: tensor([  5.3499, -17.2040])\n",
      "    Grad: tensor([-0.0030,  0.0171])\n",
      "Epoch 3040, Loss 3.0\n",
      "    Params: tensor([  5.3499, -17.2042])\n",
      "    Grad: tensor([-0.0030,  0.0171])\n",
      "Epoch 3041, Loss 3.0\n",
      "    Params: tensor([  5.3500, -17.2044])\n",
      "    Grad: tensor([-0.0030,  0.0171])\n",
      "Epoch 3042, Loss 3.0\n",
      "    Params: tensor([  5.3500, -17.2045])\n",
      "    Grad: tensor([-0.0030,  0.0171])\n",
      "Epoch 3043, Loss 3.0\n",
      "    Params: tensor([  5.3500, -17.2047])\n",
      "    Grad: tensor([-0.0030,  0.0170])\n",
      "Epoch 3044, Loss 3.0\n",
      "    Params: tensor([  5.3501, -17.2049])\n",
      "    Grad: tensor([-0.0030,  0.0170])\n",
      "Epoch 3045, Loss 3.0\n",
      "    Params: tensor([  5.3501, -17.2050])\n",
      "    Grad: tensor([-0.0030,  0.0170])\n",
      "Epoch 3046, Loss 3.0\n",
      "    Params: tensor([  5.3501, -17.2052])\n",
      "    Grad: tensor([-0.0030,  0.0169])\n",
      "Epoch 3047, Loss 3.0\n",
      "    Params: tensor([  5.3502, -17.2054])\n",
      "    Grad: tensor([-0.0030,  0.0169])\n",
      "Epoch 3048, Loss 3.0\n",
      "    Params: tensor([  5.3502, -17.2056])\n",
      "    Grad: tensor([-0.0030,  0.0169])\n",
      "Epoch 3049, Loss 3.0\n",
      "    Params: tensor([  5.3502, -17.2057])\n",
      "    Grad: tensor([-0.0030,  0.0169])\n",
      "Epoch 3050, Loss 3.0\n",
      "    Params: tensor([  5.3502, -17.2059])\n",
      "    Grad: tensor([-0.0030,  0.0168])\n",
      "Epoch 3051, Loss 3.0\n",
      "    Params: tensor([  5.3503, -17.2061])\n",
      "    Grad: tensor([-0.0030,  0.0168])\n",
      "Epoch 3052, Loss 3.0\n",
      "    Params: tensor([  5.3503, -17.2062])\n",
      "    Grad: tensor([-0.0030,  0.0168])\n",
      "Epoch 3053, Loss 3.0\n",
      "    Params: tensor([  5.3503, -17.2064])\n",
      "    Grad: tensor([-0.0030,  0.0167])\n",
      "Epoch 3054, Loss 3.0\n",
      "    Params: tensor([  5.3504, -17.2066])\n",
      "    Grad: tensor([-0.0030,  0.0167])\n",
      "Epoch 3055, Loss 3.0\n",
      "    Params: tensor([  5.3504, -17.2067])\n",
      "    Grad: tensor([-0.0030,  0.0167])\n",
      "Epoch 3056, Loss 3.0\n",
      "    Params: tensor([  5.3504, -17.2069])\n",
      "    Grad: tensor([-0.0029,  0.0167])\n",
      "Epoch 3057, Loss 3.0\n",
      "    Params: tensor([  5.3505, -17.2071])\n",
      "    Grad: tensor([-0.0029,  0.0166])\n",
      "Epoch 3058, Loss 3.0\n",
      "    Params: tensor([  5.3505, -17.2072])\n",
      "    Grad: tensor([-0.0029,  0.0166])\n",
      "Epoch 3059, Loss 3.0\n",
      "    Params: tensor([  5.3505, -17.2074])\n",
      "    Grad: tensor([-0.0029,  0.0166])\n",
      "Epoch 3060, Loss 3.0\n",
      "    Params: tensor([  5.3505, -17.2076])\n",
      "    Grad: tensor([-0.0029,  0.0165])\n",
      "Epoch 3061, Loss 3.0\n",
      "    Params: tensor([  5.3506, -17.2077])\n",
      "    Grad: tensor([-0.0029,  0.0165])\n",
      "Epoch 3062, Loss 3.0\n",
      "    Params: tensor([  5.3506, -17.2079])\n",
      "    Grad: tensor([-0.0029,  0.0165])\n",
      "Epoch 3063, Loss 3.0\n",
      "    Params: tensor([  5.3506, -17.2081])\n",
      "    Grad: tensor([-0.0029,  0.0165])\n",
      "Epoch 3064, Loss 3.0\n",
      "    Params: tensor([  5.3507, -17.2082])\n",
      "    Grad: tensor([-0.0029,  0.0164])\n",
      "Epoch 3065, Loss 3.0\n",
      "    Params: tensor([  5.3507, -17.2084])\n",
      "    Grad: tensor([-0.0029,  0.0164])\n",
      "Epoch 3066, Loss 3.0\n",
      "    Params: tensor([  5.3507, -17.2085])\n",
      "    Grad: tensor([-0.0029,  0.0164])\n",
      "Epoch 3067, Loss 3.0\n",
      "    Params: tensor([  5.3507, -17.2087])\n",
      "    Grad: tensor([-0.0029,  0.0164])\n",
      "Epoch 3068, Loss 3.0\n",
      "    Params: tensor([  5.3508, -17.2089])\n",
      "    Grad: tensor([-0.0029,  0.0163])\n",
      "Epoch 3069, Loss 3.0\n",
      "    Params: tensor([  5.3508, -17.2090])\n",
      "    Grad: tensor([-0.0029,  0.0163])\n",
      "Epoch 3070, Loss 3.0\n",
      "    Params: tensor([  5.3508, -17.2092])\n",
      "    Grad: tensor([-0.0029,  0.0163])\n",
      "Epoch 3071, Loss 3.0\n",
      "    Params: tensor([  5.3509, -17.2094])\n",
      "    Grad: tensor([-0.0029,  0.0162])\n",
      "Epoch 3072, Loss 3.0\n",
      "    Params: tensor([  5.3509, -17.2095])\n",
      "    Grad: tensor([-0.0029,  0.0162])\n",
      "Epoch 3073, Loss 3.0\n",
      "    Params: tensor([  5.3509, -17.2097])\n",
      "    Grad: tensor([-0.0029,  0.0162])\n",
      "Epoch 3074, Loss 3.0\n",
      "    Params: tensor([  5.3509, -17.2098])\n",
      "    Grad: tensor([-0.0029,  0.0162])\n",
      "Epoch 3075, Loss 3.0\n",
      "    Params: tensor([  5.3510, -17.2100])\n",
      "    Grad: tensor([-0.0029,  0.0161])\n",
      "Epoch 3076, Loss 3.0\n",
      "    Params: tensor([  5.3510, -17.2102])\n",
      "    Grad: tensor([-0.0029,  0.0161])\n",
      "Epoch 3077, Loss 3.0\n",
      "    Params: tensor([  5.3510, -17.2103])\n",
      "    Grad: tensor([-0.0028,  0.0161])\n",
      "Epoch 3078, Loss 3.0\n",
      "    Params: tensor([  5.3511, -17.2105])\n",
      "    Grad: tensor([-0.0028,  0.0160])\n",
      "Epoch 3079, Loss 3.0\n",
      "    Params: tensor([  5.3511, -17.2107])\n",
      "    Grad: tensor([-0.0028,  0.0160])\n",
      "Epoch 3080, Loss 3.0\n",
      "    Params: tensor([  5.3511, -17.2108])\n",
      "    Grad: tensor([-0.0028,  0.0160])\n",
      "Epoch 3081, Loss 3.0\n",
      "    Params: tensor([  5.3511, -17.2110])\n",
      "    Grad: tensor([-0.0028,  0.0160])\n",
      "Epoch 3082, Loss 3.0\n",
      "    Params: tensor([  5.3512, -17.2111])\n",
      "    Grad: tensor([-0.0028,  0.0159])\n",
      "Epoch 3083, Loss 3.0\n",
      "    Params: tensor([  5.3512, -17.2113])\n",
      "    Grad: tensor([-0.0028,  0.0159])\n",
      "Epoch 3084, Loss 3.0\n",
      "    Params: tensor([  5.3512, -17.2114])\n",
      "    Grad: tensor([-0.0028,  0.0159])\n",
      "Epoch 3085, Loss 3.0\n",
      "    Params: tensor([  5.3513, -17.2116])\n",
      "    Grad: tensor([-0.0028,  0.0159])\n",
      "Epoch 3086, Loss 3.0\n",
      "    Params: tensor([  5.3513, -17.2118])\n",
      "    Grad: tensor([-0.0028,  0.0158])\n",
      "Epoch 3087, Loss 3.0\n",
      "    Params: tensor([  5.3513, -17.2119])\n",
      "    Grad: tensor([-0.0028,  0.0158])\n",
      "Epoch 3088, Loss 3.0\n",
      "    Params: tensor([  5.3513, -17.2121])\n",
      "    Grad: tensor([-0.0028,  0.0158])\n",
      "Epoch 3089, Loss 3.0\n",
      "    Params: tensor([  5.3514, -17.2122])\n",
      "    Grad: tensor([-0.0028,  0.0157])\n",
      "Epoch 3090, Loss 3.0\n",
      "    Params: tensor([  5.3514, -17.2124])\n",
      "    Grad: tensor([-0.0028,  0.0157])\n",
      "Epoch 3091, Loss 3.0\n",
      "    Params: tensor([  5.3514, -17.2126])\n",
      "    Grad: tensor([-0.0028,  0.0157])\n",
      "Epoch 3092, Loss 3.0\n",
      "    Params: tensor([  5.3515, -17.2127])\n",
      "    Grad: tensor([-0.0027,  0.0157])\n",
      "Epoch 3093, Loss 3.0\n",
      "    Params: tensor([  5.3515, -17.2129])\n",
      "    Grad: tensor([-0.0027,  0.0156])\n",
      "Epoch 3094, Loss 3.0\n",
      "    Params: tensor([  5.3515, -17.2130])\n",
      "    Grad: tensor([-0.0027,  0.0156])\n",
      "Epoch 3095, Loss 3.0\n",
      "    Params: tensor([  5.3515, -17.2132])\n",
      "    Grad: tensor([-0.0028,  0.0156])\n",
      "Epoch 3096, Loss 3.0\n",
      "    Params: tensor([  5.3516, -17.2133])\n",
      "    Grad: tensor([-0.0028,  0.0156])\n",
      "Epoch 3097, Loss 3.0\n",
      "    Params: tensor([  5.3516, -17.2135])\n",
      "    Grad: tensor([-0.0027,  0.0155])\n",
      "Epoch 3098, Loss 3.0\n",
      "    Params: tensor([  5.3516, -17.2136])\n",
      "    Grad: tensor([-0.0027,  0.0155])\n",
      "Epoch 3099, Loss 3.0\n",
      "    Params: tensor([  5.3516, -17.2138])\n",
      "    Grad: tensor([-0.0027,  0.0155])\n",
      "Epoch 3100, Loss 3.0\n",
      "    Params: tensor([  5.3517, -17.2140])\n",
      "    Grad: tensor([-0.0027,  0.0155])\n",
      "Epoch 3101, Loss 3.0\n",
      "    Params: tensor([  5.3517, -17.2141])\n",
      "    Grad: tensor([-0.0027,  0.0154])\n",
      "Epoch 3102, Loss 3.0\n",
      "    Params: tensor([  5.3517, -17.2143])\n",
      "    Grad: tensor([-0.0027,  0.0154])\n",
      "Epoch 3103, Loss 3.0\n",
      "    Params: tensor([  5.3518, -17.2144])\n",
      "    Grad: tensor([-0.0027,  0.0154])\n",
      "Epoch 3104, Loss 3.0\n",
      "    Params: tensor([  5.3518, -17.2146])\n",
      "    Grad: tensor([-0.0027,  0.0153])\n",
      "Epoch 3105, Loss 3.0\n",
      "    Params: tensor([  5.3518, -17.2147])\n",
      "    Grad: tensor([-0.0027,  0.0153])\n",
      "Epoch 3106, Loss 3.0\n",
      "    Params: tensor([  5.3518, -17.2149])\n",
      "    Grad: tensor([-0.0027,  0.0153])\n",
      "Epoch 3107, Loss 3.0\n",
      "    Params: tensor([  5.3519, -17.2150])\n",
      "    Grad: tensor([-0.0027,  0.0153])\n",
      "Epoch 3108, Loss 3.0\n",
      "    Params: tensor([  5.3519, -17.2152])\n",
      "    Grad: tensor([-0.0027,  0.0152])\n",
      "Epoch 3109, Loss 3.0\n",
      "    Params: tensor([  5.3519, -17.2153])\n",
      "    Grad: tensor([-0.0027,  0.0152])\n",
      "Epoch 3110, Loss 3.0\n",
      "    Params: tensor([  5.3519, -17.2155])\n",
      "    Grad: tensor([-0.0027,  0.0152])\n",
      "Epoch 3111, Loss 3.0\n",
      "    Params: tensor([  5.3520, -17.2156])\n",
      "    Grad: tensor([-0.0027,  0.0152])\n",
      "Epoch 3112, Loss 3.0\n",
      "    Params: tensor([  5.3520, -17.2158])\n",
      "    Grad: tensor([-0.0027,  0.0151])\n",
      "Epoch 3113, Loss 3.0\n",
      "    Params: tensor([  5.3520, -17.2159])\n",
      "    Grad: tensor([-0.0027,  0.0151])\n",
      "Epoch 3114, Loss 3.0\n",
      "    Params: tensor([  5.3521, -17.2161])\n",
      "    Grad: tensor([-0.0027,  0.0151])\n",
      "Epoch 3115, Loss 3.0\n",
      "    Params: tensor([  5.3521, -17.2162])\n",
      "    Grad: tensor([-0.0026,  0.0151])\n",
      "Epoch 3116, Loss 3.0\n",
      "    Params: tensor([  5.3521, -17.2164])\n",
      "    Grad: tensor([-0.0026,  0.0150])\n",
      "Epoch 3117, Loss 3.0\n",
      "    Params: tensor([  5.3521, -17.2165])\n",
      "    Grad: tensor([-0.0027,  0.0150])\n",
      "Epoch 3118, Loss 3.0\n",
      "    Params: tensor([  5.3522, -17.2167])\n",
      "    Grad: tensor([-0.0026,  0.0150])\n",
      "Epoch 3119, Loss 3.0\n",
      "    Params: tensor([  5.3522, -17.2168])\n",
      "    Grad: tensor([-0.0026,  0.0150])\n",
      "Epoch 3120, Loss 3.0\n",
      "    Params: tensor([  5.3522, -17.2170])\n",
      "    Grad: tensor([-0.0026,  0.0149])\n",
      "Epoch 3121, Loss 3.0\n",
      "    Params: tensor([  5.3522, -17.2171])\n",
      "    Grad: tensor([-0.0026,  0.0149])\n",
      "Epoch 3122, Loss 3.0\n",
      "    Params: tensor([  5.3523, -17.2173])\n",
      "    Grad: tensor([-0.0026,  0.0149])\n",
      "Epoch 3123, Loss 3.0\n",
      "    Params: tensor([  5.3523, -17.2174])\n",
      "    Grad: tensor([-0.0026,  0.0149])\n",
      "Epoch 3124, Loss 3.0\n",
      "    Params: tensor([  5.3523, -17.2176])\n",
      "    Grad: tensor([-0.0026,  0.0148])\n",
      "Epoch 3125, Loss 3.0\n",
      "    Params: tensor([  5.3523, -17.2177])\n",
      "    Grad: tensor([-0.0026,  0.0148])\n",
      "Epoch 3126, Loss 3.0\n",
      "    Params: tensor([  5.3524, -17.2179])\n",
      "    Grad: tensor([-0.0026,  0.0148])\n",
      "Epoch 3127, Loss 3.0\n",
      "    Params: tensor([  5.3524, -17.2180])\n",
      "    Grad: tensor([-0.0026,  0.0148])\n",
      "Epoch 3128, Loss 3.0\n",
      "    Params: tensor([  5.3524, -17.2182])\n",
      "    Grad: tensor([-0.0026,  0.0147])\n",
      "Epoch 3129, Loss 3.0\n",
      "    Params: tensor([  5.3524, -17.2183])\n",
      "    Grad: tensor([-0.0026,  0.0147])\n",
      "Epoch 3130, Loss 3.0\n",
      "    Params: tensor([  5.3525, -17.2185])\n",
      "    Grad: tensor([-0.0026,  0.0147])\n",
      "Epoch 3131, Loss 3.0\n",
      "    Params: tensor([  5.3525, -17.2186])\n",
      "    Grad: tensor([-0.0026,  0.0147])\n",
      "Epoch 3132, Loss 3.0\n",
      "    Params: tensor([  5.3525, -17.2188])\n",
      "    Grad: tensor([-0.0026,  0.0146])\n",
      "Epoch 3133, Loss 3.0\n",
      "    Params: tensor([  5.3525, -17.2189])\n",
      "    Grad: tensor([-0.0026,  0.0146])\n",
      "Epoch 3134, Loss 3.0\n",
      "    Params: tensor([  5.3526, -17.2191])\n",
      "    Grad: tensor([-0.0026,  0.0146])\n",
      "Epoch 3135, Loss 3.0\n",
      "    Params: tensor([  5.3526, -17.2192])\n",
      "    Grad: tensor([-0.0026,  0.0146])\n",
      "Epoch 3136, Loss 3.0\n",
      "    Params: tensor([  5.3526, -17.2193])\n",
      "    Grad: tensor([-0.0026,  0.0145])\n",
      "Epoch 3137, Loss 3.0\n",
      "    Params: tensor([  5.3527, -17.2195])\n",
      "    Grad: tensor([-0.0026,  0.0145])\n",
      "Epoch 3138, Loss 3.0\n",
      "    Params: tensor([  5.3527, -17.2196])\n",
      "    Grad: tensor([-0.0025,  0.0145])\n",
      "Epoch 3139, Loss 3.0\n",
      "    Params: tensor([  5.3527, -17.2198])\n",
      "    Grad: tensor([-0.0026,  0.0145])\n",
      "Epoch 3140, Loss 3.0\n",
      "    Params: tensor([  5.3527, -17.2199])\n",
      "    Grad: tensor([-0.0025,  0.0144])\n",
      "Epoch 3141, Loss 3.0\n",
      "    Params: tensor([  5.3528, -17.2201])\n",
      "    Grad: tensor([-0.0026,  0.0144])\n",
      "Epoch 3142, Loss 3.0\n",
      "    Params: tensor([  5.3528, -17.2202])\n",
      "    Grad: tensor([-0.0025,  0.0144])\n",
      "Epoch 3143, Loss 3.0\n",
      "    Params: tensor([  5.3528, -17.2204])\n",
      "    Grad: tensor([-0.0025,  0.0144])\n",
      "Epoch 3144, Loss 3.0\n",
      "    Params: tensor([  5.3528, -17.2205])\n",
      "    Grad: tensor([-0.0025,  0.0143])\n",
      "Epoch 3145, Loss 3.0\n",
      "    Params: tensor([  5.3529, -17.2206])\n",
      "    Grad: tensor([-0.0025,  0.0143])\n",
      "Epoch 3146, Loss 3.0\n",
      "    Params: tensor([  5.3529, -17.2208])\n",
      "    Grad: tensor([-0.0025,  0.0143])\n",
      "Epoch 3147, Loss 3.0\n",
      "    Params: tensor([  5.3529, -17.2209])\n",
      "    Grad: tensor([-0.0025,  0.0143])\n",
      "Epoch 3148, Loss 3.0\n",
      "    Params: tensor([  5.3529, -17.2211])\n",
      "    Grad: tensor([-0.0025,  0.0142])\n",
      "Epoch 3149, Loss 3.0\n",
      "    Params: tensor([  5.3530, -17.2212])\n",
      "    Grad: tensor([-0.0025,  0.0142])\n",
      "Epoch 3150, Loss 3.0\n",
      "    Params: tensor([  5.3530, -17.2214])\n",
      "    Grad: tensor([-0.0025,  0.0142])\n",
      "Epoch 3151, Loss 3.0\n",
      "    Params: tensor([  5.3530, -17.2215])\n",
      "    Grad: tensor([-0.0025,  0.0142])\n",
      "Epoch 3152, Loss 3.0\n",
      "    Params: tensor([  5.3530, -17.2216])\n",
      "    Grad: tensor([-0.0025,  0.0141])\n",
      "Epoch 3153, Loss 3.0\n",
      "    Params: tensor([  5.3531, -17.2218])\n",
      "    Grad: tensor([-0.0025,  0.0141])\n",
      "Epoch 3154, Loss 3.0\n",
      "    Params: tensor([  5.3531, -17.2219])\n",
      "    Grad: tensor([-0.0025,  0.0141])\n",
      "Epoch 3155, Loss 3.0\n",
      "    Params: tensor([  5.3531, -17.2221])\n",
      "    Grad: tensor([-0.0025,  0.0141])\n",
      "Epoch 3156, Loss 3.0\n",
      "    Params: tensor([  5.3531, -17.2222])\n",
      "    Grad: tensor([-0.0025,  0.0141])\n",
      "Epoch 3157, Loss 3.0\n",
      "    Params: tensor([  5.3532, -17.2223])\n",
      "    Grad: tensor([-0.0025,  0.0140])\n",
      "Epoch 3158, Loss 3.0\n",
      "    Params: tensor([  5.3532, -17.2225])\n",
      "    Grad: tensor([-0.0025,  0.0140])\n",
      "Epoch 3159, Loss 3.0\n",
      "    Params: tensor([  5.3532, -17.2226])\n",
      "    Grad: tensor([-0.0025,  0.0140])\n",
      "Epoch 3160, Loss 3.0\n",
      "    Params: tensor([  5.3532, -17.2228])\n",
      "    Grad: tensor([-0.0025,  0.0140])\n",
      "Epoch 3161, Loss 3.0\n",
      "    Params: tensor([  5.3533, -17.2229])\n",
      "    Grad: tensor([-0.0025,  0.0139])\n",
      "Epoch 3162, Loss 3.0\n",
      "    Params: tensor([  5.3533, -17.2230])\n",
      "    Grad: tensor([-0.0024,  0.0139])\n",
      "Epoch 3163, Loss 3.0\n",
      "    Params: tensor([  5.3533, -17.2232])\n",
      "    Grad: tensor([-0.0025,  0.0139])\n",
      "Epoch 3164, Loss 3.0\n",
      "    Params: tensor([  5.3533, -17.2233])\n",
      "    Grad: tensor([-0.0024,  0.0139])\n",
      "Epoch 3165, Loss 3.0\n",
      "    Params: tensor([  5.3534, -17.2235])\n",
      "    Grad: tensor([-0.0025,  0.0138])\n",
      "Epoch 3166, Loss 3.0\n",
      "    Params: tensor([  5.3534, -17.2236])\n",
      "    Grad: tensor([-0.0024,  0.0138])\n",
      "Epoch 3167, Loss 3.0\n",
      "    Params: tensor([  5.3534, -17.2237])\n",
      "    Grad: tensor([-0.0024,  0.0138])\n",
      "Epoch 3168, Loss 3.0\n",
      "    Params: tensor([  5.3534, -17.2239])\n",
      "    Grad: tensor([-0.0024,  0.0138])\n",
      "Epoch 3169, Loss 3.0\n",
      "    Params: tensor([  5.3534, -17.2240])\n",
      "    Grad: tensor([-0.0024,  0.0137])\n",
      "Epoch 3170, Loss 3.0\n",
      "    Params: tensor([  5.3535, -17.2241])\n",
      "    Grad: tensor([-0.0024,  0.0137])\n",
      "Epoch 3171, Loss 3.0\n",
      "    Params: tensor([  5.3535, -17.2243])\n",
      "    Grad: tensor([-0.0024,  0.0137])\n",
      "Epoch 3172, Loss 3.0\n",
      "    Params: tensor([  5.3535, -17.2244])\n",
      "    Grad: tensor([-0.0024,  0.0137])\n",
      "Epoch 3173, Loss 3.0\n",
      "    Params: tensor([  5.3535, -17.2246])\n",
      "    Grad: tensor([-0.0024,  0.0137])\n",
      "Epoch 3174, Loss 3.0\n",
      "    Params: tensor([  5.3536, -17.2247])\n",
      "    Grad: tensor([-0.0024,  0.0136])\n",
      "Epoch 3175, Loss 3.0\n",
      "    Params: tensor([  5.3536, -17.2248])\n",
      "    Grad: tensor([-0.0024,  0.0136])\n",
      "Epoch 3176, Loss 3.0\n",
      "    Params: tensor([  5.3536, -17.2250])\n",
      "    Grad: tensor([-0.0024,  0.0136])\n",
      "Epoch 3177, Loss 3.0\n",
      "    Params: tensor([  5.3536, -17.2251])\n",
      "    Grad: tensor([-0.0024,  0.0136])\n",
      "Epoch 3178, Loss 3.0\n",
      "    Params: tensor([  5.3537, -17.2252])\n",
      "    Grad: tensor([-0.0024,  0.0135])\n",
      "Epoch 3179, Loss 3.0\n",
      "    Params: tensor([  5.3537, -17.2254])\n",
      "    Grad: tensor([-0.0024,  0.0135])\n",
      "Epoch 3180, Loss 3.0\n",
      "    Params: tensor([  5.3537, -17.2255])\n",
      "    Grad: tensor([-0.0024,  0.0135])\n",
      "Epoch 3181, Loss 3.0\n",
      "    Params: tensor([  5.3537, -17.2256])\n",
      "    Grad: tensor([-0.0024,  0.0135])\n",
      "Epoch 3182, Loss 3.0\n",
      "    Params: tensor([  5.3538, -17.2258])\n",
      "    Grad: tensor([-0.0024,  0.0134])\n",
      "Epoch 3183, Loss 3.0\n",
      "    Params: tensor([  5.3538, -17.2259])\n",
      "    Grad: tensor([-0.0024,  0.0134])\n",
      "Epoch 3184, Loss 3.0\n",
      "    Params: tensor([  5.3538, -17.2260])\n",
      "    Grad: tensor([-0.0023,  0.0134])\n",
      "Epoch 3185, Loss 3.0\n",
      "    Params: tensor([  5.3538, -17.2262])\n",
      "    Grad: tensor([-0.0024,  0.0134])\n",
      "Epoch 3186, Loss 3.0\n",
      "    Params: tensor([  5.3539, -17.2263])\n",
      "    Grad: tensor([-0.0023,  0.0134])\n",
      "Epoch 3187, Loss 3.0\n",
      "    Params: tensor([  5.3539, -17.2264])\n",
      "    Grad: tensor([-0.0023,  0.0133])\n",
      "Epoch 3188, Loss 3.0\n",
      "    Params: tensor([  5.3539, -17.2266])\n",
      "    Grad: tensor([-0.0024,  0.0133])\n",
      "Epoch 3189, Loss 3.0\n",
      "    Params: tensor([  5.3539, -17.2267])\n",
      "    Grad: tensor([-0.0024,  0.0133])\n",
      "Epoch 3190, Loss 3.0\n",
      "    Params: tensor([  5.3539, -17.2268])\n",
      "    Grad: tensor([-0.0023,  0.0133])\n",
      "Epoch 3191, Loss 3.0\n",
      "    Params: tensor([  5.3540, -17.2270])\n",
      "    Grad: tensor([-0.0024,  0.0132])\n",
      "Epoch 3192, Loss 3.0\n",
      "    Params: tensor([  5.3540, -17.2271])\n",
      "    Grad: tensor([-0.0024,  0.0132])\n",
      "Epoch 3193, Loss 3.0\n",
      "    Params: tensor([  5.3540, -17.2272])\n",
      "    Grad: tensor([-0.0023,  0.0132])\n",
      "Epoch 3194, Loss 3.0\n",
      "    Params: tensor([  5.3540, -17.2274])\n",
      "    Grad: tensor([-0.0023,  0.0132])\n",
      "Epoch 3195, Loss 3.0\n",
      "    Params: tensor([  5.3541, -17.2275])\n",
      "    Grad: tensor([-0.0023,  0.0132])\n",
      "Epoch 3196, Loss 3.0\n",
      "    Params: tensor([  5.3541, -17.2276])\n",
      "    Grad: tensor([-0.0023,  0.0131])\n",
      "Epoch 3197, Loss 3.0\n",
      "    Params: tensor([  5.3541, -17.2278])\n",
      "    Grad: tensor([-0.0023,  0.0131])\n",
      "Epoch 3198, Loss 3.0\n",
      "    Params: tensor([  5.3541, -17.2279])\n",
      "    Grad: tensor([-0.0023,  0.0131])\n",
      "Epoch 3199, Loss 3.0\n",
      "    Params: tensor([  5.3542, -17.2280])\n",
      "    Grad: tensor([-0.0023,  0.0131])\n",
      "Epoch 3200, Loss 3.0\n",
      "    Params: tensor([  5.3542, -17.2282])\n",
      "    Grad: tensor([-0.0023,  0.0130])\n",
      "Epoch 3201, Loss 3.0\n",
      "    Params: tensor([  5.3542, -17.2283])\n",
      "    Grad: tensor([-0.0023,  0.0130])\n",
      "Epoch 3202, Loss 3.0\n",
      "    Params: tensor([  5.3542, -17.2284])\n",
      "    Grad: tensor([-0.0023,  0.0130])\n",
      "Epoch 3203, Loss 3.0\n",
      "    Params: tensor([  5.3543, -17.2285])\n",
      "    Grad: tensor([-0.0023,  0.0130])\n",
      "Epoch 3204, Loss 3.0\n",
      "    Params: tensor([  5.3543, -17.2287])\n",
      "    Grad: tensor([-0.0023,  0.0130])\n",
      "Epoch 3205, Loss 3.0\n",
      "    Params: tensor([  5.3543, -17.2288])\n",
      "    Grad: tensor([-0.0023,  0.0129])\n",
      "Epoch 3206, Loss 3.0\n",
      "    Params: tensor([  5.3543, -17.2289])\n",
      "    Grad: tensor([-0.0023,  0.0129])\n",
      "Epoch 3207, Loss 3.0\n",
      "    Params: tensor([  5.3543, -17.2291])\n",
      "    Grad: tensor([-0.0023,  0.0129])\n",
      "Epoch 3208, Loss 3.0\n",
      "    Params: tensor([  5.3544, -17.2292])\n",
      "    Grad: tensor([-0.0023,  0.0129])\n",
      "Epoch 3209, Loss 3.0\n",
      "    Params: tensor([  5.3544, -17.2293])\n",
      "    Grad: tensor([-0.0023,  0.0128])\n",
      "Epoch 3210, Loss 3.0\n",
      "    Params: tensor([  5.3544, -17.2294])\n",
      "    Grad: tensor([-0.0023,  0.0128])\n",
      "Epoch 3211, Loss 3.0\n",
      "    Params: tensor([  5.3544, -17.2296])\n",
      "    Grad: tensor([-0.0023,  0.0128])\n",
      "Epoch 3212, Loss 3.0\n",
      "    Params: tensor([  5.3545, -17.2297])\n",
      "    Grad: tensor([-0.0023,  0.0128])\n",
      "Epoch 3213, Loss 3.0\n",
      "    Params: tensor([  5.3545, -17.2298])\n",
      "    Grad: tensor([-0.0022,  0.0128])\n",
      "Epoch 3214, Loss 3.0\n",
      "    Params: tensor([  5.3545, -17.2300])\n",
      "    Grad: tensor([-0.0023,  0.0127])\n",
      "Epoch 3215, Loss 3.0\n",
      "    Params: tensor([  5.3545, -17.2301])\n",
      "    Grad: tensor([-0.0023,  0.0127])\n",
      "Epoch 3216, Loss 3.0\n",
      "    Params: tensor([  5.3545, -17.2302])\n",
      "    Grad: tensor([-0.0022,  0.0127])\n",
      "Epoch 3217, Loss 3.0\n",
      "    Params: tensor([  5.3546, -17.2303])\n",
      "    Grad: tensor([-0.0022,  0.0127])\n",
      "Epoch 3218, Loss 3.0\n",
      "    Params: tensor([  5.3546, -17.2305])\n",
      "    Grad: tensor([-0.0022,  0.0126])\n",
      "Epoch 3219, Loss 3.0\n",
      "    Params: tensor([  5.3546, -17.2306])\n",
      "    Grad: tensor([-0.0022,  0.0126])\n",
      "Epoch 3220, Loss 3.0\n",
      "    Params: tensor([  5.3546, -17.2307])\n",
      "    Grad: tensor([-0.0022,  0.0126])\n",
      "Epoch 3221, Loss 3.0\n",
      "    Params: tensor([  5.3547, -17.2308])\n",
      "    Grad: tensor([-0.0022,  0.0126])\n",
      "Epoch 3222, Loss 3.0\n",
      "    Params: tensor([  5.3547, -17.2310])\n",
      "    Grad: tensor([-0.0022,  0.0126])\n",
      "Epoch 3223, Loss 3.0\n",
      "    Params: tensor([  5.3547, -17.2311])\n",
      "    Grad: tensor([-0.0022,  0.0125])\n",
      "Epoch 3224, Loss 3.0\n",
      "    Params: tensor([  5.3547, -17.2312])\n",
      "    Grad: tensor([-0.0022,  0.0125])\n",
      "Epoch 3225, Loss 3.0\n",
      "    Params: tensor([  5.3547, -17.2313])\n",
      "    Grad: tensor([-0.0022,  0.0125])\n",
      "Epoch 3226, Loss 3.0\n",
      "    Params: tensor([  5.3548, -17.2315])\n",
      "    Grad: tensor([-0.0022,  0.0125])\n",
      "Epoch 3227, Loss 3.0\n",
      "    Params: tensor([  5.3548, -17.2316])\n",
      "    Grad: tensor([-0.0022,  0.0125])\n",
      "Epoch 3228, Loss 3.0\n",
      "    Params: tensor([  5.3548, -17.2317])\n",
      "    Grad: tensor([-0.0022,  0.0124])\n",
      "Epoch 3229, Loss 3.0\n",
      "    Params: tensor([  5.3548, -17.2318])\n",
      "    Grad: tensor([-0.0022,  0.0124])\n",
      "Epoch 3230, Loss 3.0\n",
      "    Params: tensor([  5.3549, -17.2320])\n",
      "    Grad: tensor([-0.0022,  0.0124])\n",
      "Epoch 3231, Loss 3.0\n",
      "    Params: tensor([  5.3549, -17.2321])\n",
      "    Grad: tensor([-0.0022,  0.0124])\n",
      "Epoch 3232, Loss 3.0\n",
      "    Params: tensor([  5.3549, -17.2322])\n",
      "    Grad: tensor([-0.0022,  0.0124])\n",
      "Epoch 3233, Loss 3.0\n",
      "    Params: tensor([  5.3549, -17.2323])\n",
      "    Grad: tensor([-0.0022,  0.0123])\n",
      "Epoch 3234, Loss 3.0\n",
      "    Params: tensor([  5.3549, -17.2325])\n",
      "    Grad: tensor([-0.0022,  0.0123])\n",
      "Epoch 3235, Loss 3.0\n",
      "    Params: tensor([  5.3550, -17.2326])\n",
      "    Grad: tensor([-0.0022,  0.0123])\n",
      "Epoch 3236, Loss 3.0\n",
      "    Params: tensor([  5.3550, -17.2327])\n",
      "    Grad: tensor([-0.0022,  0.0123])\n",
      "Epoch 3237, Loss 3.0\n",
      "    Params: tensor([  5.3550, -17.2328])\n",
      "    Grad: tensor([-0.0022,  0.0122])\n",
      "Epoch 3238, Loss 3.0\n",
      "    Params: tensor([  5.3550, -17.2329])\n",
      "    Grad: tensor([-0.0022,  0.0122])\n",
      "Epoch 3239, Loss 3.0\n",
      "    Params: tensor([  5.3551, -17.2331])\n",
      "    Grad: tensor([-0.0022,  0.0122])\n",
      "Epoch 3240, Loss 3.0\n",
      "    Params: tensor([  5.3551, -17.2332])\n",
      "    Grad: tensor([-0.0022,  0.0122])\n",
      "Epoch 3241, Loss 3.0\n",
      "    Params: tensor([  5.3551, -17.2333])\n",
      "    Grad: tensor([-0.0022,  0.0122])\n",
      "Epoch 3242, Loss 3.0\n",
      "    Params: tensor([  5.3551, -17.2334])\n",
      "    Grad: tensor([-0.0022,  0.0121])\n",
      "Epoch 3243, Loss 3.0\n",
      "    Params: tensor([  5.3551, -17.2336])\n",
      "    Grad: tensor([-0.0022,  0.0121])\n",
      "Epoch 3244, Loss 3.0\n",
      "    Params: tensor([  5.3552, -17.2337])\n",
      "    Grad: tensor([-0.0021,  0.0121])\n",
      "Epoch 3245, Loss 3.0\n",
      "    Params: tensor([  5.3552, -17.2338])\n",
      "    Grad: tensor([-0.0021,  0.0121])\n",
      "Epoch 3246, Loss 3.0\n",
      "    Params: tensor([  5.3552, -17.2339])\n",
      "    Grad: tensor([-0.0021,  0.0121])\n",
      "Epoch 3247, Loss 3.0\n",
      "    Params: tensor([  5.3552, -17.2340])\n",
      "    Grad: tensor([-0.0021,  0.0120])\n",
      "Epoch 3248, Loss 3.0\n",
      "    Params: tensor([  5.3552, -17.2342])\n",
      "    Grad: tensor([-0.0021,  0.0120])\n",
      "Epoch 3249, Loss 3.0\n",
      "    Params: tensor([  5.3553, -17.2343])\n",
      "    Grad: tensor([-0.0021,  0.0120])\n",
      "Epoch 3250, Loss 3.0\n",
      "    Params: tensor([  5.3553, -17.2344])\n",
      "    Grad: tensor([-0.0021,  0.0120])\n",
      "Epoch 3251, Loss 3.0\n",
      "    Params: tensor([  5.3553, -17.2345])\n",
      "    Grad: tensor([-0.0021,  0.0120])\n",
      "Epoch 3252, Loss 3.0\n",
      "    Params: tensor([  5.3553, -17.2346])\n",
      "    Grad: tensor([-0.0021,  0.0119])\n",
      "Epoch 3253, Loss 3.0\n",
      "    Params: tensor([  5.3553, -17.2348])\n",
      "    Grad: tensor([-0.0021,  0.0119])\n",
      "Epoch 3254, Loss 3.0\n",
      "    Params: tensor([  5.3554, -17.2349])\n",
      "    Grad: tensor([-0.0021,  0.0119])\n",
      "Epoch 3255, Loss 3.0\n",
      "    Params: tensor([  5.3554, -17.2350])\n",
      "    Grad: tensor([-0.0021,  0.0119])\n",
      "Epoch 3256, Loss 3.0\n",
      "    Params: tensor([  5.3554, -17.2351])\n",
      "    Grad: tensor([-0.0021,  0.0119])\n",
      "Epoch 3257, Loss 3.0\n",
      "    Params: tensor([  5.3554, -17.2352])\n",
      "    Grad: tensor([-0.0021,  0.0118])\n",
      "Epoch 3258, Loss 3.0\n",
      "    Params: tensor([  5.3555, -17.2353])\n",
      "    Grad: tensor([-0.0021,  0.0118])\n",
      "Epoch 3259, Loss 3.0\n",
      "    Params: tensor([  5.3555, -17.2355])\n",
      "    Grad: tensor([-0.0021,  0.0118])\n",
      "Epoch 3260, Loss 3.0\n",
      "    Params: tensor([  5.3555, -17.2356])\n",
      "    Grad: tensor([-0.0021,  0.0118])\n",
      "Epoch 3261, Loss 3.0\n",
      "    Params: tensor([  5.3555, -17.2357])\n",
      "    Grad: tensor([-0.0021,  0.0118])\n",
      "Epoch 3262, Loss 3.0\n",
      "    Params: tensor([  5.3555, -17.2358])\n",
      "    Grad: tensor([-0.0021,  0.0117])\n",
      "Epoch 3263, Loss 3.0\n",
      "    Params: tensor([  5.3556, -17.2359])\n",
      "    Grad: tensor([-0.0021,  0.0117])\n",
      "Epoch 3264, Loss 3.0\n",
      "    Params: tensor([  5.3556, -17.2361])\n",
      "    Grad: tensor([-0.0021,  0.0117])\n",
      "Epoch 3265, Loss 3.0\n",
      "    Params: tensor([  5.3556, -17.2362])\n",
      "    Grad: tensor([-0.0021,  0.0117])\n",
      "Epoch 3266, Loss 3.0\n",
      "    Params: tensor([  5.3556, -17.2363])\n",
      "    Grad: tensor([-0.0021,  0.0117])\n",
      "Epoch 3267, Loss 3.0\n",
      "    Params: tensor([  5.3556, -17.2364])\n",
      "    Grad: tensor([-0.0021,  0.0116])\n",
      "Epoch 3268, Loss 3.0\n",
      "    Params: tensor([  5.3557, -17.2365])\n",
      "    Grad: tensor([-0.0021,  0.0116])\n",
      "Epoch 3269, Loss 3.0\n",
      "    Params: tensor([  5.3557, -17.2366])\n",
      "    Grad: tensor([-0.0021,  0.0116])\n",
      "Epoch 3270, Loss 3.0\n",
      "    Params: tensor([  5.3557, -17.2368])\n",
      "    Grad: tensor([-0.0021,  0.0116])\n",
      "Epoch 3271, Loss 3.0\n",
      "    Params: tensor([  5.3557, -17.2369])\n",
      "    Grad: tensor([-0.0021,  0.0116])\n",
      "Epoch 3272, Loss 3.0\n",
      "    Params: tensor([  5.3557, -17.2370])\n",
      "    Grad: tensor([-0.0021,  0.0115])\n",
      "Epoch 3273, Loss 3.0\n",
      "    Params: tensor([  5.3558, -17.2371])\n",
      "    Grad: tensor([-0.0020,  0.0115])\n",
      "Epoch 3274, Loss 3.0\n",
      "    Params: tensor([  5.3558, -17.2372])\n",
      "    Grad: tensor([-0.0020,  0.0115])\n",
      "Epoch 3275, Loss 3.0\n",
      "    Params: tensor([  5.3558, -17.2373])\n",
      "    Grad: tensor([-0.0020,  0.0115])\n",
      "Epoch 3276, Loss 3.0\n",
      "    Params: tensor([  5.3558, -17.2374])\n",
      "    Grad: tensor([-0.0020,  0.0115])\n",
      "Epoch 3277, Loss 3.0\n",
      "    Params: tensor([  5.3558, -17.2376])\n",
      "    Grad: tensor([-0.0020,  0.0114])\n",
      "Epoch 3278, Loss 3.0\n",
      "    Params: tensor([  5.3559, -17.2377])\n",
      "    Grad: tensor([-0.0020,  0.0114])\n",
      "Epoch 3279, Loss 3.0\n",
      "    Params: tensor([  5.3559, -17.2378])\n",
      "    Grad: tensor([-0.0020,  0.0114])\n",
      "Epoch 3280, Loss 3.0\n",
      "    Params: tensor([  5.3559, -17.2379])\n",
      "    Grad: tensor([-0.0020,  0.0114])\n",
      "Epoch 3281, Loss 3.0\n",
      "    Params: tensor([  5.3559, -17.2380])\n",
      "    Grad: tensor([-0.0020,  0.0114])\n",
      "Epoch 3282, Loss 3.0\n",
      "    Params: tensor([  5.3559, -17.2381])\n",
      "    Grad: tensor([-0.0020,  0.0113])\n",
      "Epoch 3283, Loss 3.0\n",
      "    Params: tensor([  5.3560, -17.2382])\n",
      "    Grad: tensor([-0.0020,  0.0113])\n",
      "Epoch 3284, Loss 3.0\n",
      "    Params: tensor([  5.3560, -17.2384])\n",
      "    Grad: tensor([-0.0020,  0.0113])\n",
      "Epoch 3285, Loss 3.0\n",
      "    Params: tensor([  5.3560, -17.2385])\n",
      "    Grad: tensor([-0.0020,  0.0113])\n",
      "Epoch 3286, Loss 3.0\n",
      "    Params: tensor([  5.3560, -17.2386])\n",
      "    Grad: tensor([-0.0020,  0.0113])\n",
      "Epoch 3287, Loss 3.0\n",
      "    Params: tensor([  5.3560, -17.2387])\n",
      "    Grad: tensor([-0.0020,  0.0112])\n",
      "Epoch 3288, Loss 3.0\n",
      "    Params: tensor([  5.3561, -17.2388])\n",
      "    Grad: tensor([-0.0020,  0.0112])\n",
      "Epoch 3289, Loss 3.0\n",
      "    Params: tensor([  5.3561, -17.2389])\n",
      "    Grad: tensor([-0.0020,  0.0112])\n",
      "Epoch 3290, Loss 3.0\n",
      "    Params: tensor([  5.3561, -17.2390])\n",
      "    Grad: tensor([-0.0020,  0.0112])\n",
      "Epoch 3291, Loss 3.0\n",
      "    Params: tensor([  5.3561, -17.2391])\n",
      "    Grad: tensor([-0.0020,  0.0112])\n",
      "Epoch 3292, Loss 3.0\n",
      "    Params: tensor([  5.3561, -17.2393])\n",
      "    Grad: tensor([-0.0020,  0.0111])\n",
      "Epoch 3293, Loss 3.0\n",
      "    Params: tensor([  5.3562, -17.2394])\n",
      "    Grad: tensor([-0.0020,  0.0111])\n",
      "Epoch 3294, Loss 3.0\n",
      "    Params: tensor([  5.3562, -17.2395])\n",
      "    Grad: tensor([-0.0020,  0.0111])\n",
      "Epoch 3295, Loss 3.0\n",
      "    Params: tensor([  5.3562, -17.2396])\n",
      "    Grad: tensor([-0.0020,  0.0111])\n",
      "Epoch 3296, Loss 3.0\n",
      "    Params: tensor([  5.3562, -17.2397])\n",
      "    Grad: tensor([-0.0020,  0.0111])\n",
      "Epoch 3297, Loss 3.0\n",
      "    Params: tensor([  5.3562, -17.2398])\n",
      "    Grad: tensor([-0.0019,  0.0111])\n",
      "Epoch 3298, Loss 3.0\n",
      "    Params: tensor([  5.3563, -17.2399])\n",
      "    Grad: tensor([-0.0019,  0.0110])\n",
      "Epoch 3299, Loss 3.0\n",
      "    Params: tensor([  5.3563, -17.2400])\n",
      "    Grad: tensor([-0.0019,  0.0110])\n",
      "Epoch 3300, Loss 3.0\n",
      "    Params: tensor([  5.3563, -17.2401])\n",
      "    Grad: tensor([-0.0019,  0.0110])\n",
      "Epoch 3301, Loss 3.0\n",
      "    Params: tensor([  5.3563, -17.2402])\n",
      "    Grad: tensor([-0.0019,  0.0110])\n",
      "Epoch 3302, Loss 3.0\n",
      "    Params: tensor([  5.3563, -17.2404])\n",
      "    Grad: tensor([-0.0019,  0.0110])\n",
      "Epoch 3303, Loss 3.0\n",
      "    Params: tensor([  5.3564, -17.2405])\n",
      "    Grad: tensor([-0.0019,  0.0109])\n",
      "Epoch 3304, Loss 3.0\n",
      "    Params: tensor([  5.3564, -17.2406])\n",
      "    Grad: tensor([-0.0019,  0.0109])\n",
      "Epoch 3305, Loss 3.0\n",
      "    Params: tensor([  5.3564, -17.2407])\n",
      "    Grad: tensor([-0.0019,  0.0109])\n",
      "Epoch 3306, Loss 3.0\n",
      "    Params: tensor([  5.3564, -17.2408])\n",
      "    Grad: tensor([-0.0019,  0.0109])\n",
      "Epoch 3307, Loss 3.0\n",
      "    Params: tensor([  5.3564, -17.2409])\n",
      "    Grad: tensor([-0.0019,  0.0109])\n",
      "Epoch 3308, Loss 3.0\n",
      "    Params: tensor([  5.3565, -17.2410])\n",
      "    Grad: tensor([-0.0019,  0.0109])\n",
      "Epoch 3309, Loss 3.0\n",
      "    Params: tensor([  5.3565, -17.2411])\n",
      "    Grad: tensor([-0.0019,  0.0108])\n",
      "Epoch 3310, Loss 3.0\n",
      "    Params: tensor([  5.3565, -17.2412])\n",
      "    Grad: tensor([-0.0019,  0.0108])\n",
      "Epoch 3311, Loss 3.0\n",
      "    Params: tensor([  5.3565, -17.2413])\n",
      "    Grad: tensor([-0.0019,  0.0108])\n",
      "Epoch 3312, Loss 3.0\n",
      "    Params: tensor([  5.3565, -17.2414])\n",
      "    Grad: tensor([-0.0019,  0.0108])\n",
      "Epoch 3313, Loss 3.0\n",
      "    Params: tensor([  5.3565, -17.2415])\n",
      "    Grad: tensor([-0.0019,  0.0108])\n",
      "Epoch 3314, Loss 3.0\n",
      "    Params: tensor([  5.3566, -17.2417])\n",
      "    Grad: tensor([-0.0019,  0.0107])\n",
      "Epoch 3315, Loss 3.0\n",
      "    Params: tensor([  5.3566, -17.2418])\n",
      "    Grad: tensor([-0.0019,  0.0107])\n",
      "Epoch 3316, Loss 3.0\n",
      "    Params: tensor([  5.3566, -17.2419])\n",
      "    Grad: tensor([-0.0019,  0.0107])\n",
      "Epoch 3317, Loss 3.0\n",
      "    Params: tensor([  5.3566, -17.2420])\n",
      "    Grad: tensor([-0.0019,  0.0107])\n",
      "Epoch 3318, Loss 3.0\n",
      "    Params: tensor([  5.3566, -17.2421])\n",
      "    Grad: tensor([-0.0019,  0.0107])\n",
      "Epoch 3319, Loss 3.0\n",
      "    Params: tensor([  5.3567, -17.2422])\n",
      "    Grad: tensor([-0.0019,  0.0107])\n",
      "Epoch 3320, Loss 3.0\n",
      "    Params: tensor([  5.3567, -17.2423])\n",
      "    Grad: tensor([-0.0019,  0.0106])\n",
      "Epoch 3321, Loss 3.0\n",
      "    Params: tensor([  5.3567, -17.2424])\n",
      "    Grad: tensor([-0.0019,  0.0106])\n",
      "Epoch 3322, Loss 3.0\n",
      "    Params: tensor([  5.3567, -17.2425])\n",
      "    Grad: tensor([-0.0019,  0.0106])\n",
      "Epoch 3323, Loss 3.0\n",
      "    Params: tensor([  5.3567, -17.2426])\n",
      "    Grad: tensor([-0.0019,  0.0106])\n",
      "Epoch 3324, Loss 3.0\n",
      "    Params: tensor([  5.3568, -17.2427])\n",
      "    Grad: tensor([-0.0019,  0.0106])\n",
      "Epoch 3325, Loss 3.0\n",
      "    Params: tensor([  5.3568, -17.2428])\n",
      "    Grad: tensor([-0.0019,  0.0105])\n",
      "Epoch 3326, Loss 3.0\n",
      "    Params: tensor([  5.3568, -17.2429])\n",
      "    Grad: tensor([-0.0019,  0.0105])\n",
      "Epoch 3327, Loss 3.0\n",
      "    Params: tensor([  5.3568, -17.2430])\n",
      "    Grad: tensor([-0.0019,  0.0105])\n",
      "Epoch 3328, Loss 3.0\n",
      "    Params: tensor([  5.3568, -17.2431])\n",
      "    Grad: tensor([-0.0018,  0.0105])\n",
      "Epoch 3329, Loss 3.0\n",
      "    Params: tensor([  5.3568, -17.2432])\n",
      "    Grad: tensor([-0.0018,  0.0105])\n",
      "Epoch 3330, Loss 3.0\n",
      "    Params: tensor([  5.3569, -17.2433])\n",
      "    Grad: tensor([-0.0018,  0.0105])\n",
      "Epoch 3331, Loss 3.0\n",
      "    Params: tensor([  5.3569, -17.2435])\n",
      "    Grad: tensor([-0.0019,  0.0104])\n",
      "Epoch 3332, Loss 3.0\n",
      "    Params: tensor([  5.3569, -17.2436])\n",
      "    Grad: tensor([-0.0018,  0.0104])\n",
      "Epoch 3333, Loss 3.0\n",
      "    Params: tensor([  5.3569, -17.2437])\n",
      "    Grad: tensor([-0.0018,  0.0104])\n",
      "Epoch 3334, Loss 3.0\n",
      "    Params: tensor([  5.3569, -17.2438])\n",
      "    Grad: tensor([-0.0018,  0.0104])\n",
      "Epoch 3335, Loss 3.0\n",
      "    Params: tensor([  5.3570, -17.2439])\n",
      "    Grad: tensor([-0.0018,  0.0104])\n",
      "Epoch 3336, Loss 3.0\n",
      "    Params: tensor([  5.3570, -17.2440])\n",
      "    Grad: tensor([-0.0018,  0.0104])\n",
      "Epoch 3337, Loss 3.0\n",
      "    Params: tensor([  5.3570, -17.2441])\n",
      "    Grad: tensor([-0.0018,  0.0103])\n",
      "Epoch 3338, Loss 3.0\n",
      "    Params: tensor([  5.3570, -17.2442])\n",
      "    Grad: tensor([-0.0018,  0.0103])\n",
      "Epoch 3339, Loss 3.0\n",
      "    Params: tensor([  5.3570, -17.2443])\n",
      "    Grad: tensor([-0.0018,  0.0103])\n",
      "Epoch 3340, Loss 3.0\n",
      "    Params: tensor([  5.3570, -17.2444])\n",
      "    Grad: tensor([-0.0018,  0.0103])\n",
      "Epoch 3341, Loss 3.0\n",
      "    Params: tensor([  5.3571, -17.2445])\n",
      "    Grad: tensor([-0.0018,  0.0103])\n",
      "Epoch 3342, Loss 3.0\n",
      "    Params: tensor([  5.3571, -17.2446])\n",
      "    Grad: tensor([-0.0018,  0.0102])\n",
      "Epoch 3343, Loss 3.0\n",
      "    Params: tensor([  5.3571, -17.2447])\n",
      "    Grad: tensor([-0.0018,  0.0102])\n",
      "Epoch 3344, Loss 3.0\n",
      "    Params: tensor([  5.3571, -17.2448])\n",
      "    Grad: tensor([-0.0018,  0.0102])\n",
      "Epoch 3345, Loss 3.0\n",
      "    Params: tensor([  5.3571, -17.2449])\n",
      "    Grad: tensor([-0.0018,  0.0102])\n",
      "Epoch 3346, Loss 3.0\n",
      "    Params: tensor([  5.3572, -17.2450])\n",
      "    Grad: tensor([-0.0018,  0.0102])\n",
      "Epoch 3347, Loss 3.0\n",
      "    Params: tensor([  5.3572, -17.2451])\n",
      "    Grad: tensor([-0.0018,  0.0102])\n",
      "Epoch 3348, Loss 3.0\n",
      "    Params: tensor([  5.3572, -17.2452])\n",
      "    Grad: tensor([-0.0018,  0.0101])\n",
      "Epoch 3349, Loss 3.0\n",
      "    Params: tensor([  5.3572, -17.2453])\n",
      "    Grad: tensor([-0.0018,  0.0101])\n",
      "Epoch 3350, Loss 3.0\n",
      "    Params: tensor([  5.3572, -17.2454])\n",
      "    Grad: tensor([-0.0018,  0.0101])\n",
      "Epoch 3351, Loss 3.0\n",
      "    Params: tensor([  5.3572, -17.2455])\n",
      "    Grad: tensor([-0.0018,  0.0101])\n",
      "Epoch 3352, Loss 3.0\n",
      "    Params: tensor([  5.3573, -17.2456])\n",
      "    Grad: tensor([-0.0018,  0.0101])\n",
      "Epoch 3353, Loss 3.0\n",
      "    Params: tensor([  5.3573, -17.2457])\n",
      "    Grad: tensor([-0.0018,  0.0101])\n",
      "Epoch 3354, Loss 3.0\n",
      "    Params: tensor([  5.3573, -17.2458])\n",
      "    Grad: tensor([-0.0018,  0.0100])\n",
      "Epoch 3355, Loss 3.0\n",
      "    Params: tensor([  5.3573, -17.2459])\n",
      "    Grad: tensor([-0.0018,  0.0100])\n",
      "Epoch 3356, Loss 3.0\n",
      "    Params: tensor([  5.3573, -17.2460])\n",
      "    Grad: tensor([-0.0018,  0.0100])\n",
      "Epoch 3357, Loss 3.0\n",
      "    Params: tensor([  5.3574, -17.2461])\n",
      "    Grad: tensor([-0.0018,  0.0100])\n",
      "Epoch 3358, Loss 3.0\n",
      "    Params: tensor([  5.3574, -17.2462])\n",
      "    Grad: tensor([-0.0018,  0.0100])\n",
      "Epoch 3359, Loss 3.0\n",
      "    Params: tensor([  5.3574, -17.2463])\n",
      "    Grad: tensor([-0.0018,  0.0100])\n",
      "Epoch 3360, Loss 3.0\n",
      "    Params: tensor([  5.3574, -17.2464])\n",
      "    Grad: tensor([-0.0017,  0.0099])\n",
      "Epoch 3361, Loss 3.0\n",
      "    Params: tensor([  5.3574, -17.2465])\n",
      "    Grad: tensor([-0.0017,  0.0099])\n",
      "Epoch 3362, Loss 3.0\n",
      "    Params: tensor([  5.3574, -17.2466])\n",
      "    Grad: tensor([-0.0017,  0.0099])\n",
      "Epoch 3363, Loss 3.0\n",
      "    Params: tensor([  5.3575, -17.2467])\n",
      "    Grad: tensor([-0.0017,  0.0099])\n",
      "Epoch 3364, Loss 3.0\n",
      "    Params: tensor([  5.3575, -17.2468])\n",
      "    Grad: tensor([-0.0017,  0.0099])\n",
      "Epoch 3365, Loss 3.0\n",
      "    Params: tensor([  5.3575, -17.2469])\n",
      "    Grad: tensor([-0.0017,  0.0098])\n",
      "Epoch 3366, Loss 3.0\n",
      "    Params: tensor([  5.3575, -17.2470])\n",
      "    Grad: tensor([-0.0017,  0.0098])\n",
      "Epoch 3367, Loss 3.0\n",
      "    Params: tensor([  5.3575, -17.2471])\n",
      "    Grad: tensor([-0.0018,  0.0098])\n",
      "Epoch 3368, Loss 3.0\n",
      "    Params: tensor([  5.3575, -17.2472])\n",
      "    Grad: tensor([-0.0017,  0.0098])\n",
      "Epoch 3369, Loss 3.0\n",
      "    Params: tensor([  5.3576, -17.2473])\n",
      "    Grad: tensor([-0.0017,  0.0098])\n",
      "Epoch 3370, Loss 3.0\n",
      "    Params: tensor([  5.3576, -17.2474])\n",
      "    Grad: tensor([-0.0017,  0.0098])\n",
      "Epoch 3371, Loss 3.0\n",
      "    Params: tensor([  5.3576, -17.2475])\n",
      "    Grad: tensor([-0.0017,  0.0098])\n",
      "Epoch 3372, Loss 3.0\n",
      "    Params: tensor([  5.3576, -17.2476])\n",
      "    Grad: tensor([-0.0017,  0.0097])\n",
      "Epoch 3373, Loss 3.0\n",
      "    Params: tensor([  5.3576, -17.2477])\n",
      "    Grad: tensor([-0.0017,  0.0097])\n",
      "Epoch 3374, Loss 3.0\n",
      "    Params: tensor([  5.3576, -17.2478])\n",
      "    Grad: tensor([-0.0017,  0.0097])\n",
      "Epoch 3375, Loss 3.0\n",
      "    Params: tensor([  5.3577, -17.2479])\n",
      "    Grad: tensor([-0.0017,  0.0097])\n",
      "Epoch 3376, Loss 3.0\n",
      "    Params: tensor([  5.3577, -17.2480])\n",
      "    Grad: tensor([-0.0017,  0.0097])\n",
      "Epoch 3377, Loss 3.0\n",
      "    Params: tensor([  5.3577, -17.2481])\n",
      "    Grad: tensor([-0.0017,  0.0096])\n",
      "Epoch 3378, Loss 3.0\n",
      "    Params: tensor([  5.3577, -17.2482])\n",
      "    Grad: tensor([-0.0017,  0.0096])\n",
      "Epoch 3379, Loss 3.0\n",
      "    Params: tensor([  5.3577, -17.2483])\n",
      "    Grad: tensor([-0.0017,  0.0096])\n",
      "Epoch 3380, Loss 3.0\n",
      "    Params: tensor([  5.3578, -17.2484])\n",
      "    Grad: tensor([-0.0017,  0.0096])\n",
      "Epoch 3381, Loss 3.0\n",
      "    Params: tensor([  5.3578, -17.2485])\n",
      "    Grad: tensor([-0.0017,  0.0096])\n",
      "Epoch 3382, Loss 3.0\n",
      "    Params: tensor([  5.3578, -17.2485])\n",
      "    Grad: tensor([-0.0017,  0.0096])\n",
      "Epoch 3383, Loss 3.0\n",
      "    Params: tensor([  5.3578, -17.2486])\n",
      "    Grad: tensor([-0.0017,  0.0096])\n",
      "Epoch 3384, Loss 3.0\n",
      "    Params: tensor([  5.3578, -17.2487])\n",
      "    Grad: tensor([-0.0017,  0.0095])\n",
      "Epoch 3385, Loss 3.0\n",
      "    Params: tensor([  5.3578, -17.2488])\n",
      "    Grad: tensor([-0.0017,  0.0095])\n",
      "Epoch 3386, Loss 3.0\n",
      "    Params: tensor([  5.3579, -17.2489])\n",
      "    Grad: tensor([-0.0017,  0.0095])\n",
      "Epoch 3387, Loss 3.0\n",
      "    Params: tensor([  5.3579, -17.2490])\n",
      "    Grad: tensor([-0.0017,  0.0095])\n",
      "Epoch 3388, Loss 3.0\n",
      "    Params: tensor([  5.3579, -17.2491])\n",
      "    Grad: tensor([-0.0017,  0.0095])\n",
      "Epoch 3389, Loss 3.0\n",
      "    Params: tensor([  5.3579, -17.2492])\n",
      "    Grad: tensor([-0.0017,  0.0095])\n",
      "Epoch 3390, Loss 3.0\n",
      "    Params: tensor([  5.3579, -17.2493])\n",
      "    Grad: tensor([-0.0017,  0.0094])\n",
      "Epoch 3391, Loss 3.0\n",
      "    Params: tensor([  5.3579, -17.2494])\n",
      "    Grad: tensor([-0.0017,  0.0094])\n",
      "Epoch 3392, Loss 3.0\n",
      "    Params: tensor([  5.3580, -17.2495])\n",
      "    Grad: tensor([-0.0017,  0.0094])\n",
      "Epoch 3393, Loss 3.0\n",
      "    Params: tensor([  5.3580, -17.2496])\n",
      "    Grad: tensor([-0.0017,  0.0094])\n",
      "Epoch 3394, Loss 3.0\n",
      "    Params: tensor([  5.3580, -17.2497])\n",
      "    Grad: tensor([-0.0016,  0.0094])\n",
      "Epoch 3395, Loss 3.0\n",
      "    Params: tensor([  5.3580, -17.2498])\n",
      "    Grad: tensor([-0.0017,  0.0094])\n",
      "Epoch 3396, Loss 3.0\n",
      "    Params: tensor([  5.3580, -17.2499])\n",
      "    Grad: tensor([-0.0016,  0.0093])\n",
      "Epoch 3397, Loss 3.0\n",
      "    Params: tensor([  5.3580, -17.2500])\n",
      "    Grad: tensor([-0.0017,  0.0093])\n",
      "Epoch 3398, Loss 3.0\n",
      "    Params: tensor([  5.3581, -17.2501])\n",
      "    Grad: tensor([-0.0016,  0.0093])\n",
      "Epoch 3399, Loss 3.0\n",
      "    Params: tensor([  5.3581, -17.2502])\n",
      "    Grad: tensor([-0.0016,  0.0093])\n",
      "Epoch 3400, Loss 3.0\n",
      "    Params: tensor([  5.3581, -17.2502])\n",
      "    Grad: tensor([-0.0016,  0.0093])\n",
      "Epoch 3401, Loss 3.0\n",
      "    Params: tensor([  5.3581, -17.2503])\n",
      "    Grad: tensor([-0.0017,  0.0093])\n",
      "Epoch 3402, Loss 3.0\n",
      "    Params: tensor([  5.3581, -17.2504])\n",
      "    Grad: tensor([-0.0016,  0.0092])\n",
      "Epoch 3403, Loss 3.0\n",
      "    Params: tensor([  5.3581, -17.2505])\n",
      "    Grad: tensor([-0.0016,  0.0092])\n",
      "Epoch 3404, Loss 3.0\n",
      "    Params: tensor([  5.3581, -17.2506])\n",
      "    Grad: tensor([-0.0016,  0.0092])\n",
      "Epoch 3405, Loss 3.0\n",
      "    Params: tensor([  5.3582, -17.2507])\n",
      "    Grad: tensor([-0.0016,  0.0092])\n",
      "Epoch 3406, Loss 3.0\n",
      "    Params: tensor([  5.3582, -17.2508])\n",
      "    Grad: tensor([-0.0016,  0.0092])\n",
      "Epoch 3407, Loss 3.0\n",
      "    Params: tensor([  5.3582, -17.2509])\n",
      "    Grad: tensor([-0.0016,  0.0092])\n",
      "Epoch 3408, Loss 3.0\n",
      "    Params: tensor([  5.3582, -17.2510])\n",
      "    Grad: tensor([-0.0016,  0.0092])\n",
      "Epoch 3409, Loss 3.0\n",
      "    Params: tensor([  5.3582, -17.2511])\n",
      "    Grad: tensor([-0.0016,  0.0091])\n",
      "Epoch 3410, Loss 3.0\n",
      "    Params: tensor([  5.3582, -17.2512])\n",
      "    Grad: tensor([-0.0016,  0.0091])\n",
      "Epoch 3411, Loss 3.0\n",
      "    Params: tensor([  5.3583, -17.2513])\n",
      "    Grad: tensor([-0.0016,  0.0091])\n",
      "Epoch 3412, Loss 3.0\n",
      "    Params: tensor([  5.3583, -17.2513])\n",
      "    Grad: tensor([-0.0016,  0.0091])\n",
      "Epoch 3413, Loss 3.0\n",
      "    Params: tensor([  5.3583, -17.2514])\n",
      "    Grad: tensor([-0.0016,  0.0091])\n",
      "Epoch 3414, Loss 3.0\n",
      "    Params: tensor([  5.3583, -17.2515])\n",
      "    Grad: tensor([-0.0016,  0.0091])\n",
      "Epoch 3415, Loss 3.0\n",
      "    Params: tensor([  5.3583, -17.2516])\n",
      "    Grad: tensor([-0.0016,  0.0090])\n",
      "Epoch 3416, Loss 3.0\n",
      "    Params: tensor([  5.3583, -17.2517])\n",
      "    Grad: tensor([-0.0016,  0.0090])\n",
      "Epoch 3417, Loss 3.0\n",
      "    Params: tensor([  5.3584, -17.2518])\n",
      "    Grad: tensor([-0.0016,  0.0090])\n",
      "Epoch 3418, Loss 3.0\n",
      "    Params: tensor([  5.3584, -17.2519])\n",
      "    Grad: tensor([-0.0016,  0.0090])\n",
      "Epoch 3419, Loss 3.0\n",
      "    Params: tensor([  5.3584, -17.2520])\n",
      "    Grad: tensor([-0.0016,  0.0090])\n",
      "Epoch 3420, Loss 3.0\n",
      "    Params: tensor([  5.3584, -17.2521])\n",
      "    Grad: tensor([-0.0016,  0.0090])\n",
      "Epoch 3421, Loss 3.0\n",
      "    Params: tensor([  5.3584, -17.2522])\n",
      "    Grad: tensor([-0.0016,  0.0090])\n",
      "Epoch 3422, Loss 3.0\n",
      "    Params: tensor([  5.3584, -17.2522])\n",
      "    Grad: tensor([-0.0016,  0.0089])\n",
      "Epoch 3423, Loss 3.0\n",
      "    Params: tensor([  5.3585, -17.2523])\n",
      "    Grad: tensor([-0.0016,  0.0089])\n",
      "Epoch 3424, Loss 3.0\n",
      "    Params: tensor([  5.3585, -17.2524])\n",
      "    Grad: tensor([-0.0016,  0.0089])\n",
      "Epoch 3425, Loss 3.0\n",
      "    Params: tensor([  5.3585, -17.2525])\n",
      "    Grad: tensor([-0.0016,  0.0089])\n",
      "Epoch 3426, Loss 3.0\n",
      "    Params: tensor([  5.3585, -17.2526])\n",
      "    Grad: tensor([-0.0016,  0.0089])\n",
      "Epoch 3427, Loss 3.0\n",
      "    Params: tensor([  5.3585, -17.2527])\n",
      "    Grad: tensor([-0.0016,  0.0089])\n",
      "Epoch 3428, Loss 3.0\n",
      "    Params: tensor([  5.3585, -17.2528])\n",
      "    Grad: tensor([-0.0016,  0.0088])\n",
      "Epoch 3429, Loss 3.0\n",
      "    Params: tensor([  5.3585, -17.2529])\n",
      "    Grad: tensor([-0.0016,  0.0088])\n",
      "Epoch 3430, Loss 3.0\n",
      "    Params: tensor([  5.3586, -17.2530])\n",
      "    Grad: tensor([-0.0015,  0.0088])\n",
      "Epoch 3431, Loss 3.0\n",
      "    Params: tensor([  5.3586, -17.2530])\n",
      "    Grad: tensor([-0.0015,  0.0088])\n",
      "Epoch 3432, Loss 3.0\n",
      "    Params: tensor([  5.3586, -17.2531])\n",
      "    Grad: tensor([-0.0016,  0.0088])\n",
      "Epoch 3433, Loss 3.0\n",
      "    Params: tensor([  5.3586, -17.2532])\n",
      "    Grad: tensor([-0.0016,  0.0088])\n",
      "Epoch 3434, Loss 3.0\n",
      "    Params: tensor([  5.3586, -17.2533])\n",
      "    Grad: tensor([-0.0015,  0.0088])\n",
      "Epoch 3435, Loss 3.0\n",
      "    Params: tensor([  5.3586, -17.2534])\n",
      "    Grad: tensor([-0.0015,  0.0087])\n",
      "Epoch 3436, Loss 3.0\n",
      "    Params: tensor([  5.3587, -17.2535])\n",
      "    Grad: tensor([-0.0016,  0.0087])\n",
      "Epoch 3437, Loss 3.0\n",
      "    Params: tensor([  5.3587, -17.2536])\n",
      "    Grad: tensor([-0.0015,  0.0087])\n",
      "Epoch 3438, Loss 3.0\n",
      "    Params: tensor([  5.3587, -17.2537])\n",
      "    Grad: tensor([-0.0015,  0.0087])\n",
      "Epoch 3439, Loss 3.0\n",
      "    Params: tensor([  5.3587, -17.2537])\n",
      "    Grad: tensor([-0.0016,  0.0087])\n",
      "Epoch 3440, Loss 3.0\n",
      "    Params: tensor([  5.3587, -17.2538])\n",
      "    Grad: tensor([-0.0015,  0.0087])\n",
      "Epoch 3441, Loss 3.0\n",
      "    Params: tensor([  5.3587, -17.2539])\n",
      "    Grad: tensor([-0.0015,  0.0087])\n",
      "Epoch 3442, Loss 3.0\n",
      "    Params: tensor([  5.3587, -17.2540])\n",
      "    Grad: tensor([-0.0015,  0.0086])\n",
      "Epoch 3443, Loss 3.0\n",
      "    Params: tensor([  5.3588, -17.2541])\n",
      "    Grad: tensor([-0.0015,  0.0086])\n",
      "Epoch 3444, Loss 3.0\n",
      "    Params: tensor([  5.3588, -17.2542])\n",
      "    Grad: tensor([-0.0015,  0.0086])\n",
      "Epoch 3445, Loss 3.0\n",
      "    Params: tensor([  5.3588, -17.2543])\n",
      "    Grad: tensor([-0.0015,  0.0086])\n",
      "Epoch 3446, Loss 3.0\n",
      "    Params: tensor([  5.3588, -17.2543])\n",
      "    Grad: tensor([-0.0015,  0.0086])\n",
      "Epoch 3447, Loss 3.0\n",
      "    Params: tensor([  5.3588, -17.2544])\n",
      "    Grad: tensor([-0.0015,  0.0086])\n",
      "Epoch 3448, Loss 3.0\n",
      "    Params: tensor([  5.3588, -17.2545])\n",
      "    Grad: tensor([-0.0015,  0.0086])\n",
      "Epoch 3449, Loss 3.0\n",
      "    Params: tensor([  5.3589, -17.2546])\n",
      "    Grad: tensor([-0.0015,  0.0085])\n",
      "Epoch 3450, Loss 3.0\n",
      "    Params: tensor([  5.3589, -17.2547])\n",
      "    Grad: tensor([-0.0015,  0.0085])\n",
      "Epoch 3451, Loss 3.0\n",
      "    Params: tensor([  5.3589, -17.2548])\n",
      "    Grad: tensor([-0.0015,  0.0085])\n",
      "Epoch 3452, Loss 3.0\n",
      "    Params: tensor([  5.3589, -17.2549])\n",
      "    Grad: tensor([-0.0015,  0.0085])\n",
      "Epoch 3453, Loss 3.0\n",
      "    Params: tensor([  5.3589, -17.2549])\n",
      "    Grad: tensor([-0.0015,  0.0085])\n",
      "Epoch 3454, Loss 3.0\n",
      "    Params: tensor([  5.3589, -17.2550])\n",
      "    Grad: tensor([-0.0015,  0.0085])\n",
      "Epoch 3455, Loss 3.0\n",
      "    Params: tensor([  5.3589, -17.2551])\n",
      "    Grad: tensor([-0.0015,  0.0085])\n",
      "Epoch 3456, Loss 3.0\n",
      "    Params: tensor([  5.3590, -17.2552])\n",
      "    Grad: tensor([-0.0015,  0.0084])\n",
      "Epoch 3457, Loss 3.0\n",
      "    Params: tensor([  5.3590, -17.2553])\n",
      "    Grad: tensor([-0.0015,  0.0084])\n",
      "Epoch 3458, Loss 3.0\n",
      "    Params: tensor([  5.3590, -17.2554])\n",
      "    Grad: tensor([-0.0015,  0.0084])\n",
      "Epoch 3459, Loss 3.0\n",
      "    Params: tensor([  5.3590, -17.2554])\n",
      "    Grad: tensor([-0.0015,  0.0084])\n",
      "Epoch 3460, Loss 3.0\n",
      "    Params: tensor([  5.3590, -17.2555])\n",
      "    Grad: tensor([-0.0015,  0.0084])\n",
      "Epoch 3461, Loss 3.0\n",
      "    Params: tensor([  5.3590, -17.2556])\n",
      "    Grad: tensor([-0.0015,  0.0084])\n",
      "Epoch 3462, Loss 3.0\n",
      "    Params: tensor([  5.3590, -17.2557])\n",
      "    Grad: tensor([-0.0015,  0.0084])\n",
      "Epoch 3463, Loss 3.0\n",
      "    Params: tensor([  5.3591, -17.2558])\n",
      "    Grad: tensor([-0.0015,  0.0083])\n",
      "Epoch 3464, Loss 3.0\n",
      "    Params: tensor([  5.3591, -17.2559])\n",
      "    Grad: tensor([-0.0015,  0.0083])\n",
      "Epoch 3465, Loss 3.0\n",
      "    Params: tensor([  5.3591, -17.2560])\n",
      "    Grad: tensor([-0.0015,  0.0083])\n",
      "Epoch 3466, Loss 3.0\n",
      "    Params: tensor([  5.3591, -17.2560])\n",
      "    Grad: tensor([-0.0015,  0.0083])\n",
      "Epoch 3467, Loss 3.0\n",
      "    Params: tensor([  5.3591, -17.2561])\n",
      "    Grad: tensor([-0.0015,  0.0083])\n",
      "Epoch 3468, Loss 3.0\n",
      "    Params: tensor([  5.3591, -17.2562])\n",
      "    Grad: tensor([-0.0015,  0.0083])\n",
      "Epoch 3469, Loss 3.0\n",
      "    Params: tensor([  5.3592, -17.2563])\n",
      "    Grad: tensor([-0.0014,  0.0083])\n",
      "Epoch 3470, Loss 3.0\n",
      "    Params: tensor([  5.3592, -17.2564])\n",
      "    Grad: tensor([-0.0014,  0.0082])\n",
      "Epoch 3471, Loss 3.0\n",
      "    Params: tensor([  5.3592, -17.2564])\n",
      "    Grad: tensor([-0.0014,  0.0082])\n",
      "Epoch 3472, Loss 3.0\n",
      "    Params: tensor([  5.3592, -17.2565])\n",
      "    Grad: tensor([-0.0015,  0.0082])\n",
      "Epoch 3473, Loss 3.0\n",
      "    Params: tensor([  5.3592, -17.2566])\n",
      "    Grad: tensor([-0.0014,  0.0082])\n",
      "Epoch 3474, Loss 3.0\n",
      "    Params: tensor([  5.3592, -17.2567])\n",
      "    Grad: tensor([-0.0014,  0.0082])\n",
      "Epoch 3475, Loss 3.0\n",
      "    Params: tensor([  5.3592, -17.2568])\n",
      "    Grad: tensor([-0.0015,  0.0082])\n",
      "Epoch 3476, Loss 3.0\n",
      "    Params: tensor([  5.3593, -17.2569])\n",
      "    Grad: tensor([-0.0014,  0.0082])\n",
      "Epoch 3477, Loss 3.0\n",
      "    Params: tensor([  5.3593, -17.2569])\n",
      "    Grad: tensor([-0.0014,  0.0081])\n",
      "Epoch 3478, Loss 3.0\n",
      "    Params: tensor([  5.3593, -17.2570])\n",
      "    Grad: tensor([-0.0015,  0.0081])\n",
      "Epoch 3479, Loss 3.0\n",
      "    Params: tensor([  5.3593, -17.2571])\n",
      "    Grad: tensor([-0.0015,  0.0081])\n",
      "Epoch 3480, Loss 3.0\n",
      "    Params: tensor([  5.3593, -17.2572])\n",
      "    Grad: tensor([-0.0014,  0.0081])\n",
      "Epoch 3481, Loss 3.0\n",
      "    Params: tensor([  5.3593, -17.2573])\n",
      "    Grad: tensor([-0.0014,  0.0081])\n",
      "Epoch 3482, Loss 3.0\n",
      "    Params: tensor([  5.3593, -17.2573])\n",
      "    Grad: tensor([-0.0014,  0.0081])\n",
      "Epoch 3483, Loss 3.0\n",
      "    Params: tensor([  5.3594, -17.2574])\n",
      "    Grad: tensor([-0.0014,  0.0081])\n",
      "Epoch 3484, Loss 3.0\n",
      "    Params: tensor([  5.3594, -17.2575])\n",
      "    Grad: tensor([-0.0014,  0.0081])\n",
      "Epoch 3485, Loss 3.0\n",
      "    Params: tensor([  5.3594, -17.2576])\n",
      "    Grad: tensor([-0.0014,  0.0080])\n",
      "Epoch 3486, Loss 3.0\n",
      "    Params: tensor([  5.3594, -17.2577])\n",
      "    Grad: tensor([-0.0014,  0.0080])\n",
      "Epoch 3487, Loss 3.0\n",
      "    Params: tensor([  5.3594, -17.2577])\n",
      "    Grad: tensor([-0.0014,  0.0080])\n",
      "Epoch 3488, Loss 3.0\n",
      "    Params: tensor([  5.3594, -17.2578])\n",
      "    Grad: tensor([-0.0014,  0.0080])\n",
      "Epoch 3489, Loss 3.0\n",
      "    Params: tensor([  5.3594, -17.2579])\n",
      "    Grad: tensor([-0.0014,  0.0080])\n",
      "Epoch 3490, Loss 3.0\n",
      "    Params: tensor([  5.3595, -17.2580])\n",
      "    Grad: tensor([-0.0014,  0.0080])\n",
      "Epoch 3491, Loss 3.0\n",
      "    Params: tensor([  5.3595, -17.2581])\n",
      "    Grad: tensor([-0.0014,  0.0080])\n",
      "Epoch 3492, Loss 3.0\n",
      "    Params: tensor([  5.3595, -17.2581])\n",
      "    Grad: tensor([-0.0014,  0.0079])\n",
      "Epoch 3493, Loss 3.0\n",
      "    Params: tensor([  5.3595, -17.2582])\n",
      "    Grad: tensor([-0.0014,  0.0079])\n",
      "Epoch 3494, Loss 3.0\n",
      "    Params: tensor([  5.3595, -17.2583])\n",
      "    Grad: tensor([-0.0014,  0.0079])\n",
      "Epoch 3495, Loss 3.0\n",
      "    Params: tensor([  5.3595, -17.2584])\n",
      "    Grad: tensor([-0.0014,  0.0079])\n",
      "Epoch 3496, Loss 3.0\n",
      "    Params: tensor([  5.3595, -17.2585])\n",
      "    Grad: tensor([-0.0014,  0.0079])\n",
      "Epoch 3497, Loss 3.0\n",
      "    Params: tensor([  5.3595, -17.2585])\n",
      "    Grad: tensor([-0.0014,  0.0079])\n",
      "Epoch 3498, Loss 3.0\n",
      "    Params: tensor([  5.3596, -17.2586])\n",
      "    Grad: tensor([-0.0014,  0.0079])\n",
      "Epoch 3499, Loss 3.0\n",
      "    Params: tensor([  5.3596, -17.2587])\n",
      "    Grad: tensor([-0.0014,  0.0078])\n",
      "Epoch 3500, Loss 3.0\n",
      "    Params: tensor([  5.3596, -17.2588])\n",
      "    Grad: tensor([-0.0014,  0.0078])\n",
      "Epoch 3501, Loss 3.0\n",
      "    Params: tensor([  5.3596, -17.2588])\n",
      "    Grad: tensor([-0.0014,  0.0078])\n",
      "Epoch 3502, Loss 3.0\n",
      "    Params: tensor([  5.3596, -17.2589])\n",
      "    Grad: tensor([-0.0014,  0.0078])\n",
      "Epoch 3503, Loss 3.0\n",
      "    Params: tensor([  5.3596, -17.2590])\n",
      "    Grad: tensor([-0.0014,  0.0078])\n",
      "Epoch 3504, Loss 3.0\n",
      "    Params: tensor([  5.3596, -17.2591])\n",
      "    Grad: tensor([-0.0014,  0.0078])\n",
      "Epoch 3505, Loss 3.0\n",
      "    Params: tensor([  5.3597, -17.2592])\n",
      "    Grad: tensor([-0.0014,  0.0078])\n",
      "Epoch 3506, Loss 3.0\n",
      "    Params: tensor([  5.3597, -17.2592])\n",
      "    Grad: tensor([-0.0014,  0.0077])\n",
      "Epoch 3507, Loss 3.0\n",
      "    Params: tensor([  5.3597, -17.2593])\n",
      "    Grad: tensor([-0.0014,  0.0077])\n",
      "Epoch 3508, Loss 3.0\n",
      "    Params: tensor([  5.3597, -17.2594])\n",
      "    Grad: tensor([-0.0014,  0.0077])\n",
      "Epoch 3509, Loss 3.0\n",
      "    Params: tensor([  5.3597, -17.2595])\n",
      "    Grad: tensor([-0.0013,  0.0077])\n",
      "Epoch 3510, Loss 3.0\n",
      "    Params: tensor([  5.3597, -17.2595])\n",
      "    Grad: tensor([-0.0014,  0.0077])\n",
      "Epoch 3511, Loss 3.0\n",
      "    Params: tensor([  5.3597, -17.2596])\n",
      "    Grad: tensor([-0.0014,  0.0077])\n",
      "Epoch 3512, Loss 3.0\n",
      "    Params: tensor([  5.3598, -17.2597])\n",
      "    Grad: tensor([-0.0013,  0.0077])\n",
      "Epoch 3513, Loss 3.0\n",
      "    Params: tensor([  5.3598, -17.2598])\n",
      "    Grad: tensor([-0.0013,  0.0077])\n",
      "Epoch 3514, Loss 3.0\n",
      "    Params: tensor([  5.3598, -17.2598])\n",
      "    Grad: tensor([-0.0013,  0.0076])\n",
      "Epoch 3515, Loss 3.0\n",
      "    Params: tensor([  5.3598, -17.2599])\n",
      "    Grad: tensor([-0.0014,  0.0076])\n",
      "Epoch 3516, Loss 3.0\n",
      "    Params: tensor([  5.3598, -17.2600])\n",
      "    Grad: tensor([-0.0013,  0.0076])\n",
      "Epoch 3517, Loss 3.0\n",
      "    Params: tensor([  5.3598, -17.2601])\n",
      "    Grad: tensor([-0.0013,  0.0076])\n",
      "Epoch 3518, Loss 3.0\n",
      "    Params: tensor([  5.3598, -17.2602])\n",
      "    Grad: tensor([-0.0013,  0.0076])\n",
      "Epoch 3519, Loss 3.0\n",
      "    Params: tensor([  5.3598, -17.2602])\n",
      "    Grad: tensor([-0.0013,  0.0076])\n",
      "Epoch 3520, Loss 3.0\n",
      "    Params: tensor([  5.3599, -17.2603])\n",
      "    Grad: tensor([-0.0013,  0.0076])\n",
      "Epoch 3521, Loss 3.0\n",
      "    Params: tensor([  5.3599, -17.2604])\n",
      "    Grad: tensor([-0.0014,  0.0076])\n",
      "Epoch 3522, Loss 3.0\n",
      "    Params: tensor([  5.3599, -17.2605])\n",
      "    Grad: tensor([-0.0014,  0.0075])\n",
      "Epoch 3523, Loss 3.0\n",
      "    Params: tensor([  5.3599, -17.2605])\n",
      "    Grad: tensor([-0.0013,  0.0075])\n",
      "Epoch 3524, Loss 3.0\n",
      "    Params: tensor([  5.3599, -17.2606])\n",
      "    Grad: tensor([-0.0013,  0.0075])\n",
      "Epoch 3525, Loss 3.0\n",
      "    Params: tensor([  5.3599, -17.2607])\n",
      "    Grad: tensor([-0.0013,  0.0075])\n",
      "Epoch 3526, Loss 3.0\n",
      "    Params: tensor([  5.3599, -17.2608])\n",
      "    Grad: tensor([-0.0013,  0.0075])\n",
      "Epoch 3527, Loss 3.0\n",
      "    Params: tensor([  5.3600, -17.2608])\n",
      "    Grad: tensor([-0.0013,  0.0075])\n",
      "Epoch 3528, Loss 3.0\n",
      "    Params: tensor([  5.3600, -17.2609])\n",
      "    Grad: tensor([-0.0013,  0.0075])\n",
      "Epoch 3529, Loss 3.0\n",
      "    Params: tensor([  5.3600, -17.2610])\n",
      "    Grad: tensor([-0.0013,  0.0075])\n",
      "Epoch 3530, Loss 3.0\n",
      "    Params: tensor([  5.3600, -17.2611])\n",
      "    Grad: tensor([-0.0013,  0.0074])\n",
      "Epoch 3531, Loss 3.0\n",
      "    Params: tensor([  5.3600, -17.2611])\n",
      "    Grad: tensor([-0.0013,  0.0074])\n",
      "Epoch 3532, Loss 3.0\n",
      "    Params: tensor([  5.3600, -17.2612])\n",
      "    Grad: tensor([-0.0013,  0.0074])\n",
      "Epoch 3533, Loss 3.0\n",
      "    Params: tensor([  5.3600, -17.2613])\n",
      "    Grad: tensor([-0.0013,  0.0074])\n",
      "Epoch 3534, Loss 3.0\n",
      "    Params: tensor([  5.3600, -17.2614])\n",
      "    Grad: tensor([-0.0013,  0.0074])\n",
      "Epoch 3535, Loss 3.0\n",
      "    Params: tensor([  5.3601, -17.2614])\n",
      "    Grad: tensor([-0.0013,  0.0074])\n",
      "Epoch 3536, Loss 3.0\n",
      "    Params: tensor([  5.3601, -17.2615])\n",
      "    Grad: tensor([-0.0013,  0.0074])\n",
      "Epoch 3537, Loss 3.0\n",
      "    Params: tensor([  5.3601, -17.2616])\n",
      "    Grad: tensor([-0.0013,  0.0074])\n",
      "Epoch 3538, Loss 3.0\n",
      "    Params: tensor([  5.3601, -17.2616])\n",
      "    Grad: tensor([-0.0013,  0.0073])\n",
      "Epoch 3539, Loss 3.0\n",
      "    Params: tensor([  5.3601, -17.2617])\n",
      "    Grad: tensor([-0.0013,  0.0073])\n",
      "Epoch 3540, Loss 3.0\n",
      "    Params: tensor([  5.3601, -17.2618])\n",
      "    Grad: tensor([-0.0013,  0.0073])\n",
      "Epoch 3541, Loss 3.0\n",
      "    Params: tensor([  5.3601, -17.2619])\n",
      "    Grad: tensor([-0.0013,  0.0073])\n",
      "Epoch 3542, Loss 3.0\n",
      "    Params: tensor([  5.3602, -17.2619])\n",
      "    Grad: tensor([-0.0013,  0.0073])\n",
      "Epoch 3543, Loss 3.0\n",
      "    Params: tensor([  5.3602, -17.2620])\n",
      "    Grad: tensor([-0.0013,  0.0073])\n",
      "Epoch 3544, Loss 3.0\n",
      "    Params: tensor([  5.3602, -17.2621])\n",
      "    Grad: tensor([-0.0013,  0.0073])\n",
      "Epoch 3545, Loss 3.0\n",
      "    Params: tensor([  5.3602, -17.2622])\n",
      "    Grad: tensor([-0.0013,  0.0073])\n",
      "Epoch 3546, Loss 3.0\n",
      "    Params: tensor([  5.3602, -17.2622])\n",
      "    Grad: tensor([-0.0013,  0.0072])\n",
      "Epoch 3547, Loss 3.0\n",
      "    Params: tensor([  5.3602, -17.2623])\n",
      "    Grad: tensor([-0.0013,  0.0072])\n",
      "Epoch 3548, Loss 3.0\n",
      "    Params: tensor([  5.3602, -17.2624])\n",
      "    Grad: tensor([-0.0013,  0.0072])\n",
      "Epoch 3549, Loss 3.0\n",
      "    Params: tensor([  5.3602, -17.2624])\n",
      "    Grad: tensor([-0.0013,  0.0072])\n",
      "Epoch 3550, Loss 3.0\n",
      "    Params: tensor([  5.3603, -17.2625])\n",
      "    Grad: tensor([-0.0013,  0.0072])\n",
      "Epoch 3551, Loss 3.0\n",
      "    Params: tensor([  5.3603, -17.2626])\n",
      "    Grad: tensor([-0.0013,  0.0072])\n",
      "Epoch 3552, Loss 3.0\n",
      "    Params: tensor([  5.3603, -17.2627])\n",
      "    Grad: tensor([-0.0013,  0.0072])\n",
      "Epoch 3553, Loss 3.0\n",
      "    Params: tensor([  5.3603, -17.2627])\n",
      "    Grad: tensor([-0.0013,  0.0072])\n",
      "Epoch 3554, Loss 3.0\n",
      "    Params: tensor([  5.3603, -17.2628])\n",
      "    Grad: tensor([-0.0013,  0.0071])\n",
      "Epoch 3555, Loss 3.0\n",
      "    Params: tensor([  5.3603, -17.2629])\n",
      "    Grad: tensor([-0.0013,  0.0071])\n",
      "Epoch 3556, Loss 3.0\n",
      "    Params: tensor([  5.3603, -17.2629])\n",
      "    Grad: tensor([-0.0012,  0.0071])\n",
      "Epoch 3557, Loss 3.0\n",
      "    Params: tensor([  5.3603, -17.2630])\n",
      "    Grad: tensor([-0.0012,  0.0071])\n",
      "Epoch 3558, Loss 3.0\n",
      "    Params: tensor([  5.3604, -17.2631])\n",
      "    Grad: tensor([-0.0013,  0.0071])\n",
      "Epoch 3559, Loss 3.0\n",
      "    Params: tensor([  5.3604, -17.2632])\n",
      "    Grad: tensor([-0.0013,  0.0071])\n",
      "Epoch 3560, Loss 3.0\n",
      "    Params: tensor([  5.3604, -17.2632])\n",
      "    Grad: tensor([-0.0013,  0.0071])\n",
      "Epoch 3561, Loss 3.0\n",
      "    Params: tensor([  5.3604, -17.2633])\n",
      "    Grad: tensor([-0.0013,  0.0071])\n",
      "Epoch 3562, Loss 3.0\n",
      "    Params: tensor([  5.3604, -17.2634])\n",
      "    Grad: tensor([-0.0013,  0.0070])\n",
      "Epoch 3563, Loss 3.0\n",
      "    Params: tensor([  5.3604, -17.2634])\n",
      "    Grad: tensor([-0.0013,  0.0070])\n",
      "Epoch 3564, Loss 3.0\n",
      "    Params: tensor([  5.3604, -17.2635])\n",
      "    Grad: tensor([-0.0013,  0.0070])\n",
      "Epoch 3565, Loss 3.0\n",
      "    Params: tensor([  5.3604, -17.2636])\n",
      "    Grad: tensor([-0.0012,  0.0070])\n",
      "Epoch 3566, Loss 3.0\n",
      "    Params: tensor([  5.3605, -17.2637])\n",
      "    Grad: tensor([-0.0012,  0.0070])\n",
      "Epoch 3567, Loss 3.0\n",
      "    Params: tensor([  5.3605, -17.2637])\n",
      "    Grad: tensor([-0.0012,  0.0070])\n",
      "Epoch 3568, Loss 3.0\n",
      "    Params: tensor([  5.3605, -17.2638])\n",
      "    Grad: tensor([-0.0012,  0.0070])\n",
      "Epoch 3569, Loss 3.0\n",
      "    Params: tensor([  5.3605, -17.2639])\n",
      "    Grad: tensor([-0.0012,  0.0070])\n",
      "Epoch 3570, Loss 3.0\n",
      "    Params: tensor([  5.3605, -17.2639])\n",
      "    Grad: tensor([-0.0012,  0.0070])\n",
      "Epoch 3571, Loss 3.0\n",
      "    Params: tensor([  5.3605, -17.2640])\n",
      "    Grad: tensor([-0.0012,  0.0069])\n",
      "Epoch 3572, Loss 3.0\n",
      "    Params: tensor([  5.3605, -17.2641])\n",
      "    Grad: tensor([-0.0012,  0.0069])\n",
      "Epoch 3573, Loss 3.0\n",
      "    Params: tensor([  5.3605, -17.2641])\n",
      "    Grad: tensor([-0.0012,  0.0069])\n",
      "Epoch 3574, Loss 3.0\n",
      "    Params: tensor([  5.3606, -17.2642])\n",
      "    Grad: tensor([-0.0012,  0.0069])\n",
      "Epoch 3575, Loss 3.0\n",
      "    Params: tensor([  5.3606, -17.2643])\n",
      "    Grad: tensor([-0.0012,  0.0069])\n",
      "Epoch 3576, Loss 3.0\n",
      "    Params: tensor([  5.3606, -17.2643])\n",
      "    Grad: tensor([-0.0012,  0.0069])\n",
      "Epoch 3577, Loss 3.0\n",
      "    Params: tensor([  5.3606, -17.2644])\n",
      "    Grad: tensor([-0.0012,  0.0069])\n",
      "Epoch 3578, Loss 3.0\n",
      "    Params: tensor([  5.3606, -17.2645])\n",
      "    Grad: tensor([-0.0012,  0.0069])\n",
      "Epoch 3579, Loss 3.0\n",
      "    Params: tensor([  5.3606, -17.2645])\n",
      "    Grad: tensor([-0.0012,  0.0068])\n",
      "Epoch 3580, Loss 3.0\n",
      "    Params: tensor([  5.3606, -17.2646])\n",
      "    Grad: tensor([-0.0012,  0.0068])\n",
      "Epoch 3581, Loss 3.0\n",
      "    Params: tensor([  5.3606, -17.2647])\n",
      "    Grad: tensor([-0.0012,  0.0068])\n",
      "Epoch 3582, Loss 3.0\n",
      "    Params: tensor([  5.3606, -17.2648])\n",
      "    Grad: tensor([-0.0012,  0.0068])\n",
      "Epoch 3583, Loss 3.0\n",
      "    Params: tensor([  5.3607, -17.2648])\n",
      "    Grad: tensor([-0.0012,  0.0068])\n",
      "Epoch 3584, Loss 3.0\n",
      "    Params: tensor([  5.3607, -17.2649])\n",
      "    Grad: tensor([-0.0012,  0.0068])\n",
      "Epoch 3585, Loss 3.0\n",
      "    Params: tensor([  5.3607, -17.2650])\n",
      "    Grad: tensor([-0.0012,  0.0068])\n",
      "Epoch 3586, Loss 3.0\n",
      "    Params: tensor([  5.3607, -17.2650])\n",
      "    Grad: tensor([-0.0012,  0.0068])\n",
      "Epoch 3587, Loss 3.0\n",
      "    Params: tensor([  5.3607, -17.2651])\n",
      "    Grad: tensor([-0.0012,  0.0068])\n",
      "Epoch 3588, Loss 3.0\n",
      "    Params: tensor([  5.3607, -17.2652])\n",
      "    Grad: tensor([-0.0012,  0.0067])\n",
      "Epoch 3589, Loss 3.0\n",
      "    Params: tensor([  5.3607, -17.2652])\n",
      "    Grad: tensor([-0.0012,  0.0067])\n",
      "Epoch 3590, Loss 3.0\n",
      "    Params: tensor([  5.3607, -17.2653])\n",
      "    Grad: tensor([-0.0012,  0.0067])\n",
      "Epoch 3591, Loss 3.0\n",
      "    Params: tensor([  5.3608, -17.2654])\n",
      "    Grad: tensor([-0.0012,  0.0067])\n",
      "Epoch 3592, Loss 3.0\n",
      "    Params: tensor([  5.3608, -17.2654])\n",
      "    Grad: tensor([-0.0012,  0.0067])\n",
      "Epoch 3593, Loss 3.0\n",
      "    Params: tensor([  5.3608, -17.2655])\n",
      "    Grad: tensor([-0.0012,  0.0067])\n",
      "Epoch 3594, Loss 3.0\n",
      "    Params: tensor([  5.3608, -17.2656])\n",
      "    Grad: tensor([-0.0012,  0.0067])\n",
      "Epoch 3595, Loss 3.0\n",
      "    Params: tensor([  5.3608, -17.2656])\n",
      "    Grad: tensor([-0.0012,  0.0067])\n",
      "Epoch 3596, Loss 3.0\n",
      "    Params: tensor([  5.3608, -17.2657])\n",
      "    Grad: tensor([-0.0012,  0.0067])\n",
      "Epoch 3597, Loss 3.0\n",
      "    Params: tensor([  5.3608, -17.2658])\n",
      "    Grad: tensor([-0.0012,  0.0066])\n",
      "Epoch 3598, Loss 3.0\n",
      "    Params: tensor([  5.3608, -17.2658])\n",
      "    Grad: tensor([-0.0012,  0.0066])\n",
      "Epoch 3599, Loss 3.0\n",
      "    Params: tensor([  5.3608, -17.2659])\n",
      "    Grad: tensor([-0.0012,  0.0066])\n",
      "Epoch 3600, Loss 3.0\n",
      "    Params: tensor([  5.3609, -17.2660])\n",
      "    Grad: tensor([-0.0012,  0.0066])\n",
      "Epoch 3601, Loss 3.0\n",
      "    Params: tensor([  5.3609, -17.2660])\n",
      "    Grad: tensor([-0.0012,  0.0066])\n",
      "Epoch 3602, Loss 3.0\n",
      "    Params: tensor([  5.3609, -17.2661])\n",
      "    Grad: tensor([-0.0012,  0.0066])\n",
      "Epoch 3603, Loss 3.0\n",
      "    Params: tensor([  5.3609, -17.2662])\n",
      "    Grad: tensor([-0.0012,  0.0066])\n",
      "Epoch 3604, Loss 3.0\n",
      "    Params: tensor([  5.3609, -17.2662])\n",
      "    Grad: tensor([-0.0012,  0.0066])\n",
      "Epoch 3605, Loss 3.0\n",
      "    Params: tensor([  5.3609, -17.2663])\n",
      "    Grad: tensor([-0.0011,  0.0066])\n",
      "Epoch 3606, Loss 3.0\n",
      "    Params: tensor([  5.3609, -17.2664])\n",
      "    Grad: tensor([-0.0012,  0.0065])\n",
      "Epoch 3607, Loss 3.0\n",
      "    Params: tensor([  5.3609, -17.2664])\n",
      "    Grad: tensor([-0.0011,  0.0065])\n",
      "Epoch 3608, Loss 3.0\n",
      "    Params: tensor([  5.3610, -17.2665])\n",
      "    Grad: tensor([-0.0012,  0.0065])\n",
      "Epoch 3609, Loss 3.0\n",
      "    Params: tensor([  5.3610, -17.2665])\n",
      "    Grad: tensor([-0.0011,  0.0065])\n",
      "Epoch 3610, Loss 3.0\n",
      "    Params: tensor([  5.3610, -17.2666])\n",
      "    Grad: tensor([-0.0011,  0.0065])\n",
      "Epoch 3611, Loss 3.0\n",
      "    Params: tensor([  5.3610, -17.2667])\n",
      "    Grad: tensor([-0.0011,  0.0065])\n",
      "Epoch 3612, Loss 3.0\n",
      "    Params: tensor([  5.3610, -17.2667])\n",
      "    Grad: tensor([-0.0011,  0.0065])\n",
      "Epoch 3613, Loss 3.0\n",
      "    Params: tensor([  5.3610, -17.2668])\n",
      "    Grad: tensor([-0.0011,  0.0065])\n",
      "Epoch 3614, Loss 3.0\n",
      "    Params: tensor([  5.3610, -17.2669])\n",
      "    Grad: tensor([-0.0011,  0.0065])\n",
      "Epoch 3615, Loss 3.0\n",
      "    Params: tensor([  5.3610, -17.2669])\n",
      "    Grad: tensor([-0.0011,  0.0064])\n",
      "Epoch 3616, Loss 3.0\n",
      "    Params: tensor([  5.3610, -17.2670])\n",
      "    Grad: tensor([-0.0011,  0.0064])\n",
      "Epoch 3617, Loss 3.0\n",
      "    Params: tensor([  5.3611, -17.2671])\n",
      "    Grad: tensor([-0.0011,  0.0064])\n",
      "Epoch 3618, Loss 3.0\n",
      "    Params: tensor([  5.3611, -17.2671])\n",
      "    Grad: tensor([-0.0011,  0.0064])\n",
      "Epoch 3619, Loss 3.0\n",
      "    Params: tensor([  5.3611, -17.2672])\n",
      "    Grad: tensor([-0.0011,  0.0064])\n",
      "Epoch 3620, Loss 3.0\n",
      "    Params: tensor([  5.3611, -17.2673])\n",
      "    Grad: tensor([-0.0011,  0.0064])\n",
      "Epoch 3621, Loss 3.0\n",
      "    Params: tensor([  5.3611, -17.2673])\n",
      "    Grad: tensor([-0.0011,  0.0064])\n",
      "Epoch 3622, Loss 3.0\n",
      "    Params: tensor([  5.3611, -17.2674])\n",
      "    Grad: tensor([-0.0011,  0.0064])\n",
      "Epoch 3623, Loss 3.0\n",
      "    Params: tensor([  5.3611, -17.2674])\n",
      "    Grad: tensor([-0.0011,  0.0064])\n",
      "Epoch 3624, Loss 3.0\n",
      "    Params: tensor([  5.3611, -17.2675])\n",
      "    Grad: tensor([-0.0011,  0.0063])\n",
      "Epoch 3625, Loss 3.0\n",
      "    Params: tensor([  5.3611, -17.2676])\n",
      "    Grad: tensor([-0.0011,  0.0063])\n",
      "Epoch 3626, Loss 3.0\n",
      "    Params: tensor([  5.3612, -17.2676])\n",
      "    Grad: tensor([-0.0011,  0.0063])\n",
      "Epoch 3627, Loss 3.0\n",
      "    Params: tensor([  5.3612, -17.2677])\n",
      "    Grad: tensor([-0.0011,  0.0063])\n",
      "Epoch 3628, Loss 3.0\n",
      "    Params: tensor([  5.3612, -17.2678])\n",
      "    Grad: tensor([-0.0011,  0.0063])\n",
      "Epoch 3629, Loss 3.0\n",
      "    Params: tensor([  5.3612, -17.2678])\n",
      "    Grad: tensor([-0.0011,  0.0063])\n",
      "Epoch 3630, Loss 3.0\n",
      "    Params: tensor([  5.3612, -17.2679])\n",
      "    Grad: tensor([-0.0011,  0.0063])\n",
      "Epoch 3631, Loss 3.0\n",
      "    Params: tensor([  5.3612, -17.2680])\n",
      "    Grad: tensor([-0.0011,  0.0063])\n",
      "Epoch 3632, Loss 3.0\n",
      "    Params: tensor([  5.3612, -17.2680])\n",
      "    Grad: tensor([-0.0011,  0.0063])\n",
      "Epoch 3633, Loss 3.0\n",
      "    Params: tensor([  5.3612, -17.2681])\n",
      "    Grad: tensor([-0.0011,  0.0062])\n",
      "Epoch 3634, Loss 3.0\n",
      "    Params: tensor([  5.3612, -17.2681])\n",
      "    Grad: tensor([-0.0011,  0.0062])\n",
      "Epoch 3635, Loss 3.0\n",
      "    Params: tensor([  5.3613, -17.2682])\n",
      "    Grad: tensor([-0.0011,  0.0062])\n",
      "Epoch 3636, Loss 3.0\n",
      "    Params: tensor([  5.3613, -17.2683])\n",
      "    Grad: tensor([-0.0011,  0.0062])\n",
      "Epoch 3637, Loss 3.0\n",
      "    Params: tensor([  5.3613, -17.2683])\n",
      "    Grad: tensor([-0.0011,  0.0062])\n",
      "Epoch 3638, Loss 3.0\n",
      "    Params: tensor([  5.3613, -17.2684])\n",
      "    Grad: tensor([-0.0011,  0.0062])\n",
      "Epoch 3639, Loss 3.0\n",
      "    Params: tensor([  5.3613, -17.2685])\n",
      "    Grad: tensor([-0.0011,  0.0062])\n",
      "Epoch 3640, Loss 3.0\n",
      "    Params: tensor([  5.3613, -17.2685])\n",
      "    Grad: tensor([-0.0011,  0.0062])\n",
      "Epoch 3641, Loss 3.0\n",
      "    Params: tensor([  5.3613, -17.2686])\n",
      "    Grad: tensor([-0.0011,  0.0062])\n",
      "Epoch 3642, Loss 3.0\n",
      "    Params: tensor([  5.3613, -17.2686])\n",
      "    Grad: tensor([-0.0011,  0.0062])\n",
      "Epoch 3643, Loss 3.0\n",
      "    Params: tensor([  5.3613, -17.2687])\n",
      "    Grad: tensor([-0.0011,  0.0061])\n",
      "Epoch 3644, Loss 3.0\n",
      "    Params: tensor([  5.3614, -17.2688])\n",
      "    Grad: tensor([-0.0011,  0.0061])\n",
      "Epoch 3645, Loss 3.0\n",
      "    Params: tensor([  5.3614, -17.2688])\n",
      "    Grad: tensor([-0.0011,  0.0061])\n",
      "Epoch 3646, Loss 3.0\n",
      "    Params: tensor([  5.3614, -17.2689])\n",
      "    Grad: tensor([-0.0011,  0.0061])\n",
      "Epoch 3647, Loss 3.0\n",
      "    Params: tensor([  5.3614, -17.2689])\n",
      "    Grad: tensor([-0.0011,  0.0061])\n",
      "Epoch 3648, Loss 3.0\n",
      "    Params: tensor([  5.3614, -17.2690])\n",
      "    Grad: tensor([-0.0011,  0.0061])\n",
      "Epoch 3649, Loss 3.0\n",
      "    Params: tensor([  5.3614, -17.2691])\n",
      "    Grad: tensor([-0.0011,  0.0061])\n",
      "Epoch 3650, Loss 3.0\n",
      "    Params: tensor([  5.3614, -17.2691])\n",
      "    Grad: tensor([-0.0011,  0.0061])\n",
      "Epoch 3651, Loss 3.0\n",
      "    Params: tensor([  5.3614, -17.2692])\n",
      "    Grad: tensor([-0.0011,  0.0061])\n",
      "Epoch 3652, Loss 3.0\n",
      "    Params: tensor([  5.3614, -17.2692])\n",
      "    Grad: tensor([-0.0011,  0.0060])\n",
      "Epoch 3653, Loss 3.0\n",
      "    Params: tensor([  5.3615, -17.2693])\n",
      "    Grad: tensor([-0.0011,  0.0060])\n",
      "Epoch 3654, Loss 3.0\n",
      "    Params: tensor([  5.3615, -17.2694])\n",
      "    Grad: tensor([-0.0011,  0.0060])\n",
      "Epoch 3655, Loss 3.0\n",
      "    Params: tensor([  5.3615, -17.2694])\n",
      "    Grad: tensor([-0.0011,  0.0060])\n",
      "Epoch 3656, Loss 3.0\n",
      "    Params: tensor([  5.3615, -17.2695])\n",
      "    Grad: tensor([-0.0011,  0.0060])\n",
      "Epoch 3657, Loss 3.0\n",
      "    Params: tensor([  5.3615, -17.2695])\n",
      "    Grad: tensor([-0.0011,  0.0060])\n",
      "Epoch 3658, Loss 3.0\n",
      "    Params: tensor([  5.3615, -17.2696])\n",
      "    Grad: tensor([-0.0010,  0.0060])\n",
      "Epoch 3659, Loss 3.0\n",
      "    Params: tensor([  5.3615, -17.2697])\n",
      "    Grad: tensor([-0.0010,  0.0060])\n",
      "Epoch 3660, Loss 3.0\n",
      "    Params: tensor([  5.3615, -17.2697])\n",
      "    Grad: tensor([-0.0010,  0.0060])\n",
      "Epoch 3661, Loss 3.0\n",
      "    Params: tensor([  5.3615, -17.2698])\n",
      "    Grad: tensor([-0.0010,  0.0060])\n",
      "Epoch 3662, Loss 3.0\n",
      "    Params: tensor([  5.3615, -17.2698])\n",
      "    Grad: tensor([-0.0010,  0.0059])\n",
      "Epoch 3663, Loss 3.0\n",
      "    Params: tensor([  5.3616, -17.2699])\n",
      "    Grad: tensor([-0.0010,  0.0059])\n",
      "Epoch 3664, Loss 3.0\n",
      "    Params: tensor([  5.3616, -17.2700])\n",
      "    Grad: tensor([-0.0010,  0.0059])\n",
      "Epoch 3665, Loss 3.0\n",
      "    Params: tensor([  5.3616, -17.2700])\n",
      "    Grad: tensor([-0.0010,  0.0059])\n",
      "Epoch 3666, Loss 3.0\n",
      "    Params: tensor([  5.3616, -17.2701])\n",
      "    Grad: tensor([-0.0010,  0.0059])\n",
      "Epoch 3667, Loss 3.0\n",
      "    Params: tensor([  5.3616, -17.2701])\n",
      "    Grad: tensor([-0.0010,  0.0059])\n",
      "Epoch 3668, Loss 3.0\n",
      "    Params: tensor([  5.3616, -17.2702])\n",
      "    Grad: tensor([-0.0010,  0.0059])\n",
      "Epoch 3669, Loss 3.0\n",
      "    Params: tensor([  5.3616, -17.2703])\n",
      "    Grad: tensor([-0.0010,  0.0059])\n",
      "Epoch 3670, Loss 3.0\n",
      "    Params: tensor([  5.3616, -17.2703])\n",
      "    Grad: tensor([-0.0010,  0.0059])\n",
      "Epoch 3671, Loss 3.0\n",
      "    Params: tensor([  5.3616, -17.2704])\n",
      "    Grad: tensor([-0.0011,  0.0059])\n",
      "Epoch 3672, Loss 3.0\n",
      "    Params: tensor([  5.3617, -17.2704])\n",
      "    Grad: tensor([-0.0010,  0.0058])\n",
      "Epoch 3673, Loss 3.0\n",
      "    Params: tensor([  5.3617, -17.2705])\n",
      "    Grad: tensor([-0.0010,  0.0058])\n",
      "Epoch 3674, Loss 3.0\n",
      "    Params: tensor([  5.3617, -17.2706])\n",
      "    Grad: tensor([-0.0010,  0.0058])\n",
      "Epoch 3675, Loss 3.0\n",
      "    Params: tensor([  5.3617, -17.2706])\n",
      "    Grad: tensor([-0.0010,  0.0058])\n",
      "Epoch 3676, Loss 3.0\n",
      "    Params: tensor([  5.3617, -17.2707])\n",
      "    Grad: tensor([-0.0010,  0.0058])\n",
      "Epoch 3677, Loss 3.0\n",
      "    Params: tensor([  5.3617, -17.2707])\n",
      "    Grad: tensor([-0.0010,  0.0058])\n",
      "Epoch 3678, Loss 3.0\n",
      "    Params: tensor([  5.3617, -17.2708])\n",
      "    Grad: tensor([-0.0010,  0.0058])\n",
      "Epoch 3679, Loss 3.0\n",
      "    Params: tensor([  5.3617, -17.2708])\n",
      "    Grad: tensor([-0.0010,  0.0058])\n",
      "Epoch 3680, Loss 3.0\n",
      "    Params: tensor([  5.3617, -17.2709])\n",
      "    Grad: tensor([-0.0010,  0.0058])\n",
      "Epoch 3681, Loss 3.0\n",
      "    Params: tensor([  5.3617, -17.2710])\n",
      "    Grad: tensor([-0.0010,  0.0058])\n",
      "Epoch 3682, Loss 3.0\n",
      "    Params: tensor([  5.3618, -17.2710])\n",
      "    Grad: tensor([-0.0010,  0.0058])\n",
      "Epoch 3683, Loss 3.0\n",
      "    Params: tensor([  5.3618, -17.2711])\n",
      "    Grad: tensor([-0.0010,  0.0057])\n",
      "Epoch 3684, Loss 3.0\n",
      "    Params: tensor([  5.3618, -17.2711])\n",
      "    Grad: tensor([-0.0010,  0.0057])\n",
      "Epoch 3685, Loss 3.0\n",
      "    Params: tensor([  5.3618, -17.2712])\n",
      "    Grad: tensor([-0.0010,  0.0057])\n",
      "Epoch 3686, Loss 3.0\n",
      "    Params: tensor([  5.3618, -17.2712])\n",
      "    Grad: tensor([-0.0010,  0.0057])\n",
      "Epoch 3687, Loss 3.0\n",
      "    Params: tensor([  5.3618, -17.2713])\n",
      "    Grad: tensor([-0.0010,  0.0057])\n",
      "Epoch 3688, Loss 3.0\n",
      "    Params: tensor([  5.3618, -17.2714])\n",
      "    Grad: tensor([-0.0010,  0.0057])\n",
      "Epoch 3689, Loss 3.0\n",
      "    Params: tensor([  5.3618, -17.2714])\n",
      "    Grad: tensor([-0.0010,  0.0057])\n",
      "Epoch 3690, Loss 3.0\n",
      "    Params: tensor([  5.3618, -17.2715])\n",
      "    Grad: tensor([-0.0010,  0.0057])\n",
      "Epoch 3691, Loss 3.0\n",
      "    Params: tensor([  5.3618, -17.2715])\n",
      "    Grad: tensor([-0.0010,  0.0057])\n",
      "Epoch 3692, Loss 3.0\n",
      "    Params: tensor([  5.3619, -17.2716])\n",
      "    Grad: tensor([-0.0010,  0.0056])\n",
      "Epoch 3693, Loss 3.0\n",
      "    Params: tensor([  5.3619, -17.2716])\n",
      "    Grad: tensor([-0.0010,  0.0056])\n",
      "Epoch 3694, Loss 3.0\n",
      "    Params: tensor([  5.3619, -17.2717])\n",
      "    Grad: tensor([-0.0010,  0.0056])\n",
      "Epoch 3695, Loss 3.0\n",
      "    Params: tensor([  5.3619, -17.2717])\n",
      "    Grad: tensor([-0.0010,  0.0056])\n",
      "Epoch 3696, Loss 3.0\n",
      "    Params: tensor([  5.3619, -17.2718])\n",
      "    Grad: tensor([-0.0010,  0.0056])\n",
      "Epoch 3697, Loss 3.0\n",
      "    Params: tensor([  5.3619, -17.2719])\n",
      "    Grad: tensor([-0.0010,  0.0056])\n",
      "Epoch 3698, Loss 3.0\n",
      "    Params: tensor([  5.3619, -17.2719])\n",
      "    Grad: tensor([-0.0010,  0.0056])\n",
      "Epoch 3699, Loss 3.0\n",
      "    Params: tensor([  5.3619, -17.2720])\n",
      "    Grad: tensor([-0.0010,  0.0056])\n",
      "Epoch 3700, Loss 3.0\n",
      "    Params: tensor([  5.3619, -17.2720])\n",
      "    Grad: tensor([-0.0010,  0.0056])\n",
      "Epoch 3701, Loss 3.0\n",
      "    Params: tensor([  5.3619, -17.2721])\n",
      "    Grad: tensor([-0.0010,  0.0056])\n",
      "Epoch 3702, Loss 3.0\n",
      "    Params: tensor([  5.3620, -17.2721])\n",
      "    Grad: tensor([-0.0010,  0.0056])\n",
      "Epoch 3703, Loss 3.0\n",
      "    Params: tensor([  5.3620, -17.2722])\n",
      "    Grad: tensor([-0.0010,  0.0055])\n",
      "Epoch 3704, Loss 3.0\n",
      "    Params: tensor([  5.3620, -17.2722])\n",
      "    Grad: tensor([-0.0010,  0.0055])\n",
      "Epoch 3705, Loss 3.0\n",
      "    Params: tensor([  5.3620, -17.2723])\n",
      "    Grad: tensor([-0.0010,  0.0055])\n",
      "Epoch 3706, Loss 3.0\n",
      "    Params: tensor([  5.3620, -17.2724])\n",
      "    Grad: tensor([-0.0010,  0.0055])\n",
      "Epoch 3707, Loss 3.0\n",
      "    Params: tensor([  5.3620, -17.2724])\n",
      "    Grad: tensor([-0.0010,  0.0055])\n",
      "Epoch 3708, Loss 3.0\n",
      "    Params: tensor([  5.3620, -17.2725])\n",
      "    Grad: tensor([-0.0010,  0.0055])\n",
      "Epoch 3709, Loss 3.0\n",
      "    Params: tensor([  5.3620, -17.2725])\n",
      "    Grad: tensor([-0.0010,  0.0055])\n",
      "Epoch 3710, Loss 3.0\n",
      "    Params: tensor([  5.3620, -17.2726])\n",
      "    Grad: tensor([-0.0010,  0.0055])\n",
      "Epoch 3711, Loss 3.0\n",
      "    Params: tensor([  5.3620, -17.2726])\n",
      "    Grad: tensor([-0.0010,  0.0055])\n",
      "Epoch 3712, Loss 3.0\n",
      "    Params: tensor([  5.3620, -17.2727])\n",
      "    Grad: tensor([-0.0010,  0.0055])\n",
      "Epoch 3713, Loss 3.0\n",
      "    Params: tensor([  5.3621, -17.2727])\n",
      "    Grad: tensor([-0.0010,  0.0055])\n",
      "Epoch 3714, Loss 3.0\n",
      "    Params: tensor([  5.3621, -17.2728])\n",
      "    Grad: tensor([-0.0010,  0.0054])\n",
      "Epoch 3715, Loss 3.0\n",
      "    Params: tensor([  5.3621, -17.2729])\n",
      "    Grad: tensor([-0.0010,  0.0054])\n",
      "Epoch 3716, Loss 3.0\n",
      "    Params: tensor([  5.3621, -17.2729])\n",
      "    Grad: tensor([-0.0010,  0.0054])\n",
      "Epoch 3717, Loss 3.0\n",
      "    Params: tensor([  5.3621, -17.2730])\n",
      "    Grad: tensor([-0.0009,  0.0054])\n",
      "Epoch 3718, Loss 3.0\n",
      "    Params: tensor([  5.3621, -17.2730])\n",
      "    Grad: tensor([-0.0009,  0.0054])\n",
      "Epoch 3719, Loss 3.0\n",
      "    Params: tensor([  5.3621, -17.2731])\n",
      "    Grad: tensor([-0.0009,  0.0054])\n",
      "Epoch 3720, Loss 3.0\n",
      "    Params: tensor([  5.3621, -17.2731])\n",
      "    Grad: tensor([-0.0009,  0.0054])\n",
      "Epoch 3721, Loss 3.0\n",
      "    Params: tensor([  5.3621, -17.2732])\n",
      "    Grad: tensor([-0.0009,  0.0054])\n",
      "Epoch 3722, Loss 3.0\n",
      "    Params: tensor([  5.3621, -17.2732])\n",
      "    Grad: tensor([-0.0009,  0.0054])\n",
      "Epoch 3723, Loss 3.0\n",
      "    Params: tensor([  5.3622, -17.2733])\n",
      "    Grad: tensor([-0.0009,  0.0054])\n",
      "Epoch 3724, Loss 3.0\n",
      "    Params: tensor([  5.3622, -17.2733])\n",
      "    Grad: tensor([-0.0009,  0.0054])\n",
      "Epoch 3725, Loss 3.0\n",
      "    Params: tensor([  5.3622, -17.2734])\n",
      "    Grad: tensor([-0.0009,  0.0053])\n",
      "Epoch 3726, Loss 3.0\n",
      "    Params: tensor([  5.3622, -17.2734])\n",
      "    Grad: tensor([-0.0009,  0.0053])\n",
      "Epoch 3727, Loss 3.0\n",
      "    Params: tensor([  5.3622, -17.2735])\n",
      "    Grad: tensor([-0.0009,  0.0053])\n",
      "Epoch 3728, Loss 3.0\n",
      "    Params: tensor([  5.3622, -17.2735])\n",
      "    Grad: tensor([-0.0010,  0.0053])\n",
      "Epoch 3729, Loss 3.0\n",
      "    Params: tensor([  5.3622, -17.2736])\n",
      "    Grad: tensor([-0.0009,  0.0053])\n",
      "Epoch 3730, Loss 3.0\n",
      "    Params: tensor([  5.3622, -17.2737])\n",
      "    Grad: tensor([-0.0009,  0.0053])\n",
      "Epoch 3731, Loss 3.0\n",
      "    Params: tensor([  5.3622, -17.2737])\n",
      "    Grad: tensor([-0.0009,  0.0053])\n",
      "Epoch 3732, Loss 3.0\n",
      "    Params: tensor([  5.3622, -17.2738])\n",
      "    Grad: tensor([-0.0010,  0.0053])\n",
      "Epoch 3733, Loss 3.0\n",
      "    Params: tensor([  5.3622, -17.2738])\n",
      "    Grad: tensor([-0.0009,  0.0053])\n",
      "Epoch 3734, Loss 3.0\n",
      "    Params: tensor([  5.3623, -17.2739])\n",
      "    Grad: tensor([-0.0009,  0.0053])\n",
      "Epoch 3735, Loss 3.0\n",
      "    Params: tensor([  5.3623, -17.2739])\n",
      "    Grad: tensor([-0.0009,  0.0053])\n",
      "Epoch 3736, Loss 3.0\n",
      "    Params: tensor([  5.3623, -17.2740])\n",
      "    Grad: tensor([-0.0009,  0.0052])\n",
      "Epoch 3737, Loss 3.0\n",
      "    Params: tensor([  5.3623, -17.2740])\n",
      "    Grad: tensor([-0.0009,  0.0052])\n",
      "Epoch 3738, Loss 3.0\n",
      "    Params: tensor([  5.3623, -17.2741])\n",
      "    Grad: tensor([-0.0009,  0.0052])\n",
      "Epoch 3739, Loss 3.0\n",
      "    Params: tensor([  5.3623, -17.2741])\n",
      "    Grad: tensor([-0.0009,  0.0052])\n",
      "Epoch 3740, Loss 3.0\n",
      "    Params: tensor([  5.3623, -17.2742])\n",
      "    Grad: tensor([-0.0009,  0.0052])\n",
      "Epoch 3741, Loss 3.0\n",
      "    Params: tensor([  5.3623, -17.2742])\n",
      "    Grad: tensor([-0.0009,  0.0052])\n",
      "Epoch 3742, Loss 3.0\n",
      "    Params: tensor([  5.3623, -17.2743])\n",
      "    Grad: tensor([-0.0009,  0.0052])\n",
      "Epoch 3743, Loss 3.0\n",
      "    Params: tensor([  5.3623, -17.2743])\n",
      "    Grad: tensor([-0.0009,  0.0052])\n",
      "Epoch 3744, Loss 3.0\n",
      "    Params: tensor([  5.3623, -17.2744])\n",
      "    Grad: tensor([-0.0009,  0.0052])\n",
      "Epoch 3745, Loss 3.0\n",
      "    Params: tensor([  5.3624, -17.2744])\n",
      "    Grad: tensor([-0.0009,  0.0052])\n",
      "Epoch 3746, Loss 3.0\n",
      "    Params: tensor([  5.3624, -17.2745])\n",
      "    Grad: tensor([-0.0009,  0.0052])\n",
      "Epoch 3747, Loss 3.0\n",
      "    Params: tensor([  5.3624, -17.2745])\n",
      "    Grad: tensor([-0.0009,  0.0051])\n",
      "Epoch 3748, Loss 3.0\n",
      "    Params: tensor([  5.3624, -17.2746])\n",
      "    Grad: tensor([-0.0009,  0.0051])\n",
      "Epoch 3749, Loss 3.0\n",
      "    Params: tensor([  5.3624, -17.2746])\n",
      "    Grad: tensor([-0.0009,  0.0051])\n",
      "Epoch 3750, Loss 3.0\n",
      "    Params: tensor([  5.3624, -17.2747])\n",
      "    Grad: tensor([-0.0009,  0.0051])\n",
      "Epoch 3751, Loss 3.0\n",
      "    Params: tensor([  5.3624, -17.2747])\n",
      "    Grad: tensor([-0.0009,  0.0051])\n",
      "Epoch 3752, Loss 3.0\n",
      "    Params: tensor([  5.3624, -17.2748])\n",
      "    Grad: tensor([-0.0009,  0.0051])\n",
      "Epoch 3753, Loss 3.0\n",
      "    Params: tensor([  5.3624, -17.2748])\n",
      "    Grad: tensor([-0.0009,  0.0051])\n",
      "Epoch 3754, Loss 3.0\n",
      "    Params: tensor([  5.3624, -17.2749])\n",
      "    Grad: tensor([-0.0009,  0.0051])\n",
      "Epoch 3755, Loss 3.0\n",
      "    Params: tensor([  5.3624, -17.2750])\n",
      "    Grad: tensor([-0.0009,  0.0051])\n",
      "Epoch 3756, Loss 3.0\n",
      "    Params: tensor([  5.3625, -17.2750])\n",
      "    Grad: tensor([-0.0009,  0.0051])\n",
      "Epoch 3757, Loss 3.0\n",
      "    Params: tensor([  5.3625, -17.2751])\n",
      "    Grad: tensor([-0.0009,  0.0051])\n",
      "Epoch 3758, Loss 3.0\n",
      "    Params: tensor([  5.3625, -17.2751])\n",
      "    Grad: tensor([-0.0009,  0.0050])\n",
      "Epoch 3759, Loss 3.0\n",
      "    Params: tensor([  5.3625, -17.2752])\n",
      "    Grad: tensor([-0.0009,  0.0050])\n",
      "Epoch 3760, Loss 3.0\n",
      "    Params: tensor([  5.3625, -17.2752])\n",
      "    Grad: tensor([-0.0009,  0.0050])\n",
      "Epoch 3761, Loss 3.0\n",
      "    Params: tensor([  5.3625, -17.2753])\n",
      "    Grad: tensor([-0.0009,  0.0050])\n",
      "Epoch 3762, Loss 3.0\n",
      "    Params: tensor([  5.3625, -17.2753])\n",
      "    Grad: tensor([-0.0009,  0.0050])\n",
      "Epoch 3763, Loss 3.0\n",
      "    Params: tensor([  5.3625, -17.2754])\n",
      "    Grad: tensor([-0.0009,  0.0050])\n",
      "Epoch 3764, Loss 3.0\n",
      "    Params: tensor([  5.3625, -17.2754])\n",
      "    Grad: tensor([-0.0009,  0.0050])\n",
      "Epoch 3765, Loss 3.0\n",
      "    Params: tensor([  5.3625, -17.2755])\n",
      "    Grad: tensor([-0.0009,  0.0050])\n",
      "Epoch 3766, Loss 3.0\n",
      "    Params: tensor([  5.3625, -17.2755])\n",
      "    Grad: tensor([-0.0009,  0.0050])\n",
      "Epoch 3767, Loss 3.0\n",
      "    Params: tensor([  5.3626, -17.2756])\n",
      "    Grad: tensor([-0.0009,  0.0050])\n",
      "Epoch 3768, Loss 3.0\n",
      "    Params: tensor([  5.3626, -17.2756])\n",
      "    Grad: tensor([-0.0009,  0.0050])\n",
      "Epoch 3769, Loss 3.0\n",
      "    Params: tensor([  5.3626, -17.2757])\n",
      "    Grad: tensor([-0.0009,  0.0050])\n",
      "Epoch 3770, Loss 3.0\n",
      "    Params: tensor([  5.3626, -17.2757])\n",
      "    Grad: tensor([-0.0009,  0.0050])\n",
      "Epoch 3771, Loss 3.0\n",
      "    Params: tensor([  5.3626, -17.2757])\n",
      "    Grad: tensor([-0.0009,  0.0049])\n",
      "Epoch 3772, Loss 3.0\n",
      "    Params: tensor([  5.3626, -17.2758])\n",
      "    Grad: tensor([-0.0009,  0.0049])\n",
      "Epoch 3773, Loss 3.0\n",
      "    Params: tensor([  5.3626, -17.2758])\n",
      "    Grad: tensor([-0.0009,  0.0049])\n",
      "Epoch 3774, Loss 3.0\n",
      "    Params: tensor([  5.3626, -17.2759])\n",
      "    Grad: tensor([-0.0009,  0.0049])\n",
      "Epoch 3775, Loss 3.0\n",
      "    Params: tensor([  5.3626, -17.2759])\n",
      "    Grad: tensor([-0.0009,  0.0049])\n",
      "Epoch 3776, Loss 3.0\n",
      "    Params: tensor([  5.3626, -17.2760])\n",
      "    Grad: tensor([-0.0009,  0.0049])\n",
      "Epoch 3777, Loss 3.0\n",
      "    Params: tensor([  5.3626, -17.2760])\n",
      "    Grad: tensor([-0.0009,  0.0049])\n",
      "Epoch 3778, Loss 3.0\n",
      "    Params: tensor([  5.3627, -17.2761])\n",
      "    Grad: tensor([-0.0009,  0.0049])\n",
      "Epoch 3779, Loss 3.0\n",
      "    Params: tensor([  5.3627, -17.2761])\n",
      "    Grad: tensor([-0.0009,  0.0049])\n",
      "Epoch 3780, Loss 3.0\n",
      "    Params: tensor([  5.3627, -17.2762])\n",
      "    Grad: tensor([-0.0009,  0.0049])\n",
      "Epoch 3781, Loss 3.0\n",
      "    Params: tensor([  5.3627, -17.2762])\n",
      "    Grad: tensor([-0.0009,  0.0049])\n",
      "Epoch 3782, Loss 3.0\n",
      "    Params: tensor([  5.3627, -17.2763])\n",
      "    Grad: tensor([-0.0009,  0.0048])\n",
      "Epoch 3783, Loss 3.0\n",
      "    Params: tensor([  5.3627, -17.2763])\n",
      "    Grad: tensor([-0.0008,  0.0048])\n",
      "Epoch 3784, Loss 3.0\n",
      "    Params: tensor([  5.3627, -17.2764])\n",
      "    Grad: tensor([-0.0008,  0.0048])\n",
      "Epoch 3785, Loss 3.0\n",
      "    Params: tensor([  5.3627, -17.2764])\n",
      "    Grad: tensor([-0.0008,  0.0048])\n",
      "Epoch 3786, Loss 3.0\n",
      "    Params: tensor([  5.3627, -17.2765])\n",
      "    Grad: tensor([-0.0008,  0.0048])\n",
      "Epoch 3787, Loss 3.0\n",
      "    Params: tensor([  5.3627, -17.2765])\n",
      "    Grad: tensor([-0.0008,  0.0048])\n",
      "Epoch 3788, Loss 3.0\n",
      "    Params: tensor([  5.3627, -17.2766])\n",
      "    Grad: tensor([-0.0008,  0.0048])\n",
      "Epoch 3789, Loss 3.0\n",
      "    Params: tensor([  5.3627, -17.2766])\n",
      "    Grad: tensor([-0.0008,  0.0048])\n",
      "Epoch 3790, Loss 3.0\n",
      "    Params: tensor([  5.3628, -17.2767])\n",
      "    Grad: tensor([-0.0008,  0.0048])\n",
      "Epoch 3791, Loss 3.0\n",
      "    Params: tensor([  5.3628, -17.2767])\n",
      "    Grad: tensor([-0.0008,  0.0048])\n",
      "Epoch 3792, Loss 3.0\n",
      "    Params: tensor([  5.3628, -17.2768])\n",
      "    Grad: tensor([-0.0008,  0.0048])\n",
      "Epoch 3793, Loss 3.0\n",
      "    Params: tensor([  5.3628, -17.2768])\n",
      "    Grad: tensor([-0.0008,  0.0048])\n",
      "Epoch 3794, Loss 3.0\n",
      "    Params: tensor([  5.3628, -17.2769])\n",
      "    Grad: tensor([-0.0008,  0.0048])\n",
      "Epoch 3795, Loss 3.0\n",
      "    Params: tensor([  5.3628, -17.2769])\n",
      "    Grad: tensor([-0.0009,  0.0047])\n",
      "Epoch 3796, Loss 3.0\n",
      "    Params: tensor([  5.3628, -17.2770])\n",
      "    Grad: tensor([-0.0008,  0.0047])\n",
      "Epoch 3797, Loss 3.0\n",
      "    Params: tensor([  5.3628, -17.2770])\n",
      "    Grad: tensor([-0.0008,  0.0047])\n",
      "Epoch 3798, Loss 3.0\n",
      "    Params: tensor([  5.3628, -17.2771])\n",
      "    Grad: tensor([-0.0008,  0.0047])\n",
      "Epoch 3799, Loss 3.0\n",
      "    Params: tensor([  5.3628, -17.2771])\n",
      "    Grad: tensor([-0.0008,  0.0047])\n",
      "Epoch 3800, Loss 3.0\n",
      "    Params: tensor([  5.3628, -17.2771])\n",
      "    Grad: tensor([-0.0008,  0.0047])\n",
      "Epoch 3801, Loss 3.0\n",
      "    Params: tensor([  5.3628, -17.2772])\n",
      "    Grad: tensor([-0.0008,  0.0047])\n",
      "Epoch 3802, Loss 3.0\n",
      "    Params: tensor([  5.3629, -17.2772])\n",
      "    Grad: tensor([-0.0008,  0.0047])\n",
      "Epoch 3803, Loss 3.0\n",
      "    Params: tensor([  5.3629, -17.2773])\n",
      "    Grad: tensor([-0.0009,  0.0047])\n",
      "Epoch 3804, Loss 3.0\n",
      "    Params: tensor([  5.3629, -17.2773])\n",
      "    Grad: tensor([-0.0008,  0.0047])\n",
      "Epoch 3805, Loss 3.0\n",
      "    Params: tensor([  5.3629, -17.2774])\n",
      "    Grad: tensor([-0.0008,  0.0047])\n",
      "Epoch 3806, Loss 3.0\n",
      "    Params: tensor([  5.3629, -17.2774])\n",
      "    Grad: tensor([-0.0008,  0.0047])\n",
      "Epoch 3807, Loss 3.0\n",
      "    Params: tensor([  5.3629, -17.2775])\n",
      "    Grad: tensor([-0.0008,  0.0047])\n",
      "Epoch 3808, Loss 3.0\n",
      "    Params: tensor([  5.3629, -17.2775])\n",
      "    Grad: tensor([-0.0008,  0.0046])\n",
      "Epoch 3809, Loss 3.0\n",
      "    Params: tensor([  5.3629, -17.2776])\n",
      "    Grad: tensor([-0.0008,  0.0046])\n",
      "Epoch 3810, Loss 3.0\n",
      "    Params: tensor([  5.3629, -17.2776])\n",
      "    Grad: tensor([-0.0008,  0.0046])\n",
      "Epoch 3811, Loss 3.0\n",
      "    Params: tensor([  5.3629, -17.2777])\n",
      "    Grad: tensor([-0.0008,  0.0046])\n",
      "Epoch 3812, Loss 3.0\n",
      "    Params: tensor([  5.3629, -17.2777])\n",
      "    Grad: tensor([-0.0008,  0.0046])\n",
      "Epoch 3813, Loss 3.0\n",
      "    Params: tensor([  5.3629, -17.2777])\n",
      "    Grad: tensor([-0.0008,  0.0046])\n",
      "Epoch 3814, Loss 3.0\n",
      "    Params: tensor([  5.3630, -17.2778])\n",
      "    Grad: tensor([-0.0008,  0.0046])\n",
      "Epoch 3815, Loss 3.0\n",
      "    Params: tensor([  5.3630, -17.2778])\n",
      "    Grad: tensor([-0.0008,  0.0046])\n",
      "Epoch 3816, Loss 3.0\n",
      "    Params: tensor([  5.3630, -17.2779])\n",
      "    Grad: tensor([-0.0008,  0.0046])\n",
      "Epoch 3817, Loss 3.0\n",
      "    Params: tensor([  5.3630, -17.2779])\n",
      "    Grad: tensor([-0.0008,  0.0046])\n",
      "Epoch 3818, Loss 3.0\n",
      "    Params: tensor([  5.3630, -17.2780])\n",
      "    Grad: tensor([-0.0008,  0.0046])\n",
      "Epoch 3819, Loss 3.0\n",
      "    Params: tensor([  5.3630, -17.2780])\n",
      "    Grad: tensor([-0.0008,  0.0046])\n",
      "Epoch 3820, Loss 3.0\n",
      "    Params: tensor([  5.3630, -17.2781])\n",
      "    Grad: tensor([-0.0008,  0.0045])\n",
      "Epoch 3821, Loss 3.0\n",
      "    Params: tensor([  5.3630, -17.2781])\n",
      "    Grad: tensor([-0.0008,  0.0045])\n",
      "Epoch 3822, Loss 3.0\n",
      "    Params: tensor([  5.3630, -17.2782])\n",
      "    Grad: tensor([-0.0008,  0.0045])\n",
      "Epoch 3823, Loss 3.0\n",
      "    Params: tensor([  5.3630, -17.2782])\n",
      "    Grad: tensor([-0.0008,  0.0045])\n",
      "Epoch 3824, Loss 3.0\n",
      "    Params: tensor([  5.3630, -17.2783])\n",
      "    Grad: tensor([-0.0008,  0.0045])\n",
      "Epoch 3825, Loss 3.0\n",
      "    Params: tensor([  5.3630, -17.2783])\n",
      "    Grad: tensor([-0.0008,  0.0045])\n",
      "Epoch 3826, Loss 3.0\n",
      "    Params: tensor([  5.3630, -17.2783])\n",
      "    Grad: tensor([-0.0008,  0.0045])\n",
      "Epoch 3827, Loss 3.0\n",
      "    Params: tensor([  5.3631, -17.2784])\n",
      "    Grad: tensor([-0.0008,  0.0045])\n",
      "Epoch 3828, Loss 3.0\n",
      "    Params: tensor([  5.3631, -17.2784])\n",
      "    Grad: tensor([-0.0008,  0.0045])\n",
      "Epoch 3829, Loss 3.0\n",
      "    Params: tensor([  5.3631, -17.2785])\n",
      "    Grad: tensor([-0.0008,  0.0045])\n",
      "Epoch 3830, Loss 3.0\n",
      "    Params: tensor([  5.3631, -17.2785])\n",
      "    Grad: tensor([-0.0008,  0.0045])\n",
      "Epoch 3831, Loss 3.0\n",
      "    Params: tensor([  5.3631, -17.2786])\n",
      "    Grad: tensor([-0.0008,  0.0045])\n",
      "Epoch 3832, Loss 3.0\n",
      "    Params: tensor([  5.3631, -17.2786])\n",
      "    Grad: tensor([-0.0008,  0.0045])\n",
      "Epoch 3833, Loss 3.0\n",
      "    Params: tensor([  5.3631, -17.2787])\n",
      "    Grad: tensor([-0.0008,  0.0044])\n",
      "Epoch 3834, Loss 3.0\n",
      "    Params: tensor([  5.3631, -17.2787])\n",
      "    Grad: tensor([-0.0008,  0.0044])\n",
      "Epoch 3835, Loss 3.0\n",
      "    Params: tensor([  5.3631, -17.2787])\n",
      "    Grad: tensor([-0.0008,  0.0044])\n",
      "Epoch 3836, Loss 3.0\n",
      "    Params: tensor([  5.3631, -17.2788])\n",
      "    Grad: tensor([-0.0008,  0.0044])\n",
      "Epoch 3837, Loss 3.0\n",
      "    Params: tensor([  5.3631, -17.2788])\n",
      "    Grad: tensor([-0.0008,  0.0044])\n",
      "Epoch 3838, Loss 3.0\n",
      "    Params: tensor([  5.3631, -17.2789])\n",
      "    Grad: tensor([-0.0008,  0.0044])\n",
      "Epoch 3839, Loss 3.0\n",
      "    Params: tensor([  5.3631, -17.2789])\n",
      "    Grad: tensor([-0.0008,  0.0044])\n",
      "Epoch 3840, Loss 3.0\n",
      "    Params: tensor([  5.3632, -17.2790])\n",
      "    Grad: tensor([-0.0008,  0.0044])\n",
      "Epoch 3841, Loss 3.0\n",
      "    Params: tensor([  5.3632, -17.2790])\n",
      "    Grad: tensor([-0.0008,  0.0044])\n",
      "Epoch 3842, Loss 3.0\n",
      "    Params: tensor([  5.3632, -17.2790])\n",
      "    Grad: tensor([-0.0008,  0.0044])\n",
      "Epoch 3843, Loss 3.0\n",
      "    Params: tensor([  5.3632, -17.2791])\n",
      "    Grad: tensor([-0.0008,  0.0044])\n",
      "Epoch 3844, Loss 3.0\n",
      "    Params: tensor([  5.3632, -17.2791])\n",
      "    Grad: tensor([-0.0008,  0.0044])\n",
      "Epoch 3845, Loss 3.0\n",
      "    Params: tensor([  5.3632, -17.2792])\n",
      "    Grad: tensor([-0.0008,  0.0044])\n",
      "Epoch 3846, Loss 3.0\n",
      "    Params: tensor([  5.3632, -17.2792])\n",
      "    Grad: tensor([-0.0008,  0.0043])\n",
      "Epoch 3847, Loss 3.0\n",
      "    Params: tensor([  5.3632, -17.2793])\n",
      "    Grad: tensor([-0.0008,  0.0043])\n",
      "Epoch 3848, Loss 3.0\n",
      "    Params: tensor([  5.3632, -17.2793])\n",
      "    Grad: tensor([-0.0008,  0.0043])\n",
      "Epoch 3849, Loss 3.0\n",
      "    Params: tensor([  5.3632, -17.2794])\n",
      "    Grad: tensor([-0.0008,  0.0043])\n",
      "Epoch 3850, Loss 3.0\n",
      "    Params: tensor([  5.3632, -17.2794])\n",
      "    Grad: tensor([-0.0008,  0.0043])\n",
      "Epoch 3851, Loss 3.0\n",
      "    Params: tensor([  5.3632, -17.2794])\n",
      "    Grad: tensor([-0.0008,  0.0043])\n",
      "Epoch 3852, Loss 3.0\n",
      "    Params: tensor([  5.3632, -17.2795])\n",
      "    Grad: tensor([-0.0008,  0.0043])\n",
      "Epoch 3853, Loss 3.0\n",
      "    Params: tensor([  5.3633, -17.2795])\n",
      "    Grad: tensor([-0.0008,  0.0043])\n",
      "Epoch 3854, Loss 3.0\n",
      "    Params: tensor([  5.3633, -17.2796])\n",
      "    Grad: tensor([-0.0008,  0.0043])\n",
      "Epoch 3855, Loss 3.0\n",
      "    Params: tensor([  5.3633, -17.2796])\n",
      "    Grad: tensor([-0.0007,  0.0043])\n",
      "Epoch 3856, Loss 3.0\n",
      "    Params: tensor([  5.3633, -17.2797])\n",
      "    Grad: tensor([-0.0007,  0.0043])\n",
      "Epoch 3857, Loss 3.0\n",
      "    Params: tensor([  5.3633, -17.2797])\n",
      "    Grad: tensor([-0.0007,  0.0043])\n",
      "Epoch 3858, Loss 3.0\n",
      "    Params: tensor([  5.3633, -17.2797])\n",
      "    Grad: tensor([-0.0007,  0.0043])\n",
      "Epoch 3859, Loss 3.0\n",
      "    Params: tensor([  5.3633, -17.2798])\n",
      "    Grad: tensor([-0.0007,  0.0043])\n",
      "Epoch 3860, Loss 3.0\n",
      "    Params: tensor([  5.3633, -17.2798])\n",
      "    Grad: tensor([-0.0007,  0.0043])\n",
      "Epoch 3861, Loss 3.0\n",
      "    Params: tensor([  5.3633, -17.2799])\n",
      "    Grad: tensor([-0.0007,  0.0042])\n",
      "Epoch 3862, Loss 3.0\n",
      "    Params: tensor([  5.3633, -17.2799])\n",
      "    Grad: tensor([-0.0007,  0.0042])\n",
      "Epoch 3863, Loss 3.0\n",
      "    Params: tensor([  5.3633, -17.2799])\n",
      "    Grad: tensor([-0.0007,  0.0042])\n",
      "Epoch 3864, Loss 3.0\n",
      "    Params: tensor([  5.3633, -17.2800])\n",
      "    Grad: tensor([-0.0007,  0.0042])\n",
      "Epoch 3865, Loss 3.0\n",
      "    Params: tensor([  5.3633, -17.2800])\n",
      "    Grad: tensor([-0.0007,  0.0042])\n",
      "Epoch 3866, Loss 3.0\n",
      "    Params: tensor([  5.3634, -17.2801])\n",
      "    Grad: tensor([-0.0007,  0.0042])\n",
      "Epoch 3867, Loss 3.0\n",
      "    Params: tensor([  5.3634, -17.2801])\n",
      "    Grad: tensor([-0.0007,  0.0042])\n",
      "Epoch 3868, Loss 3.0\n",
      "    Params: tensor([  5.3634, -17.2802])\n",
      "    Grad: tensor([-0.0007,  0.0042])\n",
      "Epoch 3869, Loss 3.0\n",
      "    Params: tensor([  5.3634, -17.2802])\n",
      "    Grad: tensor([-0.0007,  0.0042])\n",
      "Epoch 3870, Loss 3.0\n",
      "    Params: tensor([  5.3634, -17.2802])\n",
      "    Grad: tensor([-0.0007,  0.0042])\n",
      "Epoch 3871, Loss 3.0\n",
      "    Params: tensor([  5.3634, -17.2803])\n",
      "    Grad: tensor([-0.0007,  0.0042])\n",
      "Epoch 3872, Loss 3.0\n",
      "    Params: tensor([  5.3634, -17.2803])\n",
      "    Grad: tensor([-0.0007,  0.0042])\n",
      "Epoch 3873, Loss 3.0\n",
      "    Params: tensor([  5.3634, -17.2804])\n",
      "    Grad: tensor([-0.0008,  0.0042])\n",
      "Epoch 3874, Loss 3.0\n",
      "    Params: tensor([  5.3634, -17.2804])\n",
      "    Grad: tensor([-0.0007,  0.0041])\n",
      "Epoch 3875, Loss 3.0\n",
      "    Params: tensor([  5.3634, -17.2805])\n",
      "    Grad: tensor([-0.0007,  0.0041])\n",
      "Epoch 3876, Loss 3.0\n",
      "    Params: tensor([  5.3634, -17.2805])\n",
      "    Grad: tensor([-0.0007,  0.0041])\n",
      "Epoch 3877, Loss 3.0\n",
      "    Params: tensor([  5.3634, -17.2805])\n",
      "    Grad: tensor([-0.0008,  0.0041])\n",
      "Epoch 3878, Loss 3.0\n",
      "    Params: tensor([  5.3634, -17.2806])\n",
      "    Grad: tensor([-0.0007,  0.0041])\n",
      "Epoch 3879, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2806])\n",
      "    Grad: tensor([-0.0007,  0.0041])\n",
      "Epoch 3880, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2807])\n",
      "    Grad: tensor([-0.0007,  0.0041])\n",
      "Epoch 3881, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2807])\n",
      "    Grad: tensor([-0.0008,  0.0041])\n",
      "Epoch 3882, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2807])\n",
      "    Grad: tensor([-0.0007,  0.0041])\n",
      "Epoch 3883, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2808])\n",
      "    Grad: tensor([-0.0007,  0.0041])\n",
      "Epoch 3884, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2808])\n",
      "    Grad: tensor([-0.0007,  0.0041])\n",
      "Epoch 3885, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2809])\n",
      "    Grad: tensor([-0.0007,  0.0041])\n",
      "Epoch 3886, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2809])\n",
      "    Grad: tensor([-0.0007,  0.0041])\n",
      "Epoch 3887, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2809])\n",
      "    Grad: tensor([-0.0007,  0.0041])\n",
      "Epoch 3888, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2810])\n",
      "    Grad: tensor([-0.0007,  0.0041])\n",
      "Epoch 3889, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2810])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3890, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2811])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3891, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2811])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3892, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2811])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3893, Loss 3.0\n",
      "    Params: tensor([  5.3635, -17.2812])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3894, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2812])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3895, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2813])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3896, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2813])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3897, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2813])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3898, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2814])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3899, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2814])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3900, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2815])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3901, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2815])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3902, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2815])\n",
      "    Grad: tensor([-0.0007,  0.0040])\n",
      "Epoch 3903, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2816])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3904, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2816])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3905, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2817])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3906, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2817])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3907, Loss 3.0\n",
      "    Params: tensor([  5.3636, -17.2817])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3908, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2818])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3909, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2818])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3910, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2819])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3911, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2819])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3912, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2819])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3913, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2820])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3914, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2820])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3915, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2821])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3916, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2821])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3917, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2821])\n",
      "    Grad: tensor([-0.0007,  0.0039])\n",
      "Epoch 3918, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2822])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3919, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2822])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3920, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2822])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3921, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2823])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3922, Loss 3.0\n",
      "    Params: tensor([  5.3637, -17.2823])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3923, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2824])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3924, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2824])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3925, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2824])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3926, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2825])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3927, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2825])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3928, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2825])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3929, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2826])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3930, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2826])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3931, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2827])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3932, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2827])\n",
      "    Grad: tensor([-0.0007,  0.0038])\n",
      "Epoch 3933, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2827])\n",
      "    Grad: tensor([-0.0007,  0.0037])\n",
      "Epoch 3934, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2828])\n",
      "    Grad: tensor([-0.0007,  0.0037])\n",
      "Epoch 3935, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2828])\n",
      "    Grad: tensor([-0.0007,  0.0037])\n",
      "Epoch 3936, Loss 3.0\n",
      "    Params: tensor([  5.3638, -17.2829])\n",
      "    Grad: tensor([-0.0007,  0.0037])\n",
      "Epoch 3937, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2829])\n",
      "    Grad: tensor([-0.0007,  0.0037])\n",
      "Epoch 3938, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2829])\n",
      "    Grad: tensor([-0.0007,  0.0037])\n",
      "Epoch 3939, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2830])\n",
      "    Grad: tensor([-0.0007,  0.0037])\n",
      "Epoch 3940, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2830])\n",
      "    Grad: tensor([-0.0007,  0.0037])\n",
      "Epoch 3941, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2830])\n",
      "    Grad: tensor([-0.0006,  0.0037])\n",
      "Epoch 3942, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2831])\n",
      "    Grad: tensor([-0.0006,  0.0037])\n",
      "Epoch 3943, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2831])\n",
      "    Grad: tensor([-0.0006,  0.0037])\n",
      "Epoch 3944, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2831])\n",
      "    Grad: tensor([-0.0006,  0.0037])\n",
      "Epoch 3945, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2832])\n",
      "    Grad: tensor([-0.0007,  0.0037])\n",
      "Epoch 3946, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2832])\n",
      "    Grad: tensor([-0.0006,  0.0037])\n",
      "Epoch 3947, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2833])\n",
      "    Grad: tensor([-0.0006,  0.0037])\n",
      "Epoch 3948, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2833])\n",
      "    Grad: tensor([-0.0006,  0.0037])\n",
      "Epoch 3949, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2833])\n",
      "    Grad: tensor([-0.0006,  0.0037])\n",
      "Epoch 3950, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2834])\n",
      "    Grad: tensor([-0.0007,  0.0036])\n",
      "Epoch 3951, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2834])\n",
      "    Grad: tensor([-0.0006,  0.0036])\n",
      "Epoch 3952, Loss 3.0\n",
      "    Params: tensor([  5.3639, -17.2834])\n",
      "    Grad: tensor([-0.0006,  0.0036])\n",
      "Epoch 3953, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2835])\n",
      "    Grad: tensor([-0.0006,  0.0036])\n",
      "Epoch 3954, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2835])\n",
      "    Grad: tensor([-0.0006,  0.0036])\n",
      "Epoch 3955, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2835])\n",
      "    Grad: tensor([-0.0006,  0.0036])\n",
      "Epoch 3956, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2836])\n",
      "    Grad: tensor([-0.0006,  0.0036])\n",
      "Epoch 3957, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2836])\n",
      "    Grad: tensor([-0.0006,  0.0036])\n",
      "Epoch 3958, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2837])\n",
      "    Grad: tensor([-0.0007,  0.0036])\n",
      "Epoch 3959, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2837])\n",
      "    Grad: tensor([-0.0006,  0.0036])\n",
      "Epoch 3960, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2837])\n",
      "    Grad: tensor([-0.0006,  0.0036])\n",
      "Epoch 3961, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2838])\n",
      "    Grad: tensor([-0.0007,  0.0036])\n",
      "Epoch 3962, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2838])\n",
      "    Grad: tensor([-0.0006,  0.0036])\n",
      "Epoch 3963, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2838])\n",
      "    Grad: tensor([-0.0007,  0.0036])\n",
      "Epoch 3964, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2839])\n",
      "    Grad: tensor([-0.0006,  0.0036])\n",
      "Epoch 3965, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2839])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3966, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2839])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3967, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2840])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3968, Loss 3.0\n",
      "    Params: tensor([  5.3640, -17.2840])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3969, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2840])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3970, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2841])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3971, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2841])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3972, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2842])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3973, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2842])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3974, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2842])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3975, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2843])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3976, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2843])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3977, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2843])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3978, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2844])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3979, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2844])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3980, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2844])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3981, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2845])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3982, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2845])\n",
      "    Grad: tensor([-0.0006,  0.0035])\n",
      "Epoch 3983, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2845])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3984, Loss 3.0\n",
      "    Params: tensor([  5.3641, -17.2846])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3985, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2846])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3986, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2846])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3987, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2847])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3988, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2847])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3989, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2847])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3990, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2848])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3991, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2848])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3992, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2848])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3993, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2849])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3994, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2849])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3995, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2849])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3996, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2850])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3997, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2850])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3998, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2850])\n",
      "    Grad: tensor([-0.0006,  0.0034])\n",
      "Epoch 3999, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2851])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4000, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2851])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4001, Loss 3.0\n",
      "    Params: tensor([  5.3642, -17.2851])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4002, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2852])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4003, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2852])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4004, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2852])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4005, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2853])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4006, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2853])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4007, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2853])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4008, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2854])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4009, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2854])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4010, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2854])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4011, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2855])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4012, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2855])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4013, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2855])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4014, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2856])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4015, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2856])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4016, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2856])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4017, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2857])\n",
      "    Grad: tensor([-0.0006,  0.0033])\n",
      "Epoch 4018, Loss 3.0\n",
      "    Params: tensor([  5.3643, -17.2857])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4019, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2857])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4020, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2858])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4021, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2858])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4022, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2858])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4023, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2859])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4024, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2859])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4025, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2859])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4026, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2860])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4027, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2860])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4028, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2860])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4029, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2861])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4030, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2861])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4031, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2861])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4032, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2862])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4033, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2862])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4034, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2862])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4035, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2862])\n",
      "    Grad: tensor([-0.0006,  0.0032])\n",
      "Epoch 4036, Loss 3.0\n",
      "    Params: tensor([  5.3644, -17.2863])\n",
      "    Grad: tensor([-0.0006,  0.0031])\n",
      "Epoch 4037, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2863])\n",
      "    Grad: tensor([-0.0006,  0.0031])\n",
      "Epoch 4038, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2863])\n",
      "    Grad: tensor([-0.0005,  0.0031])\n",
      "Epoch 4039, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2864])\n",
      "    Grad: tensor([-0.0005,  0.0031])\n",
      "Epoch 4040, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2864])\n",
      "    Grad: tensor([-0.0005,  0.0031])\n",
      "Epoch 4041, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2864])\n",
      "    Grad: tensor([-0.0006,  0.0031])\n",
      "Epoch 4042, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2865])\n",
      "    Grad: tensor([-0.0005,  0.0031])\n",
      "Epoch 4043, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2865])\n",
      "    Grad: tensor([-0.0005,  0.0031])\n",
      "Epoch 4044, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2865])\n",
      "    Grad: tensor([-0.0005,  0.0031])\n",
      "Epoch 4045, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2866])\n",
      "    Grad: tensor([-0.0006,  0.0031])\n",
      "Epoch 4046, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2866])\n",
      "    Grad: tensor([-0.0005,  0.0031])\n",
      "Epoch 4047, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2866])\n",
      "    Grad: tensor([-0.0005,  0.0031])\n",
      "Epoch 4048, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2866])\n",
      "    Grad: tensor([-0.0005,  0.0031])\n",
      "Epoch 4049, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2867])\n",
      "    Grad: tensor([-0.0006,  0.0031])\n",
      "Epoch 4050, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2867])\n",
      "    Grad: tensor([-0.0005,  0.0031])\n",
      "Epoch 4051, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2867])\n",
      "    Grad: tensor([-0.0005,  0.0031])\n",
      "Epoch 4052, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2868])\n",
      "    Grad: tensor([-0.0006,  0.0031])\n",
      "Epoch 4053, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2868])\n",
      "    Grad: tensor([-0.0005,  0.0031])\n",
      "Epoch 4054, Loss 3.0\n",
      "    Params: tensor([  5.3645, -17.2868])\n",
      "    Grad: tensor([-0.0005,  0.0031])\n",
      "Epoch 4055, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2869])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4056, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2869])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4057, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2869])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4058, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2870])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4059, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2870])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4060, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2870])\n",
      "    Grad: tensor([-0.0006,  0.0030])\n",
      "Epoch 4061, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2870])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4062, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2871])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4063, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2871])\n",
      "    Grad: tensor([-0.0006,  0.0030])\n",
      "Epoch 4064, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2871])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4065, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2872])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4066, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2872])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4067, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2872])\n",
      "    Grad: tensor([-0.0006,  0.0030])\n",
      "Epoch 4068, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2873])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4069, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2873])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4070, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2873])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4071, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2873])\n",
      "    Grad: tensor([-0.0006,  0.0030])\n",
      "Epoch 4072, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2874])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4073, Loss 3.0\n",
      "    Params: tensor([  5.3646, -17.2874])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4074, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2874])\n",
      "    Grad: tensor([-0.0005,  0.0030])\n",
      "Epoch 4075, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2875])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4076, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2875])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4077, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2875])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4078, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2875])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4079, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2876])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4080, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2876])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4081, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2876])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4082, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2877])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4083, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2877])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4084, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2877])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4085, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2878])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4086, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2878])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4087, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2878])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4088, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2878])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4089, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2879])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4090, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2879])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4091, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2879])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4092, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2880])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4093, Loss 3.0\n",
      "    Params: tensor([  5.3647, -17.2880])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4094, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2880])\n",
      "    Grad: tensor([-0.0005,  0.0029])\n",
      "Epoch 4095, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2880])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4096, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2881])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4097, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2881])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4098, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2881])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4099, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2882])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4100, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2882])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4101, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2882])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4102, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2882])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4103, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2883])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4104, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2883])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4105, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2883])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4106, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2884])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4107, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2884])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4108, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2884])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4109, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2884])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4110, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2885])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4111, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2885])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4112, Loss 3.0\n",
      "    Params: tensor([  5.3648, -17.2885])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4113, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2885])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4114, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2886])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4115, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2886])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4116, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2886])\n",
      "    Grad: tensor([-0.0005,  0.0028])\n",
      "Epoch 4117, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2887])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4118, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2887])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4119, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2887])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4120, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2887])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4121, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2888])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4122, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2888])\n",
      "    Grad: tensor([-0.0004,  0.0027])\n",
      "Epoch 4123, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2888])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4124, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2888])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4125, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2889])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4126, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2889])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4127, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2889])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4128, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2889])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4129, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2890])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4130, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2890])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4131, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2890])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4132, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2891])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4133, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2891])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4134, Loss 3.0\n",
      "    Params: tensor([  5.3649, -17.2891])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4135, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2891])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4136, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2892])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4137, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2892])\n",
      "    Grad: tensor([-0.0005,  0.0027])\n",
      "Epoch 4138, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2892])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4139, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2892])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4140, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2893])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4141, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2893])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4142, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2893])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4143, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2894])\n",
      "    Grad: tensor([-0.0004,  0.0026])\n",
      "Epoch 4144, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2894])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4145, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2894])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4146, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2894])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4147, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2895])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4148, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2895])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4149, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2895])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4150, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2895])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4151, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2896])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4152, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2896])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4153, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2896])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4154, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2896])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4155, Loss 3.0\n",
      "    Params: tensor([  5.3650, -17.2897])\n",
      "    Grad: tensor([-0.0004,  0.0026])\n",
      "Epoch 4156, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2897])\n",
      "    Grad: tensor([-0.0004,  0.0026])\n",
      "Epoch 4157, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2897])\n",
      "    Grad: tensor([-0.0004,  0.0026])\n",
      "Epoch 4158, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2897])\n",
      "    Grad: tensor([-0.0005,  0.0026])\n",
      "Epoch 4159, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2898])\n",
      "    Grad: tensor([-0.0004,  0.0026])\n",
      "Epoch 4160, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2898])\n",
      "    Grad: tensor([-0.0004,  0.0026])\n",
      "Epoch 4161, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2898])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4162, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2898])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4163, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2899])\n",
      "    Grad: tensor([-0.0005,  0.0025])\n",
      "Epoch 4164, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2899])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4165, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2899])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4166, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2899])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4167, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2900])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4168, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2900])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4169, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2900])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4170, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2900])\n",
      "    Grad: tensor([-0.0005,  0.0025])\n",
      "Epoch 4171, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2901])\n",
      "    Grad: tensor([-0.0005,  0.0025])\n",
      "Epoch 4172, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2901])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4173, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2901])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4174, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2901])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4175, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2902])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4176, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2902])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4177, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2902])\n",
      "    Grad: tensor([-0.0005,  0.0025])\n",
      "Epoch 4178, Loss 3.0\n",
      "    Params: tensor([  5.3651, -17.2902])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4179, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2903])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4180, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2903])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4181, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2903])\n",
      "    Grad: tensor([-0.0004,  0.0025])\n",
      "Epoch 4182, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2903])\n",
      "    Grad: tensor([-0.0005,  0.0025])\n",
      "Epoch 4183, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2904])\n",
      "    Grad: tensor([-0.0005,  0.0025])\n",
      "Epoch 4184, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2904])\n",
      "    Grad: tensor([-0.0005,  0.0024])\n",
      "Epoch 4185, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2904])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4186, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2904])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4187, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2905])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4188, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2905])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4189, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2905])\n",
      "    Grad: tensor([-0.0005,  0.0024])\n",
      "Epoch 4190, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2905])\n",
      "    Grad: tensor([-0.0005,  0.0024])\n",
      "Epoch 4191, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2906])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4192, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2906])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4193, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2906])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4194, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2906])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4195, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2907])\n",
      "    Grad: tensor([-0.0005,  0.0024])\n",
      "Epoch 4196, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2907])\n",
      "    Grad: tensor([-0.0005,  0.0024])\n",
      "Epoch 4197, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2907])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4198, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2907])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4199, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2908])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4200, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2908])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4201, Loss 3.0\n",
      "    Params: tensor([  5.3652, -17.2908])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4202, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2908])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4203, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2908])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4204, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2909])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4205, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2909])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4206, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2909])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4207, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2909])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4208, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2910])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4209, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2910])\n",
      "    Grad: tensor([-0.0004,  0.0024])\n",
      "Epoch 4210, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2910])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4211, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2910])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4212, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2911])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4213, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2911])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4214, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2911])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4215, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2911])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4216, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2911])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4217, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2912])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4218, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2912])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4219, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2912])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4220, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2912])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4221, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2913])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4222, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2913])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4223, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2913])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4224, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2913])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4225, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2914])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4226, Loss 3.0\n",
      "    Params: tensor([  5.3653, -17.2914])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4227, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2914])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4228, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2914])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4229, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2914])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4230, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2915])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4231, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2915])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4232, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2915])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4233, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2915])\n",
      "    Grad: tensor([-0.0004,  0.0023])\n",
      "Epoch 4234, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2916])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4235, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2916])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4236, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2916])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4237, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2916])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4238, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2916])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4239, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2917])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4240, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2917])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4241, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2917])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4242, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2917])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4243, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2918])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4244, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2918])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4245, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2918])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4246, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2918])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4247, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2919])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4248, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2919])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4249, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2919])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4250, Loss 3.0\n",
      "    Params: tensor([  5.3654, -17.2919])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4251, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2919])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4252, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2920])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4253, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2920])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4254, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2920])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4255, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2920])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4256, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2920])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4257, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2921])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4258, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2921])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4259, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2921])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4260, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2921])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4261, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2922])\n",
      "    Grad: tensor([-0.0004,  0.0022])\n",
      "Epoch 4262, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2922])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4263, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2922])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4264, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2922])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4265, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2922])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4266, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2923])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4267, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2923])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4268, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2923])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4269, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2923])\n",
      "    Grad: tensor([-0.0003,  0.0021])\n",
      "Epoch 4270, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2923])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4271, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2924])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4272, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2924])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4273, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2924])\n",
      "    Grad: tensor([-0.0003,  0.0021])\n",
      "Epoch 4274, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2924])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4275, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2924])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4276, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2925])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4277, Loss 3.0\n",
      "    Params: tensor([  5.3655, -17.2925])\n",
      "    Grad: tensor([-0.0003,  0.0021])\n",
      "Epoch 4278, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2925])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4279, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2925])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4280, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2925])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4281, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2926])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4282, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2926])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4283, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2926])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4284, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2926])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4285, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2927])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4286, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2927])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4287, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2927])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4288, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2927])\n",
      "    Grad: tensor([-0.0004,  0.0021])\n",
      "Epoch 4289, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2927])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4290, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2928])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4291, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2928])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4292, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2928])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4293, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2928])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4294, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2928])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4295, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2929])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4296, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2929])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4297, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2929])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4298, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2929])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4299, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2929])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4300, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2930])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4301, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2930])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4302, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2930])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4303, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2930])\n",
      "    Grad: tensor([-0.0003,  0.0020])\n",
      "Epoch 4304, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2930])\n",
      "    Grad: tensor([-0.0003,  0.0020])\n",
      "Epoch 4305, Loss 3.0\n",
      "    Params: tensor([  5.3656, -17.2931])\n",
      "    Grad: tensor([-0.0003,  0.0020])\n",
      "Epoch 4306, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2931])\n",
      "    Grad: tensor([-0.0003,  0.0020])\n",
      "Epoch 4307, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2931])\n",
      "    Grad: tensor([-0.0003,  0.0020])\n",
      "Epoch 4308, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2931])\n",
      "    Grad: tensor([-0.0003,  0.0020])\n",
      "Epoch 4309, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2931])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4310, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2932])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4311, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2932])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4312, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2932])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4313, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2932])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4314, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2932])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4315, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2933])\n",
      "    Grad: tensor([-0.0004,  0.0020])\n",
      "Epoch 4316, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2933])\n",
      "    Grad: tensor([-0.0003,  0.0020])\n",
      "Epoch 4317, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2933])\n",
      "    Grad: tensor([-0.0003,  0.0020])\n",
      "Epoch 4318, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2933])\n",
      "    Grad: tensor([-0.0003,  0.0020])\n",
      "Epoch 4319, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2933])\n",
      "    Grad: tensor([-0.0003,  0.0020])\n",
      "Epoch 4320, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2934])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4321, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2934])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4322, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2934])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4323, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2934])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4324, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2934])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4325, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2934])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4326, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2935])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4327, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2935])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4328, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2935])\n",
      "    Grad: tensor([-0.0004,  0.0019])\n",
      "Epoch 4329, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2935])\n",
      "    Grad: tensor([-0.0004,  0.0019])\n",
      "Epoch 4330, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2935])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4331, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2936])\n",
      "    Grad: tensor([-0.0004,  0.0019])\n",
      "Epoch 4332, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2936])\n",
      "    Grad: tensor([-0.0004,  0.0019])\n",
      "Epoch 4333, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2936])\n",
      "    Grad: tensor([-0.0004,  0.0019])\n",
      "Epoch 4334, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2936])\n",
      "    Grad: tensor([-0.0004,  0.0019])\n",
      "Epoch 4335, Loss 3.0\n",
      "    Params: tensor([  5.3657, -17.2936])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4336, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2937])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4337, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2937])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4338, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2937])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4339, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2937])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4340, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2937])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4341, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2938])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4342, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2938])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4343, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2938])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4344, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2938])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4345, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2938])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4346, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2938])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4347, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2939])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4348, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2939])\n",
      "    Grad: tensor([-0.0003,  0.0019])\n",
      "Epoch 4349, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2939])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4350, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2939])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4351, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2939])\n",
      "    Grad: tensor([-0.0004,  0.0018])\n",
      "Epoch 4352, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2940])\n",
      "    Grad: tensor([-0.0004,  0.0018])\n",
      "Epoch 4353, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2940])\n",
      "    Grad: tensor([-0.0004,  0.0018])\n",
      "Epoch 4354, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2940])\n",
      "    Grad: tensor([-0.0004,  0.0018])\n",
      "Epoch 4355, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2940])\n",
      "    Grad: tensor([-0.0004,  0.0018])\n",
      "Epoch 4356, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2940])\n",
      "    Grad: tensor([-0.0004,  0.0018])\n",
      "Epoch 4357, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2941])\n",
      "    Grad: tensor([-0.0004,  0.0018])\n",
      "Epoch 4358, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2941])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4359, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2941])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4360, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2941])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4361, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2941])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4362, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2941])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4363, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2942])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4364, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2942])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4365, Loss 3.0\n",
      "    Params: tensor([  5.3658, -17.2942])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4366, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2942])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4367, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2942])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4368, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2943])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4369, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2943])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4370, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2943])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4371, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2943])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4372, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2943])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4373, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2943])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4374, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2944])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4375, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2944])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4376, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2944])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4377, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2944])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4378, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2944])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4379, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2944])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4380, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2945])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4381, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2945])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4382, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2945])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4383, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2945])\n",
      "    Grad: tensor([-0.0003,  0.0018])\n",
      "Epoch 4384, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2945])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4385, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2945])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4386, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2946])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4387, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2946])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4388, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2946])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4389, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2946])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4390, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2946])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4391, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2946])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4392, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2947])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4393, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2947])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4394, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2947])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4395, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2947])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4396, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2947])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4397, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2948])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4398, Loss 3.0\n",
      "    Params: tensor([  5.3659, -17.2948])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4399, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2948])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4400, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2948])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4401, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2948])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4402, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2948])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4403, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2949])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4404, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2949])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4405, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2949])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4406, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2949])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4407, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2949])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4408, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2949])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4409, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2950])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4410, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2950])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4411, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2950])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4412, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2950])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4413, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2950])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4414, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2950])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4415, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2951])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4416, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2951])\n",
      "    Grad: tensor([-0.0003,  0.0017])\n",
      "Epoch 4417, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2951])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4418, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2951])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4419, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2951])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4420, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2951])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4421, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2952])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4422, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2952])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4423, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2952])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4424, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2952])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4425, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2952])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4426, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2952])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4427, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2953])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4428, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2953])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4429, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2953])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4430, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2953])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4431, Loss 3.0\n",
      "    Params: tensor([  5.3660, -17.2953])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4432, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2953])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4433, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2954])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4434, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2954])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4435, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2954])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4436, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2954])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4437, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2954])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4438, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2954])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4439, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2954])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4440, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2955])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4441, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2955])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4442, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2955])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4443, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2955])\n",
      "    Grad: tensor([-0.0002,  0.0016])\n",
      "Epoch 4444, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2955])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4445, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2955])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4446, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2956])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4447, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2956])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4448, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2956])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4449, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2956])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4450, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2956])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4451, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2956])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4452, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2956])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4453, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2957])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4454, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2957])\n",
      "    Grad: tensor([-0.0003,  0.0016])\n",
      "Epoch 4455, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2957])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4456, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2957])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4457, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2957])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4458, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2957])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4459, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2957])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4460, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2958])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4461, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2958])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4462, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2958])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4463, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2958])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4464, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2958])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4465, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2958])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4466, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2959])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4467, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2959])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4468, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2959])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4469, Loss 3.0\n",
      "    Params: tensor([  5.3661, -17.2959])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4470, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2959])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4471, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2959])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4472, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2959])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4473, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2960])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4474, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2960])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4475, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2960])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4476, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2960])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4477, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2960])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4478, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2960])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4479, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2961])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4480, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2961])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4481, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2961])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4482, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2961])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4483, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2961])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4484, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2961])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4485, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2961])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4486, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2962])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4487, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2962])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4488, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2962])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4489, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2962])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4490, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2962])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4491, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2962])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4492, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2963])\n",
      "    Grad: tensor([-0.0003,  0.0015])\n",
      "Epoch 4493, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2963])\n",
      "    Grad: tensor([-0.0003,  0.0014])\n",
      "Epoch 4494, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2963])\n",
      "    Grad: tensor([-0.0003,  0.0014])\n",
      "Epoch 4495, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2963])\n",
      "    Grad: tensor([-0.0003,  0.0014])\n",
      "Epoch 4496, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2963])\n",
      "    Grad: tensor([-0.0003,  0.0014])\n",
      "Epoch 4497, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2963])\n",
      "    Grad: tensor([-0.0003,  0.0014])\n",
      "Epoch 4498, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2963])\n",
      "    Grad: tensor([-0.0003,  0.0014])\n",
      "Epoch 4499, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2964])\n",
      "    Grad: tensor([-0.0003,  0.0014])\n",
      "Epoch 4500, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2964])\n",
      "    Grad: tensor([-0.0003,  0.0014])\n",
      "Epoch 4501, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2964])\n",
      "    Grad: tensor([-0.0003,  0.0014])\n",
      "Epoch 4502, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2964])\n",
      "    Grad: tensor([-0.0003,  0.0014])\n",
      "Epoch 4503, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2964])\n",
      "    Grad: tensor([-0.0003,  0.0014])\n",
      "Epoch 4504, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2964])\n",
      "    Grad: tensor([-0.0003,  0.0014])\n",
      "Epoch 4505, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2964])\n",
      "    Grad: tensor([-0.0003,  0.0014])\n",
      "Epoch 4506, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2965])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4507, Loss 3.0\n",
      "    Params: tensor([  5.3662, -17.2965])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4508, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2965])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4509, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2965])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4510, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2965])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4511, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2965])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4512, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2965])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4513, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2965])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4514, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2966])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4515, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2966])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4516, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2966])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4517, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2966])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4518, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2966])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4519, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2966])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4520, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2966])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4521, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2967])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4522, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2967])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4523, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2967])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4524, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2967])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4525, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2967])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4526, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2967])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4527, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2967])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4528, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2967])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4529, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2968])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4530, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2968])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4531, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2968])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4532, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2968])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4533, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2968])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4534, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2968])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4535, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2968])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4536, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2969])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4537, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2969])\n",
      "    Grad: tensor([-0.0002,  0.0014])\n",
      "Epoch 4538, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2969])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4539, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2969])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4540, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2969])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4541, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2969])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4542, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2969])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4543, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2969])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4544, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2970])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4545, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2970])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4546, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2970])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4547, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2970])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4548, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2970])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4549, Loss 3.0\n",
      "    Params: tensor([  5.3663, -17.2970])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4550, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2970])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4551, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2971])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4552, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2971])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4553, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2971])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4554, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2971])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4555, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2971])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4556, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2971])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4557, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2971])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4558, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2971])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4559, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2972])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4560, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2972])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4561, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2972])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4562, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2972])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4563, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2972])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4564, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2972])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4565, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2972])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4566, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2973])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4567, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2973])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4568, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2973])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4569, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2973])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4570, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2973])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4571, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2973])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4572, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2973])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4573, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2973])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4574, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2974])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4575, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2974])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4576, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2974])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4577, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2974])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4578, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2974])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4579, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2974])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4580, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2974])\n",
      "    Grad: tensor([-0.0002,  0.0013])\n",
      "Epoch 4581, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2975])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4582, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2975])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4583, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2975])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4584, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2975])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4585, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2975])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4586, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2975])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4587, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2975])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4588, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2975])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4589, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2976])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4590, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2976])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4591, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2976])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4592, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2976])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4593, Loss 3.0\n",
      "    Params: tensor([  5.3664, -17.2976])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4594, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2976])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4595, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2976])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4596, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2976])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4597, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2976])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4598, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2977])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4599, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2977])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4600, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2977])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4601, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2977])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4602, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2977])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4603, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2977])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4604, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2977])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4605, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2977])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4606, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2977])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4607, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2978])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4608, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2978])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4609, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2978])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4610, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2978])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4611, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2978])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4612, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2978])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4613, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2978])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4614, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2978])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4615, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2978])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4616, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2979])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4617, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2979])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4618, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2979])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4619, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2979])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4620, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2979])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4621, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2979])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4622, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2979])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4623, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2979])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4624, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2980])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4625, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2980])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4626, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2980])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4627, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2980])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4628, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2980])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4629, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2980])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4630, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2980])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4631, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2980])\n",
      "    Grad: tensor([-0.0002,  0.0012])\n",
      "Epoch 4632, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2980])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4633, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2981])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4634, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2981])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4635, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2981])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4636, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2981])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4637, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2981])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4638, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2981])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4639, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2981])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4640, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2981])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4641, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2981])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4642, Loss 3.0\n",
      "    Params: tensor([  5.3665, -17.2982])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4643, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2982])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4644, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2982])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4645, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2982])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4646, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2982])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4647, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2982])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4648, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2982])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4649, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2982])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4650, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2983])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4651, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2983])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4652, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2983])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4653, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2983])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4654, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2983])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4655, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2983])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4656, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2983])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4657, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2983])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4658, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2983])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4659, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2984])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4660, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2984])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4661, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2984])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4662, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2984])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4663, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2984])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4664, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2984])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4665, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2984])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4666, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2984])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4667, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2984])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4668, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2985])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4669, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2985])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4670, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2985])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4671, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2985])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4672, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2985])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4673, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2985])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4674, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2985])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4675, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2985])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4676, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2985])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4677, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2986])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4678, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2986])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4679, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2986])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4680, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2986])\n",
      "    Grad: tensor([-0.0002,  0.0011])\n",
      "Epoch 4681, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2986])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4682, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2986])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4683, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2986])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4684, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2986])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4685, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2986])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4686, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2987])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4687, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2987])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4688, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2987])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4689, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2987])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4690, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2987])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4691, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2987])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4692, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2987])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4693, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2987])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4694, Loss 3.0\n",
      "    Params: tensor([  5.3666, -17.2987])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4695, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2987])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4696, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2987])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4697, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2988])\n",
      "    Grad: tensor([-0.0001,  0.0010])\n",
      "Epoch 4698, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2988])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4699, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2988])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4700, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2988])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4701, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2988])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4702, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2988])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4703, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2988])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4704, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2988])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4705, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2988])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4706, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2988])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4707, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2989])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4708, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2989])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4709, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2989])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4710, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2989])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4711, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2989])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4712, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2989])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4713, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2989])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4714, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2989])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4715, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2989])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4716, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2989])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4717, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2989])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4718, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2990])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4719, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2990])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4720, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2990])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4721, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2990])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4722, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2990])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4723, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2990])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4724, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2990])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4725, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2990])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4726, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2990])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4727, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2990])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4728, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2991])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4729, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2991])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4730, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2991])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4731, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2991])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4732, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2991])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4733, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2991])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4734, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2991])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4735, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2991])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4736, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2991])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4737, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2991])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4738, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2991])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4739, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2992])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4740, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2992])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4741, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2992])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4742, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2992])\n",
      "    Grad: tensor([-0.0002,  0.0010])\n",
      "Epoch 4743, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2992])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4744, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2992])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4745, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2992])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4746, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2992])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4747, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2992])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4748, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2992])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4749, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2993])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4750, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2993])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4751, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2993])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4752, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2993])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4753, Loss 3.0\n",
      "    Params: tensor([  5.3667, -17.2993])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4754, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2993])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4755, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2993])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4756, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2993])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4757, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2993])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4758, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2993])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4759, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2993])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4760, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2994])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4761, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2994])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4762, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2994])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4763, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2994])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4764, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2994])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4765, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2994])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4766, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2994])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4767, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2994])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4768, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2994])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4769, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2994])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4770, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2995])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4771, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2995])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4772, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2995])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4773, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2995])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4774, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2995])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4775, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2995])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4776, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2995])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4777, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2995])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4778, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2995])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4779, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2995])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4780, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2995])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4781, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2996])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4782, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2996])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4783, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2996])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4784, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2996])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4785, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2996])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4786, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2996])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4787, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2996])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4788, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2996])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4789, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2996])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4790, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2996])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4791, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2997])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4792, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2997])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4793, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2997])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4794, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2997])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4795, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2997])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4796, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2997])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4797, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2997])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4798, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2997])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4799, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2997])\n",
      "    Grad: tensor([-0.0001,  0.0009])\n",
      "Epoch 4800, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2997])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4801, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2997])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4802, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2998])\n",
      "    Grad: tensor([-0.0001,  0.0009])\n",
      "Epoch 4803, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2998])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4804, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2998])\n",
      "    Grad: tensor([-0.0002,  0.0009])\n",
      "Epoch 4805, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2998])\n",
      "    Grad: tensor([-0.0001,  0.0009])\n",
      "Epoch 4806, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2998])\n",
      "    Grad: tensor([-0.0001,  0.0009])\n",
      "Epoch 4807, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2998])\n",
      "    Grad: tensor([-0.0001,  0.0009])\n",
      "Epoch 4808, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2998])\n",
      "    Grad: tensor([-0.0001,  0.0009])\n",
      "Epoch 4809, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2998])\n",
      "    Grad: tensor([-0.0001,  0.0009])\n",
      "Epoch 4810, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2998])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4811, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2998])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4812, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2998])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4813, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2998])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4814, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2998])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4815, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2999])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4816, Loss 3.0\n",
      "    Params: tensor([  5.3668, -17.2999])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4817, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.2999])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4818, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.2999])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4819, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.2999])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4820, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.2999])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4821, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.2999])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4822, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.2999])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4823, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.2999])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4824, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.2999])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4825, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.2999])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4826, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.2999])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4827, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.2999])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4828, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3000])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4829, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3000])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4830, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3000])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4831, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3000])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4832, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3000])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4833, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3000])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4834, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3000])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4835, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3000])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4836, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3000])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4837, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3000])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4838, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3000])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4839, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3000])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4840, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3000])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4841, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3001])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4842, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3001])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4843, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3001])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4844, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3001])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4845, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3001])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4846, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3001])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4847, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3001])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4848, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3001])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4849, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3001])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4850, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3001])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4851, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3001])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4852, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3001])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4853, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3001])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4854, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3002])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4855, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3002])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4856, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3002])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4857, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3002])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4858, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3002])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4859, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3002])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4860, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3002])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4861, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3002])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4862, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3002])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4863, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3002])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4864, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3002])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4865, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3002])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4866, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3002])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4867, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3003])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4868, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3003])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4869, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3003])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4870, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3003])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4871, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3003])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4872, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3003])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4873, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3003])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4874, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3003])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4875, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3003])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4876, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3003])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4877, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3003])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4878, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3003])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4879, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3003])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4880, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4881, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4882, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4883, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0008])\n",
      "Epoch 4884, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4885, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4886, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4887, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4888, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4889, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4890, Loss 3.0\n",
      "    Params: tensor([  5.3669, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4891, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4892, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4893, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3004])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4894, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3005])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4895, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3005])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4896, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3005])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4897, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3005])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4898, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3005])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4899, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3005])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4900, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3005])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4901, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3005])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4902, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3005])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4903, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3005])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4904, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3005])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4905, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3005])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4906, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3005])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4907, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3006])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4908, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3006])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4909, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3006])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4910, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3006])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4911, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3006])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4912, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3006])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4913, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3006])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4914, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3006])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4915, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3006])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4916, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3006])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4917, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3006])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4918, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3006])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4919, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3006])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4920, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3007])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4921, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3007])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4922, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3007])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4923, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3007])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4924, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3007])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4925, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3007])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4926, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3007])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4927, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3007])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4928, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3007])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4929, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3007])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4930, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3007])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4931, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3007])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4932, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3007])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4933, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3008])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4934, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3008])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4935, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3008])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4936, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3008])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4937, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3008])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4938, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3008])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4939, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3008])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4940, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3008])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4941, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3008])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4942, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3008])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4943, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3008])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4944, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3008])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4945, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3008])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4946, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4947, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4948, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4949, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4950, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4951, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4952, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-9.5010e-05,  6.6668e-04])\n",
      "Epoch 4953, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4954, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4955, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4956, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4957, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4958, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4959, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4960, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4961, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-9.6381e-05,  6.5720e-04])\n",
      "Epoch 4962, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3009])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4963, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4964, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4965, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0007])\n",
      "Epoch 4966, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4967, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4968, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3010])\n",
      "    Grad: tensor([-9.6202e-05,  6.5023e-04])\n",
      "Epoch 4969, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3010])\n",
      "    Grad: tensor([-9.5904e-05,  6.4930e-04])\n",
      "Epoch 4970, Loss 3.0\n",
      "    Params: tensor([  5.3670, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4971, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4972, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4973, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4974, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4975, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4976, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4977, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4978, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3010])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4979, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3010])\n",
      "    Grad: tensor([-9.1910e-05,  6.3980e-04])\n",
      "Epoch 4980, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4981, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4982, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4983, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4984, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4985, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4986, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4987, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-9.9421e-05,  6.3089e-04])\n",
      "Epoch 4988, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-9.8109e-05,  6.2972e-04])\n",
      "Epoch 4989, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4990, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4991, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4992, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4993, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4994, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-9.4235e-05,  6.2457e-04])\n",
      "Epoch 4995, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-9.0718e-05,  6.2406e-04])\n",
      "Epoch 4996, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-9.4056e-05,  6.2260e-04])\n",
      "Epoch 4997, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3011])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4998, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 4999, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5000, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5001, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5002, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5003, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5004, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-9.3043e-05,  6.1464e-04])\n",
      "Epoch 5005, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-9.7871e-05,  6.1291e-04])\n",
      "Epoch 5006, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5007, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5008, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5009, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5010, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5011, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5012, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-9.9778e-05,  6.0585e-04])\n",
      "Epoch 5013, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-9.7573e-05,  6.0517e-04])\n",
      "Epoch 5014, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3012])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5015, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-9.7752e-05,  6.0266e-04])\n",
      "Epoch 5016, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5017, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5018, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5019, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5020, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5021, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5022, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5023, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-9.9003e-05,  5.9462e-04])\n",
      "Epoch 5024, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5025, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5026, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5027, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5028, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5029, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5030, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-9.3758e-05,  5.8880e-04])\n",
      "Epoch 5031, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-9.5248e-05,  5.8734e-04])\n",
      "Epoch 5032, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3013])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5033, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5034, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5035, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5036, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5037, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5038, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5039, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5040, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-9.4712e-05,  5.7846e-04])\n",
      "Epoch 5041, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-9.9421e-05,  5.7638e-04])\n",
      "Epoch 5042, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5043, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5044, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5045, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5046, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5047, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5048, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-9.8050e-05,  5.6991e-04])\n",
      "Epoch 5049, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3014])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5050, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5051, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5052, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5053, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5054, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5055, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5056, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5057, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5058, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-9.4771e-05,  5.6040e-04])\n",
      "Epoch 5059, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5060, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-9.8526e-05,  5.5754e-04])\n",
      "Epoch 5061, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5062, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5063, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5064, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0006])\n",
      "Epoch 5065, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5066, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-9.7752e-05,  5.5179e-04])\n",
      "Epoch 5067, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3015])\n",
      "    Grad: tensor([-9.5665e-05,  5.5104e-04])\n",
      "Epoch 5068, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5069, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5070, Loss 3.0\n",
      "    Params: tensor([  5.3671, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5071, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5072, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5073, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5074, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5075, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-9.5248e-05,  5.4315e-04])\n",
      "Epoch 5076, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5077, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-9.8348e-05,  5.4047e-04])\n",
      "Epoch 5078, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5079, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5080, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5081, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5082, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5083, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-9.2447e-05,  5.3561e-04])\n",
      "Epoch 5084, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3016])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5085, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5086, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5087, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5088, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5089, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5090, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5091, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5092, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-9.4473e-05,  5.2649e-04])\n",
      "Epoch 5093, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5094, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5095, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5096, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5097, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5098, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5099, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5100, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5101, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5102, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3017])\n",
      "    Grad: tensor([-9.7573e-05,  5.1579e-04])\n",
      "Epoch 5103, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5104, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5105, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5106, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5107, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5108, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5109, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5110, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-9.7036e-05,  5.0789e-04])\n",
      "Epoch 5111, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5112, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5113, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5114, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5115, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5116, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5117, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5118, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-8.8215e-05,  5.0113e-04])\n",
      "Epoch 5119, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3018])\n",
      "    Grad: tensor([-9.5189e-05,  4.9901e-04])\n",
      "Epoch 5120, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5121, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5122, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5123, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5124, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5125, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5126, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5127, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5128, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-9.8705e-05,  4.8947e-04])\n",
      "Epoch 5129, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5130, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5131, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5132, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5133, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5134, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5135, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-8.7440e-05,  4.8429e-04])\n",
      "Epoch 5136, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-9.6321e-05,  4.8181e-04])\n",
      "Epoch 5137, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3019])\n",
      "    Grad: tensor([-9.6083e-05,  4.8101e-04])\n",
      "Epoch 5138, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5139, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-9.7394e-05,  4.7854e-04])\n",
      "Epoch 5140, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-0.0001,  0.0005])\n",
      "Epoch 5141, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-8.6188e-05,  4.7892e-04])\n",
      "Epoch 5142, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-9.5487e-05,  4.7615e-04])\n",
      "Epoch 5143, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-8.1480e-05,  4.7803e-04])\n",
      "Epoch 5144, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-8.2374e-05,  4.7696e-04])\n",
      "Epoch 5145, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-8.4817e-05,  4.7559e-04])\n",
      "Epoch 5146, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-6.5565e-05,  4.7833e-04])\n",
      "Epoch 5147, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-9.9599e-05,  4.7129e-04])\n",
      "Epoch 5148, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-8.5056e-05,  4.7299e-04])\n",
      "Epoch 5149, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-6.7830e-05,  4.7562e-04])\n",
      "Epoch 5150, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-7.4685e-05,  4.7365e-04])\n",
      "Epoch 5151, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-6.3479e-05,  4.7508e-04])\n",
      "Epoch 5152, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-7.4685e-05,  4.7246e-04])\n",
      "Epoch 5153, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-5.6803e-05,  4.7493e-04])\n",
      "Epoch 5154, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-7.1347e-05,  4.7159e-04])\n",
      "Epoch 5155, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-7.8738e-05,  4.6968e-04])\n",
      "Epoch 5156, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-6.6519e-05,  4.7123e-04])\n",
      "Epoch 5157, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-7.9691e-05,  4.6819e-04])\n",
      "Epoch 5158, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-5.7757e-05,  4.7144e-04])\n",
      "Epoch 5159, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-6.1452e-05,  4.6986e-04])\n",
      "Epoch 5160, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3020])\n",
      "    Grad: tensor([-8.1062e-05,  4.6557e-04])\n",
      "Epoch 5161, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-6.4194e-05,  4.6796e-04])\n",
      "Epoch 5162, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-6.9201e-05,  4.6638e-04])\n",
      "Epoch 5163, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-8.6367e-05,  4.6274e-04])\n",
      "Epoch 5164, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-6.4731e-05,  4.6605e-04])\n",
      "Epoch 5165, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-7.8678e-05,  4.6280e-04])\n",
      "Epoch 5166, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-6.6340e-05,  4.6447e-04])\n",
      "Epoch 5167, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-7.8142e-05,  4.6158e-04])\n",
      "Epoch 5168, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-6.1095e-05,  4.6396e-04])\n",
      "Epoch 5169, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-6.9559e-05,  4.6170e-04])\n",
      "Epoch 5170, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-8.0049e-05,  4.5907e-04])\n",
      "Epoch 5171, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-6.9320e-05,  4.6054e-04])\n",
      "Epoch 5172, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-8.0228e-05,  4.5806e-04])\n",
      "Epoch 5173, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-5.8532e-05,  4.6119e-04])\n",
      "Epoch 5174, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-7.0393e-05,  4.5818e-04])\n",
      "Epoch 5175, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-8.3685e-05,  4.5541e-04])\n",
      "Epoch 5176, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-6.7055e-05,  4.5767e-04])\n",
      "Epoch 5177, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-7.8142e-05,  4.5508e-04])\n",
      "Epoch 5178, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-6.2525e-05,  4.5717e-04])\n",
      "Epoch 5179, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-7.5102e-05,  4.5422e-04])\n",
      "Epoch 5180, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-6.3539e-05,  4.5580e-04])\n",
      "Epoch 5181, Loss 3.0\n",
      "    Params: tensor([  5.3672, -17.3021])\n",
      "    Grad: tensor([-7.1347e-05,  4.5359e-04])\n",
      "Epoch 5182, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3021])\n",
      "    Grad: tensor([-8.2612e-05,  4.5103e-04])\n",
      "Epoch 5183, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3021])\n",
      "    Grad: tensor([-6.4552e-05,  4.5341e-04])\n",
      "Epoch 5184, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3021])\n",
      "    Grad: tensor([-7.5519e-05,  4.5088e-04])\n",
      "Epoch 5185, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3021])\n",
      "    Grad: tensor([-6.0558e-05,  4.5291e-04])\n",
      "Epoch 5186, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3021])\n",
      "    Grad: tensor([-7.2300e-05,  4.5040e-04])\n",
      "Epoch 5187, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-5.5552e-05,  4.5261e-04])\n",
      "Epoch 5188, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-6.6817e-05,  4.4972e-04])\n",
      "Epoch 5189, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-7.3552e-05,  4.4772e-04])\n",
      "Epoch 5190, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-5.6207e-05,  4.5022e-04])\n",
      "Epoch 5191, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-6.8963e-05,  4.4733e-04])\n",
      "Epoch 5192, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-8.2433e-05,  4.4432e-04])\n",
      "Epoch 5193, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-6.1691e-05,  4.4715e-04])\n",
      "Epoch 5194, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-7.2658e-05,  4.4447e-04])\n",
      "Epoch 5195, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-6.3241e-05,  4.4572e-04])\n",
      "Epoch 5196, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-7.1049e-05,  4.4382e-04])\n",
      "Epoch 5197, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-7.9572e-05,  4.4155e-04])\n",
      "Epoch 5198, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-6.6578e-05,  4.4295e-04])\n",
      "Epoch 5199, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-7.6115e-05,  4.4066e-04])\n",
      "Epoch 5200, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-6.4909e-05,  4.4206e-04])\n",
      "Epoch 5201, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-7.4029e-05,  4.3973e-04])\n",
      "Epoch 5202, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-5.7220e-05,  4.4182e-04])\n",
      "Epoch 5203, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-6.9141e-05,  4.3914e-04])\n",
      "Epoch 5204, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-7.9274e-05,  4.3672e-04])\n",
      "Epoch 5205, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-6.2644e-05,  4.3911e-04])\n",
      "Epoch 5206, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-7.6950e-05,  4.3586e-04])\n",
      "Epoch 5207, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-5.8472e-05,  4.3839e-04])\n",
      "Epoch 5208, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-7.1049e-05,  4.3541e-04])\n",
      "Epoch 5209, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-8.1122e-05,  4.3315e-04])\n",
      "Epoch 5210, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-6.7830e-05,  4.3494e-04])\n",
      "Epoch 5211, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-7.8022e-05,  4.3234e-04])\n",
      "Epoch 5212, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-6.0022e-05,  4.3491e-04])\n",
      "Epoch 5213, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3022])\n",
      "    Grad: tensor([-7.2837e-05,  4.3198e-04])\n",
      "Epoch 5214, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-5.3346e-05,  4.3473e-04])\n",
      "Epoch 5215, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-7.1049e-05,  4.3109e-04])\n",
      "Epoch 5216, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-8.1480e-05,  4.2847e-04])\n",
      "Epoch 5217, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-6.2227e-05,  4.3121e-04])\n",
      "Epoch 5218, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-7.5340e-05,  4.2832e-04])\n",
      "Epoch 5219, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-4.9055e-05,  4.3195e-04])\n",
      "Epoch 5220, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-6.4313e-05,  4.2874e-04])\n",
      "Epoch 5221, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-8.0526e-05,  4.2504e-04])\n",
      "Epoch 5222, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-6.1214e-05,  4.2775e-04])\n",
      "Epoch 5223, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-6.6459e-05,  4.2623e-04])\n",
      "Epoch 5224, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-8.3268e-05,  4.2263e-04])\n",
      "Epoch 5225, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-6.8307e-05,  4.2465e-04])\n",
      "Epoch 5226, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-8.2433e-05,  4.2138e-04])\n",
      "Epoch 5227, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-6.4433e-05,  4.2400e-04])\n",
      "Epoch 5228, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-7.0155e-05,  4.2239e-04])\n",
      "Epoch 5229, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-8.2731e-05,  4.1941e-04])\n",
      "Epoch 5230, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-7.1585e-05,  4.2078e-04])\n",
      "Epoch 5231, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-4.9651e-05,  4.2391e-04])\n",
      "Epoch 5232, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-6.4611e-05,  4.2057e-04])\n",
      "Epoch 5233, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-7.6830e-05,  4.1765e-04])\n",
      "Epoch 5234, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-6.1512e-05,  4.1974e-04])\n",
      "Epoch 5235, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-7.3969e-05,  4.1705e-04])\n",
      "Epoch 5236, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-5.7042e-05,  4.1941e-04])\n",
      "Epoch 5237, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-6.2168e-05,  4.1783e-04])\n",
      "Epoch 5238, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-7.9215e-05,  4.1422e-04])\n",
      "Epoch 5239, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3023])\n",
      "    Grad: tensor([-6.6876e-05,  4.1553e-04])\n",
      "Epoch 5240, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.6115e-05,  4.1333e-04])\n",
      "Epoch 5241, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-6.0678e-05,  4.1547e-04])\n",
      "Epoch 5242, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-6.7234e-05,  4.1354e-04])\n",
      "Epoch 5243, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.9572e-05,  4.1077e-04])\n",
      "Epoch 5244, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-6.6757e-05,  4.1243e-04])\n",
      "Epoch 5245, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.7546e-05,  4.0978e-04])\n",
      "Epoch 5246, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-5.7101e-05,  4.1264e-04])\n",
      "Epoch 5247, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.0035e-05,  4.0966e-04])\n",
      "Epoch 5248, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.9274e-05,  4.0740e-04])\n",
      "Epoch 5249, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-6.1631e-05,  4.0951e-04])\n",
      "Epoch 5250, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.3791e-05,  4.0692e-04])\n",
      "Epoch 5251, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-5.3406e-05,  4.0996e-04])\n",
      "Epoch 5252, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-6.6221e-05,  4.0695e-04])\n",
      "Epoch 5253, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.8738e-05,  4.0400e-04])\n",
      "Epoch 5254, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-6.2943e-05,  4.0612e-04])\n",
      "Epoch 5255, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.4148e-05,  4.0343e-04])\n",
      "Epoch 5256, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-5.6982e-05,  4.0597e-04])\n",
      "Epoch 5257, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-6.6400e-05,  4.0367e-04])\n",
      "Epoch 5258, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.8559e-05,  4.0066e-04])\n",
      "Epoch 5259, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.0751e-05,  4.0156e-04])\n",
      "Epoch 5260, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.6115e-05,  4.0001e-04])\n",
      "Epoch 5261, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-6.2108e-05,  4.0179e-04])\n",
      "Epoch 5262, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.0989e-05,  3.9956e-04])\n",
      "Epoch 5263, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-8.1122e-05,  3.9691e-04])\n",
      "Epoch 5264, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.1168e-05,  3.9822e-04])\n",
      "Epoch 5265, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3024])\n",
      "    Grad: tensor([-7.9632e-05,  3.9604e-04])\n",
      "Epoch 5266, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-6.0976e-05,  3.9873e-04])\n",
      "Epoch 5267, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-7.5161e-05,  3.9539e-04])\n",
      "Epoch 5268, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-5.5909e-05,  3.9819e-04])\n",
      "Epoch 5269, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-6.9439e-05,  3.9518e-04])\n",
      "Epoch 5270, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-8.2612e-05,  3.9223e-04])\n",
      "Epoch 5271, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-6.3181e-05,  3.9512e-04])\n",
      "Epoch 5272, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-7.6294e-05,  3.9172e-04])\n",
      "Epoch 5273, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-6.3717e-05,  3.9351e-04])\n",
      "Epoch 5274, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-7.4744e-05,  3.9089e-04])\n",
      "Epoch 5275, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-5.7220e-05,  3.9345e-04])\n",
      "Epoch 5276, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-6.7532e-05,  3.9080e-04])\n",
      "Epoch 5277, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-7.6890e-05,  3.8850e-04])\n",
      "Epoch 5278, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-6.2227e-05,  3.9032e-04])\n",
      "Epoch 5279, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-7.0810e-05,  3.8800e-04])\n",
      "Epoch 5280, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-8.1480e-05,  3.8540e-04])\n",
      "Epoch 5281, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-6.3658e-05,  3.8782e-04])\n",
      "Epoch 5282, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-7.4387e-05,  3.8517e-04])\n",
      "Epoch 5283, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-6.0856e-05,  3.8713e-04])\n",
      "Epoch 5284, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-6.8188e-05,  3.8525e-04])\n",
      "Epoch 5285, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-8.5175e-05,  3.8159e-04])\n",
      "Epoch 5286, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-6.6280e-05,  3.8403e-04])\n",
      "Epoch 5287, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-7.5102e-05,  3.8183e-04])\n",
      "Epoch 5288, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-6.2943e-05,  3.8356e-04])\n",
      "Epoch 5289, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-7.2122e-05,  3.8126e-04])\n",
      "Epoch 5290, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-5.7399e-05,  3.8323e-04])\n",
      "Epoch 5291, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3025])\n",
      "    Grad: tensor([-6.8307e-05,  3.8058e-04])\n",
      "Epoch 5292, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-7.8499e-05,  3.7792e-04])\n",
      "Epoch 5293, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-6.7711e-05,  3.7929e-04])\n",
      "Epoch 5294, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-7.6771e-05,  3.7712e-04])\n",
      "Epoch 5295, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-5.8353e-05,  3.7959e-04])\n",
      "Epoch 5296, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-6.9857e-05,  3.7694e-04])\n",
      "Epoch 5297, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-8.2374e-05,  3.7399e-04])\n",
      "Epoch 5298, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-6.3837e-05,  3.7700e-04])\n",
      "Epoch 5299, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-8.1718e-05,  3.7295e-04])\n",
      "Epoch 5300, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-6.3539e-05,  3.7539e-04])\n",
      "Epoch 5301, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-6.6876e-05,  3.7420e-04])\n",
      "Epoch 5302, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-8.4102e-05,  3.7059e-04])\n",
      "Epoch 5303, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-6.9022e-05,  3.7262e-04])\n",
      "Epoch 5304, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-7.8022e-05,  3.7041e-04])\n",
      "Epoch 5305, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-6.5148e-05,  3.7178e-04])\n",
      "Epoch 5306, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-7.5519e-05,  3.6934e-04])\n",
      "Epoch 5307, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-5.6803e-05,  3.7217e-04])\n",
      "Epoch 5308, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-6.4492e-05,  3.6985e-04])\n",
      "Epoch 5309, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-7.6473e-05,  3.6699e-04])\n",
      "Epoch 5310, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-6.1035e-05,  3.6901e-04])\n",
      "Epoch 5311, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-7.0214e-05,  3.6681e-04])\n",
      "Epoch 5312, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-7.8797e-05,  3.6448e-04])\n",
      "Epoch 5313, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-7.4089e-05,  3.6478e-04])\n",
      "Epoch 5314, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-5.1737e-05,  3.6809e-04])\n",
      "Epoch 5315, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-5.8293e-05,  3.6615e-04])\n",
      "Epoch 5316, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-7.1108e-05,  3.6326e-04])\n",
      "Epoch 5317, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3026])\n",
      "    Grad: tensor([-8.6188e-05,  3.5998e-04])\n",
      "Epoch 5318, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3027])\n",
      "    Grad: tensor([-6.8903e-05,  3.6237e-04])\n",
      "Epoch 5319, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3027])\n",
      "    Grad: tensor([-7.9393e-05,  3.5980e-04])\n",
      "Epoch 5320, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3027])\n",
      "    Grad: tensor([-6.3896e-05,  3.6192e-04])\n",
      "Epoch 5321, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3027])\n",
      "    Grad: tensor([-7.3135e-05,  3.5959e-04])\n",
      "Epoch 5322, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3027])\n",
      "    Grad: tensor([-6.3777e-05,  3.6079e-04])\n",
      "Epoch 5323, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3027])\n",
      "    Grad: tensor([-7.3493e-05,  3.5822e-04])\n",
      "Epoch 5324, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3027])\n",
      "    Grad: tensor([-5.0902e-05,  3.6156e-04])\n",
      "Epoch 5325, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3027])\n",
      "    Grad: tensor([-6.8545e-05,  3.5775e-04])\n",
      "Epoch 5326, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3027])\n",
      "    Grad: tensor([-7.7367e-05,  3.5548e-04])\n",
      "Epoch 5327, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3027])\n",
      "    Grad: tensor([-6.2108e-05,  3.5748e-04])\n",
      "Epoch 5328, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3027])\n",
      "    Grad: tensor([-7.4923e-05,  3.5465e-04])\n",
      "Epoch 5329, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3027])\n",
      "    Grad: tensor([-5.7697e-05,  3.5709e-04])\n",
      "Epoch 5330, Loss 3.0\n",
      "    Params: tensor([  5.3673, -17.3027])\n",
      "    Grad: tensor([-6.6876e-05,  3.5492e-04])\n",
      "Epoch 5331, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-7.7844e-05,  3.5235e-04])\n",
      "Epoch 5332, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-6.7472e-05,  3.5343e-04])\n",
      "Epoch 5333, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-7.6413e-05,  3.5110e-04])\n",
      "Epoch 5334, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-5.9962e-05,  3.5352e-04])\n",
      "Epoch 5335, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-6.8605e-05,  3.5119e-04])\n",
      "Epoch 5336, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-8.0824e-05,  3.4833e-04])\n",
      "Epoch 5337, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-6.9261e-05,  3.4982e-04])\n",
      "Epoch 5338, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-7.3969e-05,  3.4797e-04])\n",
      "Epoch 5339, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-5.6624e-05,  3.5042e-04])\n",
      "Epoch 5340, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-6.7592e-05,  3.4773e-04])\n",
      "Epoch 5341, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-7.8678e-05,  3.4520e-04])\n",
      "Epoch 5342, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-6.7174e-05,  3.4654e-04])\n",
      "Epoch 5343, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-7.4744e-05,  3.4460e-04])\n",
      "Epoch 5344, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3027])\n",
      "    Grad: tensor([-5.8591e-05,  3.4675e-04])\n",
      "Epoch 5345, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-7.1585e-05,  3.4386e-04])\n",
      "Epoch 5346, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-5.0545e-05,  3.4681e-04])\n",
      "Epoch 5347, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-6.7711e-05,  3.4320e-04])\n",
      "Epoch 5348, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-7.9393e-05,  3.4052e-04])\n",
      "Epoch 5349, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-5.7757e-05,  3.4368e-04])\n",
      "Epoch 5350, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-6.9141e-05,  3.4112e-04])\n",
      "Epoch 5351, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-8.5115e-05,  3.3742e-04])\n",
      "Epoch 5352, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-6.9916e-05,  3.3957e-04])\n",
      "Epoch 5353, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-7.9215e-05,  3.3724e-04])\n",
      "Epoch 5354, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-6.4731e-05,  3.3918e-04])\n",
      "Epoch 5355, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-7.4267e-05,  3.3686e-04])\n",
      "Epoch 5356, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-5.3287e-05,  3.3972e-04])\n",
      "Epoch 5357, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-7.1645e-05,  3.3602e-04])\n",
      "Epoch 5358, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-4.9531e-05,  3.3912e-04])\n",
      "Epoch 5359, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-6.2287e-05,  3.3617e-04])\n",
      "Epoch 5360, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-7.8797e-05,  3.3247e-04])\n",
      "Epoch 5361, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-5.8889e-05,  3.3551e-04])\n",
      "Epoch 5362, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-6.8426e-05,  3.3319e-04])\n",
      "Epoch 5363, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-8.5831e-05,  3.2961e-04])\n",
      "Epoch 5364, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-6.6102e-05,  3.3236e-04])\n",
      "Epoch 5365, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-7.5817e-05,  3.2973e-04])\n",
      "Epoch 5366, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-6.0380e-05,  3.3188e-04])\n",
      "Epoch 5367, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-7.5817e-05,  3.2863e-04])\n",
      "Epoch 5368, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-5.3465e-05,  3.3161e-04])\n",
      "Epoch 5369, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-6.2466e-05,  3.2932e-04])\n",
      "Epoch 5370, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3028])\n",
      "    Grad: tensor([-7.3552e-05,  3.2666e-04])\n",
      "Epoch 5371, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-6.2644e-05,  3.2809e-04])\n",
      "Epoch 5372, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-7.3433e-05,  3.2544e-04])\n",
      "Epoch 5373, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-5.4181e-05,  3.2818e-04])\n",
      "Epoch 5374, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-6.7890e-05,  3.2508e-04])\n",
      "Epoch 5375, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-7.5042e-05,  3.2312e-04])\n",
      "Epoch 5376, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-6.0022e-05,  3.2517e-04])\n",
      "Epoch 5377, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-7.7009e-05,  3.2175e-04])\n",
      "Epoch 5378, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-5.5373e-05,  3.2479e-04])\n",
      "Epoch 5379, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-6.7115e-05,  3.2181e-04])\n",
      "Epoch 5380, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-8.0168e-05,  3.1888e-04])\n",
      "Epoch 5381, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-6.5863e-05,  3.2094e-04])\n",
      "Epoch 5382, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-7.2777e-05,  3.1897e-04])\n",
      "Epoch 5383, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-6.0380e-05,  3.2046e-04])\n",
      "Epoch 5384, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-6.9439e-05,  3.1826e-04])\n",
      "Epoch 5385, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-8.1122e-05,  3.1543e-04])\n",
      "Epoch 5386, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-7.0453e-05,  3.1686e-04])\n",
      "Epoch 5387, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-7.7605e-05,  3.1495e-04])\n",
      "Epoch 5388, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-5.7638e-05,  3.1769e-04])\n",
      "Epoch 5389, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-7.2777e-05,  3.1441e-04])\n",
      "Epoch 5390, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-5.0962e-05,  3.1760e-04])\n",
      "Epoch 5391, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-7.0274e-05,  3.1352e-04])\n",
      "Epoch 5392, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-8.0884e-05,  3.1087e-04])\n",
      "Epoch 5393, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-6.4611e-05,  3.1322e-04])\n",
      "Epoch 5394, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-7.2122e-05,  3.1129e-04])\n",
      "Epoch 5395, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-5.6684e-05,  3.1337e-04])\n",
      "Epoch 5396, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3029])\n",
      "    Grad: tensor([-7.0214e-05,  3.1036e-04])\n",
      "Epoch 5397, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-7.9095e-05,  3.0807e-04])\n",
      "Epoch 5398, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-6.2466e-05,  3.0991e-04])\n",
      "Epoch 5399, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-6.9439e-05,  3.0798e-04])\n",
      "Epoch 5400, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-8.0168e-05,  3.0541e-04])\n",
      "Epoch 5401, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-6.7234e-05,  3.0726e-04])\n",
      "Epoch 5402, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-7.9393e-05,  3.0422e-04])\n",
      "Epoch 5403, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-6.2227e-05,  3.0676e-04])\n",
      "Epoch 5404, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-7.1466e-05,  3.0458e-04])\n",
      "Epoch 5405, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-8.3804e-05,  3.0157e-04])\n",
      "Epoch 5406, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-7.2896e-05,  3.0300e-04])\n",
      "Epoch 5407, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-5.2333e-05,  3.0577e-04])\n",
      "Epoch 5408, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-6.2823e-05,  3.0336e-04])\n",
      "Epoch 5409, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-7.6652e-05,  3.0032e-04])\n",
      "Epoch 5410, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-5.4240e-05,  3.0351e-04])\n",
      "Epoch 5411, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-7.3016e-05,  2.9948e-04])\n",
      "Epoch 5412, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-5.7280e-05,  3.0166e-04])\n",
      "Epoch 5413, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-6.4433e-05,  2.9969e-04])\n",
      "Epoch 5414, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-7.5877e-05,  2.9707e-04])\n",
      "Epoch 5415, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-6.4850e-05,  2.9844e-04])\n",
      "Epoch 5416, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-7.3493e-05,  2.9615e-04])\n",
      "Epoch 5417, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-6.0976e-05,  2.9770e-04])\n",
      "Epoch 5418, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-6.9678e-05,  2.9546e-04])\n",
      "Epoch 5419, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-7.9274e-05,  2.9317e-04])\n",
      "Epoch 5420, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-6.8486e-05,  2.9454e-04])\n",
      "Epoch 5421, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-7.8022e-05,  2.9197e-04])\n",
      "Epoch 5422, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3030])\n",
      "    Grad: tensor([-5.5075e-05,  2.9549e-04])\n",
      "Epoch 5423, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-6.6221e-05,  2.9290e-04])\n",
      "Epoch 5424, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-8.4281e-05,  2.8881e-04])\n",
      "Epoch 5425, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-6.9916e-05,  2.9078e-04])\n",
      "Epoch 5426, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-7.5698e-05,  2.8920e-04])\n",
      "Epoch 5427, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-6.1691e-05,  2.9093e-04])\n",
      "Epoch 5428, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-6.6817e-05,  2.8908e-04])\n",
      "Epoch 5429, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-7.3969e-05,  2.8718e-04])\n",
      "Epoch 5430, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-6.2406e-05,  2.8852e-04])\n",
      "Epoch 5431, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-7.6413e-05,  2.8527e-04])\n",
      "Epoch 5432, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-3.7909e-05,  2.9203e-04])\n",
      "Epoch 5433, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-5.0068e-05,  2.8911e-04])\n",
      "Epoch 5434, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-5.7578e-05,  2.8720e-04])\n",
      "Epoch 5435, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-7.1824e-05,  2.8387e-04])\n",
      "Epoch 5436, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-3.7968e-05,  2.8971e-04])\n",
      "Epoch 5437, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-4.8637e-05,  2.8715e-04])\n",
      "Epoch 5438, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-5.8472e-05,  2.8449e-04])\n",
      "Epoch 5439, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-5.3942e-05,  2.8503e-04])\n",
      "Epoch 5440, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-4.1723e-05,  2.8688e-04])\n",
      "Epoch 5441, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-5.3644e-05,  2.8396e-04])\n",
      "Epoch 5442, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-4.8995e-05,  2.8467e-04])\n",
      "Epoch 5443, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-4.2737e-05,  2.8551e-04])\n",
      "Epoch 5444, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-3.1531e-05,  2.8712e-04])\n",
      "Epoch 5445, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-4.0889e-05,  2.8482e-04])\n",
      "Epoch 5446, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-3.0398e-05,  2.8643e-04])\n",
      "Epoch 5447, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-5.0068e-05,  2.8199e-04])\n",
      "Epoch 5448, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-3.6776e-05,  2.8399e-04])\n",
      "Epoch 5449, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-3.3140e-05,  2.8452e-04])\n",
      "Epoch 5450, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-1.8656e-05,  2.8673e-04])\n",
      "Epoch 5451, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-5.8174e-05,  2.7916e-04])\n",
      "Epoch 5452, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-5.5194e-05,  2.7934e-04])\n",
      "Epoch 5453, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-4.8459e-05,  2.8023e-04])\n",
      "Epoch 5454, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-3.3677e-05,  2.8262e-04])\n",
      "Epoch 5455, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-2.7120e-05,  2.8315e-04])\n",
      "Epoch 5456, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-1.7524e-05,  2.8464e-04])\n",
      "Epoch 5457, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-3.7313e-05,  2.8089e-04])\n",
      "Epoch 5458, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3031])\n",
      "    Grad: tensor([-3.5286e-05,  2.8107e-04])\n",
      "Epoch 5459, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.6524e-05,  2.8196e-04])\n",
      "Epoch 5460, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-1.4722e-05,  2.8393e-04])\n",
      "Epoch 5461, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.4273e-05,  2.8002e-04])\n",
      "Epoch 5462, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.0279e-05,  2.8056e-04])\n",
      "Epoch 5463, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-1.8239e-05,  2.8217e-04])\n",
      "Epoch 5464, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.8862e-05,  2.7832e-04])\n",
      "Epoch 5465, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.9266e-05,  2.7961e-04])\n",
      "Epoch 5466, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-1.8239e-05,  2.8116e-04])\n",
      "Epoch 5467, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.8445e-05,  2.7728e-04])\n",
      "Epoch 5468, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.8087e-05,  2.7710e-04])\n",
      "Epoch 5469, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.9147e-05,  2.7853e-04])\n",
      "Epoch 5470, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-1.6630e-05,  2.8047e-04])\n",
      "Epoch 5471, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.6597e-05,  2.7660e-04])\n",
      "Epoch 5472, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.6584e-05,  2.7779e-04])\n",
      "Epoch 5473, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-1.3888e-05,  2.7931e-04])\n",
      "Epoch 5474, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.2842e-05,  2.7552e-04])\n",
      "Epoch 5475, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.6405e-05,  2.7642e-04])\n",
      "Epoch 5476, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-1.7762e-05,  2.7761e-04])\n",
      "Epoch 5477, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.7849e-05,  2.7379e-04])\n",
      "Epoch 5478, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.8849e-05,  2.7508e-04])\n",
      "Epoch 5479, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.0921e-05,  2.7621e-04])\n",
      "Epoch 5480, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-4.0412e-05,  2.7242e-04])\n",
      "Epoch 5481, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.3915e-05,  2.7332e-04])\n",
      "Epoch 5482, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.4736e-05,  2.7451e-04])\n",
      "Epoch 5483, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-1.7345e-05,  2.7531e-04])\n",
      "Epoch 5484, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.7313e-05,  2.7153e-04])\n",
      "Epoch 5485, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.3961e-05,  2.7356e-04])\n",
      "Epoch 5486, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.5988e-05,  2.7314e-04])\n",
      "Epoch 5487, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-1.5199e-05,  2.7457e-04])\n",
      "Epoch 5488, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.4750e-05,  2.7090e-04])\n",
      "Epoch 5489, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.5809e-05,  2.7215e-04])\n",
      "Epoch 5490, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-1.5497e-05,  2.7364e-04])\n",
      "Epoch 5491, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.5107e-05,  2.6989e-04])\n",
      "Epoch 5492, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.8014e-05,  2.7078e-04])\n",
      "Epoch 5493, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-1.9372e-05,  2.7198e-04])\n",
      "Epoch 5494, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.8743e-05,  2.6816e-04])\n",
      "Epoch 5495, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.0041e-05,  2.6929e-04])\n",
      "Epoch 5496, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.3723e-05,  2.7022e-04])\n",
      "Epoch 5497, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-4.3571e-05,  2.6634e-04])\n",
      "Epoch 5498, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.5644e-05,  2.6754e-04])\n",
      "Epoch 5499, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.8372e-05,  2.6843e-04])\n",
      "Epoch 5500, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-1.8835e-05,  2.6986e-04])\n",
      "Epoch 5501, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.8028e-05,  2.6605e-04])\n",
      "Epoch 5502, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.0100e-05,  2.6688e-04])\n",
      "Epoch 5503, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.2352e-05,  2.6813e-04])\n",
      "Epoch 5504, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-4.2081e-05,  2.6426e-04])\n",
      "Epoch 5505, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.1471e-05,  2.6584e-04])\n",
      "Epoch 5506, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-2.5153e-05,  2.6673e-04])\n",
      "Epoch 5507, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-1.8418e-05,  2.6751e-04])\n",
      "Epoch 5508, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.7909e-05,  2.6384e-04])\n",
      "Epoch 5509, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.0875e-05,  2.6467e-04])\n",
      "Epoch 5510, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-1.9789e-05,  2.6625e-04])\n",
      "Epoch 5511, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3032])\n",
      "    Grad: tensor([-3.9756e-05,  2.6241e-04])\n",
      "Epoch 5512, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3033])\n",
      "    Grad: tensor([-3.0339e-05,  2.6366e-04])\n",
      "Epoch 5513, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3033])\n",
      "    Grad: tensor([-2.1935e-05,  2.6479e-04])\n",
      "Epoch 5514, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3033])\n",
      "    Grad: tensor([-4.1366e-05,  2.6101e-04])\n",
      "Epoch 5515, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3033])\n",
      "    Grad: tensor([-3.8624e-05,  2.6119e-04])\n",
      "Epoch 5516, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3033])\n",
      "    Grad: tensor([-3.1948e-05,  2.6226e-04])\n",
      "Epoch 5517, Loss 3.0\n",
      "    Params: tensor([  5.3674, -17.3033])\n",
      "    Grad: tensor([-1.9968e-05,  2.6405e-04])\n",
      "Epoch 5518, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.9816e-05,  2.6035e-04])\n",
      "Epoch 5519, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.9206e-05,  2.6187e-04])\n",
      "Epoch 5520, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.5392e-05,  2.6214e-04])\n",
      "Epoch 5521, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-1.6749e-05,  2.6327e-04])\n",
      "Epoch 5522, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.5644e-05,  2.5946e-04])\n",
      "Epoch 5523, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.5213e-05,  2.6098e-04])\n",
      "Epoch 5524, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-1.4186e-05,  2.6253e-04])\n",
      "Epoch 5525, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.4034e-05,  2.5865e-04])\n",
      "Epoch 5526, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.3915e-05,  2.5859e-04])\n",
      "Epoch 5527, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.3365e-05,  2.6003e-04])\n",
      "Epoch 5528, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-4.2319e-05,  2.5633e-04])\n",
      "Epoch 5529, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.6716e-05,  2.5687e-04])\n",
      "Epoch 5530, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.6286e-05,  2.5842e-04])\n",
      "Epoch 5531, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-1.8060e-05,  2.5955e-04])\n",
      "Epoch 5532, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.7491e-05,  2.5576e-04])\n",
      "Epoch 5533, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.2709e-05,  2.5785e-04])\n",
      "Epoch 5534, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-4.2140e-05,  2.5401e-04])\n",
      "Epoch 5535, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.1531e-05,  2.5561e-04])\n",
      "Epoch 5536, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.6107e-05,  2.5651e-04])\n",
      "Epoch 5537, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.0325e-05,  2.5702e-04])\n",
      "Epoch 5538, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-4.0293e-05,  2.5314e-04])\n",
      "Epoch 5539, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.2485e-05,  2.5406e-04])\n",
      "Epoch 5540, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.1875e-05,  2.5555e-04])\n",
      "Epoch 5541, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-4.1664e-05,  2.5183e-04])\n",
      "Epoch 5542, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.4690e-05,  2.5260e-04])\n",
      "Epoch 5543, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.4557e-05,  2.5415e-04])\n",
      "Epoch 5544, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-1.5676e-05,  2.5541e-04])\n",
      "Epoch 5545, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.5942e-05,  2.5156e-04])\n",
      "Epoch 5546, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.1292e-05,  2.5210e-04])\n",
      "Epoch 5547, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.1458e-05,  2.5338e-04])\n",
      "Epoch 5548, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-4.0829e-05,  2.4951e-04])\n",
      "Epoch 5549, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.2246e-05,  2.5094e-04])\n",
      "Epoch 5550, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.3246e-05,  2.5216e-04])\n",
      "Epoch 5551, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-4.3392e-05,  2.4828e-04])\n",
      "Epoch 5552, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.6120e-05,  2.4918e-04])\n",
      "Epoch 5553, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.5332e-05,  2.5073e-04])\n",
      "Epoch 5554, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-1.6630e-05,  2.5198e-04])\n",
      "Epoch 5555, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.6538e-05,  2.4810e-04])\n",
      "Epoch 5556, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.4094e-05,  2.4828e-04])\n",
      "Epoch 5557, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.5153e-05,  2.4953e-04])\n",
      "Epoch 5558, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-1.4126e-05,  2.5108e-04])\n",
      "Epoch 5559, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.4153e-05,  2.4724e-04])\n",
      "Epoch 5560, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.4974e-05,  2.4849e-04])\n",
      "Epoch 5561, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-1.9073e-05,  2.4933e-04])\n",
      "Epoch 5562, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-3.8326e-05,  2.4548e-04])\n",
      "Epoch 5563, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3033])\n",
      "    Grad: tensor([-2.9206e-05,  2.4670e-04])\n",
      "Epoch 5564, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-1.7524e-05,  2.4849e-04])\n",
      "Epoch 5565, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.7253e-05,  2.4468e-04])\n",
      "Epoch 5566, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.2544e-05,  2.4515e-04])\n",
      "Epoch 5567, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.9504e-05,  2.4536e-04])\n",
      "Epoch 5568, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-1.7166e-05,  2.4730e-04])\n",
      "Epoch 5569, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.6657e-05,  2.4343e-04])\n",
      "Epoch 5570, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.0398e-05,  2.4432e-04])\n",
      "Epoch 5571, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-1.5259e-05,  2.4658e-04])\n",
      "Epoch 5572, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.5286e-05,  2.4280e-04])\n",
      "Epoch 5573, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.2127e-05,  2.4298e-04])\n",
      "Epoch 5574, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-1.8179e-05,  2.4518e-04])\n",
      "Epoch 5575, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.7193e-05,  2.4140e-04])\n",
      "Epoch 5576, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.7074e-05,  2.4125e-04])\n",
      "Epoch 5577, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.0756e-05,  2.4179e-04])\n",
      "Epoch 5578, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.0683e-05,  2.4340e-04])\n",
      "Epoch 5579, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-4.0054e-05,  2.3946e-04])\n",
      "Epoch 5580, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.2902e-05,  2.4053e-04])\n",
      "Epoch 5581, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-1.8716e-05,  2.4274e-04])\n",
      "Epoch 5582, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.8028e-05,  2.3898e-04])\n",
      "Epoch 5583, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.1292e-05,  2.3982e-04])\n",
      "Epoch 5584, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.1233e-05,  2.3964e-04])\n",
      "Epoch 5585, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.0385e-05,  2.4119e-04])\n",
      "Epoch 5586, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.9816e-05,  2.3741e-04])\n",
      "Epoch 5587, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.8908e-05,  2.3890e-04])\n",
      "Epoch 5588, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-1.8537e-05,  2.4050e-04])\n",
      "Epoch 5589, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.8147e-05,  2.3660e-04])\n",
      "Epoch 5590, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.3021e-05,  2.3717e-04])\n",
      "Epoch 5591, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.5988e-05,  2.3800e-04])\n",
      "Epoch 5592, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-9.2387e-06,  2.4027e-04])\n",
      "Epoch 5593, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.9445e-05,  2.3639e-04])\n",
      "Epoch 5594, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.4140e-05,  2.3705e-04])\n",
      "Epoch 5595, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-1.7703e-05,  2.3800e-04])\n",
      "Epoch 5596, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.6836e-05,  2.3425e-04])\n",
      "Epoch 5597, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.8908e-05,  2.3538e-04])\n",
      "Epoch 5598, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.0206e-05,  2.3663e-04])\n",
      "Epoch 5599, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-4.0114e-05,  2.3279e-04])\n",
      "Epoch 5600, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.4915e-05,  2.3505e-04])\n",
      "Epoch 5601, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.2411e-05,  2.3517e-04])\n",
      "Epoch 5602, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-4.2439e-05,  2.3144e-04])\n",
      "Epoch 5603, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.8789e-05,  2.3338e-04])\n",
      "Epoch 5604, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.8968e-05,  2.3285e-04])\n",
      "Epoch 5605, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-1.8597e-05,  2.3434e-04])\n",
      "Epoch 5606, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.8445e-05,  2.3064e-04])\n",
      "Epoch 5607, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.9802e-05,  2.3183e-04])\n",
      "Epoch 5608, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.2948e-05,  2.3264e-04])\n",
      "Epoch 5609, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-4.2439e-05,  2.2891e-04])\n",
      "Epoch 5610, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.0220e-05,  2.3076e-04])\n",
      "Epoch 5611, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.2590e-05,  2.3177e-04])\n",
      "Epoch 5612, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-4.3094e-05,  2.2805e-04])\n",
      "Epoch 5613, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-3.3319e-05,  2.2918e-04])\n",
      "Epoch 5614, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.9922e-05,  2.2972e-04])\n",
      "Epoch 5615, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-2.0504e-05,  2.3085e-04])\n",
      "Epoch 5616, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3034])\n",
      "    Grad: tensor([-4.0710e-05,  2.2718e-04])\n",
      "Epoch 5617, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.0816e-05,  2.2835e-04])\n",
      "Epoch 5618, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.0206e-05,  2.2984e-04])\n",
      "Epoch 5619, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-4.0352e-05,  2.2608e-04])\n",
      "Epoch 5620, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.3796e-05,  2.2691e-04])\n",
      "Epoch 5621, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.2709e-05,  2.2843e-04])\n",
      "Epoch 5622, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-4.2677e-05,  2.2471e-04])\n",
      "Epoch 5623, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.6955e-05,  2.2513e-04])\n",
      "Epoch 5624, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.0816e-05,  2.2614e-04])\n",
      "Epoch 5625, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.2948e-05,  2.2721e-04])\n",
      "Epoch 5626, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-4.2260e-05,  2.2355e-04])\n",
      "Epoch 5627, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.3557e-05,  2.2486e-04])\n",
      "Epoch 5628, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.1815e-05,  2.2641e-04])\n",
      "Epoch 5629, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-4.2379e-05,  2.2256e-04])\n",
      "Epoch 5630, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.5048e-05,  2.2343e-04])\n",
      "Epoch 5631, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.7478e-05,  2.2432e-04])\n",
      "Epoch 5632, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-1.8299e-05,  2.2557e-04])\n",
      "Epoch 5633, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.8505e-05,  2.2164e-04])\n",
      "Epoch 5634, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.1888e-05,  2.2253e-04])\n",
      "Epoch 5635, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.3127e-05,  2.2382e-04])\n",
      "Epoch 5636, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-4.2915e-05,  2.2009e-04])\n",
      "Epoch 5637, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.7789e-05,  2.2063e-04])\n",
      "Epoch 5638, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.5928e-05,  2.2247e-04])\n",
      "Epoch 5639, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-1.4663e-05,  2.2411e-04])\n",
      "Epoch 5640, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.5226e-05,  2.2024e-04])\n",
      "Epoch 5641, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.6822e-05,  2.2113e-04])\n",
      "Epoch 5642, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.2531e-05,  2.2173e-04])\n",
      "Epoch 5643, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-4.2021e-05,  2.1794e-04])\n",
      "Epoch 5644, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.8743e-05,  2.1815e-04])\n",
      "Epoch 5645, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.4378e-05,  2.2042e-04])\n",
      "Epoch 5646, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-1.5199e-05,  2.2161e-04])\n",
      "Epoch 5647, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.5167e-05,  2.1774e-04])\n",
      "Epoch 5648, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.0518e-05,  2.1824e-04])\n",
      "Epoch 5649, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-1.9431e-05,  2.1985e-04])\n",
      "Epoch 5650, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.9637e-05,  2.1601e-04])\n",
      "Epoch 5651, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.0279e-05,  2.1720e-04])\n",
      "Epoch 5652, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-1.3769e-05,  2.1952e-04])\n",
      "Epoch 5653, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.3796e-05,  2.1568e-04])\n",
      "Epoch 5654, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.4153e-05,  2.1550e-04])\n",
      "Epoch 5655, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.2888e-05,  2.1699e-04])\n",
      "Epoch 5656, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-4.2558e-05,  2.1324e-04])\n",
      "Epoch 5657, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.5048e-05,  2.1413e-04])\n",
      "Epoch 5658, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.3842e-05,  2.1592e-04])\n",
      "Epoch 5659, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-1.8656e-05,  2.1645e-04])\n",
      "Epoch 5660, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.8505e-05,  2.1252e-04])\n",
      "Epoch 5661, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.9564e-05,  2.1377e-04])\n",
      "Epoch 5662, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-1.8239e-05,  2.1541e-04])\n",
      "Epoch 5663, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.9160e-05,  2.1151e-04])\n",
      "Epoch 5664, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.2604e-05,  2.1240e-04])\n",
      "Epoch 5665, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.6107e-05,  2.1330e-04])\n",
      "Epoch 5666, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-1.7107e-05,  2.1452e-04])\n",
      "Epoch 5667, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-3.7670e-05,  2.1064e-04])\n",
      "Epoch 5668, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3035])\n",
      "    Grad: tensor([-2.6643e-05,  2.1225e-04])\n",
      "Epoch 5669, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-1.9372e-05,  2.1279e-04])\n",
      "Epoch 5670, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.9637e-05,  2.0891e-04])\n",
      "Epoch 5671, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.1233e-05,  2.1017e-04])\n",
      "Epoch 5672, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.7120e-05,  2.1070e-04])\n",
      "Epoch 5673, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-1.8418e-05,  2.1195e-04])\n",
      "Epoch 5674, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.8207e-05,  2.0805e-04])\n",
      "Epoch 5675, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.6762e-05,  2.0984e-04])\n",
      "Epoch 5676, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.0266e-05,  2.1073e-04])\n",
      "Epoch 5677, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-4.0472e-05,  2.0683e-04])\n",
      "Epoch 5678, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.0577e-05,  2.0808e-04])\n",
      "Epoch 5679, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.0027e-05,  2.0969e-04])\n",
      "Epoch 5680, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-4.0174e-05,  2.0579e-04])\n",
      "Epoch 5681, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.1233e-05,  2.0704e-04])\n",
      "Epoch 5682, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.1173e-05,  2.0680e-04])\n",
      "Epoch 5683, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-1.9848e-05,  2.0841e-04])\n",
      "Epoch 5684, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.9518e-05,  2.0459e-04])\n",
      "Epoch 5685, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.0398e-05,  2.0584e-04])\n",
      "Epoch 5686, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-1.8358e-05,  2.0781e-04])\n",
      "Epoch 5687, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.7670e-05,  2.0388e-04])\n",
      "Epoch 5688, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.2008e-05,  2.0444e-04])\n",
      "Epoch 5689, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.3246e-05,  2.0564e-04])\n",
      "Epoch 5690, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-4.3094e-05,  2.0179e-04])\n",
      "Epoch 5691, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.3915e-05,  2.0316e-04])\n",
      "Epoch 5692, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.9743e-05,  2.0376e-04])\n",
      "Epoch 5693, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-1.7345e-05,  2.0564e-04])\n",
      "Epoch 5694, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.7074e-05,  2.0182e-04])\n",
      "Epoch 5695, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.4332e-05,  2.0188e-04])\n",
      "Epoch 5696, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.1994e-05,  2.0349e-04])\n",
      "Epoch 5697, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-4.2021e-05,  1.9974e-04])\n",
      "Epoch 5698, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.4988e-05,  2.0063e-04])\n",
      "Epoch 5699, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.4438e-05,  2.0212e-04])\n",
      "Epoch 5700, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-1.7762e-05,  2.0301e-04])\n",
      "Epoch 5701, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.7313e-05,  1.9917e-04])\n",
      "Epoch 5702, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.1888e-05,  2.0012e-04])\n",
      "Epoch 5703, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.0921e-05,  2.0161e-04])\n",
      "Epoch 5704, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-4.1306e-05,  1.9783e-04])\n",
      "Epoch 5705, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.4034e-05,  1.9866e-04])\n",
      "Epoch 5706, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.6405e-05,  1.9974e-04])\n",
      "Epoch 5707, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-1.7464e-05,  2.0096e-04])\n",
      "Epoch 5708, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.7313e-05,  1.9708e-04])\n",
      "Epoch 5709, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.7895e-05,  1.9827e-04])\n",
      "Epoch 5710, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-1.6391e-05,  1.9988e-04])\n",
      "Epoch 5711, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.6299e-05,  1.9601e-04])\n",
      "Epoch 5712, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.0935e-05,  1.9655e-04])\n",
      "Epoch 5713, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.0385e-05,  1.9810e-04])\n",
      "Epoch 5714, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-4.0114e-05,  1.9428e-04])\n",
      "Epoch 5715, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.7299e-05,  1.9628e-04])\n",
      "Epoch 5716, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.1756e-05,  1.9675e-04])\n",
      "Epoch 5717, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-4.1246e-05,  1.9297e-04])\n",
      "Epoch 5718, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.2544e-05,  1.9410e-04])\n",
      "Epoch 5719, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-2.5749e-05,  1.9503e-04])\n",
      "Epoch 5720, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-1.5140e-05,  1.9664e-04])\n",
      "Epoch 5721, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3036])\n",
      "    Grad: tensor([-3.5048e-05,  1.9276e-04])\n",
      "Epoch 5722, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.7180e-05,  1.9413e-04])\n",
      "Epoch 5723, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.5630e-05,  1.9395e-04])\n",
      "Epoch 5724, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-1.3769e-05,  1.9550e-04])\n",
      "Epoch 5725, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.3915e-05,  1.9175e-04])\n",
      "Epoch 5726, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.6643e-05,  1.9264e-04])\n",
      "Epoch 5727, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-1.0729e-05,  1.9532e-04])\n",
      "Epoch 5728, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.0160e-05,  1.9142e-04])\n",
      "Epoch 5729, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.7657e-05,  1.9160e-04])\n",
      "Epoch 5730, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-1.8299e-05,  1.9279e-04])\n",
      "Epoch 5731, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.8266e-05,  1.8901e-04])\n",
      "Epoch 5732, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.1948e-05,  1.8990e-04])\n",
      "Epoch 5733, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.1577e-05,  1.9142e-04])\n",
      "Epoch 5734, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-4.0710e-05,  1.8772e-04])\n",
      "Epoch 5735, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.4034e-05,  1.8838e-04])\n",
      "Epoch 5736, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.8253e-05,  1.8892e-04])\n",
      "Epoch 5737, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-1.8954e-05,  1.9035e-04])\n",
      "Epoch 5738, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.8624e-05,  1.8653e-04])\n",
      "Epoch 5739, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.8014e-05,  1.8814e-04])\n",
      "Epoch 5740, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-1.9372e-05,  1.8933e-04])\n",
      "Epoch 5741, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.9220e-05,  1.8546e-04])\n",
      "Epoch 5742, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.3379e-05,  1.8632e-04])\n",
      "Epoch 5743, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.5630e-05,  1.8722e-04])\n",
      "Epoch 5744, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-1.8895e-05,  1.8811e-04])\n",
      "Epoch 5745, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.8862e-05,  1.8439e-04])\n",
      "Epoch 5746, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.9862e-05,  1.8555e-04])\n",
      "Epoch 5747, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-1.9431e-05,  1.8710e-04])\n",
      "Epoch 5748, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.9399e-05,  1.8334e-04])\n",
      "Epoch 5749, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.8074e-05,  1.8477e-04])\n",
      "Epoch 5750, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.1338e-05,  1.8561e-04])\n",
      "Epoch 5751, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-4.0650e-05,  1.8188e-04])\n",
      "Epoch 5752, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-4.2677e-05,  1.8135e-04])\n",
      "Epoch 5753, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.8968e-05,  1.8340e-04])\n",
      "Epoch 5754, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.0564e-05,  1.8454e-04])\n",
      "Epoch 5755, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-4.0114e-05,  1.8087e-04])\n",
      "Epoch 5756, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.7120e-05,  1.8284e-04])\n",
      "Epoch 5757, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.0146e-05,  1.8367e-04])\n",
      "Epoch 5758, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-4.0233e-05,  1.7983e-04])\n",
      "Epoch 5759, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.4928e-05,  1.8036e-04])\n",
      "Epoch 5760, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.0683e-05,  1.8266e-04])\n",
      "Epoch 5761, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-4.0531e-05,  1.7878e-04])\n",
      "Epoch 5762, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.8087e-05,  1.7896e-04])\n",
      "Epoch 5763, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.8431e-05,  1.8016e-04])\n",
      "Epoch 5764, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.3425e-05,  1.8066e-04])\n",
      "Epoch 5765, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-4.3154e-05,  1.7682e-04])\n",
      "Epoch 5766, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.2663e-05,  1.7843e-04])\n",
      "Epoch 5767, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.2352e-05,  1.7998e-04])\n",
      "Epoch 5768, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-4.2140e-05,  1.7613e-04])\n",
      "Epoch 5769, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.2604e-05,  1.7756e-04])\n",
      "Epoch 5770, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.2723e-05,  1.7732e-04])\n",
      "Epoch 5771, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-1.7405e-05,  1.7923e-04])\n",
      "Epoch 5772, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-3.6657e-05,  1.7539e-04])\n",
      "Epoch 5773, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3037])\n",
      "    Grad: tensor([-2.6226e-05,  1.7703e-04])\n",
      "Epoch 5774, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-1.3292e-05,  1.7893e-04])\n",
      "Epoch 5775, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.3617e-05,  1.7518e-04])\n",
      "Epoch 5776, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.2127e-05,  1.7500e-04])\n",
      "Epoch 5777, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-2.0802e-05,  1.7661e-04])\n",
      "Epoch 5778, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-4.0591e-05,  1.7276e-04])\n",
      "Epoch 5779, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.0279e-05,  1.7431e-04])\n",
      "Epoch 5780, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-2.5392e-05,  1.7476e-04])\n",
      "Epoch 5781, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-1.8656e-05,  1.7565e-04])\n",
      "Epoch 5782, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.8445e-05,  1.7193e-04])\n",
      "Epoch 5783, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.1650e-05,  1.7282e-04])\n",
      "Epoch 5784, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-2.0802e-05,  1.7437e-04])\n",
      "Epoch 5785, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-4.0174e-05,  1.7071e-04])\n",
      "Epoch 5786, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-2.9624e-05,  1.7226e-04])\n",
      "Epoch 5787, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-2.1219e-05,  1.7348e-04])\n",
      "Epoch 5788, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-4.0948e-05,  1.6966e-04])\n",
      "Epoch 5789, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.3736e-05,  1.7050e-04])\n",
      "Epoch 5790, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.0577e-05,  1.7062e-04])\n",
      "Epoch 5791, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-1.9670e-05,  1.7226e-04])\n",
      "Epoch 5792, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.9279e-05,  1.6847e-04])\n",
      "Epoch 5793, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.2902e-05,  1.6925e-04])\n",
      "Epoch 5794, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-2.2054e-05,  1.7086e-04])\n",
      "Epoch 5795, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-4.1962e-05,  1.6707e-04])\n",
      "Epoch 5796, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.0696e-05,  1.6856e-04])\n",
      "Epoch 5797, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-2.4140e-05,  1.6946e-04])\n",
      "Epoch 5798, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-1.7762e-05,  1.7029e-04])\n",
      "Epoch 5799, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.7670e-05,  1.6645e-04])\n",
      "Epoch 5800, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.2187e-05,  1.6719e-04])\n",
      "Epoch 5801, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-2.3246e-05,  1.6838e-04])\n",
      "Epoch 5802, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-4.2617e-05,  1.6463e-04])\n",
      "Epoch 5803, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.2067e-05,  1.6612e-04])\n",
      "Epoch 5804, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-2.5272e-05,  1.6695e-04])\n",
      "Epoch 5805, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-1.7285e-05,  1.6817e-04])\n",
      "Epoch 5806, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.6418e-05,  1.6436e-04])\n",
      "Epoch 5807, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-2.7776e-05,  1.6555e-04])\n",
      "Epoch 5808, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-1.6570e-05,  1.6713e-04])\n",
      "Epoch 5809, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.5882e-05,  1.6329e-04])\n",
      "Epoch 5810, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.6061e-05,  1.6311e-04])\n",
      "Epoch 5811, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-2.3544e-05,  1.6502e-04])\n",
      "Epoch 5812, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-4.3392e-05,  1.6129e-04])\n",
      "Epoch 5813, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-3.6359e-05,  1.6209e-04])\n",
      "Epoch 5814, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-2.6941e-05,  1.6335e-04])\n",
      "Epoch 5815, Loss 3.0\n",
      "    Params: tensor([  5.3675, -17.3038])\n",
      "    Grad: tensor([-1.9968e-05,  1.6424e-04])\n",
      "Epoch 5816, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3038])\n",
      "    Grad: tensor([-4.0054e-05,  1.6043e-04])\n",
      "Epoch 5817, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3038])\n",
      "    Grad: tensor([-2.8849e-05,  1.6209e-04])\n",
      "Epoch 5818, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3038])\n",
      "    Grad: tensor([-1.9372e-05,  1.6326e-04])\n",
      "Epoch 5819, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3038])\n",
      "    Grad: tensor([-3.8624e-05,  1.5959e-04])\n",
      "Epoch 5820, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3038])\n",
      "    Grad: tensor([-3.6657e-05,  1.5971e-04])\n",
      "Epoch 5821, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3038])\n",
      "    Grad: tensor([-2.8431e-05,  1.6090e-04])\n",
      "Epoch 5822, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3038])\n",
      "    Grad: tensor([-1.9550e-05,  1.6209e-04])\n",
      "Epoch 5823, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3038])\n",
      "    Grad: tensor([-3.8981e-05,  1.5831e-04])\n",
      "Epoch 5824, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3038])\n",
      "    Grad: tensor([-2.6941e-05,  1.6022e-04])\n",
      "Epoch 5825, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3038])\n",
      "    Grad: tensor([-1.8537e-05,  1.6141e-04])\n",
      "Epoch 5826, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.7372e-05,  1.5762e-04])\n",
      "Epoch 5827, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.4332e-05,  1.5777e-04])\n",
      "Epoch 5828, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.4915e-05,  1.5897e-04])\n",
      "Epoch 5829, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-1.9133e-05,  1.5980e-04])\n",
      "Epoch 5830, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.8743e-05,  1.5599e-04])\n",
      "Epoch 5831, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.2352e-05,  1.5822e-04])\n",
      "Epoch 5832, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-4.2200e-05,  1.5447e-04])\n",
      "Epoch 5833, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.2902e-05,  1.5590e-04])\n",
      "Epoch 5834, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.7835e-05,  1.5637e-04])\n",
      "Epoch 5835, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-1.7464e-05,  1.5798e-04])\n",
      "Epoch 5836, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.7014e-05,  1.5417e-04])\n",
      "Epoch 5837, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.5988e-05,  1.5572e-04])\n",
      "Epoch 5838, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-1.6809e-05,  1.5697e-04])\n",
      "Epoch 5839, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.6538e-05,  1.5312e-04])\n",
      "Epoch 5840, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.4034e-05,  1.5333e-04])\n",
      "Epoch 5841, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.8670e-05,  1.5381e-04])\n",
      "Epoch 5842, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-1.2636e-05,  1.5643e-04])\n",
      "Epoch 5843, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.2485e-05,  1.5262e-04])\n",
      "Epoch 5844, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.5690e-05,  1.5354e-04])\n",
      "Epoch 5845, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.1636e-05,  1.5366e-04])\n",
      "Epoch 5846, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-4.1604e-05,  1.4982e-04])\n",
      "Epoch 5847, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.0935e-05,  1.5137e-04])\n",
      "Epoch 5848, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.1875e-05,  1.5274e-04])\n",
      "Epoch 5849, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-4.1544e-05,  1.4901e-04])\n",
      "Epoch 5850, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.2246e-05,  1.5050e-04])\n",
      "Epoch 5851, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.9325e-05,  1.5068e-04])\n",
      "Epoch 5852, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-1.8597e-05,  1.5223e-04])\n",
      "Epoch 5853, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.8385e-05,  1.4839e-04])\n",
      "Epoch 5854, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.9147e-05,  1.4964e-04])\n",
      "Epoch 5855, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-1.9372e-05,  1.5086e-04])\n",
      "Epoch 5856, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.9220e-05,  1.4699e-04])\n",
      "Epoch 5857, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.3081e-05,  1.4788e-04])\n",
      "Epoch 5858, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.3723e-05,  1.4904e-04])\n",
      "Epoch 5859, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-4.3631e-05,  1.4529e-04])\n",
      "Epoch 5860, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.9220e-05,  1.4582e-04])\n",
      "Epoch 5861, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.0458e-05,  1.4701e-04])\n",
      "Epoch 5862, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.2292e-05,  1.4818e-04])\n",
      "Epoch 5863, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-4.2021e-05,  1.4445e-04])\n",
      "Epoch 5864, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.1650e-05,  1.4588e-04])\n",
      "Epoch 5865, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.2888e-05,  1.4701e-04])\n",
      "Epoch 5866, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-4.2737e-05,  1.4323e-04])\n",
      "Epoch 5867, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.3975e-05,  1.4439e-04])\n",
      "Epoch 5868, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.1292e-05,  1.4469e-04])\n",
      "Epoch 5869, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.2590e-05,  1.4582e-04])\n",
      "Epoch 5870, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-4.2677e-05,  1.4201e-04])\n",
      "Epoch 5871, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.9922e-05,  1.4389e-04])\n",
      "Epoch 5872, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.2650e-05,  1.4478e-04])\n",
      "Epoch 5873, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-4.2379e-05,  1.4091e-04])\n",
      "Epoch 5874, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.7074e-05,  1.4153e-04])\n",
      "Epoch 5875, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.4617e-05,  1.4338e-04])\n",
      "Epoch 5876, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-1.7524e-05,  1.4430e-04])\n",
      "Epoch 5877, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-3.7491e-05,  1.4037e-04])\n",
      "Epoch 5878, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3039])\n",
      "    Grad: tensor([-2.9325e-05,  1.4162e-04])\n",
      "Epoch 5879, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.6226e-05,  1.4198e-04])\n",
      "Epoch 5880, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-1.4544e-05,  1.4353e-04])\n",
      "Epoch 5881, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.4332e-05,  1.3974e-04])\n",
      "Epoch 5882, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.4021e-05,  1.4129e-04])\n",
      "Epoch 5883, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-1.6153e-05,  1.4222e-04])\n",
      "Epoch 5884, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.6120e-05,  1.3834e-04])\n",
      "Epoch 5885, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.9206e-05,  1.3921e-04])\n",
      "Epoch 5886, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.0266e-05,  1.4040e-04])\n",
      "Epoch 5887, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-4.0472e-05,  1.3658e-04])\n",
      "Epoch 5888, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.4809e-05,  1.3742e-04])\n",
      "Epoch 5889, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.1994e-05,  1.3942e-04])\n",
      "Epoch 5890, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-4.1962e-05,  1.3557e-04])\n",
      "Epoch 5891, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.3319e-05,  1.3646e-04])\n",
      "Epoch 5892, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.3782e-05,  1.3760e-04])\n",
      "Epoch 5893, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-4.3452e-05,  1.3390e-04])\n",
      "Epoch 5894, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.2544e-05,  1.3545e-04])\n",
      "Epoch 5895, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.4080e-05,  1.3652e-04])\n",
      "Epoch 5896, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-1.6153e-05,  1.3766e-04])\n",
      "Epoch 5897, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.6359e-05,  1.3384e-04])\n",
      "Epoch 5898, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.3796e-05,  1.3399e-04])\n",
      "Epoch 5899, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.0742e-05,  1.3596e-04])\n",
      "Epoch 5900, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-4.0352e-05,  1.3214e-04])\n",
      "Epoch 5901, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.2008e-05,  1.3340e-04])\n",
      "Epoch 5902, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.0146e-05,  1.3492e-04])\n",
      "Epoch 5903, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-4.0889e-05,  1.3119e-04])\n",
      "Epoch 5904, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.5524e-05,  1.3173e-04])\n",
      "Epoch 5905, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.6882e-05,  1.3286e-04])\n",
      "Epoch 5906, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-1.4365e-05,  1.3483e-04])\n",
      "Epoch 5907, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.4392e-05,  1.3098e-04])\n",
      "Epoch 5908, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.3617e-05,  1.3074e-04])\n",
      "Epoch 5909, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.4557e-05,  1.3199e-04])\n",
      "Epoch 5910, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-1.6570e-05,  1.3304e-04])\n",
      "Epoch 5911, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.6716e-05,  1.2916e-04])\n",
      "Epoch 5912, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.7716e-05,  1.3039e-04])\n",
      "Epoch 5913, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-1.4901e-05,  1.3235e-04])\n",
      "Epoch 5914, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.4869e-05,  1.2848e-04])\n",
      "Epoch 5915, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.9743e-05,  1.2895e-04])\n",
      "Epoch 5916, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-1.9491e-05,  1.3059e-04])\n",
      "Epoch 5917, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.9339e-05,  1.2669e-04])\n",
      "Epoch 5918, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.3021e-05,  1.2764e-04])\n",
      "Epoch 5919, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.2113e-05,  1.2919e-04])\n",
      "Epoch 5920, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-4.2021e-05,  1.2541e-04])\n",
      "Epoch 5921, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.7372e-05,  1.2556e-04])\n",
      "Epoch 5922, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.0637e-05,  1.2645e-04])\n",
      "Epoch 5923, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-1.8001e-05,  1.2836e-04])\n",
      "Epoch 5924, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.7789e-05,  1.2451e-04])\n",
      "Epoch 5925, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.9147e-05,  1.2571e-04])\n",
      "Epoch 5926, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.2233e-05,  1.2678e-04])\n",
      "Epoch 5927, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-4.2319e-05,  1.2285e-04])\n",
      "Epoch 5928, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-3.6299e-05,  1.2374e-04])\n",
      "Epoch 5929, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-2.8431e-05,  1.2466e-04])\n",
      "Epoch 5930, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3040])\n",
      "    Grad: tensor([-1.7822e-05,  1.2630e-04])\n",
      "Epoch 5931, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.7909e-05,  1.2243e-04])\n",
      "Epoch 5932, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.1352e-05,  1.2326e-04])\n",
      "Epoch 5933, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.0564e-05,  1.2481e-04])\n",
      "Epoch 5934, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-4.0472e-05,  1.2103e-04])\n",
      "Epoch 5935, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.2485e-05,  1.2192e-04])\n",
      "Epoch 5936, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.1935e-05,  1.2353e-04])\n",
      "Epoch 5937, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-4.1187e-05,  1.1969e-04])\n",
      "Epoch 5938, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-4.1723e-05,  1.1948e-04])\n",
      "Epoch 5939, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.0220e-05,  1.2109e-04])\n",
      "Epoch 5940, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.0802e-05,  1.2234e-04])\n",
      "Epoch 5941, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-4.0889e-05,  1.1840e-04])\n",
      "Epoch 5942, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.1590e-05,  1.1984e-04])\n",
      "Epoch 5943, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.5749e-05,  1.2076e-04])\n",
      "Epoch 5944, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-1.4186e-05,  1.2237e-04])\n",
      "Epoch 5945, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.4571e-05,  1.1846e-04])\n",
      "Epoch 5946, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.3723e-05,  1.2007e-04])\n",
      "Epoch 5947, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-4.3631e-05,  1.1617e-04])\n",
      "Epoch 5948, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-4.1902e-05,  1.1602e-04])\n",
      "Epoch 5949, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.5107e-05,  1.1685e-04])\n",
      "Epoch 5950, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.6226e-05,  1.1811e-04])\n",
      "Epoch 5951, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-7.9870e-06,  1.2073e-04])\n",
      "Epoch 5952, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.7776e-05,  1.1694e-04])\n",
      "Epoch 5953, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-1.9133e-05,  1.1820e-04])\n",
      "Epoch 5954, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.8505e-05,  1.1432e-04])\n",
      "Epoch 5955, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.2187e-05,  1.1516e-04])\n",
      "Epoch 5956, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.7776e-05,  1.1566e-04])\n",
      "Epoch 5957, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-1.7047e-05,  1.1730e-04])\n",
      "Epoch 5958, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.6776e-05,  1.1337e-04])\n",
      "Epoch 5959, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.7716e-05,  1.1480e-04])\n",
      "Epoch 5960, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.4080e-05,  1.1492e-04])\n",
      "Epoch 5961, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-1.2934e-05,  1.1650e-04])\n",
      "Epoch 5962, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.2544e-05,  1.1262e-04])\n",
      "Epoch 5963, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.2233e-05,  1.1423e-04])\n",
      "Epoch 5964, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-4.1723e-05,  1.1045e-04])\n",
      "Epoch 5965, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.8968e-05,  1.1238e-04])\n",
      "Epoch 5966, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.1233e-05,  1.1185e-04])\n",
      "Epoch 5967, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.1517e-05,  1.1304e-04])\n",
      "Epoch 5968, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-4.1366e-05,  1.0923e-04])\n",
      "Epoch 5969, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.2604e-05,  1.1051e-04])\n",
      "Epoch 5970, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-1.8477e-05,  1.1265e-04])\n",
      "Epoch 5971, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.8207e-05,  1.0893e-04])\n",
      "Epoch 5972, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.9504e-05,  1.1006e-04])\n",
      "Epoch 5973, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.8014e-05,  1.0988e-04])\n",
      "Epoch 5974, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-1.6570e-05,  1.1167e-04])\n",
      "Epoch 5975, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.6359e-05,  1.0782e-04])\n",
      "Epoch 5976, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.3140e-05,  1.0797e-04])\n",
      "Epoch 5977, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-1.9014e-05,  1.1030e-04])\n",
      "Epoch 5978, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.8803e-05,  1.0639e-04])\n",
      "Epoch 5979, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.4392e-05,  1.0693e-04])\n",
      "Epoch 5980, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.4796e-05,  1.0812e-04])\n",
      "Epoch 5981, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-1.6153e-05,  1.0937e-04])\n",
      "Epoch 5982, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-3.6001e-05,  1.0556e-04])\n",
      "Epoch 5983, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3041])\n",
      "    Grad: tensor([-2.3425e-05,  1.0750e-04])\n",
      "Epoch 5984, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-4.2915e-05,  1.0377e-04])\n",
      "Epoch 5985, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.7372e-05,  1.0455e-04])\n",
      "Epoch 5986, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.2246e-05,  1.0502e-04])\n",
      "Epoch 5987, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.6405e-05,  1.0559e-04])\n",
      "Epoch 5988, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-1.7464e-05,  1.0684e-04])\n",
      "Epoch 5989, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.6716e-05,  1.0303e-04])\n",
      "Epoch 5990, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.6941e-05,  1.0470e-04])\n",
      "Epoch 5991, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-1.9729e-05,  1.0553e-04])\n",
      "Epoch 5992, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.9399e-05,  1.0183e-04])\n",
      "Epoch 5993, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.5928e-05,  1.0368e-04])\n",
      "Epoch 5994, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0862e-05,  1.0422e-04])\n",
      "Epoch 5995, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-4.0233e-05,  1.0040e-04])\n",
      "Epoch 5996, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.5048e-05,  1.0127e-04])\n",
      "Epoch 5997, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.5928e-05,  1.0252e-04])\n",
      "Epoch 5998, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-1.7762e-05,  1.0365e-04])\n",
      "Epoch 5999, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.7134e-05,  9.9927e-05])\n",
      "Epoch 6000, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.7955e-05,  1.0106e-04])\n",
      "Epoch 6001, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.3067e-05,  1.0157e-04])\n",
      "Epoch 6002, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-4.3392e-05,  9.7692e-05])\n",
      "Epoch 6003, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.9683e-05,  9.9659e-05])\n",
      "Epoch 6004, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.2590e-05,  1.0058e-04])\n",
      "Epoch 6005, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-4.2021e-05,  9.6679e-05])\n",
      "Epoch 6006, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.7611e-05,  9.7394e-05])\n",
      "Epoch 6007, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.0935e-05,  9.8228e-05])\n",
      "Epoch 6008, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0742e-05,  9.9778e-05])\n",
      "Epoch 6009, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.9876e-05,  9.6083e-05])\n",
      "Epoch 6010, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.9564e-05,  9.7543e-05])\n",
      "Epoch 6011, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-1.3649e-05,  9.9808e-05])\n",
      "Epoch 6012, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.3021e-05,  9.6023e-05])\n",
      "Epoch 6013, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.2723e-05,  9.5606e-05])\n",
      "Epoch 6014, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0146e-05,  9.7483e-05])\n",
      "Epoch 6015, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.9995e-05,  9.3669e-05])\n",
      "Epoch 6016, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-1.6034e-05,  9.7960e-05])\n",
      "Epoch 6017, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.5882e-05,  9.4086e-05])\n",
      "Epoch 6018, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-1.6093e-06,  1.0023e-04])\n",
      "Epoch 6019, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.1458e-05,  9.6411e-05])\n",
      "Epoch 6020, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-4.1127e-05,  9.2596e-05])\n",
      "Epoch 6021, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-1.8537e-05,  9.6470e-05])\n",
      "Epoch 6022, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.8207e-05,  9.2834e-05])\n",
      "Epoch 6023, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-1.1683e-05,  9.7394e-05])\n",
      "Epoch 6024, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.1412e-05,  9.3669e-05])\n",
      "Epoch 6025, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([3.3379e-06, 9.9778e-05])\n",
      "Epoch 6026, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-1.6391e-05,  9.5993e-05])\n",
      "Epoch 6027, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.5882e-05,  9.2238e-05])\n",
      "Epoch 6028, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-1.0967e-05,  9.6411e-05])\n",
      "Epoch 6029, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-3.0279e-05,  9.2804e-05])\n",
      "Epoch 6030, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([1.1921e-07, 9.8139e-05])\n",
      "Epoch 6031, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6032, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6033, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6034, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6035, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6036, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6037, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6038, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6039, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6040, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6041, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6042, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6043, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6044, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6045, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6046, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6047, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6048, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6049, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6050, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6051, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6052, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6053, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6054, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6055, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6056, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6057, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6058, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6059, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6060, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6061, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6062, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6063, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6064, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6065, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6066, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6067, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6068, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6069, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6070, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6071, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6072, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6073, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6074, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6075, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6076, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6077, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6078, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6079, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6080, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6081, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6082, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6083, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6084, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6085, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6086, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6087, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6088, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6089, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6090, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6091, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6092, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6093, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6094, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6095, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6096, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6097, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6098, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6099, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6100, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6101, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6102, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6103, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6104, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6105, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6106, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6107, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6108, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6109, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6110, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6111, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6112, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6113, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6114, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6115, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6116, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6117, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6118, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6119, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6120, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6121, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6122, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6123, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6124, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6125, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6126, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6127, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6128, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6129, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6130, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6131, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6132, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6133, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6134, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6135, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6136, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6137, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6138, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6139, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6140, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6141, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6142, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6143, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6144, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6145, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6146, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6147, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6148, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6149, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6150, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6151, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6152, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6153, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6154, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6155, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6156, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6157, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6158, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6159, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6160, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6161, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6162, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6163, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6164, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6165, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6166, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6167, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6168, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6169, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6170, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6171, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6172, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6173, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6174, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6175, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6176, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6177, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6178, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6179, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6180, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6181, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6182, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6183, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6184, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6185, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6186, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6187, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6188, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6189, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6190, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6191, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6192, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6193, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6194, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6195, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6196, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6197, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6198, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6199, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6200, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6201, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6202, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6203, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6204, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6205, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6206, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6207, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6208, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6209, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6210, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6211, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6212, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6213, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6214, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6215, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6216, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6217, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6218, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6219, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6220, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6221, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6222, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6223, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6224, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6225, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6226, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6227, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6228, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6229, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6230, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6231, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6232, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6233, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6234, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6235, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6236, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6237, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6238, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6239, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6240, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6241, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6242, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6243, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6244, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6245, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6246, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6247, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6248, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6249, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6250, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6251, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6252, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6253, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6254, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6255, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6256, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6257, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6258, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6259, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6260, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6261, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6262, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6263, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6264, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6265, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6266, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6267, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6268, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6269, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6270, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6271, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6272, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6273, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6274, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6275, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6276, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6277, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6278, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6279, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6280, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6281, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6282, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6283, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6284, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6285, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6286, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6287, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6288, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6289, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6290, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6291, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6292, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6293, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6294, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6295, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6296, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6297, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6298, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6299, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6300, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6301, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6302, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6303, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6304, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6305, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6306, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6307, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6308, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6309, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6310, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6311, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6312, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6313, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6314, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6315, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6316, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6317, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6318, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6319, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6320, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6321, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6322, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6323, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6324, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6325, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6326, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6327, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6328, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6329, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6330, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6331, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6332, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6333, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6334, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6335, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6336, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6337, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6338, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6339, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6340, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6341, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6342, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6343, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6344, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6345, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6346, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6347, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6348, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6349, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6350, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6351, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6352, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6353, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6354, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6355, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6356, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6357, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6358, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6359, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6360, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6361, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6362, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6363, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6364, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6365, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6366, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6367, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6368, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6369, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6370, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6371, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6372, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6373, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6374, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6375, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6376, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6377, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6378, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6379, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6380, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6381, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6382, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6383, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6384, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6385, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6386, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6387, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6388, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6389, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6390, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6391, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6392, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6393, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6394, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6395, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6396, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6397, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6398, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6399, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6400, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6401, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6402, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6403, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6404, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6405, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6406, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6407, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6408, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6409, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6410, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6411, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6412, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6413, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6414, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6415, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6416, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6417, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6418, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6419, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6420, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6421, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6422, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6423, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6424, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6425, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6426, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6427, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6428, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6429, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6430, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6431, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6432, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6433, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6434, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6435, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6436, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6437, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6438, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6439, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6440, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6441, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6442, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6443, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6444, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6445, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6446, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6447, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6448, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6449, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6450, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6451, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6452, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6453, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6454, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6455, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6456, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6457, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6458, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6459, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6460, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6461, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6462, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6463, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6464, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6465, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6466, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6467, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6468, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6469, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6470, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6471, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6472, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6473, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6474, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6475, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6476, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6477, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6478, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6479, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6480, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6481, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6482, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6483, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6484, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6485, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6486, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6487, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6488, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6489, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6490, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6491, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6492, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6493, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6494, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6495, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6496, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6497, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6498, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6499, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6500, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6501, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6502, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6503, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6504, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6505, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6506, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6507, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6508, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6509, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6510, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6511, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6512, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6513, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6514, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6515, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6516, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6517, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6518, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6519, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6520, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6521, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6522, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6523, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6524, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6525, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6526, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6527, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6528, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6529, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6530, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6531, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6532, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6533, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6534, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6535, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6536, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6537, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6538, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6539, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6540, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6541, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6542, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6543, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6544, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6545, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6546, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6547, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6548, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6549, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6550, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6551, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6552, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6553, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6554, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6555, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6556, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6557, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6558, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6559, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6560, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6561, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6562, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6563, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6564, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6565, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6566, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6567, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6568, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6569, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6570, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6571, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6572, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6573, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6574, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6575, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6576, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6577, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6578, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6579, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6580, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6581, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6582, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6583, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6584, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6585, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6586, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6587, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6588, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6589, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6590, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6591, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6592, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6593, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6594, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6595, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6596, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6597, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6598, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6599, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6600, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6601, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6602, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6603, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6604, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6605, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6606, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6607, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6608, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6609, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6610, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6611, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6612, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6613, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6614, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6615, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6616, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6617, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6618, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6619, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6620, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6621, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6622, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6623, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6624, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6625, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6626, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6627, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6628, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6629, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6630, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6631, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6632, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6633, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6634, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6635, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6636, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6637, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6638, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6639, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6640, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6641, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6642, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6643, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6644, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6645, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6646, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6647, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6648, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6649, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6650, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6651, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6652, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6653, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6654, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6655, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6656, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6657, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6658, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6659, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6660, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6661, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6662, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6663, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6664, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6665, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6666, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6667, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6668, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6669, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6670, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6671, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6672, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6673, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6674, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6675, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6676, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6677, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6678, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6679, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6680, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6681, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6682, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6683, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6684, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6685, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6686, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6687, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6688, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6689, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6690, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6691, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6692, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6693, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6694, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6695, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6696, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6697, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6698, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6699, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6700, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6701, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6702, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6703, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6704, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6705, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6706, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6707, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6708, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6709, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6710, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6711, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6712, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6713, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6714, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6715, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6716, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6717, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6718, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6719, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6720, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6721, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6722, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6723, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6724, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6725, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6726, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6727, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6728, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6729, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6730, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6731, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6732, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6733, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6734, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6735, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6736, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6737, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6738, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6739, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6740, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6741, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6742, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6743, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6744, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6745, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6746, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6747, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6748, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6749, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6750, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6751, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6752, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6753, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6754, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6755, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6756, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6757, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6758, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6759, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6760, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6761, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6762, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6763, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6764, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6765, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6766, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6767, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6768, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6769, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6770, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6771, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6772, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6773, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6774, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6775, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6776, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6777, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6778, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6779, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6780, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6781, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6782, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6783, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6784, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6785, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6786, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6787, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6788, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6789, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6790, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6791, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6792, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6793, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6794, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6795, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6796, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6797, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6798, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6799, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6800, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6801, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6802, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6803, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6804, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6805, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6806, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6807, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6808, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6809, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6810, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6811, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6812, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6813, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6814, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6815, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6816, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6817, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6818, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6819, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6820, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6821, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6822, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6823, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6824, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6825, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6826, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6827, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6828, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6829, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6830, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6831, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6832, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6833, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6834, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6835, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6836, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6837, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6838, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6839, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6840, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6841, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6842, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6843, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6844, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6845, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6846, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6847, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6848, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6849, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6850, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6851, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6852, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6853, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6854, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6855, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6856, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6857, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6858, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6859, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6860, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6861, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6862, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6863, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6864, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6865, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6866, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6867, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6868, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6869, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6870, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6871, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6872, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6873, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6874, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6875, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6876, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6877, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6878, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6879, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6880, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6881, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6882, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6883, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6884, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6885, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6886, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6887, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6888, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6889, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6890, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6891, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6892, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6893, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6894, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6895, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6896, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6897, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6898, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6899, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6900, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6901, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6902, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6903, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6904, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6905, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6906, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6907, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6908, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6909, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6910, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6911, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6912, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6913, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6914, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6915, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6916, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6917, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6918, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6919, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6920, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6921, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6922, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6923, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6924, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6925, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6926, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6927, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6928, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6929, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6930, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6931, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6932, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6933, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6934, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6935, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6936, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6937, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6938, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6939, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6940, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6941, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6942, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6943, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6944, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6945, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6946, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6947, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6948, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6949, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6950, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6951, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6952, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6953, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6954, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6955, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6956, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6957, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6958, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6959, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6960, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6961, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6962, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6963, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6964, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6965, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6966, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6967, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6968, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6969, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6970, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6971, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6972, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6973, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6974, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6975, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6976, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6977, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6978, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6979, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6980, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6981, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6982, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6983, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6984, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6985, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6986, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6987, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6988, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6989, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6990, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6991, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6992, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6993, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6994, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6995, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6996, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6997, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6998, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 6999, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7000, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7001, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7002, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7003, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7004, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7005, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7006, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7007, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7008, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7009, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7010, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7011, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7012, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7013, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7014, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7015, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7016, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7017, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7018, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7019, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7020, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7021, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7022, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7023, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7024, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7025, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7026, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7027, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7028, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7029, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7030, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7031, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7032, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7033, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7034, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7035, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7036, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7037, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7038, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7039, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7040, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7041, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7042, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7043, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7044, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7045, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7046, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7047, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7048, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7049, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7050, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7051, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7052, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7053, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7054, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7055, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7056, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7057, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7058, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7059, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7060, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7061, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7062, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7063, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7064, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7065, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7066, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7067, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7068, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7069, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7070, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7071, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7072, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7073, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7074, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7075, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7076, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7077, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7078, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7079, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7080, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7081, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7082, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7083, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7084, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7085, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7086, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7087, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7088, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7089, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7090, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7091, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7092, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7093, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7094, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7095, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7096, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7097, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7098, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7099, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7100, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7101, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7102, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7103, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7104, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7105, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7106, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7107, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7108, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7109, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7110, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7111, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7112, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7113, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7114, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7115, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7116, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7117, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7118, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7119, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7120, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7121, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7122, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7123, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7124, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7125, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7126, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7127, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7128, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7129, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7130, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7131, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7132, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7133, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7134, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7135, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7136, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7137, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7138, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7139, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7140, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7141, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7142, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7143, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7144, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7145, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7146, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7147, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7148, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7149, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7150, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7151, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7152, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7153, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7154, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7155, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7156, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7157, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7158, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7159, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7160, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7161, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7162, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7163, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7164, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7165, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7166, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7167, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7168, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7169, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7170, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7171, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7172, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7173, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7174, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7175, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7176, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7177, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7178, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7179, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7180, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7181, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7182, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7183, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7184, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7185, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7186, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7187, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7188, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7189, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7190, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7191, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7192, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7193, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7194, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7195, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7196, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7197, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7198, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7199, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7200, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7201, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7202, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7203, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7204, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7205, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7206, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7207, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7208, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7209, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7210, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7211, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7212, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7213, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7214, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7215, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7216, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7217, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7218, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7219, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7220, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7221, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7222, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7223, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7224, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7225, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7226, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7227, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7228, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7229, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7230, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7231, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7232, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7233, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7234, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7235, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7236, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7237, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7238, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7239, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7240, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7241, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7242, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7243, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7244, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7245, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7246, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7247, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7248, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7249, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7250, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7251, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7252, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7253, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7254, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7255, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7256, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7257, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7258, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7259, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7260, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7261, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7262, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7263, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7264, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7265, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7266, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7267, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7268, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7269, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7270, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7271, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7272, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7273, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7274, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7275, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7276, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7277, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7278, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7279, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7280, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7281, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7282, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7283, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7284, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7285, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7286, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7287, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7288, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7289, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7290, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7291, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7292, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7293, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7294, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7295, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7296, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7297, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7298, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7299, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7300, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7301, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7302, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7303, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7304, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7305, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7306, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7307, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7308, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7309, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7310, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7311, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7312, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7313, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7314, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7315, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7316, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7317, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7318, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7319, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7320, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7321, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7322, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7323, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7324, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7325, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7326, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7327, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7328, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7329, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7330, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7331, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7332, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7333, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7334, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7335, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7336, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7337, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7338, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7339, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7340, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7341, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7342, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7343, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7344, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7345, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7346, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7347, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7348, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7349, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7350, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7351, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7352, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7353, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7354, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7355, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7356, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7357, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7358, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7359, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7360, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7361, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7362, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7363, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7364, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7365, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7366, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7367, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7368, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7369, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7370, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7371, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7372, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7373, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7374, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7375, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7376, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7377, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7378, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7379, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7380, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7381, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7382, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7383, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7384, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7385, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7386, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7387, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7388, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7389, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7390, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7391, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7392, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7393, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7394, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7395, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7396, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7397, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7398, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7399, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7400, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7401, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7402, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7403, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7404, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7405, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7406, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7407, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7408, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7409, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7410, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7411, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7412, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7413, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7414, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7415, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7416, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7417, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7418, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7419, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7420, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7421, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7422, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7423, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7424, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7425, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7426, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7427, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7428, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7429, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7430, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7431, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7432, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7433, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7434, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7435, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7436, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7437, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7438, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7439, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7440, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7441, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7442, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7443, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7444, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7445, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7446, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7447, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7448, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7449, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7450, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7451, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7452, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7453, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7454, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7455, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7456, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7457, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7458, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7459, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7460, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7461, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7462, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7463, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7464, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7465, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7466, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7467, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7468, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7469, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7470, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7471, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7472, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7473, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7474, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7475, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7476, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7477, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7478, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7479, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7480, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7481, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7482, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7483, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7484, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7485, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7486, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7487, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7488, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7489, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7490, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7491, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7492, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7493, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7494, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7495, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7496, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7497, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7498, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7499, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7500, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7501, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7502, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7503, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7504, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7505, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7506, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7507, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7508, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7509, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7510, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7511, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7512, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7513, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7514, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7515, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7516, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7517, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7518, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7519, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7520, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7521, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7522, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7523, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7524, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7525, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7526, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7527, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7528, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7529, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7530, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7531, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7532, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7533, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7534, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7535, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7536, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7537, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7538, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7539, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7540, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7541, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7542, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7543, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7544, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7545, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7546, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7547, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7548, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7549, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7550, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7551, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7552, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7553, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7554, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7555, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7556, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7557, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7558, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7559, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7560, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7561, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7562, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7563, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7564, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7565, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7566, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7567, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7568, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7569, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7570, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7571, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7572, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7573, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7574, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7575, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7576, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7577, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7578, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7579, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7580, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7581, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7582, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7583, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7584, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7585, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7586, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7587, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7588, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7589, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7590, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7591, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7592, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7593, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7594, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7595, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7596, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7597, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7598, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7599, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7600, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7601, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7602, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7603, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7604, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7605, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7606, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7607, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7608, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7609, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7610, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7611, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7612, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7613, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7614, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7615, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7616, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7617, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7618, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7619, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7620, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7621, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7622, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7623, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7624, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7625, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7626, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7627, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7628, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7629, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7630, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7631, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7632, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7633, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7634, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7635, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7636, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7637, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7638, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7639, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7640, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7641, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7642, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7643, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7644, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7645, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7646, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7647, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7648, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7649, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7650, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7651, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7652, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7653, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7654, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7655, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7656, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7657, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7658, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7659, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7660, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7661, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7662, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7663, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7664, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7665, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7666, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7667, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7668, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7669, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7670, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7671, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7672, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7673, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7674, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7675, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7676, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7677, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7678, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7679, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7680, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7681, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7682, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7683, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7684, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7685, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7686, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7687, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7688, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7689, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7690, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7691, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7692, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7693, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7694, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7695, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7696, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7697, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7698, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7699, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7700, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7701, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7702, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7703, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7704, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7705, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7706, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7707, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7708, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7709, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7710, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7711, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7712, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7713, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7714, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7715, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7716, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7717, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7718, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7719, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7720, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7721, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7722, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7723, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7724, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7725, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7726, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7727, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7728, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7729, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7730, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7731, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7732, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7733, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7734, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7735, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7736, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7737, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7738, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7739, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7740, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7741, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7742, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7743, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7744, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7745, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7746, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7747, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7748, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7749, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7750, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7751, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7752, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7753, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7754, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7755, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7756, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7757, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7758, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7759, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7760, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7761, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7762, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7763, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7764, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7765, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7766, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7767, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7768, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7769, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7770, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7771, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7772, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7773, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7774, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7775, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7776, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7777, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7778, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7779, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7780, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7781, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7782, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7783, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7784, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7785, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7786, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7787, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7788, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7789, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7790, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7791, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7792, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7793, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7794, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7795, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7796, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7797, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7798, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7799, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7800, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7801, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7802, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7803, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7804, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7805, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7806, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7807, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7808, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7809, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7810, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7811, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7812, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7813, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7814, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7815, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7816, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7817, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7818, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7819, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7820, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7821, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7822, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7823, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7824, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7825, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7826, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7827, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7828, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7829, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7830, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7831, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7832, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7833, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7834, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7835, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7836, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7837, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7838, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7839, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7840, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7841, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7842, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7843, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7844, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7845, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7846, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7847, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7848, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7849, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7850, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7851, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7852, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7853, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7854, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7855, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7856, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7857, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7858, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7859, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7860, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7861, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7862, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7863, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7864, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7865, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7866, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7867, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7868, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7869, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7870, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7871, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7872, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7873, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7874, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7875, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7876, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7877, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7878, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7879, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7880, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7881, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7882, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7883, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7884, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7885, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7886, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7887, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7888, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7889, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7890, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7891, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7892, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7893, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7894, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7895, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7896, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7897, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7898, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7899, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7900, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7901, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7902, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7903, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7904, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7905, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7906, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7907, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7908, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7909, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7910, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7911, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7912, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7913, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7914, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7915, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7916, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7917, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7918, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7919, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7920, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7921, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7922, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7923, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7924, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7925, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7926, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7927, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7928, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7929, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7930, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7931, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7932, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7933, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7934, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7935, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7936, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7937, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7938, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7939, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7940, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7941, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7942, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7943, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7944, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7945, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7946, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7947, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7948, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7949, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7950, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7951, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7952, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7953, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7954, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7955, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7956, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7957, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7958, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7959, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7960, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7961, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7962, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7963, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7964, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7965, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7966, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7967, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7968, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7969, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7970, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7971, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7972, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7973, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7974, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7975, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7976, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7977, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7978, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7979, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7980, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7981, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7982, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7983, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7984, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7985, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7986, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7987, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7988, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7989, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7990, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7991, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7992, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7993, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7994, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7995, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7996, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7997, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7998, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 7999, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8000, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8001, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8002, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8003, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8004, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8005, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8006, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8007, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8008, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8009, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8010, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8011, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8012, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8013, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8014, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8015, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8016, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8017, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8018, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8019, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8020, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8021, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8022, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8023, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8024, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8025, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8026, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8027, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8028, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8029, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8030, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8031, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8032, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8033, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8034, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8035, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8036, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8037, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8038, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8039, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8040, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8041, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8042, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8043, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8044, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8045, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8046, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8047, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8048, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8049, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8050, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8051, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8052, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8053, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8054, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8055, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8056, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8057, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8058, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8059, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8060, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8061, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8062, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8063, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8064, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8065, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8066, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8067, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8068, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8069, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8070, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8071, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8072, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8073, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8074, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8075, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8076, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8077, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8078, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8079, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8080, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8081, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8082, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8083, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8084, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8085, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8086, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8087, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8088, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8089, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8090, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8091, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8092, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8093, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8094, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8095, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8096, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8097, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8098, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8099, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8100, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8101, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8102, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8103, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8104, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8105, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8106, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8107, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8108, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8109, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8110, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8111, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8112, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8113, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8114, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8115, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8116, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8117, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8118, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8119, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8120, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8121, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8122, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8123, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8124, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8125, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8126, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8127, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8128, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8129, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8130, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8131, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8132, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8133, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8134, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8135, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8136, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8137, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8138, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8139, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8140, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8141, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8142, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8143, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8144, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8145, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8146, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8147, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8148, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8149, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8150, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8151, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8152, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8153, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8154, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8155, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8156, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8157, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8158, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8159, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8160, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8161, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8162, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8163, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8164, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8165, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8166, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8167, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8168, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8169, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8170, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8171, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8172, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8173, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8174, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8175, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8176, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8177, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8178, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8179, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8180, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8181, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8182, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8183, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8184, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8185, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8186, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8187, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8188, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8189, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8190, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8191, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8192, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8193, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8194, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8195, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8196, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8197, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8198, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8199, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8200, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8201, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8202, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8203, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8204, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8205, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8206, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8207, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8208, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8209, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8210, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8211, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8212, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8213, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8214, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8215, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8216, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8217, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8218, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8219, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8220, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8221, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8222, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8223, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8224, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8225, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8226, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8227, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8228, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8229, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8230, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8231, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8232, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8233, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8234, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8235, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8236, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8237, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8238, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8239, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8240, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8241, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8242, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8243, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8244, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8245, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8246, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8247, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8248, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8249, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8250, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8251, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8252, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8253, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8254, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8255, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8256, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8257, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8258, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8259, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8260, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8261, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8262, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8263, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8264, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8265, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8266, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8267, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8268, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8269, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8270, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8271, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8272, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8273, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8274, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8275, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8276, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8277, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8278, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8279, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8280, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8281, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8282, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8283, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8284, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8285, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8286, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8287, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8288, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8289, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8290, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8291, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8292, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8293, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8294, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8295, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8296, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8297, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8298, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8299, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8300, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8301, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8302, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8303, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8304, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8305, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8306, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8307, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8308, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8309, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8310, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8311, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8312, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8313, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8314, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8315, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8316, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8317, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8318, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8319, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8320, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8321, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8322, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8323, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8324, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8325, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8326, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8327, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8328, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8329, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8330, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8331, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8332, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8333, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8334, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8335, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8336, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8337, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8338, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8339, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8340, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8341, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8342, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8343, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8344, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8345, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8346, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8347, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8348, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8349, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8350, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8351, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8352, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8353, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8354, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8355, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8356, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8357, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8358, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8359, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8360, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8361, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8362, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8363, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8364, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8365, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8366, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8367, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8368, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8369, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8370, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8371, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8372, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8373, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8374, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8375, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8376, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8377, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8378, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8379, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8380, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8381, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8382, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8383, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8384, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8385, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8386, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8387, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8388, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8389, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8390, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8391, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8392, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8393, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8394, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8395, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8396, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8397, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8398, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8399, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8400, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8401, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8402, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8403, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8404, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8405, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8406, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8407, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8408, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8409, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8410, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8411, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8412, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8413, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8414, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8415, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8416, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8417, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8418, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8419, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8420, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8421, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8422, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8423, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8424, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8425, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8426, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8427, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8428, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8429, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8430, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8431, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8432, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8433, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8434, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8435, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8436, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8437, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8438, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8439, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8440, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8441, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8442, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8443, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8444, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8445, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8446, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8447, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8448, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8449, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8450, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8451, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8452, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8453, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8454, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8455, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8456, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8457, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8458, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8459, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8460, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8461, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8462, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8463, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8464, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8465, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8466, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8467, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8468, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8469, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8470, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8471, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8472, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8473, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8474, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8475, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8476, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8477, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8478, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8479, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8480, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8481, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8482, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8483, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8484, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8485, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8486, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8487, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8488, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8489, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8490, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8491, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8492, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8493, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8494, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8495, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8496, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8497, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8498, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8499, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8500, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8501, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8502, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8503, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8504, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8505, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8506, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8507, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8508, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8509, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8510, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8511, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8512, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8513, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8514, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8515, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8516, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8517, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8518, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8519, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8520, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8521, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8522, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8523, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8524, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8525, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8526, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8527, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8528, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8529, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8530, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8531, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8532, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8533, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8534, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8535, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8536, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8537, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8538, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8539, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8540, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8541, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8542, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8543, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8544, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8545, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8546, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8547, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8548, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8549, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8550, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8551, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8552, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8553, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8554, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8555, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8556, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8557, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8558, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8559, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8560, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8561, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8562, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8563, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8564, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8565, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8566, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8567, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8568, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8569, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8570, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8571, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8572, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8573, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8574, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8575, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8576, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8577, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8578, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8579, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8580, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8581, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8582, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8583, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8584, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8585, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8586, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8587, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8588, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8589, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8590, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8591, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8592, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8593, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8594, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8595, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8596, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8597, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8598, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8599, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8600, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8601, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8602, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8603, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8604, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8605, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8606, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8607, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8608, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8609, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8610, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8611, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8612, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8613, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8614, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8615, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8616, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8617, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8618, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8619, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8620, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8621, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8622, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8623, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8624, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8625, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8626, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8627, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8628, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8629, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8630, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8631, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8632, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8633, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8634, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8635, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8636, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8637, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8638, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8639, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8640, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8641, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8642, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8643, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8644, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8645, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8646, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8647, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8648, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8649, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8650, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8651, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8652, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8653, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8654, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8655, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8656, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8657, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8658, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8659, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8660, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8661, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8662, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8663, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8664, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8665, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8666, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8667, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8668, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8669, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8670, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8671, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8672, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8673, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8674, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8675, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8676, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8677, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8678, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8679, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8680, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8681, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8682, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8683, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8684, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8685, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8686, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8687, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8688, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8689, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8690, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8691, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8692, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8693, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8694, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8695, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8696, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8697, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8698, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8699, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8700, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8701, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8702, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8703, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8704, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8705, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8706, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8707, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8708, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8709, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8710, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8711, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8712, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8713, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8714, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8715, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8716, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8717, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8718, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8719, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8720, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8721, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8722, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8723, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8724, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8725, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8726, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8727, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8728, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8729, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8730, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8731, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8732, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8733, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8734, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8735, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8736, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8737, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8738, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8739, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8740, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8741, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8742, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8743, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8744, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8745, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8746, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8747, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8748, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8749, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8750, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8751, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8752, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8753, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8754, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8755, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8756, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8757, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8758, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8759, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8760, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8761, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8762, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8763, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8764, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8765, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8766, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8767, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8768, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8769, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8770, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8771, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8772, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8773, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8774, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8775, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8776, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8777, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8778, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8779, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8780, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8781, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8782, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8783, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8784, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8785, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8786, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8787, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8788, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8789, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8790, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8791, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8792, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8793, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8794, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8795, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8796, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8797, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8798, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8799, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8800, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8801, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8802, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8803, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8804, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8805, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8806, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8807, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8808, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8809, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8810, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8811, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8812, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8813, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8814, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8815, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8816, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8817, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8818, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8819, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8820, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8821, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8822, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8823, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8824, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8825, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8826, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8827, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8828, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8829, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8830, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8831, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8832, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8833, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8834, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8835, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8836, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8837, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8838, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8839, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8840, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8841, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8842, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8843, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8844, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8845, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8846, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8847, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8848, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8849, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8850, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8851, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8852, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8853, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8854, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8855, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8856, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8857, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8858, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8859, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8860, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8861, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8862, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8863, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8864, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8865, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8866, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8867, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8868, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8869, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8870, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8871, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8872, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8873, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8874, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8875, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8876, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8877, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8878, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8879, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8880, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8881, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8882, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8883, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8884, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8885, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8886, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8887, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8888, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8889, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8890, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8891, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8892, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8893, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8894, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8895, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8896, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8897, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8898, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8899, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8900, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8901, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8902, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8903, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8904, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8905, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8906, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8907, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8908, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8909, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8910, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8911, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8912, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8913, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8914, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8915, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8916, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8917, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8918, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8919, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8920, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8921, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8922, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8923, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8924, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8925, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8926, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8927, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8928, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8929, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8930, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8931, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8932, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8933, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8934, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8935, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8936, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8937, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8938, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8939, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8940, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8941, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8942, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8943, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8944, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8945, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8946, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8947, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8948, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8949, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8950, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8951, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8952, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8953, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8954, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8955, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8956, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8957, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8958, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8959, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8960, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8961, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8962, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8963, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8964, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8965, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8966, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8967, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8968, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8969, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8970, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8971, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8972, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8973, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8974, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8975, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8976, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8977, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8978, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8979, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8980, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8981, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8982, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8983, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8984, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8985, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8986, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8987, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8988, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8989, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8990, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8991, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8992, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8993, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8994, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8995, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8996, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8997, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8998, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 8999, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9000, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9001, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9002, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9003, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9004, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9005, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9006, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9007, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9008, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9009, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9010, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9011, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9012, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9013, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9014, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9015, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9016, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9017, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9018, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9019, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9020, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9021, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9022, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9023, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9024, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9025, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9026, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9027, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9028, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9029, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9030, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9031, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9032, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9033, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9034, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9035, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9036, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9037, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9038, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9039, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9040, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9041, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9042, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9043, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9044, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9045, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9046, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9047, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9048, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9049, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9050, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9051, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9052, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9053, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9054, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9055, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9056, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9057, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9058, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9059, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9060, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9061, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9062, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9063, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9064, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9065, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9066, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9067, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9068, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9069, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9070, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9071, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9072, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9073, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9074, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9075, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9076, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9077, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9078, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9079, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9080, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9081, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9082, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9083, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9084, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9085, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9086, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9087, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9088, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9089, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9090, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9091, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9092, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9093, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9094, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9095, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9096, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9097, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9098, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9099, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9100, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9101, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9102, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9103, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9104, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9105, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9106, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9107, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9108, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9109, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9110, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9111, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9112, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9113, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9114, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9115, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9116, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9117, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9118, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9119, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9120, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9121, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9122, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9123, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9124, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9125, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9126, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9127, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9128, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9129, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9130, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9131, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9132, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9133, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9134, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9135, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9136, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9137, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9138, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9139, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9140, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9141, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9142, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9143, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9144, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9145, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9146, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9147, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9148, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9149, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9150, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9151, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9152, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9153, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9154, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9155, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9156, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9157, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9158, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9159, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9160, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9161, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9162, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9163, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9164, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9165, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9166, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9167, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9168, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9169, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9170, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9171, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9172, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9173, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9174, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9175, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9176, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9177, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9178, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9179, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9180, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9181, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9182, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9183, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9184, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9185, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9186, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9187, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9188, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9189, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9190, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9191, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9192, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9193, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9194, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9195, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9196, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9197, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9198, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9199, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9200, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9201, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9202, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9203, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9204, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9205, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9206, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9207, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9208, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9209, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9210, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9211, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9212, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9213, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9214, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9215, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9216, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9217, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9218, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9219, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9220, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9221, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9222, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9223, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9224, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9225, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9226, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9227, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9228, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9229, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9230, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9231, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9232, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9233, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9234, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9235, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9236, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9237, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9238, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9239, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9240, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9241, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9242, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9243, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9244, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9245, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9246, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9247, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9248, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9249, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9250, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9251, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9252, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9253, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9254, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9255, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9256, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9257, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9258, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9259, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9260, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9261, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9262, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9263, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9264, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9265, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9266, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9267, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9268, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9269, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9270, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9271, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9272, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9273, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9274, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9275, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9276, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9277, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9278, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9279, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9280, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9281, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9282, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9283, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9284, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9285, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9286, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9287, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9288, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9289, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9290, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9291, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9292, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9293, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9294, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9295, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9296, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9297, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9298, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9299, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9300, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9301, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9302, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9303, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9304, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9305, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9306, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9307, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9308, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9309, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9310, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9311, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9312, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9313, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9314, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9315, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9316, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9317, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9318, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9319, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9320, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9321, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9322, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9323, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9324, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9325, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9326, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9327, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9328, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9329, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9330, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9331, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9332, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9333, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9334, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9335, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9336, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9337, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9338, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9339, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9340, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9341, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9342, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9343, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9344, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9345, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9346, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9347, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9348, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9349, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9350, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9351, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9352, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9353, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9354, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9355, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9356, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9357, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9358, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9359, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9360, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9361, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9362, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9363, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9364, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9365, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9366, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9367, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9368, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9369, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9370, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9371, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9372, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9373, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9374, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9375, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9376, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9377, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9378, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9379, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9380, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9381, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9382, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9383, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9384, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9385, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9386, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9387, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9388, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9389, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9390, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9391, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9392, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9393, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9394, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9395, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9396, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9397, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9398, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9399, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9400, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9401, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9402, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9403, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9404, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9405, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9406, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9407, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9408, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9409, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9410, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9411, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9412, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9413, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9414, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9415, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9416, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9417, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9418, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9419, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9420, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9421, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9422, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9423, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9424, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9425, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9426, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9427, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9428, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9429, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9430, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9431, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9432, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9433, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9434, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9435, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9436, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9437, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9438, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9439, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9440, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9441, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9442, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9443, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9444, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9445, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9446, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9447, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9448, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9449, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9450, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9451, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9452, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9453, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9454, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9455, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9456, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9457, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9458, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9459, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9460, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9461, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9462, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9463, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9464, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9465, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9466, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9467, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9468, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9469, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9470, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9471, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9472, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9473, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9474, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9475, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9476, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9477, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9478, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9479, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9480, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9481, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9482, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9483, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9484, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9485, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9486, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9487, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9488, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9489, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9490, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9491, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9492, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9493, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9494, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9495, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9496, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9497, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9498, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9499, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9500, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9501, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9502, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9503, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9504, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9505, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9506, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9507, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9508, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9509, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9510, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9511, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9512, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9513, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9514, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9515, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9516, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9517, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9518, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9519, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9520, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9521, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9522, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9523, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9524, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9525, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9526, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9527, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9528, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9529, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9530, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9531, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9532, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9533, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9534, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9535, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9536, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9537, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9538, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9539, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9540, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9541, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9542, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9543, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9544, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9545, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9546, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9547, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9548, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9549, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9550, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9551, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9552, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9553, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9554, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9555, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9556, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9557, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9558, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9559, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9560, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9561, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9562, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9563, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9564, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9565, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9566, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9567, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9568, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9569, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9570, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9571, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9572, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9573, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9574, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9575, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9576, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9577, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9578, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9579, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9580, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9581, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9582, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9583, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9584, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9585, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9586, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9587, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9588, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9589, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9590, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9591, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9592, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9593, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9594, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9595, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9596, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9597, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9598, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9599, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9600, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9601, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9602, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9603, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9604, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9605, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9606, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9607, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9608, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9609, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9610, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9611, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9612, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9613, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9614, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9615, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9616, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9617, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9618, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9619, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9620, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9621, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9622, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9623, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9624, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9625, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9626, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9627, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9628, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9629, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9630, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9631, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9632, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9633, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9634, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9635, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9636, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9637, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9638, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9639, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9640, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9641, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9642, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9643, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9644, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9645, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9646, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9647, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9648, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9649, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9650, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9651, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9652, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9653, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9654, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9655, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9656, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9657, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9658, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9659, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9660, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9661, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9662, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9663, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9664, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9665, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9666, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9667, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9668, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9669, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9670, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9671, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9672, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9673, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9674, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9675, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9676, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9677, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9678, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9679, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9680, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9681, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9682, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9683, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9684, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9685, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9686, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9687, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9688, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9689, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9690, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9691, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9692, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9693, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9694, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9695, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9696, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9697, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9698, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9699, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9700, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9701, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9702, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9703, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9704, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9705, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9706, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9707, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9708, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9709, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9710, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9711, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9712, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9713, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9714, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9715, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9716, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9717, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9718, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9719, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9720, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9721, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9722, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9723, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9724, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9725, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9726, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9727, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9728, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9729, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9730, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9731, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9732, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9733, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9734, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9735, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9736, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9737, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9738, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9739, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9740, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9741, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9742, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9743, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9744, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9745, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9746, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9747, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9748, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9749, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9750, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9751, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9752, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9753, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9754, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9755, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9756, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9757, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9758, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9759, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9760, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9761, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9762, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9763, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9764, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9765, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9766, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9767, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9768, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9769, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9770, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9771, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9772, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9773, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9774, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9775, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9776, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9777, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9778, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9779, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9780, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9781, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9782, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9783, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9784, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9785, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9786, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9787, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9788, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9789, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9790, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9791, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9792, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9793, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9794, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9795, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9796, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9797, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9798, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9799, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9800, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9801, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9802, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9803, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9804, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9805, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9806, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9807, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9808, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9809, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9810, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9811, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9812, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9813, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9814, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9815, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9816, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9817, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9818, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9819, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9820, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9821, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9822, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9823, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9824, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9825, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9826, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9827, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9828, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9829, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9830, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9831, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9832, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9833, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9834, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9835, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9836, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9837, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9838, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9839, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9840, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9841, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9842, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9843, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9844, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9845, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9846, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9847, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9848, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9849, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9850, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9851, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9852, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9853, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9854, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9855, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9856, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9857, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9858, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9859, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9860, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9861, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9862, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9863, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9864, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9865, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9866, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9867, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9868, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9869, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9870, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9871, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9872, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9873, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9874, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9875, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9876, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9877, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9878, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9879, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9880, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9881, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9882, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9883, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9884, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9885, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9886, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9887, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9888, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9889, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9890, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9891, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9892, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9893, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9894, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9895, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9896, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9897, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9898, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9899, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9900, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9901, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9902, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9903, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9904, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9905, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9906, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9907, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9908, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9909, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9910, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9911, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9912, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9913, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9914, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9915, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9916, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9917, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9918, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9919, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9920, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9921, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9922, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9923, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9924, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9925, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9926, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9927, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9928, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9929, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9930, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9931, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9932, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9933, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9934, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9935, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9936, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9937, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9938, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9939, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9940, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9941, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9942, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9943, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9944, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9945, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9946, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9947, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9948, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9949, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9950, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9951, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9952, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9953, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9954, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9955, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9956, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9957, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9958, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9959, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9960, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9961, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9962, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9963, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9964, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9965, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9966, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9967, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9968, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9969, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9970, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9971, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9972, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9973, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9974, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9975, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9976, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9977, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9978, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9979, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9980, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9981, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9982, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9983, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9984, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9985, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9986, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9987, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9988, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9989, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9990, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9991, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9992, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9993, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9994, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9995, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9996, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9997, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9998, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n",
      "Epoch 9999, Loss 3.0\n",
      "    Params: tensor([  5.3676, -17.3042])\n",
      "    Grad: tensor([-2.0623e-05,  9.4354e-05])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([  5.3676, -17.3042])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = training_loop(\n",
    "    n_epochs=10000,\n",
    "    learning_rate=0.01,\n",
    "    params = torch.Tensor([0, 0]),\n",
    "    t_u=t_un,\n",
    "    t_c=t_c)\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([  5.3676, -17.3042])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7f6a5fa46850>]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 3600x2400 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light",
      "transient": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "t_p = model(t_un, *params) # unpacking with tensors is along the first dimension\n",
    "# so its like params[0], params[1] etc\n",
    "\n",
    "fig = plt.figure(dpi=600) #dpi is dots per inch\n",
    "plt.xlabel(\"Temperature (Fahrenheit\")\n",
    "plt.ylabel(\"Temperature Celsius\")\n",
    "plt.plot(t_u.numpy(), t_p.detach().numpy())\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "# tracks the whole tree of tensors resulting from\n",
    "# operations on params\n",
    "\n",
    "params.grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([9034.5938,  165.2000])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(model(t_u, *params), t_c)\n",
    "loss.backward()\n",
    "\n",
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must zero your tensor gradients!\n",
    "if params.grad is not None:\n",
    "    params.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewriting training loop\n",
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        \n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        loss.backward()\n",
    "        \n",
    "        # bit weird with the no_grad() but I guess you don't want\n",
    "        # a loop where the learning rate gets back into your gradient\n",
    "        with torch.no_grad():\n",
    "            params -= learning_rate * params.grad\n",
    "            \n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "        \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.957001\n",
      "Epoch 1000, Loss 3.846232\n",
      "Epoch 1500, Loss 3.095423\n",
      "Epoch 2000, Loss 2.958291\n",
      "Epoch 2500, Loss 2.933243\n",
      "Epoch 3000, Loss 2.928668\n",
      "Epoch 3500, Loss 2.927833\n",
      "Epoch 4000, Loss 2.927681\n",
      "Epoch 4500, Loss 2.927653\n",
      "Epoch 5000, Loss 2.927647\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([  5.3671, -17.3012], requires_grad=True)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs=5000,\n",
    "    learning_rate=1e-2,\n",
    "    params=torch.tensor([0.0, 0.0], requires_grad=True),\n",
    "    t_u = t_un,\n",
    "    t_c = t_c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['ASGD',\n 'Adadelta',\n 'Adagrad',\n 'Adam',\n 'AdamW',\n 'Adamax',\n 'LBFGS',\n 'NAdam',\n 'Optimizer',\n 'RAdam',\n 'RMSprop',\n 'Rprop',\n 'SGD',\n 'SparseAdam',\n '__builtins__',\n '__cached__',\n '__doc__',\n '__file__',\n '__loader__',\n '__name__',\n '__package__',\n '__path__',\n '__spec__',\n '_functional',\n '_multi_tensor',\n 'lr_scheduler',\n 'swa_utils']"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "dir(optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing it again with the SGD optimizer\n",
    "\n",
    "def training_loop2(n_epochs, params, t_u, t_c, optimizer):\n",
    "    for epoch in range(n_epochs):\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() #once created, optimizer object is linked to the model\n",
    "        \n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 187.386368\n",
      "Epoch 500, Loss 3.077850\n",
      "Epoch 1000, Loss 2.927648\n",
      "Epoch 1500, Loss 2.927645\n",
      "Epoch 2000, Loss 2.927646\n",
      "Epoch 2500, Loss 2.927646\n",
      "Epoch 3000, Loss 2.927646\n",
      "Epoch 3500, Loss 2.927646\n",
      "Epoch 4000, Loss 2.927647\n",
      "Epoch 4500, Loss 2.927646\n",
      "Epoch 5000, Loss 2.927645\n",
      "Epoch 5500, Loss 2.927647\n",
      "Epoch 6000, Loss 2.927646\n",
      "Epoch 6500, Loss 2.927645\n",
      "Epoch 7000, Loss 2.927647\n",
      "Epoch 7500, Loss 2.927645\n",
      "Epoch 8000, Loss 2.927692\n",
      "Epoch 8500, Loss 2.927646\n",
      "Epoch 9000, Loss 2.927647\n",
      "Epoch 9500, Loss 2.927727\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([  0.5368, -17.3048], requires_grad=True)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([0., 0.], requires_grad=True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "\n",
    "training_loop2(\n",
    "    n_epochs=10000,\n",
    "    params=params,\n",
    "    t_u=t_u,\n",
    "    t_c=t_c,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_u.shape\n",
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "shuffled_indices\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "validation_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_indices, validation_indices\n",
    "\n",
    "train_t_u = t_u[train_indices]\n",
    "train_t_c = t_c[train_indices]\n",
    "\n",
    "val_t_u = t_u[validation_indices]\n",
    "val_t_c = t_c[validation_indices]\n",
    "\n",
    "def training_loop3(n_epochs, optimizer, params, train_t_u,\n",
    "                   train_t_c, val_t_u, val_t_c):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_t_p = model(train_t_u, *params)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 500 == 0:\n",
    "            with torch.no_grad():\n",
    "                val_t_p = model(val_t_u, *params)\n",
    "                val_loss = loss_fn(val_t_p, val_t_c)\n",
    "                assert val_loss.requires_grad == False\n",
    "                \n",
    "            print(f'Epoch {epoch}, Training loss {train_loss.item():.4f}')\n",
    "            print(f'    Validation loss {val_loss.item():.4f}')\n",
    "    \n",
    "    return params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Training loss 3.3503\n",
      "    Validation loss 2.7295\n",
      "Epoch 1000, Training loss 3.2093\n",
      "    Validation loss 1.8614\n",
      "Epoch 1500, Training loss 3.2093\n",
      "    Validation loss 1.8585\n",
      "Epoch 2000, Training loss 3.2093\n",
      "    Validation loss 1.8585\n",
      "Epoch 2500, Training loss 3.2093\n",
      "    Validation loss 1.8585\n",
      "Epoch 3000, Training loss 3.2093\n",
      "    Validation loss 1.8585\n",
      "Epoch 3500, Training loss 3.2093\n",
      "    Validation loss 1.8583\n",
      "Epoch 4000, Training loss 3.2093\n",
      "    Validation loss 1.8585\n",
      "Epoch 4500, Training loss 3.2093\n",
      "    Validation loss 1.8585\n",
      "Epoch 5000, Training loss 3.2093\n",
      "    Validation loss 1.8585\n",
      "Epoch 5500, Training loss 3.4980\n",
      "    Validation loss 2.2848\n",
      "Epoch 6000, Training loss 3.2093\n",
      "    Validation loss 1.8578\n",
      "Epoch 6500, Training loss 3.2093\n",
      "    Validation loss 1.8585\n",
      "Epoch 7000, Training loss 3.4305\n",
      "    Validation loss 2.1037\n",
      "Epoch 7500, Training loss 3.2116\n",
      "    Validation loss 1.8560\n",
      "Epoch 8000, Training loss 3.2093\n",
      "    Validation loss 1.8584\n",
      "Epoch 8500, Training loss 3.2093\n",
      "    Validation loss 1.8579\n",
      "Epoch 9000, Training loss 3.2093\n",
      "    Validation loss 1.8584\n",
      "Epoch 9500, Training loss 3.2093\n",
      "    Validation loss 1.8585\n",
      "Epoch 10000, Training loss 3.2093\n",
      "    Validation loss 1.8585\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([  0.5253, -16.6644], requires_grad=True)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([0., 0.], requires_grad=True)\n",
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "\n",
    "training_loop3(\n",
    "    n_epochs=10000,\n",
    "    optimizer=optimizer,\n",
    "    params=params,\n",
    "    train_t_u=train_t_u,\n",
    "    train_t_c=train_t_c,\n",
    "    val_t_u=val_t_u,\n",
    "    val_t_c=val_t_c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7f6a5ead99d0>]"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAADIUAAAiJCAYAAAA77SfnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAFxGAABcRgEUlENBAAEAAElEQVR4nOzdZ5Sddb3+4fuZSUgIJaF36b333otiQRQpdlQU5Ahy7CKigAiKCoiCKAiKhWJBkSK9hF5DAOk91AChhbSZ5/8i+D/nKDJJmN/e+5m5rrVmuRbzzP5891oIeTE3u6rrOgAAAAAAAAAAAAAAADRLV7sPAAAAAAAAAAAAAAAAYOYZhQAAAAAAAAAAAAAAADSQUQgAAAAAAAAAAAAAAEADGYUAAAAAAAAAAAAAAAA0kFEIAAAAAAAAAAAAAABAAxmFAAAAAAAAAAAAAAAANJBRCAAAAAAAAAAAAAAAQAMZhQAAAAAAAAAAAAAAADSQUQgAAAAAAAAAAAAAAEADGYUAAAAAAAAAAAAAAAA0kFEIAAAAAAAAAAAAAABAAxmFAAAAAAAAAAAAAAAANJBRCAAAAAAAAAAAAAAAQAMZhQAAAAAAAAAAAAAAADSQUQgAAAAAAAAAAAAAAEADGYUAAAAAAAAAAAAAAAA0kFEIAAAAAAAAAAAAAABAAxmFAAAAAAAAAAAAAAAANJBRCAAAAAAAAAAAAAAAQAMZhQAAAAAAAAAAAAAAADSQUQgAAAAAAAAAAAAAAEADGYUAAAAAAAAAAAAAAAA0kFEIAAAAAAAAAAAAAABAAxmFAAAAAAAAAAAAAAAANJBRCAAAAAAAAAAAAAAAQAMZhQAAAAAAAAAAAAAAADSQUQgAAAAAAAAAAAAAAEADGYUAAAAAAAAAAAAAAAA0kFEIAAAAAAAAAAAAAABAAxmFAAAAAAAAAAAAAAAANJBRCAAAAAAAAAAAAAAAQAMZhQAAAAAAAAAAAAAAADSQUQgAAAAAAAAAAAAAAEADGYUAAAAAAAAAAAAAAAA0kFEIAAAAAAAAAAAAAABAAxmFAAAAAAAAAAAAAAAANJBRCAAAAAAAAAAAAAAAQAMZhQAAAAAAAAAAAAAAADSQUQgAAAAAAAAAAAAAAEADGYUAAAAAAAAAAAAAAAA0kFEIAAAAAAAAAAAAAABAAxmFAAAAAAAAAAAAAAAANJBRCAAAAAAAAAAAAAAAQAMZhQAAAAAAAAAAAAAAADSQUQgAAAAAAAAAAAAAAEADGYUAAAAAAAAAAAAAAAA0kFEIAAAAAAAAAAAAAABAAxmFAAAAAAAAAAAAAAAANJBRCAAAAAAAAAAAAAAAQAMZhQAAAAAAAAAAAAAAADSQUQgAAAAAAAAAAAAAAEADGYUAAAAAAAAAAAAAAAA0kFEIAAAAAAAAAAAAAABAAxmFAAAAAAAAAAAAAAAANJBRCAAAAAAAAAAAAAAAQAMNafcBAINZVVVPJRn1Bt+akuSx1l4DAAAAAAAAAAAAAI21RJLZ3uCvT6jreuFWH9MqVV3X7b4BYNCqqmpSkmHtvgMAAAAAAAAAAAAABqjJdV0Pb/cRpXS1+wAAAAAAAAAAAAAAAABmnlEIAAAAAAAAAAAAAABAAxmFAAAAAAAAAAAAAAAANJBRCAAAAAAAAAAAAAAAQAMNafcBAIPclCTD/vUvDhs2LMsuu2wbzgEAAAAAAAAAAACA5nnggQcyefLkN/rWlFbf0kpGIQDt9ViSVf71Ly677LK5884723AOAAAAAAAAAAAAADTPqquumrvuuuuNvvVYq29ppa52HwAAAAAAAAAAAAAAAMDMMwoBAAAAAAAAAAAAAABoIKMQAAAAAAAAAAAAAACABjIKAQAAAAAAAAAAAAAAaCCjEAAAAAAAAAAAAAAAgAYyCgEAAAAAAAAAAAAAAGggoxAAAAAAAAAAAAAAAIAGMgoBAAAAAAAAAAAAAABoIKMQAAAAAAAAAAAAAACABjIKAQAAAAAAAAAAAAAAaCCjEAAAAAAAAAAAAAAAgAYyCgEAAAAAAAAAAAAAAGggoxAAAAAAAAAAAAAAAIAGMgoBAAAAAAAAAAAAAABoIKMQAAAAAAAAAAAAAACABjIKAQAAAAAAAAAAAAAAaCCjEAAAAAAAAAAAAAAAgAYyCgEAAAAAAAAAAAAAAGggoxAAAAAAAAAAAAAAAIAGMgoBAAAAAAAAAAAAAABoIKMQAAAAAAAAAAAAAACABjIKAQAAAAAAAAAAAAAAaCCjEAAAAAAAAAAAAAAAgAYyCgEAAAAAAAAAAAAAAGggoxAAAAAAAAAAAAAAAIAGMgoBAAAAAAAAAAAAAABoIKMQAAAAAAAAAAAAAACABjIKAQAAAAAAAAAAAAAAaCCjEAAAAAAAAAAAAAAAgAYyCgEAAAAAAAAAAAAAAGggoxAAAAAAAAAAAAAAAIAGMgoBAAAAAAAAAAAAAABoIKMQAAAAAAAAAAAAAACABjIKAQAAAAAAAAAAAAAAaCCjEAAAAAAAAAAAAAAAgAYyCgEAAAAAAAAAAAAAAGggoxAAAAAAAAAAAAAAAIAGMgoBAAAAAAAAAAAAAABoIKMQAAAAAAAAAAAAAACABjIKAQAAAAAAAAAAAAAAaCCjEAAAAAAAAAAAAAAAgAYyCgEAAAAAAAAAAAAAAGggoxAAAAAAAAAAAAAAAIAGMgoBAAAAAAAAAAAAAABoIKMQAAAAAAAAAAAAAACABjIKAQAAAAAAAAAAAAAAaCCjEAAAAAAAAAAAAAAAgAYyCgEAAAAAAAAAAAAAAGggoxAAAAAAAAAAAAAAAIAGGtLuAwAAAAAAAAAAAAAAYJb19iTj702euC155q5k0oRk2uSkZ0rSPVsyZFgyfFSy4CrJomsn8y+fdHW3+WjoH0YhAAAAAAAAAAAAAAA0R10nD49O7jkvGXdL8tTtydSJM/7zQ+dIFl49WWydZMV3JkttllRVuXuhIKMQAAAAAAAAAAAAAAA632sTkjGnJzedPP2TQWbV1FeTx66b/nXd8cn8KyTrfSpZc49k9lH9dS20hFEIAAAAAAAAAAAAAACd6/kHk9HHJGPPmrlPBJlR4+9NLvhqcskhyeq7JpsdkMy7TP93oICudh8AAAAAAAAAAAAAAAD/pmdaMvro5KcbJbf8qswg5H+bOnF656cbTR+h9PaU7UE/MAoBAAAAAAAAAAAAAKCzPHtP8ssdkou/nfRMbm27Z3Jy8beSk3eYfgd0MKMQAAAAAAAAAAAAAAA6Q29vcvWxyc82T8bd3N5bxt00/Y6rj51+F3SgIe0+AAAAAAAAAAAAAAAA0jM1OXvfZOyZ7b7kf/RMTi46OHnqjmTn45Puoe2+CP4PnxQCAAAAAAAAAAAAAEB7TZ2UnPHRzhqE/G9jz5x+39RJ7b4E/g+jEAAAAAAAAAAAAAAA2qdnanLWnsm957f7kjd37/nJHz4x/V7oEEYhAAAAAAAAAAAAAAC0R29vcva+nT8I+ad7zpt+b29vuy+BJEYhAAAAAAAAAAAAAAC0y7XHJWPPbPcVM2fsmcm1P2n3FZDEKAQAAAAAAAAAAAAAgHZ49p7k0sPbfcWsufQ70++HNjMKAQAAAAAAAAAAAACgtXqmJWd/NumZ3O5LZk3P5OTsfZPennZfwiBnFAIAAAAAAAAAAAAAQGtd+5Nk3M3tvuKtGXdTcs1x7b6CQc4oBAAAAAAAAAAAAACA1nn+weSy77b7iv5x2Xenvx9oE6MQAAAAAAAAAAAAAABaZ/QxSc/kdl/RP3omT38/0CZGIQAAAAAAAAAAAAAAtMZrE5KxZ7X7iv419qxk0ovtvoJByigEAAAAAAAAAAAAAIDWGHN6MnViu6/oX1MnTn9f0AZGIQAAAAAAAAAAAAAAlFfXyY0ntfuKMm48afr7gxYzCgEAAAAAAAAAAAAAoLyHRyfP3dfuK8oYf2/yyNXtvoJByCgEAAAAAAAAAAAAAIDy7jmv3ReUdfcAf390JKMQAAAAAAAAAAAAAADKG3dLuy8o64kB/v7oSEYhAAAAAAAAAAAAAACU1duTPHV7u68o68nbp79PaCGjEAAAAAAAAAAAAAAAyhp/bzJ1YruvKGvqq8n4+9p9BYOMUQgAAAAAAAAAAAAAAGU9cVu7L2iNJ29r9wUMMkYhAAAAAAAAAAAAAACU9cxd7b6gNQbL+6RjGIUAAAAAAAAAAAAAAFDWpAntvqA1XpvQ7gsYZIxCAAAAAAAAAAAAAAAoa9rkdl/QGoPlfdIxjEIAAAAAAAAAAAAAACirZ0q7L2iNHqMQWssoBAAAAAAAAAAAAACAsrpna/cFrdE9rN0XMMgYhQAAAAAAAAAAAAAAUNaQQTKWGCzvk45hFAIAAAAAAAAAAAAAQFnDR7X7gtaYfVS7L2CQMQoBAAAAAAAAAAAAAKCsBVdp9wWtMVjeJx3DKAQAAAAAAAAAAAAAgLIWXavdF7TGImu1+wIGGaMQAAAAAAAAAAAAAADKmn+FZOiIdl9R1tA5kvmXb/cVDDJGIQAAAAAAAAAAAAAAlNXVnSy8RruvKGuRNaa/T2ghoxAAAAAAAAAAAAAAAMpbbJ12X1DWogP8/dGRjEIAAAAAAAAAAAAAAChvxXe2+4KyVhrg74+OZBQCAAAAAAAAAAAAAEB5S22WzLd8u68oY/4VkiU3bfcVDEJGIQAAAAAAAAAAAAAAlFdVyfp7tfuKMtbfa/r7gxYzCgEAAAAAAAAAAAAAoDXW3CMZOqLdV/SvoSOmvy9oA6MQAAAAAAAAAAAAAABaY/ZRyeq7tvuK/rX6rsnwke2+gkHKKAQAAAAAAAAAAAAAgNbZ7ICke1i7r+gf3cOmvx9oE6MQAAAAAAAAAAAAAABaZ95lkq0PbPcV/WPrA6e/H2gToxAAAAAAAAAAAAAAAFpr488li63b7ivemsXWSzbZr91XMMgZhQAAAAAAAAAAAAAA0FrdQ5KdT0i6h7X7klnTPSzZ+fikq7vdlzDIGYUAAAAAAAAAAAAAANB6C6yYbPONdl8xa7Y5aPr90GZGIQAAAAAAAAAAAAAAtMfG+yWr79buK2bO6rslG3+u3VdAEqMQAAAAAAAAAAAAAADapasr2fn4ZIUd233JjFnxndPv7fKr+HQGfycCAAAAAAAAAAAAANA+3UOTXU/t/GHIiu9MPnDK9HuhQxiFAAAAAAAAAAAAAADQXkOHJ7uflqy+W7sveWOr75bs9uvpd0IHMQoBAAAAAAAAAAAAAKD9uocm7zsx2f7QpHtYu6+ZrntYsv1h0+/yCSF0IKMQAAAAAAAAAAAAAAA6Q1dXsunnk32uShZbt723LLbe9Ds23X/6XdCB/J0JAAAAAAAAAAAAAEBnWWDF5JMXJtsd0vpPDekeNv3TSj514fQ7oIMNafcBAAAAAAAAAAAAAADwb7qHJJsdkKyyUzL6mGTsWcnUieV6Q0ckq+86vTnvMuU60I+MQgAAAAAAAAAAAAAA6FzzLpPs9ONkh8OSMacnN56UjL+3/15//hWS9fdK1twjGT6y/14XWsAoBAAAAAAAAAAAAACAzjd8ZLLh3skGn0keuTq5+7zkiVuSJ8fM3CeIDJ0jWWSNZNF1kpXemSy5aVJV5e6GgoxCAAAAAAAAAAAAAABojqpKltps+leS9PYk4+9Lnrwteeau5LUJybTJSc/kpHtYMmRYMvuoZMFVkkXWSuZfPunqbt/90I+MQgAAAAAAAAAAAAAAaK6u7mTBlaZ/wSDT1e4DAAAAAAAAAAAAAAAAmHlGIQAAAAAAAAAAAAAAAA1kFAIAAAAAAAAAAAAAANBARiEAAAAAAAAAAAAAAAANZBQCAAAAAAAAAAAAAADQQEYhAAAAAAAAAAAAAAAADWQUAgAAAAAAAAAAAAAA0EBGIQAAAAAAAAAAAAAAAA1kFAIAAAAAAAAAAAAAANBARiEAAAAAAAAAAAAAAAANZBQCAAAAAAAAAAAAAADQQEYhAAAAAAAAAAAAAAAADWQUAgAAAAAAAAAAAAAA0EBGIQAAAAAAAAAAAAAAAA1kFAIAAAAAAAAAAAAAANBARiEAAAAAAAAAAAAAAAANZBQCAAAAAAAAAAAAAADQQEYhAAAAAAAAAAAAAAAADWQUAgAAAAAAAAAAAAAA0EBGIQAAAAAAAAAAAAAAAA1kFAIAAAAAAAAAAAAAANBARiEAAAAAAAAAAAAAAAANZBQCAAAAAAAAAAAAAADQQEYhAAAAAAAAAAAAAAAADWQUAgAAAAAAAAAAAAAA0EBGIQAAAAAAAAAAAAAAAA1kFAIAAAAAAAAAAAAAANBARiEAAAAAAAAAAAAAAAANZBQCAAAAAAAAAAAAAADQQEYhAAAAAAAAAAAAAAAADWQUAgAAAAAAAAAAAAAA0EBGIQAAAAAAAAAAAAAAAA1kFAIAAAAAAAAAAAAAANBARiEAAAAAAAAAAAAAAAANZBQCAAAAAAAAAAAAAADQQEYhAAAAAAAAAAAAAAAADWQUAgAAAAAAAAAAAAAA0EBGIQAAAAAAAAAAAAAAAA1kFAIAAAAAAAAAAAAAANBARiEAAAAAAAAAAAAAAAANZBQCAAAAAAAAAAAAAADQQEYhAAAAAAAAAAAAAAAADWQUAgAAAAAAAAAAAAAA0EBGIQAAAAAAAAAAAAAAAA00pN0HAAAAAAAAAAAAAADAW/XEhNfy51vH5S+3jcsLE6dm+NCurLzw3PnMFstkvaXmbfd5UIRRCAAAAAAAAAAAAAAAjfXSpKlZ85ALU9f//r3Hnn8tF971dN6z5qI5Zve10t1Vtf5AKMgoBAAAAAAAAAAAAACARvreBXfnhMsf6PO5c8Y8kRFDu3PkLqunqgxDGDiMQgAAAAAAAAAAAAAAaJS7nngp7/zxVTP1M2fc9Fjev85i2XCZ+QpdBa1nFAIAAAAAAAAAAAAAQCNM7enNe44bnbufenmWfv4PNz9uFMKAYhQCAAAAAAAAAAAAAEDHO/Omx/KVP9z+ll7jmgee66droDMYhQAAAAAAAAAAAAAA0LGefmlSNvzuJf3yWsOGdPXL60CnMAoBAAAAAAAAAAAAAKDj1HWdz59+W/465ol+e805h/sVegYWf0cDAAAAAAAAAAAAANBRrrl/fD500vX9/ro7r7VYv78mtJNRCAAAAAAAAAAAAAAAHWHilGnZ4PBL8srkaf3+2iNnH5rd11+i318X2skoBAAAAAAAAAAAAACAtjvukvvyw4vuLfLaI2cfml/uuX7mGOZX6BlY/B0NAAAAAAAAAAAAAEDb3P/MK9nuR1cUbZyx90ZZaeG5izagHYxCAAAAAAAAAAAAAABouZ7eOrv+7Jrc8uiEYo2h3VVu+eb2mWv40GINaCejEAAAAAAAAAAAAAAAWuqcMU9kv9/fWrRx6ifWz1YrLli0Ae1mFAIAAAAAAAAAAAAAQEs898rkrPudi4s2tl9lofz8o+umqqqiHegERiEAAAAAAAAAAAAAABR34J/H5nfXP1q0MfqrW2fxeUYUbUAnMQoBAAAAAAAAAAAAAKCYmx95PruccG3RxmHvXTUf3Xipog3oREYhAAAAAAAAAAAAAAD0u0lTe7LVUZfnqZcmFWssOd+IXPjfW2TYkO5iDehkRiEAAAAAAAAAAAAAAPSrk0c/lMP+dlfRxl/+a9OsucSoog3odEYhAAAAAAAAAAAAAAD0i0efm5gtjrqsaGPPTZbKt3datWgDmsIoBAAAAAAAAAAAAACAt6S3t86ep96YK+99tmjntoO3z6gRsxVtQJMYhQAAAAAAAAAAAAAAMMsuuuvpfPrXNxVt/Owj6+Qdqy1StAFNZBQCAAAAAAAAAAAAAMBMe3Hi1Kx56IVFG5suN19O++SG6eqqinagqYxCAAAAAAAAAAAAAACYKYefe1d+cdVDRRuXf2mrLDX/HEUb0HRGIQAAAAAAAAAAAAAAzJA7xr2Ydx83umjj6zuulL23XLZoAwYKoxAAAAAAAAAAAAAAAN7UlGm9ecexV+bBZ18t1ph/zmEZ/dWtM3xod7EGDDRGIQAAAAAAAAAAAAAA/Ee/u/7RHPjnsUUbZ+2zcdZfat6iDRiIjEIAAAAAAAAAAAAAAPg3T0x4LZsceWnRxm7rLZ7vf2DNog0YyIxCAAAAAAAAAAAAAAD4/+q6zr6/vSXn3/FU0c6N39guC8w1rGgDBjqjEAAAAAAAAAAAAAAAkiRX3vtsPvbLG4o2jtl9rey89mJFGzBYGIUAAAAAAAAAAAAAAAxyr0yelnUPuyiTp/UWa6y1xKj88bObpLurKtaAwcYoBAAAAAAAAAAAAABgEDv6ontz7CX3FW1c+N9bZIWF5iragMHIKAQAAAAAAAAAAAAAYBC656mX8/ZjrizaOGC75XPAdisUbcBgZhQCAAAAAAAAAAAAADCITOvpzS4nXJMxj79YrDH70O7cdNB2mWOYX1mHkvw/DAAAAAAAAAAAAABgkDj71nE54IzbijZO+9QG2Xz5BYo2gOmMQgAAAAAAAAAAAAAABrhnX56c9Q+/uGjjXasvkp98aO1UVVW0A/wPoxAAAAAAAAAAAAAAgAHsy2eNyVk3P160ce3Xt8kiI2cv2gD+nVEIAAAAAAAAAAAAAMAAdMNDz2e3E68t2jji/avngxu8rWgD+M+MQgAAAAAAAAAAAAAABpDXpvRks+9dmudenVKssdyCc+a8/TfPbEO6ijWAvhmFAAAAAAAAAAAAAAAMECde8UCOOP/uoo2/7bdZVltsZNEGMGOMQgAAAAAAAAAAAAAAGu6h8a9m6x9cXrTxmS2WyYHvXLloA5g5RiEAAAAAAAAAAAAAAA3V21vnwyddn2sffK5oZ8zBO2TkiKFFG8DMMwoBAAAAAAAAAAAAAGigC+54Mvv85paijZM+tl62W2Whog1g1hmFAAAAAAAAAAAAAAA0yAuvTsnah11UtLHVigvklD3XT1VVRTvAW2MUArOgqqqhSVZKslqSVV//38WTjHr9a2SSniSTkjyf5IkkDyW5PcmNSa6p63pKq+8GAAAAAAAAAAAAoNm+/dc7c+o1DxdtXPnlrfO2+UYUbQD9wygEZkBVVV1J1k6yTZJtk2yepK9/0w1JMizTByJLJ9n0f31vYlVVFyb5VZK/1XU9rd+PfgNVVT2cZMlWtP6DT9d1fVIb+wAAAAAAAAAAAACNdNtjE7LzT68u2jj43avkk5stXbQB9C+jEPgPqqoakukDkN2TvDfJvP348iOS7Pz610NVVR2Z5OS6rnv6sQEAAAAAAAAAAABAw02e1pPtfnRFHnv+tWKNRUcOz6Vf2irDh3YXawBlGIXAv6iqatUkByR5X5L5WpBcOsmJSfauqmqvuq5vbUETAAAAAAAAAAAAgA7362sfzsF/ubNo44+f3STrLjlP0QZQjlEI/Lv3JNmrDd11klxbVdXn67o+sQ19AAAAAAAAAAAAADrA4y9MzGbfu6xo48Mbvi2Hv2/1og2gPKMQ6CzDkvysqqpF67r+VruPAQAAAAAAAAAAAKB16rrOp399Uy7+xzNFOzcftF3mm3NY0QbQGkYh8Nb1JLkzyT+SPJRkfJJXkwxPMl+SRZJslmTFmXjNg6uqmljX9ff6+VYAAAAAAAAAAAAAOtBl9zyTT5xyY9HGTz60dt69xqJFG0BrGYXArLk7yTlJzk9yfV3XE/v6gaqqFknymST7ZfpYpC9HVFU1tq7r897SpTPumiSnFG5cVfj1AQAAAAAAAAAAABrl5UlTs9ahF6Wnty7WWG/JeXLG3hunu6sq1gDawygEZtyEJKcmOa2u61tm9ofrun4yySFVVf0gyTFJ9urjR6okJ1VVtUpd1xNmtjcL7qvr+qQWdAAAAAAAAAAAAABI8v0L7s7xlz9QtHHJF7fMsgvMWbQBtI9RCPTt/iRHJfnNjHwiSF/qun41yaerqroqyS+TdL/J44sk+WqSr7/VLgAAAAAAAAAAAACd4R9PvpQdj72qaONLO6yQz22zfNEG0H5GIfCf3Zvk0CSn13Xd098vXtf1r6uqmiPJ8X08ul9VVUfUdf1Sf98AAAAAAAAAAAAAQOtM6+nNu48bnbuferlYY67hQ3L9gdtmxGx+VRwGA/9Ph3/3dJJ9k/yirutpJUN1XZ9QVdVGST72Jo/NkWS3JCeVvAUAAAAAAAAAAACAcs666bF8+Q+3F2387tMbZpNl5y/aADqLUQj8i7quT2lx8sAkH0gy4k2e2TlGIQAAAAAAAAAAAACN8/RLk7Lhdy8p2th5rUVz9O5rpaqqoh2g8xiFQJvVdT2uqqrfJ/nUmzy2eVVVXXVd97bqLgAAAAAAAAAAAABmXV3X+e8zbsvZtz1RtHP9gdtmobmHF20AncsoBDrD3/Lmo5C5kyyZ5KHWnAMAAAAAAAAAAADArLrmgfH50C+uL9r4/gfWyG7rLVG0AXQ+oxDoDFfOwDPLxCgEAAAAAAAAAAAAoGNNnDItG373krw8aVqxxsqLzJ2/fm7TDO3uKtYAmsMoBDpAXdfPV1U1Jclsb/LYqBadAwAAAAAAAAAAAMBM+ull9+eov99TtHH+5zfPyovMXbQBNItRCHSO8UkWfZPvz96qQwAAAAAAAAAAAACYMfc/80q2+9EVRRv7brVsvvKOlYo2gGYyCoHOMaKP709qyRUAAAAAAAAAAAAA9Kmnt87uJ16bmx55oViju6vKrQdvn7mHDy3WAJrNKAQ6QFVVcyUZ2cdj5f7EAAAAAAAAAAAAAMAMO2fME9nv97cWbZzyifWz9YoLFm0AzWcUAp1h7SRVH8880IpDAAAAAAAAAAAAAHhjz70yOet+5+Kije1XWSg//+i6qaq+frUUwCgEOsW7+vj+S0kebcUhSVJVVXeSpZO8LckCSWZP0pNk4uu3PJ7ksbquX2nVTQAAAAAAAAAAAADtdOCfx+Z315f9dc7RX906i88zomgDGFiMQqDNXh9g7N7HY6Pruu4tfMrbqqo6JMm2mf7JJX3+iaKqqgeT3Jzk0iTn1XXdsuEKAAAAAAAAAAAAQCvc/MgL2eWEa4o2DnvvqvnoxksVbQADk1EItN/OSZbs45m/tuCOrV//mhnLvP61a5JUVXVVkhOTnFHX9bT+PQ8AAAAAAAAAAACgdSZN7clWR12ep16aVKyx5HwjcuF/b5FhQ7qLNYCBzSgE2uj1Twk5tI/HpiQ5qwXn9IfNX//6dlVVB9V1fUa7DwIAAAAAAAAAAACYWSePfiiH/e2uoo2//NemWXOJUUUbwMBnFALt9dkkq/TxzK/qun6+Fcf0o+WSnF5V1UeSfLqu66fafRAAAAAAAAAAAABAXx59bmK2OOqyoo09N1kq395p1aINYPAwCoE2qapqqSRH9PHY1CTfK39NMe9OcnNVVTvVdX1zu4+ZGVVV/VeSfVuQWrYFDQAAAAAAAAAAAOBN1HWdPU+5MVfc+2zRzq3f3D7zzDFb0QYwuBiFQBtUVdWd5FdJ5uzj0WPqun6gBSeVtGiSK6uqeldd15e3+5iZsED6/hQXAAAAAAAAAAAAoOEuvuvp7PXrm4o2TvjwOtlx9UWKNoDBySgE2uOwJFv08cxjrz/XCg8kuT7J2CR3JHkoyYuvf72WZJ4k873+tV6SLZNsnmT+GXz9EUnOqapqm7qub+zf0wEAAAAAAAAAAABm3ouvTc2ah1xYtLHJsvPlN5/aMF1dVdEOMHgZhUCLVVX1niRf6+OxOskn67p+ueApVyb5S5Jz67q+p49nn339K0muTnLs6592smuSryRZewZ6cyb5Y1VV69R1PX4WbwYAAAAAAAAAAAB4yw4/96784qqHijYu+9JWWXr+OYo2AIxCoIWqqlotyW+T9DX3/Eld1xcXOOGFJGcnOWEGhiBvqq7rniSnJzm9qqoPJjkxyVx9/NgSSX6e5P1vpQ0AAAAAAAAAAAAwK+4Y92Lefdzooo2v7bhS9tly2aINgH8yCoEWqapqwSTnpO/hxI1JvlTojPXrup7W3y9a1/Xvq6q6KckfkqzRx+Pvq6pqx7quz+/vOwAAAAAAAAAAAADeyNSe3ux47FW5/5lXijXmm2O2jP7qNpl9tu5iDYB/ZRQCLVBV1ZxJzkuyVB+PPpdk17qup5S4o8Qg5H+99n1VVW2Z5PIka/bx+OFJOn0U8mySu1rQWTbJsBZ0AAAAAAAAAAAAYFD6/Q2P5ut/Glu0cebeG2eDpect2gB4I0YhUFhVVbMl+XOSdft49LUk763r+pHyV5VR1/WEqqp2SnJLkvne5NG1q6ratq7rS1p02kyr6/qnSX5aulNV1Z1JVindAQAAAAAAAAAAgMHmyRdfy8ZHXFq0seu6i+eoXfv6b2kDlGMUAgVVVdWd5PdJtuvj0amZ/gkhV5e/qqy6rh+tquoLSX7Vx6MfS9KxoxAAAAAAAAAAAACgmeq6zud+d2vOHftk0c6N39guC8w1rGgDoC9GIVBIVVVVkpOSvL+PR3uTfKyu63PLX9UypyX5YpI13uSZ91ZVNbSu66ktugkAAAAAAAAAAAAY4K6679l89OQbijaO3n3NvG/txYs2AGaUUQiUc2ySPWfguX3quj698C0tVdd1XVXVMUl++SaPjUyydpKyf/ICAAAAAAAAAAAABrxXJk/Let+5KJOm9hZrrLn4yPzxs5tkSHdXsQbAzDIKgQKqqvpukv1m4NEv1nX9i9L3tMmfk5yYZOibPLNxjEIAAAAAAAAAAACAt+Doi+7NsZfcV7Rx4X9vkRUWmqtoA2BWGIVAP6uq6sAkX5+BR79V1/WPSt/TLnVdT6iq6rYk67/JYyu16BwAAAAAAAAAAABggLn36Zezw9FXFm3sv+3y+cL2KxRtALwVRiHQj6qq+nySw2fg0aPquj609D0d4Ja8+ShkqRbdAQAAAAAAAAAAAAwQ03p6s8sJ12TM4y8Wawwf2pWbDto+cw7z69ZAZ/NPKegnVVV9JskxM/DoT+q6/krhczrFw318f8FWHAEAAAAAAAAAAAAMDGffOi4HnHFb0cZpn9ogmy+/QNEGQH8xCoF+UFXVR5P8bAYePTnJ/oXP6SR9TXBHtOQKAAAAAAAAAAAAoNGefXly1j/84qKNd62+SH7yobVTVVXRDkB/MgqBt6iqql2TnJKkrz8B/D7JZ+q6rstf1TGm9PH9oS25AgAAAAAAAAAAAGisL581Jmfd/HjRxrVf3yaLjJy9aAOgBKMQeAuqqtopyW+TdPfx6J+TfKyu697yV3WUvv509FpLrgAAAAAAAAAAAAAa54aHns9uJ15btHHE+1fPBzd4W9EGQElGITCLqqp6e5Iz0/enXZyfZI+6rqeVv6rjLNzH919pyRUAAAAAAAAAAABAY0ya2pPNvndpxr8ypVhjuQXnzHn7b57ZhnQVawC0glEIzIKqqrbK9E//GNbHo5cmeX9d1+X+VNLZluvj++NacgUAAAAAAAAAAADQCCde8UCOOP/uoo2/7bdZVltsZNEGQKsYhcBMqqpq4yTnJJm9j0dHJ9mprutJ5a/qWBv28f2HWnIFAAAAAAAAAAAA0NEeHv9qtvrB5UUbe222dA569ypFGwCtZhQCM6GqqnWTnJ9kzj4evTHJu+q6frX8VZ2pqqpVkizVx2O3t+AUAAAAAAAAAAAAoEP19tb5yMnX55oHnivaGXPwDhk5YmjRBkA7GIXADKqqavUkf0/S1+eFjUny9rquXyp/VUf72Aw8c03xKwAAAAAAAAAAAICOdMEdT2Wf39xctPHzj66bHVZduGgDoJ2MQmAGVFW1QpKLkszXx6N3Jdm+rusXyl/VuaqqmifJ3n089kBd1w+04h4AAAAAAAAAAACgc7zw6pSsfdhFRRtbrrBATv3E+qmqqmgHoN2MQqAPVVUtleSSJAv18eh9Sbar6/rZ4kd1viOSjOrjmTNbcAcAAAAAAAAAAADQQQ45586ccvXDRRtXfnnrvG2+EUUbAJ3CKATeRFVVi2b6IGTxPh59OMk2dV0/WfyoDldV1QfS96eE9CQ5uQXnAAAAAAAAAAAAAB1gzGMT8t6fXl20cdC7Vs5emy9TtAHQaYxC4D+oqmqBTB+E9PWng8czfRDyePmrZl5VVaskebKu6xda0No+yWkz8OhZdV0/UPoeAAAAAAAAAAAAoL0mT+vJDkdfmUeem1issfDcw3P5l7fK8KHdxRoAnaqr3QdAJ6qqalSSC5Os1MejT2X6IOSh4kfNuh2SPFhV1TerqpqvRKCa7mtJzksyvI/HX0tyYIk7AAAAAAAAAAAAgM5x2nWPZMWDLig6CPnjZzfOdQduaxACDFo+KQT+RVVVcyY5P8lafTw6Psm2dV3fV/yot25UkkOTfK2qqt8lObWu6375DLaqqtZKcmSSt8/gj3y7w0c0AAAAAAAAAAAAwFswbsJr2fTIS4s2PrjB23LE+1cv2gBoAqMQ+He/T7LRDDx3RpJNqqrapPA9//RkXdfnvsXXGJFkryR7VVX1WJJzk1yU5Jq6rp+a0RepqmqeJFsl+WyS7Wei/9ckR83E8wAAAAAAAAAAAEBD1HWdz5x2cy666+minZsP2i7zzTmsaAOgKYxC4N/N6Gz0v4pe8e+uyPQRR39ZIsk+r3+lqqonk9yd5MEkTyV5PsmkJD1J5kkyb5L5k6yXZLUk1Uz2rk3ykbqu6/44HgAAAAAAAAAAAOgcl93zTD5xyo1FG8d9cO28Z81FizYAmsYoBPinRV7/2rrAa1+eZKe6rl8u8NoAAAAAAAAAAABAm7w8aWrWOvSi9PSW+29Gr7fkPDlj743T3TWz/z1rgIHPKAQo7cdJvljX9bR2HwIAAAAAAAAAAAD0n6P+fnd+etkDRRsXf2HLLLfgnEUbAE1mFAKUcm+Sfeq6vqzdhwAAAAAAAAAAAAD95x9PvpQdj72qaONLO6yQz22zfNEGwEBgFAID391J7kqySot69yU5MslpdV1PbVETAAAAAAAAAAAAKGxaT2/e85Or848nXyrWmGv4kFx/4LYZMZtfcwaYEf5pCQNcXdcXJLmgqqoFk2ydZMsk6ydZLcnwfso8luSCJL9JclVd13U/vS4AAAAAAAAAAADQAc666bF8+Q+3F238bq8Ns8ly8xdtAAw0RiHwL+q6XqrdN5RQ1/UzSc54/StVVXUnWTnJmkmWSbLE61+LJxmZZMTrX8OSTEsyKcnLSZ5MMi7JPUnGJrmxrut7WvleAAAAAAAAAAAAgNZ45qVJ2eC7lxRt7LzWojl697VSVVXRDsBAZBQCg1Rd1z1J7nj9CwAAAAAAAAAAAOD/q+s6XzhzTP5867iinesP3DYLzT28aANgIDMKAQAAAAAAAAAAAAD+v2sfeC4f/MV1RRvf/8Aa2W29JYo2AAYDoxAAAAAAAAAAAAAAIBOnTMuG370kL0+aVqyx8iJz56+f2zRDu7uKNQAGE6MQAAAAAAAAAAAAABjkfnrZ/Tnq7/cUbZy3/+ZZZdG5izYABhujEAAAAAAAAAAAAAAYpB549pVs+8Mrijb22XLZfG3HlYo2AAYroxAAAAAAAAAAAAAAGGR6eut88OfX5YaHny/WqKpkzLd2yNzDhxZrAAx2RiEAAAAAAAAAAAAAMIj87fYn8rnf3Vq0ccqe62frlRYs2gDAKAQAAAAAAAAAAAAABoXnX52SdQ67qGhju5UXyi8+tm6qqiraAWA6oxAAAAAAAAAAAAAAGOAOOntsfnPdo0UbV31l6ywx74iiDQD+L6MQAAAAAAAAAAAAABigbnn0hbz/+GuKNg7ZadV8fJOlijYAeGNGIQAAAAAAAAAAAAAwwEya2pNtfnB5nnhxUrHGEvPOnou/sGWGDeku1gDgzRmFAAAAAAAAAAAAAMAAcsrVD+WQc+4q2jj7vzbNWkuMKtoAoG9GIQAAAAAAAAAAAAAwADz2/MRs/v3LijY+vvGSOeS9qxVtADDjjEIAAAAAAAAAAAAAoMHqus4nTr0xl9/zbNHOrd/cPvPMMVvRBgAzxygEAAAAAAAAAAAAABrq4ruezl6/vqlo44QPr5MdV1+kaAOAWWMUAgAAAAAAAAAAAAAN8+JrU7PmIRcWbWy8zHz57V4bpqurKtoBYNYZhQAAAAAAAAAAAABAg3z3vH/k51c+WLRx2Ze2ytLzz1G0AcBbZxQCAAAAAAAAAAAAAA1wx7gX8+7jRhdtfG3HlbLPlssWbQDQf4xCAAAAAAAAAAAAAKCDTe3pzY7HXpX7n3mlWGO+OWbL6K9uk9ln6y7WAKD/GYUAAAAAAAAAAAAAQIc6/YZH87U/jS3aOOMzG2XDZeYr2gCgDKMQAAAAAAAAAAAAAOgwT704KRsdcUnRxq7rLp6jdl2zaAOAsoxCAAAAAAAAAAAAAKBD1HWdz/3+1px7+5NFOzd8Y9ssONfwog0AyjMKAQAAAAAAAAAAAIAOMPq+8fnIydcXbRy9+5p539qLF20A0DpGIQAAAAAAAAAAAADQRq9Mnpb1vnNRJk3tLdZYY/GR+dNnN8mQ7q5iDQBazygEAAAAAAAAAAAAANrk2Ivvy9EX31u08fcDtsiKC89VtAFAexiFAAAAAAAAAAAAAECL3ff0y9n+6CuLNvbfZrl8YYcVizYAaC+jEAAAAAAAAAAAAABokZ7eOruccE1ue2xCscawIV25+ZvbZ85hflUYYKDzT3oAAAAAAAAAAAAAaIG/3DYunz/9tqKNX39yg2yxwgJFGwB0DqMQAAAAAAAAAAAAACho/CuTs953Li7a2HG1hXP8h9dJVVVFOwB0FqMQAAAAAAAAAAAAACjkq3+4PWfc9FjRxjVf2yaLjpq9aAOAzmQUAgAAAAAAAAAAAAD97MaHn8+uP7u2aOPw962WD2+4ZNEGAJ3NKAQAAAAAAAAAAAAA+smkqT3Z7HuXZfwrk4s1lllgjlzw+S0y25CuYg0AmsEoBAAAAAAAAAAAAAD6wS+ufDCHn/ePoo1zPrdZVl98ZNEGAM1hFAIAAAAAAAAAAAAAb8HD41/NVj+4vGhjr82WzkHvXqVoA4DmMQoBAAAAAAAAAAAAgFnQ21vno7+8Plff/1zRzpiDd8jIEUOLNgBoJqMQAAAAAAAAAAAAAJhJF9zxVPb5zc1FGz//6LrZYdWFizYAaDajEAAAAAAAAAAAAACYQRMmTslah15UtLHFCgvk1D3XT1dXVbQDQPMZhQAAAAAAAAAAAADADDjknDtzytUPF21c+eWt87b5RhRtADBwGIUAAAAAAAAAAAAAwJu4/fEJ2eknVxdtHPSulbPX5ssUbQAw8BiFAAAAAAAAAAAAAMAbmDKtN9sffUUeeW5iscbCcw/P5V/eKsOHdhdrADBwGYUAAAAAAAAAAAAAwL847bpH8s2z7yja+ONnN866S85btAHAwGYUAgAAAAAAAAAAAACvGzfhtWx65KVFG3usv0SO3GWNog0ABgejEAAAAAAAAAAAAAAGvbqus/dpN+fCu54u2rn5oO0y35zDijYAGDyMQgAAAAAAAAAAAAAY1C6/55nsecqNRRs//uDa2WnNRYs2ABh8jEIAAAAAAAAAAAAAGJRenjQ1ax96Uab11sUa6y45T87ce+N0d1XFGgAMXkYhAAAAAAAAAAAAAAw6P/j7PfnJZfcXbVz8hS2y3IJzFW0AMLgZhQAAAAAAAAAAAAAwaNz91Et5xzFXFW18YfsVsv+2yxdtAEBiFAIAAAAAAAAAAADAIDCtpzfv/enVufOJl4o15hw2JNcfuG3mGOZXdAFoDf/GAQAAAAAAAAAAAGBA++PNj+eLZ40p2vjtXhtm0+XmL9oAgH9lFAIAAAAAAAAAAADAgPTMS5OywXcvKdrYac1Fc+wea6WqqqIdAHgjRiEAAAAAAAAAAAAADCh1XeeLZ47Jn24dV7Rz/YHbZqG5hxdtAMCbMQoBAAAAAAAAAAAAYMC47sHnssfPryva+P4ua2S39Zco2gCAGWEUAgAAAAAAAAAAAEDjvTalJxsdcUlefG1qscZKC8+Vc/bbLEO7u4o1AGBmGIUAAAAAAAAAAAAA0Gg/vez+HPX3e4o2zt1/s6y66MiiDQCYWUYhAAAAAAAAAAAAADTSA8++km1/eEXRxj5bLpuv7bhS0QYAzCqjEAAAAAAAAAAAAAAapbe3zh4/vy43PPx8sUZVJWO+tUPmHj60WAMA3iqjEAAAAAAAAAAAAAAa49zbn8x//e6Woo1f7rletllpoaINAOgPRiEAAAAAAAAAAAAAdLznX52SdQ67qGhju5UXzC8+tl6qqiraAYD+YhQCAAAAAAAAAAAAQEf75tl35LTrHinauOorW2eJeUcUbQBAfzMKAQAAAAAAAAAAAKAj3fLoC3n/8dcUbRyy06r5+CZLFW0AQClGIQAAAAAAAAAAAAB0lElTe7LNDy7PEy9OKtZYfJ7Zc8kXt8ywId3FGgBQmlEIAAAAAAAAAAAAAB3jlKsfyiHn3FW08ed9N8nab5unaAMAWsEoBAAAAAAAAAAAAIC2e+z5idn8+5cVbXxs4yVz6HtXK9oAgFYyCgEAAAAAAAAAAACgbeq6zidOvTGX3/Ns0c6t39w+88wxW9EGALSaUQgAAAAAAAAAAAAAbXHp3U/nk6feVLRx/IfXyTtXX6RoAwDaxSgEAAAAAAAAAAAAgJZ68bWpWfOQC4s2Nlx63vz+0xulq6sq2gGAdjIKAQAAAAAAAAAAAKBljjj/HznxigeLNi794pZZZoE5izYAoBMYhQAAAAAAAAAAAABQ3J1PvJh3/Xh00cZX37FSPrvVskUbANBJjEIAAAAAAAAAAAAAKGZqT2/e9eOrcu/TrxRrzDNiaK752raZfbbuYg0A6ERGIQAAAAAAAAAAAAAUccaNj+arfxxbtHH6ZzbKRsvMV7QBAJ3KKAQAAAAAAAAAAACAfvXUi5Oy0RGXFG3sss7i+cGua6SqqqIdAOhkRiEAAAAAAAAAAAAA9Iu6rrPf72/N325/smjnhm9smwXnGl60AQBNYBQCAAAAAAAAAAAAwFt29f3j8+GTri/a+OGua2aXdRcv2gCAJjEKAQAAAAAAAAAAAGCWvTp5WtY//OJMnNJTrLH6YiPz5303yZDurmINAGgioxAAAAAAAAAAAAAAZsmxF9+Xoy++t2jj7wdskRUXnqtoAwCayigEAAAAAAAAAAAAgJly39MvZ/ujryza2G+b5fLFHVYs2gCApjMKAQAAAAAAAAAAAGCG9PTW2eWEa3LbYxOKNWYb0pWbD9oucw0fWqwBAAOFUQgAAAAAAAAAAAAAffrLbePy+dNvK9r41Sc3yJYrLFC0AQADiVEIAAAAAAAAAAAAAP/R+FcmZ73vXFy08Y5VF84JH1knVVUV7QDAQGMUAgAAAAAAAAAAAMAb+uofbs8ZNz1WtHHN17bJoqNmL9oAgIHKKAQAAAAAAAAAAACA/+PGh5/Prj+7tmjjOzuvlo9stGTRBgAMdEYhAAAAAAAAAAAAACRJJk3tyebfvyzPvjy5WGOZ+efIBQdskdmGdBVrAMBgYRQCAAAAAAAAAAAAQE666sF859x/FG389XObZo3FRxVtAMBgYhQCAAAAAAAAAAAAMIg9PP7VbPWDy4s2PrXZ0vnmu1cp2gCAwcgoBAAAAAAAAAAAAGAQ6u2t8/FTbshV940v2hlz8A4ZOWJo0QYADFZGIQAAAAAAAAAAAACDzN/vfCp7n3Zz0caJH103b1914aINABjsjEIAAAAAAAAAAAAABokJE6dkrUMvKtrYfPn586tPbJCurqpoBwAwCgEAAAAAAAAAAAAYFA4956788uqHijau+PJWWXK+OYo2AID/YRQCAAAAAAAAAAAAMICNffzFvOcno4s2DnrXytlr82WKNgCAf2cUAgAAAAAAAAAAADAATZnWm7cfc2UeGv9qscaCcw3LlV/ZOsOHdhdrAAD/mVEIAAAAAAAAAAAAwADzm+seyUFn31G08Yd9Ns56S81btAEAvDmjEAAAAAAAAAAAAIAB4okJr2WTIy8t2thj/SVy5C5rFG0AADPGKAQAAAAAAAAAAACg4eq6zj6/uTl/v/Ppop2bDtou8885rGgDAJhxRiEAAAAAAAAAAAAADXbFvc/m47+8oWjj2D3WynvXWqxoAwCYeUYhAAAAAAAAAAAAAA308qSpWeewizK1py7WWOdto3LWPpuku6sq1gAAZp1RCAAAAAAAAAAAAEDD/PDCe3LcpfcXbVz8hS2y3IJzFW0AAG+NUQgAAAAAAAAAAABAQ9z91Et5xzFXFW18YfsVsv+2yxdtAAD9wygEAAAAAAAAAAAAoMNN6+nNe396de584qVijTmHDcn1B26bOYb59VIAaAr/1gYAAAAAAAAAAADoYH+8+fF88awxRRu/3WvDbLrc/EUbAED/MwoBAAAAAAAAAAAA6EDPvDwpGxx+SdHGTmsummP3WCtVVRXtAABlGIUAAAAAAAAAAAAAdJC6rvPFM8fkT7eOK9q57uvbZuGRw4s2AICyjEIAAAAAAAAAAAAAOsT1Dz6X3X9+XdHG93dZI7utv0TRBgDQGkYhAAAAAAAAAAAAAG322pSebHLkJXlh4tRijRUWmjPn7r95hnZ3FWsAAK1lFAIAAAAAAAAAAADQRidc/kC+d8HdRRvn7r9ZVl10ZNEGANB6RiEAAAAAAAAAAAAAbfDgs69kmx9eUbSx95bL5Os7rly0AQC0j1EIAAAAAAAAAAAAQAv19tb54C+uy/UPPV+0M+ZbO2Tk7EOLNgCA9jIKAQAAAAAAAAAAAGiR88Y+mX1/e0vRxskfXy/brrxQ0QYA0BmMQgAAAAAAAAAAAAAKe/7VKVnnsIuKNrZZacGc/PH1UlVV0Q4A0DmMQgAAAAAAAAAAAAAKOvgvd+TX1z5StHHVV7bOEvOOKNoAADqPUQgAAAAAAAAAAABAAbc++kLed/w1RRvffs8q2XPTpYs2AIDOZRQCAAAAAAAAAAAA0I8mT+vJNj+4IuMmvFassdio2XPpl7bMsCHdxRoAQOczCgEAAAAAAAAAAADoJ7+65uF86693Fm38ed9Nsvbb5inaAACawSgEAAAAAAAAAAAA4C167PmJ2fz7lxVtfHSjJXPYzqsVbQAAzWIUAgAAAAAAAAAAADCL6rrOp351Uy69+5minVu+uX3mnWO2og0AoHmMQgAAAAAAAAAAAABmwaV3P51PnnpT0cZPP7RO3rXGIkUbAEBzGYUAAAAAAAAAAAAAzISXJk3NGt++sGhjw6Xnze8/vVG6uqqiHQCg2YxCAAAAAAAAAAAAAGbQEef/Iyde8WDRxqVf3DLLLDBn0QYAMDAYhQAAAAAAAAAAAAD04c4nXsy7fjy6aOMr71gx+261XNEGADCwGIUAAAAAAAAAAAAA/AdTe3rz7h+Pzj1Pv1ysMWrE0Fz7tW0z+2zdxRoAwMBkFAIAAAAAAAAAAADwBs688bF85Y+3F22c/pmNstEy8xVtAAADl1EIAAAAAAAAAAAAwP/y1IuTstERlxRt7LLO4vnBrmukqqqiHQBgYDMKAQAAAAAAAAAAAEhS13X2P/22nDPmiaKdG76xbRaca3jRBgAwOBiFAAAAAAAAAAAAAIPeNfePz4dOur5o4we7rpkPrLt40QYAMLgYhQAAAAAAAAAAAACD1quTp2XD716SVyZPK9ZYbbG5c/a+m2ZId1exBgAwOBmFAAAAAAAAAAAAAIPSjy+5Lz+66N6ijQsO2DwrLTx30QYAMHgZhQAAAAAAAAAAAACDyv3PvJztfnRl0cbntl4uX3r7ikUbAABGIQAAAAAAAAAAAMCg0NNbZ9efXZNbHp1QrDG0u8ot39w+cw0fWqwBAPBPRiEAAAAAAAAAAADAgPeX28bl86ffVrRx6ifWz1YrLli0AQDwvxmFAAAAAAAAAAAAAAPW+FcmZ73vXFy08fZVF8rPPrJuqqoq2gEA+FdGIQAAAAAAAAAAAMCA9PU/3Z7f3/BY0cbVX9smi42avWgDAOA/MQoBAAAAAAAAAAAABpSbHn4+H/jZtUUb39l5tXxkoyWLNgAA+mIUAgAAAAAAAAAAAAwIk6b2ZIvvX5ZnXp5crLH0/HPk7wdskdmGdBVrAADMKKMQAAAAAAAAAAAAoPFOuurBfOfcfxRt/PVzm2aNxUcVbQAAzAyjEAAAAAAAAAAAAKCxHnnu1Wx51OVFG5/cdOkc/J5VijYAAGaFUQgAAAAAAAAAAADQOL29dT5+yg256r7xRTu3Hbx9Ro2YrWgDAGBWGYUAAAAAAAAAAAAAjXLhnU/lM6fdXLRx4kfXzdtXXbhoAwDgrTIKAQAAAAAAAAAAGAx6e5Lx9yZP3JY8c1cyaUIybXLSMyXpni0ZMiwZPipZcJVk0bWT+ZdPurrbfDT8Xy9OnJo1D72waGPz5efPrz6xQbq6qqIdAID+YBQCAAAAAAAAAAAwENV18vDo5J7zknG3JE/dnkydOOM/P3SOZOHVk8XWSVZ8Z7LUZknll+Rpn8P+dldOHv1Q0cYVX94qS843R9EGAEB/MgoBAAAAAAAAAAAYSF6bkIw5Pbnp5OmfDDKrpr6aPHbd9K/rjk/mXyFZ71PJmnsks4/qr2uhT2MffzHv+cnooo1vvHPlfHqLZYo2AABKMAoBAAAAAAAAAAAYCJ5/MBl9TDL2rJn7RJAZNf7e5IKvJpcckqy+a7LZAcm8fomecqZM6807jr0yDz77arHGAnMNy1Vf2TrDh3YXawAAlGQUAgAAAAAAAAAA0GQ905Jrj0suOyLpmVy+N3Vicsuvpn8aydYHJpvsl3T5hXr612+vfyTf+PMdRRt/2GfjrLfUvEUbAAClGYUAAAAAAAAAAAA01bP3JGd/Nhl3c+vbPZOTi7+V/OOcZOfjkwVWbP0NDDhPTHgtmxx5adHG7ustke99YI2iDQCAVjEKAQAAAAAAAAAAaJre3umfDnLp4a35dJA3M+6m5GebJ9t8I9l4v6Srq7330Eh1Xeezv7klF9z5VNHOjd/YLgvMNaxoAwCglYxCAAAAAAAAAAAAmqRnanL2vsnYM9t9yf/omZxcdHDy1B3TPzWke2i7L6JBrrz32XzslzcUbRy7x1p571qLFW0AALSDUQgAAAAAAAAAAEBTTJ2UnLVncu/57b7kjY09M5n8crLrqcnQ4e2+hg73yuRpWefQizKlp7dYY+23jcof9tkk3V1VsQYAQDsZhQAAAAAAAAAAADRBz9TOHoT8073nJ3/4RLLbr31iCP/Rjy68Jz++9P6ijYv+e4ssv9BcRRsAAO1mFAIAAAAAAAAAANDpenuTs/ft/EHIP91z3vR733di0tXV7mvoIPc89XLefsyVRRsHbLd8DthuhaINAIBOYRQCAAAAAAAAAADQ6a49Lhl7ZruvmDljz0wWXj3ZdP92X0IHmNbTm/cdf03GjnuxWGPEbN258RvbZY5hfjUSABg8/MkHAAAAAAAAAACgkz17T3Lp4e2+YtZc+p1khbcnC6zY7ktooz/d8ni+cOaYoo3ffGrDbLb8/EUbAACdyCgEAAAAAAAAAACgU/VMS87+bNIzud2XzJqeycnZ+yafujDp6m73NbTYMy9PygaHX1K08e41FslxH1w7VVUV7QAAdCqjEAAAAAAAAAAAgE517U+ScTe3+4q3ZtxNyTXHJZsd0O5LaJG6rvOls27PH295vGjnuq9vm4VHDi/aAADodEYhAAAAAAAAAAAAnej5B5PLvtvuK/rHZd9NVtkpmXeZdl9CYdc/+Fx2//l1RRtHvn/17LHB24o2AACawigEAAAAAAAAAACgE40+JumZ3O4r+kfP5OnvZ6cft/sSCnltSk82OfKSvDBxarHGCgvNmXP33zxDu7uKNQAAmsYoBAAAAAAAAAAAoNO8NiEZe1a7r+hfY89KdjgsGT6y3ZfQz064/IF874K7izb+tt9mWW0xf+8AAPwroxAAAAAAAAAAAIBOM+b0ZOrEdl/Rv6ZOnP6+Nty73ZfQTx589pVs88Mrijb23mKZfP2dKxdtAAA0mVEIAAAAAAAAAABAJ6nr5MaT2n1FGTeelGzwmaSq2n0Jb0Fvb50P/uK6XP/Q80U7Y761Q0bOPrRoAwCg6YxCAAAAAAAAAAAAOsnDo5Pn7mv3FWWMvzd55Opkqc3afQmz6LyxT2bf/8feXYdZWtZ9AP/es2xQS4MgyNIr3d0hCAYvdmFgK8ZrAQKiKGJhYhd2vgYS0khKhyC9KwjSsfTW/f4xuzK77MzsxHPOxOdzXeeamee5z/39HWflYpb5nvvnVzSa8YM3bpk9nr9SoxkAACOFUggAAAAAAAAAAMBQcuPJ7Z6gWTecrBQyDD30+PRsdvTpjWbsPnnF/OCNW6Y4SQYAYKEphQAAAAAAAAAAAAwldzZ7CkPb3TXCX98IdOSf/pGfXPSvRjPO++huWW3ZxRrNAAAYiZRCAAAAAAAAAAAAhorZs5K7r2n3FM36zzWdr7NjTLsnoRdX3fFw9j/+gkYzjnzR+nnLjms0mgEAMJIphQAAAAAAAAAAAAwV99+UzHii3VM0a8bjyf03JytObvckdOPpmbOyx5fOzb8ferKxjOcuvWjO/NAumTBWOQgAYCCUQgAAAAAAAAAAAIaKu65q9wSt8Z+rlEKGqBMunJpP/Pm6RjP+793bZ/PnLdNoBgDAaKEUAgAAAAAAAAAAMFTce327J2iN0fI6h5F/P/REdvzc2Y1mvH7b5+XT+2/UaAYAwGijFAIAAAAAAAAAADBUPPVwuydojScfbvcEzFFrzdt+clnO+Oe9jeZcccReWXbxcY1mAACMRkohAAAAAAAAAAAAQ8XMp9s9QWuMltc5xJ19w715848vbTTj+Ndunv02XrnRDACA0UwpBAAAAAAAAAAAYKiYNb3dE7TGLKWQdpr21Ixs8snTUmtzGVtPWja/fPu2GdNRmgsBAEApBAAAAAAAAAAAYMgYM67dE7TGmPHtnmDU+typN+Rb59zaaMaZH9ola62wRKMZAAB0UgoBAAAAAAAAAAAYKhYZJWWJ0fI6h5Dr75qWfb92XqMZH9l7vbxnt7UbzQAAYF5KIQAAAAAAAAAAAEPFhKXbPUFrLLp0uycYNWbMmp0Xf/383HD3o41lLLXo2Fx06O5ZbJxfSQQAaDX/BgYAAAAAAAAAADBUrLh+uydojdHyOtvsN5fdkY/+7ppGM375tm2z3VrLNZoBAED3lEIAAAAAAAAAAACGilU2bfcErbHypu2eYES7Z9pT2eaYMxvNOGCz5+ZLr9wkpZRGcwAA6JlSCAAAAAAAAAAAwFCx/LrJ2MWSGU+0e5LmjF08WX6ddk8xItVa8/5fXZU/X31XozmXHLZHVpw4odEMAAAWjlIIAAAAAAAAAADAUNExJnnOxskdF7d7kuasvHHn62RQXXjL/Xnt9//eaMYXX7FJXr7Fqo1mAADQN0ohAAAAAAAAAAAAQ8lzNx/ZpZBVNm/3BCPKE9NnZuvPnJnHnp7ZWMYGq0zMn96zQxYZ09FYBgAA/aMUAgAAAAAAAAAAMJSst29y8TfbPUVzJu/b7glGjK+feXO+dPpNjWac+oGdMvk5ExvNAACg/5RCAAAAAAAAAAAAhpJJOybLrZM8cHO7Jxl8y6+brL5Du6cY9m6597Hsedy5jWa8d7e18+G912s0AwCAgVMKAQAAAAAAAAAAGEpKSbZ6a3Lqx9o9yeDb6q2dr49+mTW75hXfvjBX3P5wYxljx5RcccReWXLC2MYyAAAYPEohAAAAAAAAAAAAQ80mr07O/GQy44l2TzJ4xi7W+brolz9ffVfe98srG8348Zu3yq7rrdhoBgAAg0spBAAAAAAAAAAAYKhZdOlko1ckV5zQ7kkGz0avSCYs1e4php0HHns6W3z6jEYz9t5gpXz79VukOMUFAGDYUQoBAAAAAAAAAAAYinb8QHL1r5JZT7d7koEbM77z9dAnh/7ftfnlJbc3mnH+x3bLqsss1mgGAADNUQoBAAAAAAAAAAAYipZdM9ntsOSMT7R7koHb7bDO18NCufxfD+Zl37qo0Yyj998wb9h29UYzAABonlIIAAAAAAAAAADAULXde5N//jm58/J2T9J/z90y2f7gdk8xLDw1Y1Z2+cLZuWdac6fDTFpusZz2wV0ybpGOxjIAAGgdpRAAAAAAAAAAAIChaswiyf7fSr69UzKruaJAY8aMT/b/ZtIxpt2TDHk/OH9Kjv7L9Y1m/Ok9O2ST1ZZuNAMAgNZSCgEAAAAAAAAAABjKVlgv2f3jyelHtnuSvtv98M756dbtDzyRnb9wdqMZb9p+Uo56yQaNZgAA0B5KIUCPSimLJFkryaQkSyZZIslTSaYl+U+SG2utT7RtQAAAAAAAAACA0WC7g5O7/5Fc+5t2T7LwNnplst172z3FkDV7ds2bfnxp/nbTfY3mXHXkXll6sXGNZgAA0D5KIdAPpZSxSSYn2TDJBnM+rppk6TmPpZLMSmd54sEkdyWZkuSaJJcmubDWOr3Vcy+sUspGSQ5Ism+STZP09FNhLaXcnOTUJH9OclattTY+JAAAAAAAAADAaNLRkez/zeTpR5ObTmn3NL1bb9/OeTs62j3JkHT69ffkbT+5rNGMb79+i+yz4XMazQAAoP2UQmAhlFI6kmyWZPckeyTZKclivTxtkSTj01kQWSPJDl3uPVFKOS3JCUn+UmudOehD90MpZe8khyTZtS9PS7LunMf7ktxUSvlyku/VWmcN+pAAAAAAAAAAAKPVmLHJK36c/PZNQ7sYst6+yct/1Dkv83jkiRnZ5FOnNZqxw9rL5adv2SYdHaXRHAAAhgalEOhGKWWRdBZAXpXkpUmWHcTtF0uy/5zHlFLKsUl+0K4SRSnluUm+nuR/BmG7dZN8K8k7SynvqLX+fRD2BAAAAAAAAAAgScZOSF710+SP706u/U27p3m2jV7ZeUKIQsizfPov1+f7509pNOOcD++aScsv3mgGAABDi1IIzKeUskGSD6SzILFcCyLXSPKdJO8opby11nplCzL/q5SyU5LfJVlxkLfeJMl5pZT311q/Nch7AwAAAAAAAACMXmPGJv/zneQ5GyZnfSaZ9XS7J0rGjE92PzzZ7r1JR0e7pxlS/nHnI3nR189vNOOwfSfn7Tuv1WgGAABDk1IIPNuLk7y1DbmbJ7loToniO60ILKW8NMlvkzT11gxjk3yzlLJ6rfWQhjIAAAAAAAAAAEafjo5kh/cn6+6T/PFdyZ2Xt2+W527ZeTrICuu1b4YhaPrM2dnnq3/Lbfc93ljG8kuMz/kf2y0Txo5pLAMAgKFNKQSGlvFJvl1KWaXW+okmg0opeyX5dZorhHT1sVLK47XWo1uQBQAAAAAAAAAweqywXvKW05KLvpGcfUxrTw0ZMz7Z/eNzTgdRSujqF3+/PYf94dpGM377zu2y1aRlG80AAGDoUwqBgZuV5Lok/0wyJcn9SR5PMiHJcklWTrJjkr68FcKRpZQnaq2fG+RZkySllElJfpPOEkpvrk3y0yTnJbk5ySNJFk+yWpJtk7wqyR5JSi/7fKqUck2t9U/9HBsAAAAAAAAAgAUZs0iy4weS9V+SnP+V5NrfJjOeaC5v7GLJRq/ozFx2zeZyhqG7Hn4y2x97VqMZr9xy1Xz+5Zs0mgEAwPChFAL9c0OSE5OckuTvtdZef4oupayc5O1JDk5nWaQ3ny2lXFtrPXlAkz57jkXSeULI0r0svSfJwbXW3y7g3iNzHv9I8v1SylZJvp1k8172/FEpZdNa6+19mxoAAAAAAAAAgF4tu2bykq8lLzg6ufpXyaXfT+6/afD2X37dZKu3Jpu8Opmw1ODtOwLUWvPun1+RU/5xd6M5l358z6yw5MK8DywAAKOFUggsvIeT/DjJT2utV/T1ybXW/yT5ZCnli0m+kuStvTylpLNwsX6t9eG+5vXgvUm27mXN1Un2rbXetTAb1lovLaVsn+RHSV7Tw9Jl0vnaD1iYfQEAAAAAAAAA6IcJSyXbvCPZ+u3Jvy5Ibjg5ueuK5D9X9+0EkbGLJytvnKyyeTJ532T1HZJSmpt7mPrbTfflwB9e0mjGV161afbf7LmNZgAAMDwphUDvbknyhSQ/W5gTQXpTa308ydtKKecl+WGSMT0sXznJx5IcOtDcJCmlrJDkqF6W3ZJkr1rrfX3Zu9b6dCnlDUkWS/LSHpb+Tyllz1rrGX3ZHwAAAAAAAACAPiolmbRj5yNJZs9K7r85+c9Vyb3XJ08+nMx8Opn1dDJmfLLI+GTRpZMV109W3jRZfp2ko6dfbRndHnt6ZjY/+vRMnzm7sYxNV1s6v3/X9hnToYwDAMCCKYVA925K8qkkv6q1zhrszWutPymlLJ7km70sPbiU8tla67RBiP1wkp7O7pye5JV9LYTMVWudVUp5Y5KrkkzqYemnkiiFAAAAAAAAAAC0UseYZMXJnQ8G5LjTb8rXzry50YzTPrhz1l1pyUYzAAAY/pRC4NnuSfLuJN+rtc5sMqjW+q1SyrZJDuxh2eJJXpnk+wPJKqVMTPKOXpZ9pdZ65UByaq2PlFLen+RPPSzbrpSyU631vIFkAQAAAAAAAABAK91496PZ+yt/azTjA3uukw/suW6jGQAAjBxKITCfWuuPWhx5WJKXJ1mshzX7Z4ClkCRvTM+nhDyc5DMDzEiS1Fr/XEo5L8lOPSx7XxKlEAAAAAAAAAAAhryZs2bnf755Ya6985HGMhYbNyaXfnzPLD7er/UBALDw/NsjtFmt9c5Syi+THNTDsp1KKR211tkDiHpDL/e/W2udNoD95/el9FwKeXEpZalaa3M/KQMAAAAAAAAAwAD94cp/54O/vrrRjJ8dtE12XGf5RjMAABiZlEJgaPhLei6FTEyyepIp/dm8lLJOkq16Wfa9/uzdgxOT/CfJyt3cH5/kZUl+OMi5AAAAAAAAAAAwYPc9+nS2+swZjWbst/HK+cZrNksppdEcAABGLqUQGBr+thBr1kw/SyFJXtzL/ctrrbf0c+8FqrXOLqX8Jsn7e1j24iiFAAAAAAAAAAAwxHzkt1fnt5f/u9GMiw7dPSsvtWijGQAAjHxKITAE1FofLKVMTzKuh2VLDyBiz17unzSAvXvbt6dSyG6llDG11lkN5QMAAAAAAAAAwEK7ZMqDeeV3Lmo047MHbJTXbP28RjMAABg9lEJg6Lg/ySo93O/X2wKUUhZJsnMvy5o65/K8JE8lmdDN/aWSbJXk4obyAQAAAAAAAACgV09On5UdPndWHnx8emMZa6+4RE55/04ZO6ajsQwAAEYfpRAYOhbr5f5T/dx3gySL93B/RpJL+rl3j2qtT5VSrkyyXQ/LlEIAAAAAAAAAAGib75x7az57yg2NZvzl4B2z4XOXajQDAIDRSSkEhoBSypLpPDWjJw/1c/vNe7l/fa316X7uvTAuS8+lkM0azAYAAAAAAAAAgAWacv/j2e2L5zSa8fad18xh+z6/0QwAAEY3pRAYGjZLUnpZc2s/9960l/vX9HPfhdXb/kohAAAAAAAAAAC0zOzZNa/7/t9z0W0PNJpz9SdekKUWHdtoBgAAKIXA0LBfL/enJbm9n3uv28v9m/u578K6pZf76zScDwAAAAAAAAAASZJT//GfvPNnVzSa8f0Dt8ye66/UaAYAAMylFAJtVkoZk+RVvSw7v9Y6u58Ra/Ryv7fSxkD1tv/ipZQVaq33NTwHAAAAAAAAAACj1EOPT89mR5/eaMau662QH71pq5RSGs0BAICulEKg/fZPsnova/7cn41L50+Yve19V3/27oO7k8xO0tHDmjWSKIUAAAAAAAAAADDojvrzdfnxhVMbzTjvo7tltWUXazQDAAAWRCkE2mjOKSGf6mXZ9CS/7WfEMkkm9LLm7n7uvVBqrTNLKQ8kWaGHZas0OQMAAAAAAAAAAKPPVXc8nP2Pv6DRjCNftH7esuMajWYAAEBPlEKgvd6VZP1e1pxQa32wn/svtxBr7u3n3n1xT3ouhSzMnAAAAAAAAAAA0KunZ87KnsedmzsefLKxjFWWmpCzPrxrJowd01gGAAAsDKUQaJNSyqQkn+1l2YwknxtAzLILsWbaAPZfWL1lLMycLVVKeU+Sd7cgaq0WZAAAAAAAAAAAjAo/uWhqjvzTdY1m/P5d22eL1ZdpNAMAABaWUgi0QSllTJITkizRy9Kv1FpvHUBUbz99PllrnTWA/RfWo73cH3KlkHSebNLbKS4AAAAAAAAAAAwB/37oiez4ubMbzXjdNs/LZ/5no0YzAACgr5RCoD2OTrJzL2vumLNuICb0cv/xAe6/sB7r5X5vcwIAAAAAAAAAwLPUWvO2n1yWM/55b6M5lx++Z5ZbYnyjGQAA0B9KIdBipZQXJzmkl2U1yVtqrb2dsNGbcb3cnznA/RdWbzm9zQkAAAAAAAAAAPM4+4Z78+YfX9poxjdeu1letPEqjWYAAMBAKIVAC5VSNkzy8ySll6XfqLWeMQiRSiEAAAAAAAAAAIwo056akU0+eVpqbS5j60nL5pdv3zZjOnr7NR8AAGgvpRBokVLKiklOTLJkL0svTfLhQYrt6OX+rEHK6U1vOWNaMgUAAAAAAAAAAMPa50+9Id8859ZGM8780C5Za4UlGs0AAIDBohQCLVBKWSLJyUkm9bL0gSSvqLVOH6To3k7oaNU/A3rLmdGSKfrmviTXtyBnrSTjW5ADAAAAAAAAADBsXX/XtOz7tfMazfjI3uvlPbut3WgGAAAMNqUQaFgpZVySPyTZopelTyZ5aa31X4MY31u5pFX/DBjby/3BKsEMmlrr8UmObzqnlHJdkvWbzgEAAAAAAAAAGI5mzJqdF3/9/Nxw96ONZUycsEguPmyPLDbOr9MBADD8+LdYaFApZUySXybZs5elM9J5QsgFgzxCbydwjBvkvO4Mu1IIAAAAAAAAAADt9ZvL7shHf3dNoxm/eNs22X6t5RvNAACAJimFQENKKSXJ95Mc0MvS2UkOrLWe1MAYj/Vyf4kGMhdkyV7u9zYnAAAAAAAAAACjxD3Tnso2x5zZaMb+m66SL79q03T+ig8AAAxfSiHDUCllmSTjkzxSa32y3fPQra8medNCrHtnrfVXDc3wYC/3x5ZSJtRan2oof66JvdzvbU4AAAAAAAAAAEa4Wmve/6ur8uer72o055LD9siKEyc0mgEAAK2iFDLElVIWT/KqJHsl2SnJiknGdLl/b5LLkvwlyS9qrY+2Y07mVUo5JsnBC7H0Q7XW7zU4ygMLsWbpJHc3OMPcjJ4szJwAAAAAAAAAAIxQF956f177vb83mvGFl2+cV2y5WqMZAADQakohQ1QpZUySDyb5aJLl5l5ewNKVkuw75/GFUsrnk3y+1jq9JYPyLKWUw5IcuhBLP1FrPa7hce5fiDXPSfOlkOf0cl8pBAAAAAAAAABgFHpi+sxsc8yZefSpmY1lPH/lifnze3fI2DEdjWUAAEC7KIX0QyllbJITsuD//WqS99RaF+aX8bvbf2KS3yfZPfMWQWp3T5nzcYkkn0yyfynlgFrr7f2dgf4ppbw/yWcWYukXaq2fanqeWusTpZQH8kyxaEFWanKGUspiSZbsZdm/mpwBAAAAAAAAAICh5xtn3ZwvnnZToxmnvH+nPH/liY1mAABAOymF9M9eSV6dBZc0LhhgIWTJJOcl2TCdZY8FZcxfFKnz3ds8yfmllN1qrbf2dxb6ppTy9iRfWYil36i1frThcbqamp5LIas3nL8w+09teAYAAAAAAAAAAIaIW+59LHsed26jGe/eda18dJ/JjWYAAMBQoBTSP6/s8vn8BY3jBrj3D5NslHnLHqX75QssiJQkqyY5qZSyTa31kQHORC9KKW9I8u2FWPqDJO9reJz5TUmyRQ/312k4f+1e7t9Ta32i4RkAAAAAAAAAAGizWbNrXvWdi3LZvx5qLGNMR8mVR+6ViRPGNpYBAABDiVJIH5VSOpK8NM8UNroWN26vtf5xAHvvn+Rl6bkM0tPJIaXLmpLOX/b/UpK39ncmeldKeUWSH6Xn8k6S/DLJ22utC/oeNum6JC/v4f56Def3tv91DecDAAAAAAAAANBmJ159Vw7+5ZWNZvzozVtlt/VWbDQDAACGGqWQvts4yVJ5pnjR9eMf+7vpnLLJ57pemm9J7eZedyeKzJ3rTaWU79RaL+3vbHSvlPKSJD9PMqaXpX9IcmCtdXbzUz3LFb3c36zh/M17ud/sT/sAAAAAAAAAALTNA489nS0+fUajGXutv1K++4YtUkpv7+kKAAAjj1JI323bw70/D2Dfl6fzZI+5ZY6uupY+HklySZL7kyyfZJMkK+aZckjJMyWVJOlI8o0k2wxgNhaglLJ3kt8k6e2syVOSvLrWOrP5qRaot1LIqqWUFWut9zaUv0Uv95VCAAAAAAAAAABGoMP+cG1+8ffbG804/2O7ZdVlFms0AwAAhjKlkL7brsvnXU/veCTJ3waw77sWcK1rGeSBJB9O8vOu5YJSypgkL0tn8WO5PLsYUpJsWUrZstZ62QDmo4tSyq7pPP1jfC9Lz0pyQK11etMzdafW+u9Syr+SrN7Dsl3TWXAZVKWUVZKs28uy8wc7FwAAAAAAAACA9rn8Xw/lZd+6sNGMo1+6Qd6w3aRGMwAAYDhQCum7jef7em754pJa66z+bFhKmZRkl8x7Ssj8hZBda63Xzf/cOZm/KaVcnOSiJM/Jgk8beV0SpZBBUErZLsmJSRbtZen5SV5Sa32q+al6dUaSg3q4v1caKIUk2bOX+zfXWv/VQC4AAAAAAAAAAC321IxZ2fUL5+Tuac39uszqyy2W0z64c8YvMqaxDAAAGE462j3AMDQp854QMtc1A9jz5d1cn1s4+d8FFUK6qrXenuTVeXYZZG5B5DWlFN/vASqlbJHklCRL9LL00iT71Vofb36qhXJ6L/dfMufUmcHW3Z/tuU5rIBMAAAAAAAAAgBb7wflTMvmIUxsthPzpPTvk3I/sphACAABdOCmkD0opSyVZKs8ULbqWQwZSCnnxfF933feWWutPF2aTWut5pZQT5+w3/4wrJNlwgHOOaqWUjZL8NZ1/BnpydZK9a63Tmp9qoZ2U5Ikki3Vzf8V0nurx18EKLKUsm2TvXpb9drDyAAAAAAAAAABovdsfeCI7f+HsRjPetP2kHPWSDRrNAACA4UoppG9W7+HeDf3ZsJSyRJLt8uzTR+YWOr7bxy2Pz7NLJnNtFqWQfimlrJvO0zaW62Xp9Un2qrU+1PxUC6/W+lgp5c/pPE2mOwdnEEshSd6ZZFwP9+9I8rdBzAMAAAAAAAAAoEVmz655048vzd9uuq/RnCuP2CvLLN7Tr6AAAMDo1tHuAYaZngoB/S0BbJ9nyjnznz5Sk/yyj/udneTRLs/varM+T0dKKZOSnJlkpV6W3pxkz1prsz/p9t8Pe7m/byll08EImlN2OriXZT+ptc7/ZxQAAAAAAAAAgCHu9OvvyZqHndxoIeTbr988U4/dTyEEAAB64aSQvlmsh3uP9HPPHRdwrcz5eHmt9a6+bFZrnVFKuTLJznl2KWSjfsw3qpVSVklnIWTVXpZOTbJ7rfU/jQ/VT7XW00sp1yTZuJslJclXkuw6CHGHJnlOD/efTvL1QcgBAAAAAAAAAKBFHnlyRjb55GmNZmy/1nL52UHbpKOj9L4YAABwUkgfNVEK2aGb6zXJKf3c858LuFaSLN/P/UalUsoK6SyErNnL0n+nsxDy7+anGrDP9XJ/l1LKBwcSUErZPslHe1n241rrPQPJAQAAAAAAAACgdT5z0vWNF0LO/vCu+cXbtlUIAQCAPnBSSN8s2sO9+U/l6FUppSPJ1j0896y+7jnH/OWEms5SyMR+7jfqlFKWTnJaksm9LL07nYWQKY0PNTh+meQDSbbqYc3nSim31FpP7OvmpZR1kvwuPf+z5dEkR/V1bwAAAAAAAAAAWu8fdz6SF339/EYzDn3h5Lxjl7UazQAAgJFKKaRvZvRwb7Ek0/q436ZJFs8zpY2u5ZDpSS7u435zPdbNdaWQhVBKWSKdp7Rs2svS+5PsUWu9ufGhBkmttZZS3pvOP1vdvaXC2CS/LaW8t9b6/YXdu5SyQ5LfJlm5l6WfrLXevbD7AgAAAAAAAADQejNmzc4+X/lbbr3v8cYyllt8XM7/2O5ZdNyYxjIAAGCkUwrpm55KH0v2cn9Bdl3AtbnlkMtrrdP7uN9cT3Rzfcl+7jfa/DLJtgux7tdJti+lbN/wPHP9p9Z60kA3qbVeUkr5bJLDelg2Psn3SikvS3JkrfXS7haWUlZP8rEkb0vv/0w5N8lX+jYxAAAAAAAAAACt9MtLbs+h/3dtoxm/ecd22XqNZRvNAACA0UAppG96Kn1MSnJnH/fbtYd75/Vxr67GdnO9p5NOeMZGC7nuPY1O8WznJhlwKWSOI5PsmGTnXtbtk2SfUsoN6fwzeXM6/3+weJLVkmyTzgJNd6eOdHVvktfWWmf1d2gAAAAAAAAAAJpz18NPZvtjz2o04xVbrJovvGKTRjMAAGA0UQrpm0d6uLdOkgsWdqNSyvgku6XzVJAFGUgpZPFurj86gD0ZQWqts0op+yc5O8nC/JQ9ec6jvx5Osnet9a4B7AEAAAAAAAAAQANqrVnj0JMbz7n043tmhSXHN54DAACjSUe7Bxhmbs0zJY75yxw79HGvvfJMeaPMt9+sDKwUslI31x8bwJ6MMLXWh9L55/CyhqPuTWch5KqGcwAAAAAAAAAA6KOf//1fjRdCvvyqTTL12P0UQgAAoAFOCumDWuvjpZSb03kqyH8vp7PUsU8ft3vtAq6VOR+vrLUO5FSPVbvZ96EB7MkIVGu9r5SyU5LvJDmwgYhLk7ys1npHA3sDAAAAAAAAANBPDz0+PZsdfXqjGZusulR+/67ts8gY710MAABNUQrpu6uSrJtnyiBzT/hYpZSyf631j71tUEpZMckBefZpI5lz7awBzvj8bvadOsB9GYFqrU8leWMp5TdJvpZkzUHY9tEkn0jytVrrrEHYDwAAAAAAAACAQfKq71yUv095sNGM0z64c9ZdaclGMwAAgEQFu+8u6OZ6SXJ0KWXCQuzxiSTjujxvfqf1Z7AkKaWMTbJeFlw4uaW/+zLy1VpPSjI5yRvSecJHf/wryaFJJtVav6wQAgAAAAAAAAAwdFx06wOZdMhJjRZC3r/HOpl67H4KIQAA0CJOCum7XyX5UpIxmfe0kJJk/SQnlFLeUGudvqAnl1L+J8k7Mm9po+vnd9Zazx7AfFuks3Ay/0kmSXLrAPYdNWqtk9o9Q7vUWmck+VmSn5VSVkvywiRbpfPP9upJJiZZLMnT6TwN5D9J/pnOE3T+Wmu9ug1jAwAAAAAAAADQgxmzZmedj5/SaMaEsR257PC9ssR4v5IGAACt5N/A+6jWel8p5a9J9sszhYuuxZCXJ1mvlHJ0kr/UWp9OklLKqknem+SD6TyhZe76zLfHTwY44s493PvnAPdmFKm13pHku3MeAAAAAAAAAAAMQ5895Z/5zrm3NZrx04O2zk7rrNBoBgAAsGBKIf3z9XSWQrrqWgzZOMlvktRSyv3p/N95mQWsS+Y9yWN6ku8McLYXdfm8694zklw2wL0BAAAAAAAAAIBh4PYHnsjOXzi70Yz9Nlo533jtZiml9L4YAABohFJIP9RaTyul/F+SAzJvwaNr4WPuY8X5n76ALec+71tzTmfol1LK8km2my9j7mxXzz21BAAAAAAAAAAAGLk2/dRpefiJGY1mXHTo7ll5qUUbzQAAAHqnFNJ/70+yV5IlsuBiSE8WdErIvUmOHuBMr0kypss8c/evSS4a4N4AAAAAAAAAAMAQ9scr78wHfn1VoxmfPWCjvGbr5zWaAQAALDylkH6qtd5ZSnlNkj9m3iJGsuDSx/xnJNYu16cneXmt9aEBjvWmHu6dN8C9AQAAAAAAAACAIejRp2Zko6NOazRj7RWXyMnv2ynjFuloNAcAAOgbpZABqLWeXEp5WZJfJFk8zy6BzF8EyQLWPJXkTbXWCwYySylluySb5dmnhCTJzCTN/tQHAAAAAAAAAAC03Nt/cllOu/6eRjN++KYts/vklRrNAAAA+kcpZIBqrSeWUjZP8r0kO8+9nHlLGfObWxa5PsmBtdYrBmGU93cda77Pz6+1PjoIGQAAAAAAAAAAwBBw5e0P5X++eWGjGZOfs2RO/cDOvS8EAADaRilkENRab06yaylltyRvTbJPkmW6Wf5EkvOS/DDJ72qtPZVHFkopZd0kL88zp4TMM16Svww0AwAAAAAAAAAAaL9Zs2vWOuzkxnMuOWyPrDhxQuM5AADAwCiFDKJa69lJzi6llCRrJ1kzz5RDHkhyX5J/1FpnDnL0jklO7OH+HwY5DwAAAAAAAAAAaLFvnHVzvnjaTY1mHLbv5Lx957UazQAAAAaPUkgD5pz+cfOcRyvyfpjOk0cAAAAAAAAAAIAR5j+PPJntPntW4zm3HbNvOjpK4zkAAMDgUQoBAAAAAAAAAAAYonb74jmZcv/jjWb85eAds+Fzl2o0AwAAaIZSCAAAAAAAAAAAwBBz2nV35+0/vbzRjBdvskq+/prNGs0AAACapRQCAAAAAAAAAAAwRDw5fVaef+Spjedc98m9s/h4vz4GAADDnX+rBwAAAAAAAAAAGAI+8tur89vL/91oxvGv3Tz7bbxyoxkAAEDrKIUAAAAAAAAAAAC00T//My0v/Op5jWY8Z+KEXHzYHo1mAAAAracUAgAAAAAAAAAA0Aa11qxx6MmN55z/sd2y6jKLNZ4DAAC0nlIIAAAAAAAAAABAi/34gik56sTrG804ePe186EXrNdoBgAA0F5KIQAAAAAAAAAAAC3ywGNPZ4tPn9F4zi2feWEWGdPReA4AANBeSiEAAAAAAAAAAAAtsP/xF+SqOx5uNOO379wuW01attEMAABg6FAKAQAAAAAAAAAAaNB5N9+XN/zgkkYzdlpn+fz0oG0azQAAAIYepZB+KKU8r90z9Eet9fZ2zwAAAAAAAAAAAKPF9Jmzs+7hpzSec/WRL8hSi41tPAcAABh6lEL6Z2qS2u4h+qjG9xsAAAAAAAAAAFriUydenx9eMKXRjM+/bOO8cqvVGs0AAACGNiWB/ivtHgAAAAAAAAAAABhabrvvsez+pXMbzZgwtiP//NQ+KcWvMAEAwGinFNJ/w+mkED/9AQAAAAAAAABAg2qtef6Rp+apGbMbzTnzQ7tkrRWWaDQDAAAYPpRCBmY4lC2GU3kFAAAAAAAAAACGnd9cdkc++rtrGs140/aTctRLNmg0AwAAGH6UQgAAAAAAAAAAAPrhkSdnZJNPntZ4zo2f3ifjFxnTeA4AADD8KIUMTDtO4ejtdBIngwAAAAAAAAAAQMPe+MNLcu5N9zWa8ZO3bJ2d112h0QwAAGB4Uwrpv97KGU2ombf0saAZ2jEXAAAAAAAAAACMCpdNfTAv//ZFjWZsstrS+dN7dmg0AwAAGBmUQvrnzS3KGZ9kuSTLJlk1yfZJVptzb0EFkZrk20kuadF8AAAAAAAAAAAwKsycNTtrf/yUxnMuO3zPLL/E+MZzAACAkUEppB9qrSe0K7uUslqSA5IcnGTNPFMMqekshhyU5OZa61faMiAAAAAAAAAAAIwwx51+U7525s2NZnzixevnzTus0WgGAAAw8iiFDDO11juSfLWU8rUkr07y1STL55mTQ8Yl+VIpZe1a63vbNykAAAAAAAAAAAxv/37oiez4ubMbz5ny2X1TSmk8BwAAGHmUQoapWmtN8stSyjlJfpZktzxTDClJ3lVKmVBrfWv7pgQAAAAAAAAAgOFp+8+embseearRjJPft1PWX2VioxkAAMDI1tHuARiYWut/kuyd5Mx0lkGSZ4ohby6lHNau2QAAAAAAAAAAYLg5+dr/ZNIhJzVaCDlg8+dm6rH7KYQAAAAD5qSQEaDWOrOUckCSC5JsMPdyOoshnyqlnF1rvahtAwIAAAAAAAAAwBD3xPSZWf/Ivzae889P7ZNFx41pPAcAABgdlEJGiFrro6WUtyW5KJ2FkMz52JHk+6WUjWuts9o2IAAAAAAAAAAADFEH//LKnHj1XY1mfOcNW2TvDZ7TaAYAADD6KIWMILXWv5dS/i/JAXmmGJIkk5O8LslP2jIYAAAAAAAAAAAMQf+485G86OvnN5qx+nKL5dyP7NZoBgAAMHophYw8X0lnKaSrkuTDUQoBAAAAAAAAAIDMnl2z5mEnN55z0aG7Z+WlFm08BwAAGL062j0Ag+6iJI90+XruiSEblFImt2EeAAAAAAAAAAAYMr73t9saL4R8aK91M/XY/RRCAACAxjkpZISptc4qpZydZP88UwiZa78kN7R8KAAAAAAAAAAAaLN7H30qW3/mzMZzbj1m34zpKI3nAAAAJEohI9XUbq5v0cohAAAAAAAAAABgKHjhV8/LP/8zrdGM/3v39tn8ecs0mgEAADA/pZCR6d4FXCtJNmj1IAAAAAAAAAAA0C5n33Bv3vzjSxvN2PP5K+X7b9yy0QwAAIDuKIWMTA/P93VNZynkOa0fBQAAAAAAAAAAWuupGbMy+YhTG8+59qgXZMkJYxvPAQAA6I5SyMi0dDfXl2zlEAAAAAAAAAAA0GqH//Ha/Ozi2xvN+PKrNsn/bLZqoxkAAAALQylkZFqxm+tjWjoFAAAAAAAAAAC0yC33Ppo9j/tboxlLLzY2Vx35gkYzAAAA+kIpZGTappvrT7Z0CgAAAAAAAAAAaFitNWscenLjOed+ZNesvtzijecAAAD0hVLICFNKWSGdpZC6gNv3tXgcAAAAAAAAAABozC/+fnsO+8O1jWa8Y+c1c+i+z280AwAAoL+UQkaeDyXpSGcppMz38bY2zgUAAAAAAAAAAIPiocenZ7OjT2885+bPvDBjx3Q0ngMAANBfSiEjSCll/SQfyIJPCUmSK1o3DQAAAAAAAAAADL7XfPfiXHTbA41m/OJt22T7tZZvNAMAAGAwKIWMEKWUdZKclmRcnjkdZH7ntnQoAAAAAAAAAAAYJBff9kBe/d2LG83Yeo1l85t3bNdoBgAAwGBSChkBSikHJTk2yXKZtxDS9cSQh5Kc0eLRAAAAAAAAAABgQGbMmp11Pn5K4zlXHLFXll18XOM5AAAAg0kpZJgqpayU5NVJ3pRk43QWQeqCls65/oNa68yWDQgAAAAAAAAAAAN07Ck35Nvn3tpoxqf33zCv33b1RjMAAACaohTSD6WUA1sZl2SxJBOTLJVkcjpLIJPm3Jv/VJAFnRLyaJIvNT0oAAAAAAAAAAAMhtsfeCI7f+HsxnOmfHbflFJ6XwgAADBEKYX0z4+z4FM5WmX+n0TnL4R0XVeTHFJrvbfxqQAAAAAAAAAAYIA2P/r0PPj49EYzTvvgzll3pSUbzQAAAGgFpZCBadfbBMxfSOmuJJIkP6u1frvheQAAAAAAAAAAYED+dNWdef+vrmo04zVbr5bPHrBxoxkAAACtpBQyMO08LSRZcCml66khv07yltaNAwAAAAAAAAAAffPoUzOy0VGnNZ5zw9H7ZMLYMY3nAAAAtJJSyMC066SQ+XUtp5Qks5IcleSYWmu7iysAAAAAAAAAALBA7/jpZfnrdfc0mvGDN26ZPZ6/UqMZAAAA7aIUMvx0V/KYW1A5O8kHa63XtGgeAAAAAAAAAADok6vueDj7H39BoxnrrrRETvvgLo1mAAAAtJtSyMC06xSO+U8oeTjJH5N8u9Z6ScunAQAAAAAAAACAhTBrds1ah53ceM4lh+2RFSdOaDwHAACg3ZRC+m/+YkarPJzk9iQ3JrkqyXlJLq61zmzTPAAAAAAAAAAA0Kvjz74lX/jrjY1mHPLCyXnnLms1mgEAADCUKIX0zxotzKpJZiZ5Osm0WuuMFmYDAAAAAAAAAMCA3P3IU9n2s2c2nnPbMfumo6Nd7/MKAADQHkoh/VBr/Ve7ZwAAAAAAAAAAgKFu9y+dk9vue7zRjBPfu2M2WnWpRjMAAACGKqUQAAAAAAAAAABgUJ123d15+08vbzRjv41XzvGv3bzRDAAAgKFOKQQAAAAAAAAAABgUT82YlclHnNp4znWf3DuLj/erTwAAAH4yAgAAAAAAAAAABuwjv706v738341mfP01m+XFm6zSaAYAAMBwohQCAAAAAAAAAAD02w13T8s+Xzmv0YyVJo7P3w/bs9EMAACA4UgpBAAAAAAAAAAA6LNaa9Y49OTGc8776G5ZbdnFGs8BAAAYjpRCAAAAAAAAAACAPjnhwqn5xJ+vazTj4N3XzodesF6jGQAAAMOdUggAAAAAAAAAALBQHnjs6Wzx6TMaz7nlMy/MImM6Gs8BAAAY7pRCAAAAAAAAAACAXh3wzQtyxe0PN5rxm3dsl63XWLbRDAAAgJFEKQQAAAAAAAAAAOjW+Tffn9f/4O+NZuy0zvL56UHbNJoBAAAwEimFAAAAAAAAAAAAzzJ95uyse/gpjedcfeQLstRiYxvPAQAAGImUQgAAAAAAAAAAgHl86sTr88MLpjSa8fmXbZxXbrVaoxkAAAAjnVIIAAAAAAAAAACQJJly/+PZ7YvnNJoxbpGO3Hj0PimlNJoDAAAwGiiFAAAAAAAAAADAKFdrzQaf+GuemD6r0ZwzP7RL1lphiUYzAAAARpNRVQoppdy2EMtqrXWtQdhnqOn1dQEAAAAAAAAAMPr87vJ/58O/vbrRjDdtPylHvWSDRjMAAABGo1FVCkkyKUlN0tPZk3WQ9hlqFuZ1AQAAAAAAAAAwSjzy5Ixs8snTGs+58dP7ZPwiYxrPAQAAGI1GWylkru4KEn0teQyXosVwKq8AAAAAAAAAANCwN//okpx9432NZpzwlq2zy7orNJoBAAAw2o3WUggAAAAAAAAAAIw6l//rwbzsWxc1mrHxqkvlz+/dsdEMAAAAOo3WUsiCTs7oz6kfw+EEjuFymgkAAAAAAAAAAA2ZOWt21v74KY3nXPrxPbPCkuMbzwEAAKDTaC2FDFZRQuECAAAAAAAAAIAh7cun35SvnnlzoxlHvGj9HLTjGo1mAAAA8GyjsRQyWKd7DIdTQgAAAAAAAAAAGKXufPjJ7HDsWY3nTPnsvinFr9IAAAC0w2grhZwwxPYBAAAAAAAAAIBBt8OxZ+XOh59sNOPk9+2U9VeZ2GgGAAAAPRtVpZBa65uH0j4AAAAAAAAAADCYTr72P3n3z69oNOOAzZ+b4165aaMZAAAALJxRVQoBAAAAAAAAAICR6InpM7P+kX9tPOefn9oni44b03gOAAAAC0cpBAAAAAAAAAAAhrH3/+rK/OmquxrN+Pbrt8g+Gz6n0QwAAAD6TikEAAAAAAAAAACGoX/c+Uhe9PXzG8143rKL5W8f3a3RDAAAAPpPKQQAAAAAAAAAAIaR2bNr1jzs5MZzLjxk96yy9KKN5wAAANB/SiEAAAAAAAAAADBMfO9vt+UzJ/+z0Yz/3WvdvG+PdRrNAAAAYHAohQAAAAAAAAAAwBB376NPZevPnNl4zq3H7JsxHaXxHAAAAAaHUggAAAAAAAAAAAxh+371vFz/n2mNZvz+Xdtni9WXaTQDAACAwacUAgAAAAAAAAAAQ9DZN96bN//o0kYz9nz+Svn+G7dsNAMAAIDmKIUAAAAAAAAAAMAQ8tSMWZl8xKmN51xz1AsyccLYxnMAAABojlIIAAAAAAAAAAAMEUf88R/56cX/ajTjuFdukgM2X7XRDAAAAFpDKWQYKaWsnWTlJMsnGZ/kkSS3Jbm51jq7nbMBAAAAAAAAANB/t9z7WPY87txGMyZOWCRXf+IFKaU0mgMAAEDrKIUMcaWUbZO8O8meSVbqZtkjpZS/JvlurfXslg0HAAAAAAAAAMCA1Fqz9sdPyazZtdGccz68ayYtv3ijGQAAALSeUsgQVUpZJcl3k7xw7qUeli+d5JVJXllKOSvJO2uttzY7IQAAAAAAAAAAA/HLS27Pof93baMZb995zRy27/MbzQAAAKB9lEL6oZSydJLrs+D//aYn2bTWev8A9t8syYlJVs4zZZDe3g5i7ro9klxeSnlNrfWU/s4AAAAAAAAAAEAzHn5iejb91OmN59z06Rdm3CIdjecAAADQPkoh/bN/kucs4HpN8qsBFkImJzkryVJd9vzv7W6eVrusK0kmJvlDKeVltdaT+jsLAAAAAAAAAACD67XfuzgX3vpAoxm/eOs22X7t5RvNAAAAYGhQCumfV8z5uKDCxnH93bSUMjbJr9JZCOla8uj1qV0+n/u8cUl+WUrZutZ6Q39nAgAAAAAAAABg4C6+7YG8+rsXN5qx1aRl8tt3bt9oBgAAAEOLUkgflVIWS7JnFlwIubzWevkAtn9/ko3TfSGkpnuly8e5J4cskeTbSXYdwEwAAAAAAAAAAPTTjFmzs87HT2k854oj9sqyi49rPAcAAIChRSmk77ZMMjadpYu5BYzM+fin/m5aSlkiyWHpvRCyoJND5pZA5i+GJMlOpZTX1lp/0d/ZAAAAAAAAAADou8+fekO+ec6tjWYc/dIN8obtJjWaAQAAwNClFNJ32/Zw78QB7Pv2JEtn3nJHMm8ZZEaS05NckOT+JMsn2SLJizNvUaXrc0uSz5dSfl1rnTWA+QAAAAAAAAAAWAh3PPhEdvr82Y3nTPnsvillQe8vCgAAwGihFNJ323X5vHb5/I5a6zUD2Pft8+03d/+5P7lfmuT1tdab539iKWXVJL9IsmOX53Q9LWTlJPskOWkA8wEAAAAAAAAA0Istjj49Dzw+vdGM0z64c9ZdaclGMwAAABgeOto9wDA0OfOWN+aWLy7r74allC2TrNtlv+SZckdNcm2SPRZUCEmSWuu/k+yR5OLMWwbp6g39nQ8AAAAAAAAAgJ796ao7M+mQkxothLxm69Uy9dj9FEIAAAD4LyeF9N3q3Vy/dgB7vryX+++stT7W04Ja64xSyquS3JhkfJ4phswtl7y4lLJorfXJAcwJAAAAAAAAAEAXjz09Mxt+4q+N59xw9D6ZMHZM4zkAAAAML0ohfVBKWSnJhMx7isdc1wxg633n26vr/ufVWi9amE1qrXeUUr6X5OAFzDghyWZJLhzAnAAAAAAAAAAAzPGun12eU/5xd6MZ3z9wy+y5/kqNZgAAADB8KYX0zfN6uHdrfzYspTwnyYZ5psQxv+/1ccsT0lkKWRClEAAAAAAAAACAAbr6jofz0uMvaDRj3ZWWyGkf3KXRDAAAAIY/pZC+mdjDvUf6uedO833d9cSQp5P8sS+b1VqvKKX8J8lz5tsr6SyFAAAAAAAAAADQD7Nm16x12MmN5/z9sD2y0sQJjecAAAAw/CmF9M1iPdzrbylkxwVcK+ksdJxba328H3tenWTlPLsUMrkfewEAAAAAAAAAjHrfPOeWfP7UGxvNOOSFk/POXdZqNAMAAICRRSmkb3oqhUzr557b93Dv1H7ueUOSfea7VpIs3c/9AAAAAAAAAABGpXumPZVtjjmz8Zzbjtk3HR2l8RwAAABGFqWQvunpXM5Fkkzvy2allEWTbJJnn+gx11l92a+Le+f7uqazFLJUP/cDAAAAAAAAABh19vjSObn1vscbzfjTe3bIJqst3WgGAAAAI5dSSN882cO9xdPHUkiS7dL5PZhb2uhaDnmk1nptH/eb67Furk/s534AAAAAAAAAAKPG6dffk7f95LJGM/bbaOUc/7rNG80AAABg5FMK6ZtHeri3dJKH+rjfrgu4NrccclEf9+rq6W6uLzaAPQEAAAAAAAAARrSnZszK5CNObTznH5/cO0uM92s7AAAADJyfLvtmWg/31koypY/77dbDvfP6uFdX47u5/sQA9gQAAAAAAAAAGLE+9rtr8uvL7mg042uv2Swv2WSVRjMAAAAYXZRC+qank0DWS3LGwm5USlkuybbpPBVkQf7Wh7nmt2Q31x8bwJ4AAAAAAAAAACPOjXc/mr2/MpBf0+jd8kuMz2WH79loBgAAAKOTUkjf3JJkepKxeXaZY48kx/dhrxcnGTNnnzLffk8kuaT/Y6a7t5RQCgEAAAAAAAAASFJrzRqHntx4znkf3S2rLbtY4zkAAACMTh3tHmA4qbXOTPKPdJY4/nt5zte7l1Im9GG7Ny3g2txyyIVzsvrred3se98A9gQAAAAAAAAAGBF+ctHUxgsh79ltrUw9dj+FEAAAABrlpJC+uyrJ5nM+73rCx5JJ3pHkq71tUErZKMnOeaZQMr+zBjjj+nn2SSZJctsA9wUAAAAAAAAAGLYefHx6Nj/69MZzbvnMC7PIGO/VCgAAQPOUQvru9CRvme/a3HLH4aWUP9Rab+9lj+N6uf+X/g5XSlkyyRrd3L6lv/sCAAAAAAAAAAxnL/vWhbn8Xw81mvGbd2yXrddYttEMAAAA6EoppO/+lGRaOk8GmVsGmXsqx3JJTiql7F9rvXVBTy6lfD7JHpn3lJCun19Za71uAPNtn6RjAbMlyQJnAgAAAAAAAAAYqS645f687vt/bzRjx7WXz8/euk2jGQAAALAgSiF9VGt9qpTy2yQH5ZnCRdfyxQZJriylnJDkxCS3p/N/502TvDvJNl2e86ztk/xogCPu1sO9awe4NwAAAAAAAADAsDB95uyse/gpjedcfeQLstRiYxvPAQAAgAVRCumfLyZ5Q5KxeeZEjq7FkCXSWQB59wKeW/LsU0Lmui/Jjwc424u77Nl178eiFAIAAAAAAAAAjAKf/sv1+f75UxrNOPaAjfLqrZ/XaAYAAAD0RimkH2qtN5ZSvpTk0MxbvOhaDFnQSSDJvIWQ+Z93dK318f7OVUpZL8nzu2R0/XhJrbX28HQAAAAAAAAAgGFtyv2PZ7cvntNoxrgxHbnx0/uklO5+NQQAAABaRymk/45O8rIk62TeosfcEkZ3BYyufyPQ9USPS5N8e4AzHdjDvYsGuDcAAAAAAAAAwJBUa82Gn/hrHp8+q9GcM/53l6y94hKNZgAAAEBfdLR7gOGq1vpUkv2S3Dv3UuY9JaS7R7qsn7v2niQH1Fr7/TcTpZQx6SyFdFdGObu/ewMAAAAAAAAADFW/u/zfWePQkxsthLxxu9Uz9dj9FEIAAAAYcpwUMgC11ltLKdsn+VOSDfPsE0LmPyd0/sJGSXJzkpfWWu8a4DgHJHlunjm1pGvWtCR/G+D+AAAAAAAAAABDxrSnZmTjo05rPOfGT++T8YuMaTwHAAAA+kMpZIBqrVNKKVsmOSzJ/yaZ+5YQ8xdE5ppbFJme5IdJDq21PjIIo3ywS17X3Jrk9IGcQgIAAAAAAAAAMJS85ceX5qwb7m0044S3bJ1d1l2h0QwAAAAYKKWQQVBrnZ7kqFLKcUlelWTfJFsnWXm+pdOSXJLkzCQ/q7XeORj5pZQ9kmzb3XhJ/jIYOQAAAAAAAAAA7XT5vx7My751UaMZGz13qZx48I6NZgAAAMBgUQoZRLXWaUm+N+eRUsqEJEvPuf1ArXVGQ9Ed6TwppDt/aigXAAAAAAAAAKBxs2bXrHXYyY3nXPrxPbPCkuMbzwEAAIDBohTSoFrrU0nubkHO6UlObzoHAAAAAAAAAKDVvnLGTfnKGTc3mnHEi9bPQTuu0WgGAAAANEEpBAAAAAAAAACAIeeuh5/M9see1XjObcfsm46O0ngOAAAANEEpBAAAAAAAAACAIWXHz52Vfz/0ZKMZJ71vx2ywylKNZgAAAEDTlEIAAAAAAAAAABgSTrn2P3nXz69oNON/NntuvvyqTRvNAAAAgFZRCgEAAAAAAAAAoK2emD4z6x/518Zzrv/U3llsnF+XAQAAYOTwUy4AAAAAAAAAAG3zwV9flT9ceWejGd963eZ54UYrN5oBAAAA7aAUAgAAAAAAAABAy1131yPZ72vnN5qx6jKL5vyP7d5oBgAAALSTUggAAAAAAAAAAC0ze3bNmoed3HjOhYfsnlWWXrTxHAAAAGgnpRAAAAAAAAAAAFri++fdlk+f9M9GMz6w5zr5wJ7rNpoBAAAAQ4VSCAAAAAAAAAAAjbrv0aez1WfOaDzn1mP2zZiO0ngOAAAADBVKIQAAAAAAAAAANOZFXz8v/7hzWqMZv3/X9tli9WUazQAAAIChaFSVQkopz2v3DO1Ua7293TMAAAAAAAAAAKPDOTfemzf96NJGM/aYvGJ+8KatGs0AAACAoWxUlUKSTE1S2z1Em9SMvu83AAAAAAAAANBiT8+clfUOP7XxnGuOekEmThjbeA4AAAAMZaOxJFDaPQAAAAAAAAAAwEh05J/+kZ9c9K9GM770ik3ysi1WbTQDAAAAhovRWAoZjSeFKMIAAAAAAAAAAI255d7Hsudx5zaaseSERXLNJ16QUvwaBAAAAMw1GkshyegqSYzGEgwAAAAAAAAA0AK11qz98VMya3azv55wzod3zaTlF280AwAAAIaj0VoKAQAAAAAAAABgAH51ye055P+ubTTjrTuukcNftH6jGQAAADCcjdZSiNMzAAAAAAAAAAD64eEnpmfTT53eeM5Nn35hxi3S0XgOAAAADGejsRRS2j0AAAAAAAAAAMBw9LrvX5wLbnmg0YxfvHWbbL/28o1mAAAAwEgx2kohb273AAAAAAAAAAAAw83fb3sgr/ruxY1mbLn6Mvndu7ZvNAMAAABGmlFVCqm1ntDuGQAAAAAAAAAAhouZs2Zn7Y+f0njOFUfslWUXH9d4DgAAAIw0o6oUAgAAAAAAAADAwvnCX2/I8Wff2mjGp166QQ7cblKjGQAAADCSKYUAAAAAAAAAAPBfdzz4RHb6/NmN50z57L4ppTSeAwAAACOZUggAAAAAAAAAAEmSLT99Ru5/7OlGM/76gZ2z3nOWbDQDAAAARgulEAAAAAAAAACAUe7PV9+V9/3yykYzXrXlavncyzduNAMAAABGG6UQAAAAAAAAAIBR6rGnZ2bDT/y18Zwbjt4nE8aOaTwHAAAARhulEAAAAAAAAACAUejdP788J197d6MZ3ztwy+y1/kqNZgAAAMBophQCAAAAAAAAADCKXPPvh/OSb1zQaMbaKy6RM/53l0YzAAAAAKUQAAAAAAAAAIBRYfbsmjUPO7nxnL8ftkdWmjih8RwAAABAKQQAAAAAAAAAYMT71jm35nOn3tBoxkf3WS/v3nXtRjMAAACAeSmFAAAAAAAAAACMUPdMeyrbHHNm4zm3HbNvOjpK4zkAAADAvJRC2qSUMjbJKkkmJlk0yfgk//3bkVrr39o0GgAAAAAAAAAwAux13Lm5+d7HGs3403t2yCarLd1oBgAAANA9pZAWKKUslmS3JLsk2SzJRklW6OEpNb43AAAAAAAAAEA/nHH9PXnrTy5rNOOFGz4n33r9Fo1mAAAAAL1TPGhQKWW/JAcl2TfJ2K63Bjln2zkZC3JxrfXkwcwDAAAAAAAAAIaep2bMyuQjTm085x+f3DtLjPcrJwAAADAU+Am9AaWUVyb5RJLJcy/Nt6T29PR+RE5N8uEk4xdw7+YkSiEAAAAAAAAAMIId8vtr8qtL72g046uv3jQv3fS5jWYAAAAAfaMUMohKKZOSfDfJHpm33LGgEsiCyh89lUW6VWu9u5Ty4yTvXMDtdUop29daL+zP3gAAAAAAAADA0HXj3Y9m76/8rdGM5ZcYl8sO36vRDAAAAKB/lEIGSSnlhUl+nmSpPFP46Fry6M8JIH3xtXSWQhaUeWASpRAAAAAAAAAAGCFqrVnj0JMbzznvo7tltWUXazwHAAAA6J+Odg8wEpRS3prkxCRLp7OIUec8SpdH7eYxKGqtNyQ5J88+oaQkeWUpRQEIAAAAAAAAAEaAn140tfFCyLt3XStTj91PIQQAAACGOEWBASqlvDHJd/JM8SN5djEjC7jehJ8l2bVL1tzspZJsn6TZ82IBAAAAAAAAgMY8+Pj0bH706Y3n3PKZF2aRMd5nFAAAAIYDpZABKKVsl+4LIfOXQWYkuTSdxYx/JXkgyXZJPphnTvQYqN8l+WaSsXn2KSR7RikEAAAAAAAAAIall3/rwlz2r4cazfj127fNNmsu12gGAAAAMLiUQvqplLJYkl8mGZfuCyElydQkX0zy41rrE/PtsdRgzlRrnVZKOT/J7nl2KWSPJEcOZh4AAAAAAAAA0KwLb7k/r/3+3xvN2GHt5fLzt27baAYAAADQDKWQ/jsqyfMybwGk6+ez0lnC+HytdVYL5zo1naWQueaeQrJVKWWJWutjLZwFAAAAAAAAAOiH6TNnZ93DT2k856oj98rSi41rPAcAAABohlJIP5RSVkzy3nRfCHkoyQG11nPbMN75XT7vOteYJBsluajlEwEAAAAAAAAAC+0zJ12f7503pdGMzx6wUV6z9fMazQAAAACapxTSP+9NMiHPnMLRtRAyPe0rhCTJFUlmpPN7W+e7NzlKIQAAAAAAAAAwJE29//Hs+sVzGs1YpKPk5s+8MKWURnMAAACA1lAK6Z/X59mFi7nlkA+2sRCSWuv0UsqtSdZbwO3JrZ4HAAAAAAAAAOhZrTUbH3VaHn16ZqM5Z/zvzll7xSUbzQAAAABaSymkj0opmyWZlHlPCZn79hn/TPLt9kw2jxvTWQBZ0EkhAAAAAAAAAMAQ8X9X/Dv/+5urG814w7ar5+j9N2w0AwAAAGgPpZC+27mb6zXJJ2ut8xcx2uHfC7hWkqzS6kEAAAAAAAAAgGeb9tSMbHzUaY3n3PjpfTJ+kTGN5wAAAADtoRTSd1t1+bxrAWR6kr+0eJbu3D3f13NPM5nYhlkAAAAAAAAAgC7eesKlOeOf9zaa8eM3b5Vd11ux0QwAAACg/ZRC+m6t+b4u6SxdnFdrfbIN8yzIo91cX7KlUwAAAAAAAAAA/3XF7Q/lgG9e2GjGBqtMzEnv26nRDAAAAGDoUArpu+dl3hNC5rq+1YP04KluriuFAAAAAAAAAECLzZpds9ZhJzeec+nH98wKS45vPAcAAAAYOpRC+q67YkWz57r2TXff1wktnQIAAAAAAAAARrmvnXlzjjv9pkYzDt/v+XnrTms2mgEAAAAMTUohfbdoN9cfaOkUPVu2m+vdnSACAAAAAAAAAAyiux5+Mtsfe1bjObcds286OkrjOQAAAMDQpBTSd9Oz4BM3ujtBpB26K4U82dIpAAAAAAAAAGAU2unzZ+WOB5v9T/R/OXjHbPjcpRrNAAAAAIY+pZC+ezwLLoV0V8RohxW6uX5/S6cAAAAAAAAAgFHk1H/8J+/82RWNZrx001Xy1Vdv1mgGAAAAMHwohfTdA0mWW8D1lVo9SA+2SlK7fF3mfH17e8YBAAAAAAAAgJHriekzs/6Rf2085/pP7Z3FxvlVDwAAAOAZ/qag76YkWS/PLl1s255x5lVKWTHJuumcb24ZZK4pbRkKAAAAAAAAAEao//31Vfm/K+9sNONbr9s8L9xo5UYzAAAAgOFJKaTvbuny+dzSRUkyuZSyXK31gfaM9V8793Cv2TNqAQAAAAAAAEaZWbNnZcojU3L9g9fnloduybTp0/L0rKczY/aMjO0Ym/FjxmfiuIlZe5m1s8FyG2TSxEkZ0zGm3WMzCK6765Hs97XzG8147tKL5oJDdm80AwAAABjelEL67uIk7+3m3ouT/Lh1oyzQ23q49/eWTTHKlFImJdmyy2OLJEv39Jxaa2l8sPmUUqYmWb3VuV28rdb6/TbmAwAAAAAAwIDUWnPZPZflrNvPynUPXJcbHrwhT858cqGfv+gii2byspOzwXIbZPfn7Z4tV9oypbT8Px0yALXWrHHoyY3nXHDI7nnu0os2ngMAAAAMb0ohfXdBN9dLkg+njaWQUspGSfbKM6eX1C6376m1XtOWwUaYUsqqeXYBZPm2DgUAAAAAAAA0atr0aTnx1hPz6xt/nSmPTOn3Pk/OfDJX3ntlrrz3yvzsnz/LGkutkVet96q8eK0XZ+K4iYM4MU34wflTcvRfrm804wN7rpMP7LluoxkAAADAyKEU0ke11n+VUq5OsknmLV+UJM8vpby01vqnNo33iQVcmzvfiS2eZUQopayUZKvMWwJZqa1DAQAAAAAAAC1zx7Q78oN//CAnTzm5TyeCLKwpj0zJsZccm69e8dXsu8a+OWjDg7LaxNUGPYeBue/Rp7PVZ85oPOfWY/bNmA4nxwAAAAALTymkf36dzlJIV3OLId8ppVxca72nlQOVUg5KckCXOeb3s1bOM4L8Nc/+XgMAAAAAAAAj3MzZM3PCdSfkm1d9M9NnT28878mZT+b3N/8+J956Yt6z2XvyxvXfmDEdYxrPpXcv/vr5ufbORxrN+P27tssWqy/baAYAAAAwMnW0e4Bh6vtJ5r4FzPwljBWT/LyUMrZVw5RSNkny9TmzzNV1rmtrree1ah4AAAAAAACA4ey2h2/LgaccmK9c8ZWWFEK6mj57er58+Zdz4CkH5raHb2tpNvM696b7MumQkxothOy23gqZeux+CiEAAABAvzkppB9qrfeXUn6Q5L15pohR8kwRY7ckp5VS9q+1Nvp2IaWULZKcnGRCFnxKSE1ybJMzAAAAAAAAAIwEs+vsnHDdCfnGld9oeRlkftfcf01eceIr8t7N3ps3bvDGdBTv+dgqT8+clfUOP7XxnKs/8YIstWjL3m8SAAAAGKGUQvrvk0lem2SZPFPG6FoM2TnJhaWUd9Razx/s8FJKR5L3JTkmzy6EzP28Jrm01vqrwc5nRLowyY8aznBiDQAAAAAAAEPSjNkzcsQFR+Sk205q9yj/NX329Bx3+XG58aEbc/QOR2dshwJB047683X58YVTG8344is2ycu3WLXRDAAAAGD0UArpp1rrA6WUjyT5QZ45LSSZtxjy/CTnllJ+n+QLtdZLB5pbShmX5DVJPjJn/7l5/x2ty+czkrxroJn02dQkNyV5QZvn6Kuba63fb/cQAAAAAAAA0GpPz3o6Hz7nwznn3+e0e5QFOum2k/L49MfzxV2/mPFjxrd7nBHp1vseyx5fOrfRjCXGL5Jrj3pBSim9LwYAAABYSEohA1Br/VEpZfckr8u8J3V0LYaUJC9L8rJSypQkv09yeZLrk3T7t3Wl82+BFk2yYpJJSTZJsmM6iwZLZN5TQdLl6675h9darxzQi6Q3dyS5LJ3f08uSXDanMDQpyZR2DgYAAAAAAAD0bsbsGUO6EDLXOf8+Jx8+98M5btfjnBgyiGqtWffwUzJjVu198QCc/eFds8byizeaAQAAAIxOSiED97YkayfZJgsuhqTLtTWTfHgBe5QFfJzZTV7X8sf8+9cuH39Ra/3iQszPwrsrc4of6SyBXFprva+9IwEAAAAAAAD9NbvOzhEXHDHkCyFznXPHOTnigiNyzI7HpKN0tHucYe/Xl96ej/3+2kYzDtpxjRzxovUbzQAAAABGN6WQAaq1PlVK2TvJGUm2zLxFjfnLGsm8pY6edLeuu7265p6S5E0LmUPPvp7knnSeAHJ3u4cBAAAAAAAABs8J152Qk247qd1j9MlJt52UyctMzps2fFO7Rxm2HnliRjb51GmN59z06Rdm3CLKOwAAAECzlEIGQa11WilltyS/SPLidBY05j81JF2ud7Uw5Y/5zf+croWQXyR5U6111kKMTi9qrT9o9wwAAAAAAADA4Lvt4dvyjSu/0e4x+uXrV349O6+6c9Zces12jzLsvP77f8/5t9zfaMbPDtomO66zfKMZAAAAAHN5S4pBUmt9PMn+ST6RZObcy3n2yR7zP7qzoLXzP6dr+WRmkkNqra+vtc4MAAAAAAAAAAs0c/bMHH7B4Zk+e3q7R+mX6bOn54gLjsis2d4rcGFdMuXBTDrkpEYLIZs/b+lMPXY/hRAAAACgpZwUMohqrTXJ0aWUPyb5ZpId5t7qsqynIshCxSxgr0uTvKvWesUA9wYAAAAAAAAY8X5y/U9y7f3XtnuMAbnm/mtywvUn5C0bvqXdowxpM2fNztofP6XxnMsP3zPLLTG+8RwAAACA+TkppAG11mtrrTsl2S/J+Zn3lI86wEe67PWPJK+vtW6jEAIAAAAAAADQuzum3ZHjrzy+3WMMiuOvPD53TLuj3WMMWV/8642NF0I++ZINMvXY/RRCAAAAgLZxUkiDaq2nJDmllLJekjcmeVGSDRe0tIdt5j9Z5L4kf07y81rrOYMxJwAAAAAAAMBo8YN//CDTZ09v9xiDYvrs6fnBP36Qo7Y/qt2jDCl3PPhEdvr82Y3nTPnsvill/v+kDwAAANBaSiEtUGu9MclhSQ4rpaySZJskmyWZnGS1JKskWTLJoknGJnk6yRNJHkhye5LbklyZ5O9Jrqm1zm71awAAAAAAAAAY7qZNn5aTp5zc7jEG1clTTs6HtvxQlhy3ZLtHGRK2+swZue/RpxvNOPUDO2XycyY2mgEAAACwsJRCWqzWeleSP8x5AAAAAAAAANAiJ956Yp6c+WS7xxhUT858Mn++9c953fNf1+5R2urEq+/Kwb+8stGMV265aj7/8k0azQAAAADoK6UQAAAAAAAAAEa8Wmt+dcOv2j1GI35946/z2smvTSml3aO03GNPz8yGn/hr4zk3HL1PJowd03gOAAAAQF8phQAAAAAAAAAw4l12z2WZOm1qu8doxJRHpuSyey7LVs/Zqt2jtNT+x1+Qq+54uNGM7x24ZfZaf6VGMwAAAAAGQikEeJZSypgkayR5XpIVkiyaZFaSJ5JMS/LvJHfUWh9r25AAAAAAAADQB2fdfla7R2jU2XecPWpKISdd85+85xdXNJqx5gqL56wP7dpoBgAAAMBgUAoB5npeKeWTSfZIslmSxXp7QinltiSXJzkrycm11tubHREAAAAAAAD657oHrmv3CI267v6R/fqSZNbsmrUOO7nxnIsP3SPPWWpC4zkAAAAAg0EpBJhrtzmPvlhzzuMVSVJKOS/Jd5L8utY6c3DHAwAAAAAAgP6ZNXtWbnjwhnaP0ah/PvjPzJo9K2M6xrR7lEa87FsX5vJ/PdRoxkf2Xi/v2W3tRjMAAAAABptSCDCYdprzOKqUcnit9dftHggAAAAAAACmPDIlT858st1jNOrJmU9m6rSpWWvptdo9yqC6+Z5Hs9eX/9Z4zq3H7JsxHaXxHAAAAIDBphQCNGHtJL8qpbw+ydtqrXe3eyAAAAAAAABGr+sfvL7dI7TE9Q9cP6JKIZMOOanxjD++Z4dsutrSjecAAAAANEUpBGjSi5JcXkp5Sa318nYP0xellPckeXcLokbO38oDAAAAAAAMUbc8dEu7R2iJmx++ud0jDIqvnnFzvnzGTY1m7LPBc/LtN2zRaAYAAABAKyiFJCmlTE7ylyQdPSz7Qq31Wy0aqUellAlJ/phk3R6WnVVrfWtrJoIerZLkb6WU/Wqt57R7mD5YIcn67R4CAAAAAACAgZs2fVq7R2iJaU8P79f56FMzstFRpzWec+1RL8iSE8Y2ngMAAADQCkohnb6eZM0e7v9yqBRCkqTW+lQp5d1JLkqyfJKygGVvLqX8otZ6VmunY5i6Ncnfk1yb5B9JpiR5ZM7jySTLJFluzmPLJLsk2Smdf/4WxmJJTiyl7F5rvXRwRwcAAAAAAICePT3r6XaP0BLTZ01v9wj9NumQkxrP+OqrN81LN31u4zkAAAAArTTqSyGllBcn2SNJnf/WnGuXJXljq+fqTa31tlLK/yQ5J8mYBSwpSb6SZOMWjsXw8rckf0pyUq31xl7W3jfnkSQXJPlqKWVMklck+WiSzRYib4kkvy+lbF5rvb+fMwMAAAAAAECfzZg9o90jtMT02cOvFHLuTffljT+8pNGMZRcflyuO2KvRDAAAAIB2GfWlkCRH9XBvWpJX11pntmiWPqm1XlhKOTLJMXl2qSVJNiilvKrW+usWj8bQ9VCSPyb51kIUQXpUa52V5FdJflVKeU2S7yRZspenrZbku0kOGEg2AAAAAAAA9MXYjrHtHqElxnWMa/cIC63WmjUOPbnxnL99ZLc8b7nFGs8BAAAAaJeOdg/QTqWU/dJ5wkFN58kaZe6tOdcOrrVOadN4C6XWemw6T3zoOnu6fH5ky4diKNuq1vqBgRZC5ldr/WWSLZJcsxDL/6eU8sLBzAcAAAAAAICejB8zvt0jtMS4McOjFPKOn17WeCHkNVs/L1OP3U8hBAAAABjxRvtJIe+Z7+u55ZCa5G+11p+1fqR+eXeSK9P5/ez6GkqSyaWUPWqtZ7ZxPoaIJk+9qbXeXErZJck5STbpZflnkpzS1CyD5L4k17cgZ60ko+O/QgAAAAAAALTJxHET2z1CS0wcP7Rf5x0PPpGdPn924zk3HL1PJowd03gOAAAAwFAwakshpZRJSV6QzvJEunxMktl5dmFkyKq1Xl9K+UaSD2be1zHXu5IohdC4WuvDpZSXJLkiyXI9LN1sqJeVaq3HJzm+6ZxSynVJ1m86BwAAAAAAYDRbe5m12z1CS6yz9DrtHqFbkw45qfGMo/ffMG/YdvXGcwAAAACGko52D9BGr8ozr790+ViT/K7W2ooTAgbTsUmenPN516JLSfKiUspSbZmKUafWenuS/12IpQc2PQsAAAAAAAAkyfrLjo736Fp/uaH3On98wZSWFEKmHrufQggAAAAwKo3ak0KSHNDDvc+2bIpBUmu9r5TygyTvzTNlkLnlkLFJXprkJ20aj9Hnp0k+lGTjHta8tJQyttY6o0UzAQAAAAAAMEqtsdQaWXSRRfPkzCd7XzxMLbrIopk0cVK7x/ivp2bMyuQjTm0854JDds9zl1608RwAAACAoWpUnhRSSlkpyVaZtzwx9+OFtdZr2jjeQBzfw72XtGwKRr1aa03ylV6WLZVks+anAQAAAAAAYLQb0zEmk5ed3O4xGvX8ZZ+fMR1j2j1GkmSrz5zReCFkv41XztRj91MIAQAAAEa9UVkKSbJzD/d+3rIpBlmt9cYkl2feU0LmFl56es3QhD8k6e0UkO1aMQgAAAAAAABssNwG7R6hURss3/7Xd9nUBzPpkJNy36NPN5oz5bP75vjXbt5oBgAAAMBwMVpLITt1+bzO9/lvWzzLYPtNl89Ll8+XK6Ws3+phGL1qrQ8nuaqXZSP77ZgAAAAAAAAYMnZ/3u7tHqFRu622W9uya62ZdMhJefm3L2o052cHbZOpx+6XUkrviwEAAABGidFaCtl0vq/n/o3RdbXWB1o8y2A7u4d7m7VsCuh0RS/3J7ViCAAAAAAAANhypS0zaeKkdo/RiDWWWiNbrrRlW7IP/b9rssahJzeaMW5MR6Yeu192XGf5RnMAAAAAhqNF2j1Am2yQeU8IyZyvz2n9KIPuiiSPJlkiz36NG7Z+HEa5qb3cX7EVQwAAAAAAAEApJa+e/Ooce8mx7R5l0L1qvVe1/PSMex99Klt/5szGc6775N5ZfPxo/dUGAAAAgN6NupNCSinLJVlm7pfz3b6mxeMMulrr7CTX5dmvLUnWafE48Egv9xdryRQAAAAAAACQ5MVrvTiLLrJou8cYVIsusmhestZLWpo56ZCTGi+EfGTv9TL12P0UQgAAAAB6MepKIUlW7uHezS2bolndvY7ntnQKSKb3cn9sS6YAAAAAAACAJBPHTcy+a+zb7jEG1b5r7Jslxy3Zkqw/XPnvTDrkpMZzph67X96z29qN5wAAAACMBKPxLTV6KoVMbdUQDZs639c1nSeH9PTaoQm9vc3Sky2ZAgAAAAAAAOY4aMODcuKtJ2b67N7e32zoG9cxLgdteFDjOTNmzc46Hz+l8ZwzP7RL1lphicZzAAAAAEaS0XhSSE9vkfJoy6ZoVnevY2JLp4DkOb3cf6wlUwAAAAAAAMAcq01cLe/Z7D3tHmNQvGez92S1ias1mrHvV89rvBCy7ZrLZuqx+ymEAAAAAPTDaDwppKeTC0ZKKaS7X7Sf0NIpIOntTOc7WzIFAAAAAAAAdHHg+gfmjH+dkWvvv7bdo/TbxstvnDeu/8bG9r/+rmnZ92vnNbb/XLces2/GdJTGcwAAAABGqtFYChnb7gHaaDS/dtpjm17uT2nJFAAAAAAAANDFIh2L5NM7fDqvOPEVmT57ervH6bNxHeNy9A5HZ0zHmEb2n3TISY3s29W3X7959tlw5cZzAAAAAEa6jnYP0AZP9XBvsZZN0azuXsfTLZ2CUa2Usn6SSb0su6YFowAAAAAAAMCzrLn0mnnvZu9t9xj9cvBmB2fNpdcc9H0/f+oNLSmETD12P4UQAAAAgEEyGk8KeaKHe0smmdaqQRq0ZDfXe3rtMNgOXIg1FzY+BQAAAAAAAHTjjRu8MTc+dGNOuq35IsRg2W/N/XLgBgvzn+IW3iNPzMgmnzptUPdckCuP2CvLLD6u8RwAAACA0WQ0lkIe7+He85Lc2apBGrRaN9d7eu0waEopyyR5Ry/Lbq213tqKeQAAAAAAAGBBOkpHjt7h6Dw+/fGc8+9z2j1Or3ZdbdccvcPR6Sgdg7ZnK04GedtOa+Tj+63feA4AAADAaDQaSyH/6eHeGkkuatUgDVpjvq9Lkprk7jbMwuj02SRL97LmNy2YAwAAAAAAYOSaPSu5/6bkrquSe69Pnno4mfl0Mmt6MmZcssj4ZMLSyYrrJ6tsliy/TtIxps1DDz1jO8bmi7t+MR8+58NDuhiy62q75ou7fDFjO8YOyn6nX39P3vaTywZlr55MPXa/xjMAAAAARrPRWAqZ2sO9TZP8ojVjNGqTdJZA5je1xXMwCpVSXp7eTwmZleQHLRgHAAAAAABg5Kg1mXp+cuPJyZ1XJHdfk8x4YuGfP3bx5DkbJc/dPFlv32TSjkkpzc07jIwfMz7H7XZcjrjgiJx0W/MnZ/TVfmvul6N3OHpQCiGzZ9esedjJgzBVz/5y8I7Z8LlLNZ4DAAAAMNqNulJIrfWJUsr9SZbLs4sTO7RhpEFVSpmcZNl0vra5J4TMNaUtQ9FWpZT1k/yn1vpQC7L2SvLThVj621rrrU3PAwAAAAAAMCI8+XBy9a+Sy37QeTJIf814PLnj4s7Hxd9Mll832fKgZJNXJ4suPVjTDltjO8bmmB2PyXrLrJdvXPmNTJ89vd0jZVzHuBy82cE5cIMD01E6BrzfgT+8JH+76b5BmKx7a6+4RM74310azQAAAADgGaOuFDLHtUl2yzOFibkFii1KKUvVWh9p22QDt1cP9/7RsikYSl6Q5BOllOOSfLPW+sBgB5RSSpKPJTk6vf9z5ckkhw32DAAAAAAAACPOg7cl538lufa3fTsRZGHdf1Ny6seSMz+ZbPSKZMcPJMuuOfg5w0hH6cibN3xzdll1lxx+weG59v5r2zbLxstvnKN3ODprLj3w78mU+x/Pbl88Z+BD9eKmT78w4xYZeHkFAAAAgIU3Wv825qIun3c9D3lskgNaPMtge3UP9y7q4R4j29JJPpXk9lLK90opg3YqTill0ySnJPlsFq5odlSt1ak1AAAAAAAA3Zk1Mzn/y8nx2yZXnNBMIaSrGU905hy/bWcJZfasZvOGgTWXXjM/eeFP8sEtPphxHeNamj2uY1z+d4v/zU9e+JNBKYRMOuSkxgshn3/5xpl67H4KIQAAAABtMFpPCumpHHFQkh+1apDBVEp5fpJtM+8JKHPd6xfx+6eUsnP+n737DrOzLtMHfn9nEhJAivSiEjoCAUSKNJUiJVlZy6Ku/uysCmth1V3pqAhk13WXFcWGa10LuC6rEqqAghQpAqGGFkB6kRoSksn398ckyyRMMpnJvOdM+Xyu61wz877vee/nkOgfc3KfJ9msn09bfSnue/AAxvldrfX2ATxvgRWSHJzk4FLKfUnOSnJ+kstqrQ8t7U1KKS9P8sYkh2TJ22kW9askX+7H9QAAAAAAAKPLo7clZx6S3H9N67O7ZicXHJfc8uvkLacma27e+hmGkDEdY/KhrT+UN73qTfnujd/N1Lun5vm5zzeWt/yY5TNpw0n58NYfzitXfuUy3+9bv7szJ5196yBMtmQzpkxuPAMAAACAxSu11r6vGmFKKS9L8miSBR/pUtJdoFjw9Y211kvaNN6AlVK+n+R9Wfi1LPj641rr+9s33fA1/7/rUPlv98Fa6/f784RSymFJ/n0pLn0wya1J7kryUJInksxK0pXk5UlWS7JGkh2SbJ2Ft+wsjcuT7FdrfaafzxvRSik3Jdly0eNbbrllbrrppjZMBAAAAAAAtMW8ecnlpyQXntBdzmi3znHJXkclu3wi6bD9IUmeeeGZ/OrOX+Xnt/08dz81eJ/Ht+EqG+adm78zB258YFZabqVlvt/MF+Zmy2PPHYTJluzKI/fO2iuPbzwHAAAAYGlttdVWufnmm3s7dXOtdatWz9Mqo3JTSK312VLKOUn+Ogtv00i6/6H7SUl2b/lgy6CUMjHJu/PS17PAGS0ch+Fp3fmPPRu498VJDlQIAQAAAAAA6EXXnOTMQ5Npp7d7khd1zU7OPzZ56MburSGdY9s9UduttNxKec+r35N3b/HuXP3w1bnovoty02M35ZYnbunXBpHlxyyfV6/26my1xlbZ85V7Zoe1d0gp/f08tt5tfdy5eXb23EG51+K8fftX5Cvv2LbRDAAAAACW3qgshcx3RrpLIQv03KyxSynlkFrrN9oyWT+V7t8Qfifdf549t4Ms8HSS5j8KBnr31SSfqbU2+9tnAAAAAACA4WjOrOSMDyTTz273JL2bdnoy+5nkoO8nY22FSJJSSnZcZ8fsuM6OSZKueV2Z8fSM3Pz4zbn9ydvz9Oyn80LXC3lh3gtZrmO5LNe5XFYet3I2XXXTbLn6lpmw8oR0dnQO6kyX3/l4/vY7VwzqPXtz90mTBq3AAgAAAMDgGM2lkF8k+UqStfJikSI9vv9yKeWKWuuf2jRff0xJslMWfh3Ji+WQ/6y1zmnHYIxq05N8rNZ6UbsHAQAAAAAAGJK65gztQsgC089OfvHB5B0/tDGkF50dndl41Y2z8aobtzy71poNj5jaeM7PP/K67LzR6o3nAAAAANB/He0eoF1qrS8k+XpeWqJIuosUKyQ5s5TyilbP1h+llA8l+ccsvBmk5/ddSU5u5UwMObcmubmFebcn+XCSrRVCAAAAAAAAFmPevOTMQ4d+IWSB26Z2zztvXrsnYb5/+Pl1jRdCVll+bGZMmawQAgAAADCEjeZNIUl3KeTTSVbJi1s2FmzXqElemeT3pZS9a613t23KxSilfDTdr2FBCaS3LSH/VWu9r9WzMXTUWs9Jck4pZa0keyZ5Q5Idk2ydZLB2fN+X5JwkP05ySa219nE9AAAAAADA6Hb5Kcm009s9Rf9MOz1ZZ2Ky2yfbPcmo9tBTs/K6k37beM4tX9w/yy/X2XgOAAAAAMumjPZ/u11K+fskp+TFUsgCPYsWjyd57/x/XN92pZQxSb6c5JN5sfzRc8tJ5v/8dJLNa60Pt3xIhrxSSmeSVyfZNslG6S5BvTLJK9JdlFph/mNckrlJZiV5JsmDSe5PcluSaUmuqrXe1ur5R4pSyk1Jtlz0+JZbbpmbbrqpDRMBAAAAAACNe/S25Jt7JF2z2z1J/3WOSz52SbLm5u2eZFSacPhZjWccNenV+bvXb9R4DgAAAMBg22qrrXLzzTf3durmWutWrZ6nVUb7ppAk+UaSD6f7H8b3LFf03BiyepLflFK+nuSYWuvT7Rg0SUopr03yzSTb56WFkP+7bP7x4xRCWJxaa1eSG+c/AAAAAAAAaIWuucmZhwzPQkjSPfeZhyYfPi/psEWiVX5+1b353H9PazxnxpTJjWcAAAAAMLhGfSmk1jqvlPKeJH9M91aExRVDOpJ8PMk7SyknJPlurXVmq+YspWyW5Igk750/14LZeqo9jl9Qa/2PVs0HAAAAAAAALIXLv5bcf027p1g291+dXHZKsvth7Z5kxHth7rxsdvTZjef87h/fmA1WX7HxHAAAAAAGX0e7BxgKaq23JPlIXrpxIz2OLShcrJXk5CT3llK+XErZoam5SinjSykHlVJ+leTmJO9L959Zzw0hPedb4P4k725qLgAAAAAAAGAAnrgruejEdk8xOC46sfv10Ji9/vXixgshe26+ZmZMmawQAgAAADCMjfpNIQvUWn9aSnl1kqOz8LaQZOGNIQt+Xi3Jp5N8upRyb5KLklyc5Jokt9Va5/Z3hlLKqkm2SrJrkjcmeX26t5csyMwiM6SXY08mObDW+nh/8wEAAAAAAIAGXXpy0jW73VMMjq7Z3a/nwK+2e5IR54Y/P5kDv/aHxnPuOnFSOjp6+9xEAAAAAIYTpZAeaq3HllJWTPIPeWn5omcpY9FzGyR5//xHknSVUu5O8kCSh5I8lmTW/MfcJOPmP16W7s0j68y/x9qLjNRb8WNxx0uSZ5JMqrVe1/erBQAAAAAAAFrm+SeTaWe0e4rBNe2MZN/jk/GrtHuSEWPC4Wc1nvHd9++QvV+96FvTAAAAAAxXSiGLqLV+ppQyM8lRebEAsujWkGThckgWuWZMkk2TbNKP6N4+gqX2cU3PQsijSf661npFPzIBAAAAAACAVrj+Z8mcme2eYnDNmdn9unb+aLsnGfa++Oub859/uLvxnBlTJjeeAQAAAEBrKYX0otZ6TCnl1iSnJVkuL90Msuj3ixZEerumz9jFHF/cPXrOdGOSN9da7+lHHgAAAAAAANAKtSZXndbuKZpx1WnJTh9JSn/eGmWBJ557Idsff37jOdcft29WWX5s4zkAAAAAtJ5SyGLUWv+rlHJjkh8k2SYLFz8W/Y3m4jZ4LK7osThL85vSnjPUJKcm+ada6wj7WCEAAAAAAAAYIWZcmjx+e7unaMZj05N7/pBM2L3dkww7Ew4/q/GMj++5ST673+aN5wAAAADQPkohS1Brvb6UskOSI5P8U5IVsuRySPo4PuBRern/bUkOqbVePMhZAAAAAAAAwGC6bWq7J2jWrVOVQvph6rQHc+h/Xdt4zowpkxvPAAAAAKD9lEL6UGudm+SLpZRvJTk2yYeTLJeFyyFJa4ogSXJvki8m+X6tdd4gZwIAAAAAAACD7f7mCwBt9cAIf32DpGtezcZHNl8QOuewPbLFOis3ngMAAADA0KAUspRqrQ8n+ftSyvFJDk7yoSQTel6yhKcvqTCyNM+rSX6b5NtJ/md+UQUAAAAAAAAY6uZ1JQ/d0O4pmvXgDd2vs6Oz3ZMMWQd987JcNeMvjWZs84pV8quP29gCAAAAMNoohfRTrfWhJF8qpZyQZLckk5NMSjKxt8sX+bokixZHZiW5OMlZSX5da713QAMDAAAAAAAA7fPY9GTOzHZP0aw5zyWP3Z6stUW7Jxly7njkmezzb79vPueEAzKms6PxHAAAAACGHqWQAaq11iSXzn8cUUpZPcn2SV6T7oLIq5K8Isl6ScYt4VZPJfnz/MedSa5L8qck02qtLzQ1PwAAAAAAANACD1zX7gla48HrlEIWMeHwsxrP+I93bZe/3m79xnMAAAAAGLqUQgZJrfXxJOfPfyyklDIuyfgky6f7v/nsJM8neb7W2tXKOQEAAAAAAIAWeuTmdk/QGqPldS6Fr/729vzb+dMbz5kxZXLjGQAAAAAMfUohLVBrnZ3uIshT7Z4FAAAAAAAAaKFZT7Z7gtZ4/sl2T9B2z86em62PO7fxnKuO2idrrjSu8RwAAAAAhgelEAAAAAAAAICmzJ3d7glaY7S8zsXY6IizMq82m/GenV+VE946sdkQAAAAAIYdpRAAAAAAAACApnS90O4JWqNrdJZCfjf90bz/P//YeM6MKZMbzwAAAABgeFIKAQAAAAAAAGhK53LtnqA1Ose1e4KWqrVmwyOmNp7zy0N3zfavennjOQAAAAAMX0ohAAAAAAAAAE0ZM0rKEqPldSY55MfX5OwbH2o0Y91VxufyI/ZuNAMAAACAkUEpBAAAAAAAAKAp41dt9wStsfyq7Z6gcX/+y8zs/s8XNZ5z6/H7Z/zYzsZzAAAAABgZlEIAAAAAAAAAmrLWlu2eoDVG+OuccPhZjWd88a+3yvt2mdB4DgAAAAAji1IIAAAAAAAAQFPW267dE7TGutu1e4JG/OCyGTnuVzc1njNjyuTGMwAAAAAYmZRCAAAAAAAAAJqyxmbJ2BWSOTPbPUlzxq6YrLFpu6cYVLPmdGWLY85pPOfSz+2ZV7x8hcZzAAAAABi5lEIAAAAAAAAAmtLRmayzTXLfFe2epDnrbtP9OkeI15342zz09KxGMw7Yep184/+9ttEMAAAAAEYHpRAAAAAAAACAJq2//cguhay3fbsnGBTX3POXvP0blzWec/dJk1JKaTwHAAAAgNFBKQQAAAAAAACgSZtPSq44td1TNGeLSe2eYJlNOPysxjN++KGd8vrN1mw8BwAAAIDRRSkEAAAAAAAAoEkTdk9W3zR5/PZ2TzL41tgs2WC3dk8xYEf+z7T85Mp7G83o7Ci588ThX5wBAAAAYGhSCgEAAAAAAABoUinJjgcn53yu3ZMMvh0P7n59w8yjz8zOjidc0HjOjV/YLy8b5215AAAAAJrjt08AAAAAAAAATdv2Xclvv5DMmdnuSQbP2BW6X9cwM+HwsxrP+MybNssn9t608RwAAAAAUAoBAAAAAAAAaNryqyYTD0qu/UG7Jxk8Ew9Kxq/S7imW2pl/uj+H/fy6xnNmTJnceAYAAAAALKAUAgAAAAAAANAKux+WXP+zpGt2uydZdp3jul/PMDC3a142OersxnMu+PQbsslaL2s8BwAAAAB6UgoBAAAAAAAAaIXVNkr2PDK54Lh2T7Ls9jyy+/UMcX91yiW58f6nG83YacPVcvpHd2k0AwAAAAAWRykEAAAAAAAAoFV2+Xhyy6+S+69p9yQDt/4Oya6faPcUS3TLg0/ngP+4pPGcO0+clM6O0ngOAAAAACyOUggAAAAAAABAq3SOSd7yjeSbeyRds9s9Tf91jkvecmrS0dnuSRZrwuFnNZ7xjfdsnwMmrtt4DgAAAAD0paPdAwAAAAAAAACMKmtunux1VLunGJi9ju6efwj68rm3tqQQMmPKZIUQAAAAAIYMm0IAAAAAAAAAWm2XTyQP3ZhMO73dkyy9ie9Idvl4u6d4iaeen5Ntv3Be4zl/OuZNefmKyzWeAwAAAAD9oRQCAAAAAAAA0GodHclbTk1mP5NMP7vd0/Rt80nd83Z0tHuShbRiM8iHd98wx/zVlo3nAAAAAMBAKIUAAAAAAAAAtEPn2OSg7ydnfGBoF0M2n5T8zfe65x0iLrj54Rz8w6sbz5kxZXLjGfTTvK7ksenJA9clj9yczHoymTs76Xoh6VwuGTMuGb9qstaWyXqvSdbYNOnobPPQAAAAAM1RCgEAAAAAAABol7Hjk3f+KDnz0GTa6e2e5qUmvqN7Q8gQKYTMm1ez0ZFTG8/59cd3z8RXrNJ4Dkuh1mTGpcltU5P7r00euiGZM3Ppnz92xWSdicn623cXnCbsnpTS3LwAAAAALaYUAgAAAAAAANBOnWOTt34rWWfr5MITkq7Z7Z4o6RyX7HV0ssvHk46Odk+TJPnA9/6Yi297tNGMjdZcMRd+5o2NZrCUnn8yuf5nydXf7d4MMlBznkvuu6L7ccWpyRqbJTt8ONn2Xcnyqw7WtAAAAABtoxQCAAAAAAAA0G4dHclun0o22z8585Dk/mvaN8v6O3RvB1lz8/bN0MOMx57LG//14sZzpn/pgCw3ZmgUYEa1J+5KLj05mXZG/zaCLK3HpifnfC757ReSiQclux+WrLbR4OcAAAAAtIhSCAAAAAAAAMBQsebmyYfOSy7/WnLRia3dGtI5LtnrqPnbQTpbl7sEEw4/q/GMf3n7NnnHjq9sPIc+dM1NLj8lueik1vy9nzMzufYH3dtI9jwy2fUTQ+bvPQAAAEB/KIUAAAAAAAAADCWdY7q3F2x5YLMbExYYu8KQ25jwnd/flROm3tJ4zowpkxvPYCk8elv7NuR0zU4uOC655ddDakMOAAAAwNJSCgEAAAAAAAAYilbbKDnwq8m+x3dvM7jqtOSx6YN3/zU2S3Y8ONn2Xcn4VQbvvsvg+Re68upjz2k854oj9s46q4xvPIc+zJvXvR3kwhNauxWnN/dfnXxzj/nbcj6RdHS0dx4AAACApaQUAgAAAAAAADCUjV8l2fmjyU4fSe75Q3Lr1OSBa5MHr+/fBpGxKybrbpOst32yxaRkg92SUpqbu58mfv7cPDNrbqMZb3vN+vm3d27XaAZLqWtOcuahybTT2z3Ji7pmJ+cfmzx0Y/fWkM6x7Z4IAAAAoE9KIQAAAAAAAADDQSnJhN27H0kyryt57PbkweuSR25Onn8ymTu7+x+2d45LxoxLll81WWvLZN3tkjU2TTo62zf/Ylxx1+N517evaDzn7pMmpQyhEsyoNmdWcsYHkulnt3uS3k07PZn9THLQ95OxNsoAAAAAQ5tSCAAAAAAAAMBw1NGZrLVF92MYqrVmwyOmNp7zs4+8Lq/baPXGc1hKXXOGdiFkgelnJ7/4YPKOH9oYAgAAAAxpHe0eAAAAAAAAAIDR5dOnX9d4IWSl8WMyY8pkhZChZN685MxDh34hZIHbpnbPO29euycBAAAAWCybQtqklDI2yXpJVk6yfJJxSf5vV3Gt9fdtGg0AAAAAAACgEQ89NSuvO+m3jefc/MX9ssJy3g4fci4/JZl2erun6J9ppyfrTEx2+2S7JwEAAADold+CtUApZYUkeyZ5Q5LXJJmYZM0lPKXGnw0AAAAAAAAwgkw4/KzGM46ctEU+8vqNG89hAB69LbnwhHZPMTAXfinZbL9kzc3bPQkAAADASygeNKiUMjnJh5NMSjK256lBznnd/IzeXFFrbXbvMgAAAAAAAMBi/Pyqe/O5/57WeM6MKZMbz2CAuuYmZx6SdM1u9yQD0zU7OfPQ5MPnJR2d7Z4GAAAAYCFKIQ0opbwjyXFJtlhwaJFL6pKePoDIGUk+m2RcL+duT6IUAgAAAAAAALTUC3PnZbOjz2485+LPvjET1lix8RyWweVfS+6/pt1TLJv7r04uOyXZ/bB2TwIAAACwkI52DzCSlFImlFLOS/LTJK9Od8GjpLsE0vORHud6Pgak1vpQku8v5p6bllJ2Hei9AQAAAAAAAPpr769c3Hgh5A2brZkZUyYrhAx1T9yVXHRiu6cYHBed2P16AAAAAIYQpZBBUko5IMm1SfbOiwWPJZVABttXF8nsuY3kfQ3kAQAAAAAAACxk2p+fyoTDz8qdjz7XaM5dJ07KDz60U6MZDJJLT066Zrd7isHRNbv79QAAAAAMIUohg6CUcnCSXydZNQtvBulZAll0W8iixY1lUmu9NcnFWbhwsmCGd5RSxgxWFgAAAAAAAMCiJhx+Vt78tUsbzTjtfTtkxpTJ6eho4nP4GHTPP5lMO6PdUwyuaWcks55q9xQAAAAA/0cpZBmVUt6f5Fvp/m+5aBkkWfK2kMH+TeWPe47W4/tVkuw6yFkAAAAAAAAA+dJvbs6Ew89qPGfGlMnZZ8u1G89hEF3/s2TOzHZPMbjmzOx+XQAAAABDhO0Ry6CUsku6CyELNoEkC5dB0uPYnCRXJfl9knuSPJ5klyT/kBeLJMvqF0lOTTI2L91Css/8bAAAAAAAAIBl9pfnXshrjj+/8Zzrj9s3qyw/tvEcBlmtyVWntXuKZlx1WrLTR5JiYw0AAADQfkohA1RKWSHJT5Msl8UXQkqSGUn+Ncn3a60zF7nHKoM5U6316VLKpUn2yktLIXsnOXYw8wAAAAAAAIDRqRWbQf5+z43zj/tt0XgODZlxafL47e2eohmPTU/u+UMyYfd2TwIAAACgFLIMPp/kVVm4ANLz+650lzD+pdba1cK5zkl3KWSBBVtIdiylvKzW+mwLZwEAAAAAAABGkLOnPZhD/uvaxnNmTJnceAYNu21quydo1q1TlUIAAACAIUEpZABKKWsl+XgWXwj5S5K31Vp/14bxLu3xfc+5OpNMTHJ5yycCAAAAAAAAhrWueTUbH9n8P/I/+1N75NXrrtx4Di1wf/PlobZ6YIS/PgAAAGDYUAoZmI8nGZ8Xt3D0LIS8kPYVQpLk2iRz0v1nWxc5t0WUQgAAAAAAAIB+eOe3Ls+Vdz/RaMZW662csz65R6MZtNC8ruShG9o9RbMevKH7dXZ0tnsSAAAAYJRTChmY/5eXFi4WlEP+oY2FkNRaXyil3Jlk815Ob9HqeQAAAAAAAIDh6Y5Hns0+/9b8W593nHBAxnR2NJ5DCz02PZkzs91TNGvOc8ljtydreRseAAAAaC+lkH4qpbwmyYQsvCWkzD99S5JvtmeyhdyW7gJIb5tCAAAAAAAAAJZowuFnNZ7x7+/cNm99zSsaz6ENHriu3RO0xoPXKYUAAAAAbacU0n+vX8zxmuQLtdZFixjt8OdejpUk67V6EAAAAAAAAGD4+NqFt+dfz5veeM6MKZMbz6CNHrm53RO0xmh5nQAAAMCQphTSfzv2+L5nAeSFJL9p8SyL89AiPy/YZrJyG2YBAAAAAAAAhrhnZ8/N1sed23jOVUftkzVXGtd4Dm0268l2T9Aazz/Z7gkAAAAAlEIGYONFfi7pLl1cUmt9vg3z9OaZxRxfqaVTAAAAAAAAAEPeJkdOzdx5te8Ll8Hf7vSqnPS2iY1mMITMnd3uCVpjtLxOAAAAYEhTCum/V2XhDSELDKW9sLMWc1wpBAAAAAAAAEiSXHL7o3nvd//YeM6MKZMbz2CI6Xqh3RO0RpdSCAAAANB+SiH9t7hixSMtnWLJFvfnOr6lUwAAAAAAAABDTq01Gx4xtfGc/z5kl7x2g9Uaz2EI6lyu3RO0Rue4dk8AAAAAoBQyAMsv5vjjLZ1iyRb3m9XFbRABAAAAAAAARoFD/+uaTJ32UKMZa688LlceuU+jGQxxY0ZJWWK0vE4AAABgSFMK6b8X0vvGjcVtEGmHxZVCnm/pFAAAAAAAAMCQ8Oe/zMzu/3xR4zm3Hr9/xo/tbDyHIW78qu2eoDWWX7XdEwAAAAAohQzAc+m9FDKU9h6vuZjjj7V0CgAAAAAAAKDtJhx+VuMZXzhwq7x/1wmN5zBMrLVluydojdHyOgEAAIAhTSmk/x5Psnovx9du9SBLsGOS2uPnMv/ne9szDgAAAAAAANBqP7p8Ro7535saz5kxZXLjGQwz623X7glaY93t2j0BAAAAgFLIANydZPO8tHTxuvaMs7BSylpJNkv3fAvKIAvc3ZahAAAAAAAAgJaZNacrWxxzTuM5l/zTnnnlais0nsMwtMZmydgVkjkz2z1Jc8aumKyxabunAAAAAFAKGYA7eny/oHRRkmxRSlm91vp4e8b6P69fwrlrWzYFAAAAAAAA0HK7nPTbPPjUrEYz9t9qnXzzva9tNINhrqMzWWeb5L4r2j1Jc9bdpvt1AgAAALRZR7sHGIaW9FurN7dsisX7uyWcu7JlUwAAAAAAAAAtc+29f8mEw89qvBBy90mTFEJYOutv3+4JmrXeCH99AAAAwLBhU0j//WExx0uSzyb5futGWWSAUiYmeVNe3F5Se5x+uNZ6Q1sGAwAAAAAAABoz4fCzGs/44Yd2yus3W7PxHEaQzSclV5za7imas8Wkdk8AAAAAkMSmkH6rtd6T5Pq8WLroWb54dSnlr9s1W5Ljejm2YL5ft3gWAAAAAAAAoEH/e939LSmEzJgyWSGE/puwe7L6pu2eohlrbJZssFu7pwAAAABIYlPIQP08ybaLHFtQEPlWKeWKWuvDrRyolPLhJG/rMceiftzKeQAAAAAAAIBmPDNrTiZ+/rzGc278wn552ThvKTNApSQ7Hpyc87l2TzL4djy4+/UBAAAADAE2hQzMaUmen//9oiWMtZL8VyllbKuGKaVsm+SUvLixZNG5ptVaL2nVPAAAAAAAAEAzPvqjqxsvhHz6TZtlxpTJCiEsu23flYxdod1TDK6xK3S/LgAAAIAhQilkAGqtjyX5bhYug5S8WMrYM8l5pZRVmp6llPLaJOclGd9jjp5qkilNzwEAAAAAAAA057r7nsyEw8/KuTc93GjOjCmT88m9N200g1Fk+VWTiQe1e4rBNfGgZHzj/xQAAAAAYKn5aJeB+0KSdyd5eV7cylF6fP/6JJeVUj5aa710sMNLKR1JPpnkxHQXQnpuBlnwfU1yVa31Z4OdDwAAAAAAADSva17NxkdObTzn/H94fTZde6XGcxiFdj8suf5nSdfsdk+y7DrHdb8eAAAAgCHEppABqrU+nuQf89LNHD2LIa9O8rtSyumllB0HI7eUslwp5f1JbkjylbxYCPm/0Xp8PyfJIYORCwAAAAAAALTW1y+6o/FCyA4bvDwzpkxWCKE5q22U7Hlku6cYHHse2f16AAAAAIYQm0KWQa31e6WUvZK8Jwtv6uhZDClJ3p7k7aWUu5P8d5JrktycZNzi7l1KKUmWT7JWkglJtk2ye5J9k7wsC28FSRYupyzIP7rW+qdlepEAAAAAAABASz301Ky87qTfNp5z54mT0tmx6GfgQQN2+Xhyy6+S+69p9yQDt/4Oya6faPcUAAAAAC+hFLLs/i7JJkl2Tu/FkPQ4tlGSz/Zyj9LL17mLyev5W9lF7197fP1JrfVfl2J+AAAAAAAAYIjY6ysX565Hn2s04+vv3j6Tt1m30QxYSOeY5C3fSL65R9I1u93T9F/nuOQtpyYdne2eBAAAAOAlOto9wHBXa52VZL8kV+fFIkjPskbPYz23hyx4LM6i1y3pXlkk85wkH1jW1wYAAAAAAAC0xnk3PZQJh5/VeCFkxpTJCiG0x5qbJ3sd1e4pBmavo7vnBwAAABiCbAoZBLXWp0speyb5SZI3Z+HSRrJwcaMu8vTFFUMWvW5Jz+lZCPlJkg/UWruWYnQAAAAAAACgjWbN6coWx5zTeM61x7wpq624XOM5sES7fCJ56MZk2untnmTpTXxHssvH2z0FAAAAwGIphQySWutzpZS3JDl6/mNMFi5r9Py6NJbm2p73n5PkmFrrv/QjAwAAAAAAAGiTfzzj+pxxzZ8bzfjnt0/MO3d8VaMZsNQ6OpK3nJrMfiaZfna7p+nb5pO65+3oaPckAAAAAIulFDKIaq01yfGllDOTnJpktwWnelzWn2JIrzG93OuqJIfUWq9dxnsDAAAAAAAADbv1oaez/8mXNJqx9srjcuWR+zSaAQPSOTY56PvJGR8Y2sWQzSclf/O97nkBAAAAhjClkAbUWqcl2aOUckCSI5Ls3vP0IEQsKIPcmGRKrfUng3BPAAAAAAAAoEG11mx4xNTGcy75pz3zytVWaDwHBmzs+OSdP0rOPDSZdnq7p3mpie/o3hCiEAIAAAAMA0ohDaq1np3k7FLK5knen+Svkmzd26VLuM2im0UeTfKrJP9Va714MOYEAAAAAAAAmvWDy2bkuF/d1GjGJ/baJJ/Zd/NGM2DQdI5N3vqtZJ2tkwtPSLpmt3uipHNcstfRyS4fTzo62j0NAAAAwFJRCmmBWuttSY5McmQpZb0kOyd5TZItkrwyyXpJVkqyfJKxSWYnmZnk8ST3JrkryZ+SXJnkhlrrvFa/BgAAAAAAAKD/Hn92dl77pQsaz7njhAMyptM/YmeY6ehIdvtUstn+yZmHJPdf075Z1t+hezvImopVAAAAwPCiFNJitdYHkvzP/AcAAAAAAAAwQr311D/kT/c+2WjGGR/bJTtOWK3RDGjcmpsnHzovufxryUUntnZrSOe4ZK+j5m8H6WxdLgAAAMAgUQoBAAAAAAAAGESX3v5Y/t93r2w0Y49N18iPPrxzoxnQUp1jkt0PS7Y8MLn05GTaGcmcmc3ljV0hmXhQd+ZqGzWXAwAAANAwpZB+KqW8IsniPmpnZq31jlbOAwAAAAAAAAwNL8ydl82OPrvxnOuP3TerrDC28Rxoi9U2Sg78arLv8cn1P0uuOi15bPrg3X+NzZIdD062fVcyfpXBuy8AAABAmyiF9N+3k+y3mHPHJ/l860YBAAAAAAAAhoIv/vrm/Ocf7m4041/evk3eseMrG82AIWP8KsnOH012+khyzx+SW6cmD1ybPHh9/zaIjF0xWXebZL3tky0mJRvslpTS3NwAAAAALaYU0n8bJ+ntN0RdSb7e4lkAAAAAAACANrr7seey579e3GjGuDEdufX4/VP8Q3ZGo1KSCbt3P5JkXlfy2O3Jg9clj9ycPP9kMnd20jU76RyXjBmXLL9qstaWybrbJWtsmnR0tm9+AAAAgIYphfTfWklqL8evqrU+2uphAAAAAAAAgNartWar487NzBe6Gs357WfekI3XfFmjGTCsdHQma23R/QAAAABAKWQAFv2Na0l3SeRPbZgFAAAAAAAAaLFfXPPnfPaM6xvN+MCuE/L5A7dqNAMAAAAAGP6UQvpvVpIVejl+d6sHAQAAAAAAAFrnqefnZNsvnNd4zm1f2j/jxnQ2ngMAAAAADH9KIf33bHovhTzT6kEAAAAAAACA1vjA9/6Yi297tNGMH35op7x+szUbzQAAAAAARhalkP57LMlavRzvaPUgAAAAAAAAQLOuueeJvP0blzeasc0rVsmvPr57oxkAAAAAwMikFNJ/05NslaQucnyVNswCAAAAAAAANGBu17xsctTZjedcffQ+WeNl4xrPAQAAAABGJqWQ/rslyVt7Ob5RqwcBAAAAAAAABt+/nz89//Hb2xvNOPavtsyHdt+w0QwAAAAAYORTCum/i5IcucixkmSHNswCAAAAAAAADJL7n3w+u025sPGcu0+alFJK4zkAAAAAwMinFNJ/lySZmWT5+T/XdJdCJpZS1qm1PtS2yQAAAAAAAIAB2W3Khbn/yecbzZj6yT2y5XorN5oBAAAAAIwuHe0eYLiptb6Q5GfpLoL01JHkva2fCAAAAAAAABioqdMezITDz2q0EPK27dfPjCmTFUIAAAAAgEFnU8jAfDXJh3r8vGBbyKdLKafWWp9rz1gAAAAAAADA0pj5wtxseey5jefc8sX9s/xynY3nAAAAAACjk00hA1BrvSHJf+Wl20LWSvKV1k8EAAAAAAAALK1P/exPjRdCvvn/XpsZUyYrhAAAAAAAjbIpZOA+k2T/JKvN/3nBtpC/K6VcX2v9RtsmAwAAAAAAAF7ixvufyl+dcmmjGRusvkJ+9497NpoBAAAAALCAUsgA1VofKaW8Pcn5efG/44JiyNdKKavWWk9q24AAAAAAAABAkmTevJqNjpzaeM7lR+yVdVdZvvEcAAAAAIAFOto9wHBWa/19kvcmmdPzcLqLIV8qpVxeStmqLcMBAAAAAAAA+c7v72q8EPLpN22WGVMmK4QAAAAAAC1nU8gyqrWeXkp5IsnpSVZNdylkQTFk5yTXllL+N8n3k5xda61tGhUAAAAAAABGjUeemZWdTvht4zl3njgpnR2l8RwAAAAAgN4ohQyCWusF8zeCnJbkgCxcDBmb5O3zH4+UUi5Lcu38x71JnkrydK316XbMDgAAAAAAACPNpP+4JDc/2Ozbb788dNds/6qXN5oBAAAAANAXpZABKKV09XXJ/K91kZ/XTvKW+Y9F7zkYoy1JrbX68wYAAAAAAGDEuui2R/LB713VaMY+r147p71/h0YzAAAAAACWlpLAwCxtg6Pkxa0h/X0uAAAAAAAAsBRmzenKFsec03jODZ/fNyuPH9t4DgAAAADA0lIKGbi6mOOLlj56/rxoQaRVFFEAAAAAAAAYkY4588b86Ip7Gs3493dum7e+5hWNZgAAAAAADIRSyLLpb9miHeWMdpRQAAAAAAAAoFF3PPJs9vm33zWasfL4Mbn+uH1Tis9gAwAAAACGJqUQAAAAAAAAYNiotWaTo85O17xmPxvt4s++MRPWWLHRDAAAAACAZaUUsmxs4QAAAAAAAIAW+cmV9+bI/5nWaMZHXr9Rjpz06kYzAAAAAAAGi1LIwNkRDQAAAAAAAC3w5MwXst0Xz2885/YTDsjYzo7GcwAAAAAABotSyMB8od0DAAAAAAAAwGjw7u9ckcvufLzRjJ8cvHN23WSNRjMAAAAAAJqgFDIAtValEAAAAAAAAGjQFXc9nnd9+4pGM3ac8PKc8bFdG80AAAAAAGiSUggAAAAAAAAwZMzpmpdNjzq78Zxrj3lTVltxucZzAAAAAACapBQCAAAAAAAADAn/cs6tOfXiOxvNOP4tW+e9r9ug0QwAAAAAgFZRCgEAAAAAAADa6r4nZmaPf7mo8Zy7T5qUUkrjOQAAAAAAraIUAgAAAAAAALTNa48/P48/90KjGef9w+uz2dorNZoBAAAAANAOSiEAAAAAAABAy/3vdffnUz+7rtGMv93plTnpbds0mgEAAAAA0E5KIQAAAAAAAEDLPDt7brY+7tzGc249fv+MH9vZeA4AAAAAQDsphQAAAAAAAAAt8bEfXZNzbnqo0Yzvvn+H7P3qtRvNAAAAAAAYKpRCAAAAAAAAgEZdf9+T+euv/6HRjM3WflnO+4c3NJoBAAAAADDUKIUAAAAAAAAAjeiaV7PxkVMbz7nyyL2z9srjG88BAAAAABhqlEIAAAAAAACAQff1i+7Il8+9rdGMww/YIh97w8aNZgAAAAAADGVKIQAAAAAAAMCgefjpWdn5xN82nnPXiZPS0VEazwEAAAAAGMqUQgAAAAAAAIBBsfdXLs6djz7XaMavPr5btnnFqo1mAAAAAAAMF0ohAAAAAAAAwDI5/+aH83c/vLrRjMkT183X37N9oxkAAAAAAMONUsgAlFJe3+4ZBqLW+vt2zwAAAAAAAMDIMWtOV7Y45pzGc276wn5ZcZy3NgEAAAAAFuU3pwNzcZLa7iH6qcafNwAAAAAAAIPkc7+4IT+/+r5GM776t6/Jgduu12jGqDevK3lsevLAdckjNyeznkzmzk66Xkg6l0vGjEvGr5qstWWy3muSNTZNOjrbPDQAAAAAsICSwLIp7R4AAAAAAAAAWunWh57O/idf0mjGGi8bl6uP3qfRjFGr1mTGpcltU5P7r00euiGZM3Ppnz92xWSdicn62yebT0om7J4Ub5sCAAAAQLsohSyb4bItxG9hAQAAAAAAWCa11mx4xNTGcy75pz3zytVWaDxn1Hn+yeT6nyVXf7d7M8hAzXkuue+K7scVpyZrbJbs8OFk23cly686WNMCAAAAAEtJKWTZDIeyxXAprgAAAAAAADBE/fDyGTn2f29qNOPje26Sz+63eaMZo9ITdyWXnpxMO6N/G0GW1mPTk3M+l/z2C8nEg5LdD0tW22jwcwAAAACAXimFAAAAAAAAAL164rkXsv3x5zeec8cJB2RMZ0fjOaNK19zk8lOSi05KumY3nzdnZnLtD7q3kex5ZLLrJ5KOzuZzAQAAAGCUUwpZNu3awrGkDSU2gwAAAAAAALDM3v6Ny3LNPX9pNOP0j+6SnTZcrdGMUenR25IzD0nuv6b12V2zkwuOS275dfKWU5M1bX8BAAAAgCYphQzckooZTap5sfjR2wztmgsAAAAAAIAR4A93PJb3nHZloxm7b7JGfnzwzo1mjErz5nVvB7nwhNZsB1mS+69OvrlHstdRyS6fSDpsggEAAACAJiiFDMyeLcoZl2T1JKsleUWS3ZLskGT8/PM9t4KU+T+fkuR/WjQfAAAAAAAAI8QLc+dls6PPbjzn+mP3zSorjG08Z9TpmpOceWgy7fR2T/KirtnJ+ccmD93YvTWk0587AAAAAAw2pZABqLX+rl3ZpZSxSSYl+XSSPfJiMaSmuxjyifk/f7rWOq/1EwIAAAAAADDcfOk3N+e0S+9uNGPK2ybmXTu9qtGMUWvOrOSMDyTTmy/1DMi005PZzyQHfT8ZO77PywEAAACApacUMszUWuck+d8k/1tK2SXJD5Jsku5SSM9iyAallHfWWl9o27AAAAAAAAAMaXc/9lz2/NeLG81YrrMjt31p/5RSGs0ZtbrmDO1CyALTz05+8cHkHT+0MQQAAAAABpFSyDBWa728lPKaJN9I8v+ycDHkwCRnllL+ysYQAAAAAAAAeqq1Zuvjzs1zL3Q1mnPBp9+QTdZ6WaMZo9q8ecmZhw79QsgCt03tnvet30o6Oto9DQAAAACMCH7TNszVWp+rtb4vyU/SXQZJXiyG7Jfkq+2aDQAAAAAAgKHnF9f8ORseMbXRQsj7d9kgM6ZMVghp2uWnJNNOb/cU/TPt9OTyr7V7CgAAAAAYMWwKGTk+kOQVSV6fhTeGHFJKOafW+ps2zgYAAAAAAECbPT1rTrb5/HmN59z2pf0zbkxn4zmj3qO3JRee0O4pBubCLyWb7ZesuXm7JwEAAACAYc+mkBGi1jo3ySFJen6k04JiyDdKKcu3ZTAAAAAAAADa7kPfv6rxQsgPPrRTZkyZrBDSCl1zkzMPSbpmt3uSgemanZx5aDKvuW01AAAAADBaKIWMILXWW5J8P91FkJ7WS3JwywcCAAAAAACgra6554lMOPysXHjrI41lTFx/lcyYMjlv2GzNxjJYxOVfS+6/pt1TLJv7r04uO6XdUwAAAADAsDem3QMw6L6Z5MM9fl6wLeSwJH6rCgAAAAAAMAp0zavZ+MipjedcddQ+WXOlcY3n0MMTdyUXndjuKQbHRScmWx6YrLZRuycBAAAAgGHLppARptZ6TZLePuppQill+1bPAwAAAAAAQGudfMH0xgshx/zVlpkxZbJCSDtcenLSNbvdUwyOrtndrwcAAAAAGDCbQkami5K8M91bQno6IMm1rR8HAAAAAACApj3w5PPZdcqFjefcdeKkdHSUxnPoxfNPJtPOaPcUg2vaGcm+xyfjV2n3JAAAAAAwLCmFjEx/Xszx17R0CgAAAAAAAFpi93++MH/+y/ONZpz1yd2z1Xr+4X5bXf+zZM7Mdk8xuObM7H5dO3+03ZMAAAAAwLDU0e4BaMQji/xck5QkW7ZhFgAAAAAAABpy9rQHM+HwsxothLz1NetnxpTJCiHtVmty1WntnqIZV53W/foAAAAAgH6zKWRkemYxx9do6RQAAAAAAAA0YuYLc7Plsec2nnPzF/fLCst5S3FImHFp8vjt7Z6iGY9NT+75QzJh93ZPAgAAAADDjt/gjkyrL+b4Si2dAgAAAAAAgEF32M/+lDOve6DRjG+8Z/scMHHdRjPop9umtnuCZt06VSkEAAAAAAZAKWRkWnsxxztaOgUAAAAAAACD5qYHnsrkr17aaMYrV1s+l/zTXo1mMED3X9vuCZr1wAh/fQAAAADQEKWQkWmPxRx/rqVTAAAAAAAAsMzmzavZ6Mjmt0RcdvheWW/V5RvPYQDmdSUP3dDuKZr14A3dr7Ojs92TAAAAAMCwYnPECFNKeVWSbZPUJGWR0w+3fiIAAAAAAAAG6rRL7mq8EPIP+2yWGVMmK4QMZY9NT+bMbPcUzZrzXPLY7e2eAgAAAACGHZtCRp5jejlW0l0SubPFswAAAAAAADAAjz4zOzuecEHjOXeeOCmdHYt+zhhDzgPXtXuC1njwumStLdo9BQAAAAAMK0ohI0gp5fVJPpjuAkhvrm7hOAAAAAAAAAzAX51ySW68/+lGM/77kF3z2g1e3mgGg+iRm9s9QWuMltcJAAAAAINIKWSEKKXsmuTX6d4Kkh5fe7qwdRMBAAAAAADQHxff9kg+8L2rGs3Ye4u18t0P7NhoBg2Y9WS7J2iN559s9wQAAAAAMOwohQxzpZTxSY5K8tkk49K9JWRBIaTnxpAHa62/b/F4AAAAAAAA9GH23K5sfvQ5jefc8Pl9s/L4sY3n0IC5s9s9QWuMltcJAAAAAINIKWQYKqV0JNkhyd8meWeStdNdBKm9XT7/+KktGxAAAAAAAIClcuz/3pgfXn5PoxlfOWjbvP21r2g0g4Z1vdDuCVqjSykEAAAAAPpLKWQASinHtjIuyQpJVk6ySpItkrw6yXI9zicvFkJ62xLycJJTmh0TAAAAAACApXXHI89mn3/7XaMZK40fkxuO2zellL4vZmjrXK7va0aCznHtngAAAAAAhh2lkIH5fHrfytEKi/7Wvi7h3IItIX9fa32m0akAAAAAAADoU601mxx1drrmNftW08WffWMmrLFioxm00JhRUpYYLa8TAAAAAAaRUsiyadfHKi36LsGSiiL/XGv9n4bnAQAAAAAAoA8//eO9OeKX0xrN+Ls9NsxRk7dsNIM2GL9quydojeVXbfcEAAAAADDsKIUsm3ZtC0l6L6QsujXkX2qtR7ZoHgAAAAAAAHrx5MwXst0Xz288Z/qXDshyYzoaz6EN1holRZ/R8joBAAAAYBAphSybdm0KWdSiZZBnkhxaa/2vNs0DAAAAAABAkvecdkX+cMfjjWb85OCds+smazSaQZutt127J2iNdbdr9wQAAAAAMOwohQwPS7ORpCSZk+THSY6qtT7U7EgAAAAAAAAszpV3PZ53fvuKRjN22ODl+cUhuzaawRCxxmbJ2BWSOTPbPUlzxq6YrLFpu6cAAAAAgGFHKWTZLE1ZY7D1tp3k5iSnJ/lurfX+Fs8DAAAAAADAfHO75mWTo85uPOfaY96U1VZcrvEchoiOzmSdbZL7mi0atdW623S/TgAAAACgX5RCBq63ckZT5iaZneSpJI8kuTfJbUmuS3JJrfXPLZwFAAAAAACAXnz53Fvz9YvubDTji3+9Vd63y4RGMxii1t9+ZJdC1tu+3RMAAAAAwLCkFDIAtdaOds8AAAAAAADA0HDfEzOzx79c1HjO3SdNSimt/NwyhpTNJyVXnNruKZqzxaR2TwAAAAAAw5JSCAAAAAAAAAzQDl+6II89O7vRjHMPe302X2elRjMYBibsnqy+afL47e2eZPCtsVmywW7tngIAAAAAhiUbLwAAAAAAAKCffnX9A5lw+FmNFkLeucMrM2PKZIUQupWS7Hhwu6doxo4Hd78+AAAAAKDfbAoBAAAAAACApfTs7LnZ+rhzG8+59fj9M35sZ+M5DDPbviv57ReSOTPbPcngGbtC9+sCAAAAAAZEKQQAAAAAAACWwqH/dU2mTnuo0YzT3rdD9tly7UYzGMaWXzWZeFBy7Q/aPcngmXhQMn6Vdk8BAAAAAMOWUggAAAAAAAAswQ1/fjIHfu0PjWZsstbLcsGn39BoBiPE7ocl1/8s6Zrd7kmWXee47tcDAAAAAAyYUggAAAAAAAD0Yt68mo2OnNp4zpVH7p21Vx7feA4jxGobJXsemVxwXLsnWXZ7Htn9egAAAACAAeto9wAAAAAAAAAw1Hzj4jsbL4T80/6bZ8aUyQoh9N8uH0/Wf227p1g26++Q7PqJdk8BAAAAAMOeTSEAAAAAAAAw38NPz8rOJ/628Zy7TpyUjo7SeA4jVOeY5C3fSL65R9I1u93T9F/nuOQtpyYdne2eBAAAAACGPaWQASil3LWYU5+rtZ7R0mEWUUp5R5IpvZyqtdaNWz0PAAAAAADAcPGmf/tdbn/k2UYz/vfvd8u2r1y10QxGiTU3T/Y6Kjn/2HZP0n97Hd09PwAAAACwzJRCBmZCkpqk58c31SQrtWWaha2Uxc8H/VZKGZNk43T/vVopycuSzErydJIHk9xWa53ZtgEBAAAAAGAZXXDzwzn4h1c3mnHA1uvkG//vtY1mMArt8onkoRuTaae3e5KlN/EdyS4fb/cUAAAAADBiKIUsmwVFi6G623uoz8cQVUqZmORtSSYl2S7Jcku4vJZSbk9yTpJfJbmw1qqEBAAAAADAkDdrTle2OOacxnNu/MJ+edk4b8vRgI6O5C2nJrOfSaaf3e5p+rb5pO55OzraPQkAAAAAjBh++wyDoJQyIckOPR6vTbLqkp5Tax1yZZ1Syn5JDk/yxv48Lclm8x+fTDK9lPLvSb5Ta+0a9CEBAAAAAGAQHP7fN+RnV93XaMZX//Y1OXDb9RrNgHSOTQ76fnLGB4Z2MWTzScnffK97XgAAAABg0CiFLJuSF7dxDEVDfb5hqZTyiry0ALJGW4daRqWU9ZOckuStg3C7zZJ8I8nHSikfrbVeOQj3BAAAAACAQXHbQ89kv5N/32jGGi8bl6uP3qfRDFjI2PHJO3+UnHloMu30dk/zUhPf0b0hRCEEAAAAAAadUggsQSll7SQ7ZuESyNptHWqQlVL2SPKLJGsN8q23TXJJKeVTtdZvDPK9AQAAAACgX2qt2fCIqY3nXPJPe+aVq63QeA68ROfY5K3fStbZOrnwhKRrdrsnSjrHJXsdnezy8aSjo93TAAAAAMCIpBQCS3ZuussNI1Ip5a+TnJGkqY9lGpvk1FLKBrXWwxvKAAAAAACAJfrR5TNyzP/e1GjG3++5cf5xvy0azYA+dXQku30q2Wz/5MxDkvuvad8s6+/QvR1kzc3bNwMAAAAAjAJKITBKlVLelOTnaa4Q0tPnSinP1VqPb0EWAAAAAAAkSZ547oVsf/z5jefcccIBGdNpCwJDyJqbJx86L7n8a8lFJ7Z2a0jnuGSvo+ZvB+lsXS4AAAAAjFJKISPPuB7f1x7fz2v1IAxdpZQJSU7Pwn9fFmdakh8luSTJ7UmeSrJiklcmeV2SdybZO0np4z5fLKXcUGv93wGODQAAAAAAS+1vvnFZrr7nL41m/Pwjr8vOG63eaAYMWOeYZPfDki0PTC49OZl2RjJnZnN5Y1dIJh7UnbnaRs3lAAAAAAALUQoZeVZczPEWfvwPQ1kpZUy6N4Ss2selDyf5RK31jF7OPTX/cWOS00opOyb5ZpLt+7jn90op29Va7+3f1AAAAAAAsHQuu+OxvPu0KxvN2G2T1fNfB7+u0QwYNKttlBz41WTf45Prf5ZcdVry2PTBu/8amyU7Hpxs+65k/CqDd18AAAAAYKkohYw86y/m+NMtnWJ0m5FkepJ92zzH4nw8yU59XHN9kkm11geW5oa11qtKKbsm+V6Sv13CpS9PcnKSty3NfQEAAAAAYGm9MHdeNjv67MZzrjv2TVl1heUaz4FBN36VZOePJjt9JLnnD8mtU5MHrk0evL5/G0TGrpisu02y3vbJFpOSDXZLSl8L5QEAAACApiiFjDxbL/Lzgt/APtrqQUaJ+5JcneSa+V+vrrU+XkqZkOTudg7Wm1LKmkk+38dldyR5U621X39naq2zSynvTbJCkr9ewqVvLaXsU2u9oD/3BwAAAACAxTnhrJvznUua/bX8SW+bmL/d6VWNZkBLlJJM2L37kSTzupLHbk8evC555Obk+SeTubOTrtlJ57hkzLhk+VWTtbZM1t0uWWPTpKOzffMDAAAAAAtRChlBSimrJtk9SV3kVE1yb8sHGnkeyPziR7pLIFf1tzgxBHw2yZL2dr+Q5B0DfV211q5SyvuTXJdkwhIu/WISpRAAAAAAAJbJjMeeyxv/9eJGM8Z2lkz/0gEpNiEwUnV0Jmtt0f0AAAAAAIYdpZCR5XNJlkt3CaRk4XLIbW2ZaPg7JcnD6d4A8lC7h1kWpZSVk3y0j8tOrrX+aVlyaq1PlVI+leR/l3DZLqWUPWqtlyxLFgAAAAAAo1OtNdt8/rw8M3tuozkXfPoN2WStlzWaAQAAAAAAy0IpZAQopaye5PAkh+WlW0IWuKplA40gtdbvtnuGQfT+LHlLyJNJThiMoFrrr0oplyTZYwmXfTKJUggAAAAAAP3yy2v/nE+ffn2jGe993QY5/i1bN5oBAAAAAACDYdSXQkop7xvE2+1aSmn2I6mSsUmWT7Jyko2SbJlkxyQdeXE7yKJbQmqSixqei6HvvX2c/3at9elBzPtKllwKeXMpZZVa61ODmAkAAAAAwAj19Kw52ebz5zWec9uX9s+4MZ2N5wAAAAAAwGAY9aWQJN/P4rdrLEnp5esH5z9abcEMtcf3C47XJH+otT7S8qkYMkopm6a7PLQk3xnk2F8neTDJuos5Py7J25P85yDnAgAAAAAwwhz8g6tywS3NvtXx/Q/umDduvlajGQAAAAAAMNiUQl5U+r6kJfcYiL5KLV9ryRQMZW/u4/w1tdY7BjOw1jqvlHJ6kk8t4bI3RykEAAAAAIDFuPbev+Rtp17WaMZW662csz65pMXXAAAAAAAwdCmFvKg/20IWV/4YyMaRwdJzptrj65W11jPaMA9Dyz59nD+rodyzsuRSyJ6llM5aa1dD+QAAAAAADENd82o2PnJq4zlXHbVP1lxpXOM5AAAAAADQFKWQFw3nTSE9LSiElCSPJHl3G2dhCCiljEny+j4uu6Ch+EuSzEoyfjHnV0myY5IrGsoHAAAAAGCY+Y8Lbs+/XzC90YyjJ786B++xUaMZAAAAAADQCkohw9viNpOUJDcleVutdUbrxmGI2irJiks4PyfJH5sIrrXOKqX8KckuS7hMKQQAAAAAgDzw5PPZdcqFjefcdeKkdHQMhc/5AgAAAACAZacU8qLFFSx6s7h3Cvpzj8HUc567kpyc5Fu11jntGYchZvs+zt9ca53dYP7VWXIp5DUNZgMAAAAAMAzs8S8X5r4nnm804zef2D1br79KoxkAAAAAANBqSiHdBuvjoFr9sVIzk9yX5NYkVya5oNZ6dYtnYOjbro/zNzSc39f9lUIAAAAAAEapc258MB/78bWNZrxlu/Vy8rv8KhoAAAAAgJFJKSTZsJ/Xl3Rv46jzv+/59fAkpw/qdC/VleSFJM/UWpv9yCxGis36OH97w/l39HF+04bzAQAAAAAYYma+MDdbHntu4zk3f3G/rLCct8MAAAAAABi5Rv1vwWut9/T3OaUsdiHI4wO5HzSsr+JTX6WNZdXX/VcspaxZa3204TkAAAAAABgCPv3z6/LLP93faMY33rN9Dpi4bqMZAAAAAAAwFIz6UgiMZKW7wbRBH5c90PAYDyWZl6RjCddsmEQpBAAAAABgBLvpgacy+auXNpqx/qrL5w+H79VoBgAAAAAADCVKIcumtnsA6MPLk4zv45qHmhyg1jq3lPJ4kjWXcNl6Tc4AAAAAAED71Fqz4RFTG8/5w+F7Zf1Vl288BwAAAAAAhhKlkIEr7R4AlsLqS3HNI41PkTycJZdClmZOAAAAAACGme9eeneO/83NjWYcts+mOWyfzRrNAAAAAACAoUopZGB+sJjj01s6BfRttaW45unGp+g7Y2nmbKlSyt8nObQFURu3IAMAAAAAoKUefWZ2djzhgsZz7jxxUjo7fI4XAAAAAACjl1LIANRaP9juGWApvbyP88/XWrtaMMczfZwfcqWQdG822bLdQwAAAAAADDdvPuXSTLv/qUYz/vuQXfPaDfr6FTgAAAAAAIx8SiEwso3v4/xzLZkiebaP833NCQAAAADAEPe76Y/m/f/5x0Yz9tx8zXzvgzs1mgEAAAAAAMOJUgiMbMv1cX5uS6boO6evOQEAAAAAGKJmz+3K5kef03jO9cftm1WWH9t4DgAAAAAADCdKITCyKYUAAAAAANCYz//qpnz/shmNZvzrQdvmb177ikYzAAAAAABguFIKgZGto4/zXS2Zou+czpZMAQAAAADAoLjz0Wez91d+12jGy8aNybTP75tSSqM5AAAAAAAwnCmFwMjW14aOVv1/QF85c1oyRf88muTmFuRsnGRcC3IAAAAAAJZZrTWbHX125nTVRnMu+uwbs+EaKzaaAQAAAAAAI4FSCIxsL/RxvlX/HzC2j/N9zdlytdavJ/l60zmllJuSbNl0DgAAAADAsvr5Vffmc/89rdGMD+++YY75K78yBQAAAACApaUUAiNbXxs4lmvJFMOwFAIAAAAAQLenZs7Jtl88r/Gc6V86IMuN6Wg8BwAAAAAARhKlEBjZnu3j/MtaMkWyUh/n+5oTAAAAAIA2+H+nXZlL73is0Ywff3jn7L7pGo1mAAAAAADASKUU0kKllA2STEiybpLVkyyfZFySzhbEP1BrPa0FOQwtT/RxfmwpZXytdVbDc6zcx/m+5gQAAAAAoIX+ePcTece3Lm80Y/tXrZpfHrpboxkAAAAAADDSKYU0qJTyuiT7J9krybZp3VaG3lyTRClk9Hl8Ka5ZNclDDc+xah/nl2ZOAAAAAAAaNrdrXjY56uzGc645ep+s/rJxjecAAAAAAMBIpxQyyEopKyQ5NMlHkmzc81R7JmKUe2wprlknzZdC1unjvFIIAAAAAECb/eu5t+VrF93RaMYXDtwq7991QqMZAAAAAAAwmiiFDKJSyoeSTEmyel5aAqmtn4jRrtY6s5TyeLr/Ti7O2k3OML8otVIfl93T5AwAAAAAACzefU/MzB7/clHjOXefNCml+AwtAAAAAAAYTEohg6CUsnKSnybZPy+WQXorgbT6nY7ahkyGnhlZcilkg4bzl+b+MxqeAQAAAACAXux4wgV59JnZjWacc9ge2WKdlRvNAAAAAACA0UopZBmVUtZOcmGSLdJdwOhZBlHIYCi4O8lrl3B+04bzN+nj/MO11pkNzwAAAAAAQA+/vv6BfOKnf2o04x07vCL/8jfbNpoBAAAAAACjnVLIMiilrJTk3CSvnn9oQSGkZxmkt40hi17T0+KuH+hzl+Z+jGw3JfmbJZzfvOH8vu5/U8P5AAAAAADM9+zsudn6uHMbz7n1+P0zfmxn4zkAAAAAADDaKYUsm1OTbJO+yyD92RjS17V1MXn9zWH0uLaP869pOH/7Ps43+1F0AAAAAAAkSf7+v67NWdMebDTjO+/bIW/acu1GMwAAAAAAgBcphQxQKWVykvdkyYWQkuSOJL9McnaSe5I8lOT/Jfn2/OtKz6+11s75918lycuTrJZkoyS7zX9sl+4/t57lkAVZc5OclOSLtdauQXuxDHd9lUJeUUpZq9b6SEP5r+3jvFIIAAAAAECDpv35qbz5a5c2mrHxmivmt595Y6MZAAAAAADASymFDEAppST5556H5n/tWdJ4KskxSb5Ra523yPN7XterWutT8+8xI93/qP8X85+7XpKPJzk4yRo9Mmu6/zyPTrJ/KeXAWuvD/XphjEi11j+XUu5JssESLntjktMHO3v+39fN+ris2XciAQAAAABGqXnzajY6cmrjOVccsXfWWWV84zkAAAAAAMBLdbR7gGHqgCRb5sUNH8nC20EeSrJrrfXrixZCllWt9YFa65FJXpXk3xc9PT9/xySXlVI2HcxshrUL+jj/poZy9+nj/O211nsaygYAAAAAGLW+cfGdjRdC/nG/zTNjymSFEAAAAAAAaCObQgbmI4v83LMQ8mySPWut05scoNY6K8lnSim/TvKjJOv1mKUk2TDJ+aWUnW0MIcn5ST68hPMHllI+VmvtGuTcv+nj/HmDnAcAAAAAMKo9/PSs7HzibxvPuevESenoKH1fCAAAAAAANEoppJ9KKePSvVWhLnpq/rGjmy6E9FRrvbiUsnuSC5NMWHB4/jyvSnJmKWW3wd5YwrBzVpKZSVZYzPm10r3V49zBCiylrJZkvz4uO2Ow8gAAAAAARrt9//13mf7ws41mnPn3u2W7V67aaAYAAAAAALD0Oto9wDC0R5Ll53+/oAiywPRa61dbPVCt9Z4kk5I83fPw/K87Jfl0q2diaKm1PpvkV31c9olBjv1YkuWWcP6+JL8f5EwAAAAAgFHnt7c8nAmHn9VoIWT/rdbJjCmTFUIAAAAAAGCIsSmk/3bo5diCcsh3WzzL/6m13lZKOSzJ9/JiIWTBxpDjSik/qLU+2q75GBL+M8m7lnB+Uillu1rrdcsaVEp5Wfoumfyw1rroxh0AAAAAAJbSrDld2eKYcxrPmfb5fbPS+LGN5wAAAAAAAP1nU0j/bbuEcz9q2RS9qLX+IMk16S6C9LRCko+2fiKGklrr+UluWMIlJcnJgxR3RJJ1lnB+dpJTBikLAAAAAGDUOeKXNzReCPmPd22XGVMmK4QAAAAAAMAQphTSfxv0+L7nloN7aq0PL+vNSymdy3iLryzy84JtIUohJMk/93H+DaWUf1iWgFLKrkn+qY/Lvj8Y/3sBAAAAABhtpj/8TCYcflZ++sf7GstYbcXlMmPK5Pz1dus3lgEAAAAAAAyOMe0eYBhaPwuXQcr8n68epPuPSdK1DM//nyQzkyy/yPH1Sinb1lqvX4Z7M/z9NMlhSXZcwjX/XEq5o9b66/7evJSyaZJfZMn/3/JMks/3994AAAAAAKNZrTUbHjG18Zzf/+OeedXqKzSeAwAAAAAADA6bQvpvlcUcv7Mf96hLOLdiP+7z0hvXOjvJZekuqyxqn2W5N8NfrbUm+XiW/HdwbJIzSikH9+fepZTdkvwuybp9XPqFWutD/bk3AAAAAMBo9qMr7mm8EHLIGzfOjCmTFUIAAAAAAGCYsSmk/8Yv5vhT/bjHC0s497IkT/TjXr2Zlt4LINss431HpVLK65Ns1s+nrb4U9+1X6WK+39Vabx/A8/5PrfWPpZSTkhy5hMvGJflOKeXtSY6ttV61uAtLKRsk+VySv0vf/5/yuyQn929iAAAAAIDR6YnnXsj2x5/feM7tJxyQsZ0+RwwAAAAAAIYjpZD+620DR9K/UsjsJZxbM8m9/bhXb/7cy7GSZPNlvO9o9aEk72/gvt8ZwHM+mGSZSiHzHZtk9ySv7+O6/ZPsX0q5Nckl87OfTvdGm1cm2TnJ67L4/1309EiSd9dauwY6NAAAAADAaPGOb16eP85Y1s+QWrKffeR1ed1GfX7GEQAAAAAAMIQphfTfM0le3svx/nyE1tNLOLdO/8bp1XOL/FzT/Y/21x+EezMC1Fq7SilvSXJRkm2X4ilbzH8M1JNJ9qu1PrAM9wAAAAAAGPEuu+OxvPu0KxvN2GWj1fPTj7yu0QwAAAAAAKA1lEL67+n0XgpZpR/3eGwJ5zbq3zi9Wn4xx1cahHszQtRa/1JKeVOSqUl2aDDqkSRvrrVe12AGAAAAAMCwNqdrXjY96uzGc6479k1ZdYXlGs8BAAAAAABaQymk/55O99aNusjx/pRCHlzCuc37PdFL9VZaSZIVBuHejCC11kdLKXsk+VaS9zUQcVWSt9da72vg3gAAAAAAI8KJU2/Jt39/V7MZb52Yd+/8qkYzAAAAAACA1lMK6b97k2zTy/FVl/YGtdYHSikz073Ro2e5pGRwNjZstZjjMwfh3owwtdZZSd5fSjk9yVczONtqnklyXJKv1lq7BuF+AAAAAAAjzozHnssb//XiRjM6O0ruOOGAlFIazQEAAAAAANpDKaT/bk3yV70c37Sf97ktyWvyYimkprsUsn0pZaVa6zMDHzG75qWbTJLk8WW4JyNcrfWsUsp5Sd6Z5JNJdhzAbe5J8s0k3661PjGY8wEAAAAAjBS11mz7hfPy9Ky5jeZc8OnXZ5O1Vmo0AwAAAAAAaC+lkP67dZGfF5Q5etsesiRXpbsUkvnPX1Di6EzyliQ/GshwpZQ3JVm3x1wLviZKIQNSa/1Akg+0eYyWqLXOSfLjJD8upbwyyQHpLodsmWSDJCsnWSHJ7HRvA3kwyS1Jrktybq31+jaMDQAAAAAwbPzy2j/n06c3+6vU//e6V+VLb5nYaAYAAAAAADA0KIX03y09vu9Z5nh5KeWVtdb7lvI+lyX5SC/HS5KPZ4ClkCSfW8zxmu7tJLBU5v9d/vb8BwAAAAAAy+DpWXOyzefPazzn1uP3z/ixnY3nAAAAAAAAQ4NSSP9dk2RWknF5sRCywPZJlrYUMjXJvCy8zWPB1x1KKZ+stX61P4OVUv4+yV5ZeDtITxf1534AAAAAAMCyO/gHV+eCWx5uNON7H9wxe26+VqMZAAAAAADA0NPR7gGGm1rrC+ne8tFb6eKv+nGfx5L8rpf7LCh0fLmUcuDS3q+U8oEkJ+elRZWelEIAAAAAAKBFrr33L5lw+FmNFkJeve7KmTFlskIIAAAAAACMUjaFDMxF6d7IscCCIsdSl0Lm+06SPXv8vKAgUpOMTfI/pZRvJ/lyrfWu3m5QStkkyZeSHJSFt430nKsmuaLWenc/5wMAAAAAAPqpa17NxkdObTznj0ftnbVWGt94DgAAAAAAMHQphQzMhUmOn//9gtJFkqxVStmt1vqHpbzPGUm+mGTjLFzm6Fnu+EiSj5RSrktyc5KHknQlWSvJjkm27OU5vTlpKWcCAAAAAAAG6Ku/vT3/dv70RjOOmvTq/N3rN2o0AwAAAAAAGB6UQgag1np5KeX+JOvlxULIAu9JslSlkFprVynliHSXQxa9T7JwyeM1SbZb5HxZ5NrenluTXFNr/c3SzAQAAAAAAPTfg089n11OurDxnLtOnJSOjsV9PhQAAAAAADDaKIUM3BlJDsuLZYwFJYz3l1KOqbU+vjQ3qbX+dynlF0n+Ji/dFrLgvgt+7u1dnp7nFz2WJE8l+dulmQUAAAAAAOi/N3z5otzz+MxGM37zid2z9fqrNJoBAAAAAAAMPx3tHmAY+8n8ryULFzbGJ/l4P+/1oSQ35MXNHj2VHsd7eyxaFulZEpmX5AO11jv7OQ8AAAAAANCHc258KBMOP6vRQsiB266XGVMmK4QAAAAAAAC9silkgGqtV5dSTkuyUi+nV+vnvZ4tpbwpydQkr83CxZBFN4cs8VY9rp2b5EO11l/1ZxYAAAAAAGDJnn+hK68+9pzGc27+4n5ZYTlv5QAAAAAAAIvnnYRlUGv9yCDe69FSyhuS/FuSBfddsA2kP0qSO5K8t9Z65WDNBwAAAAAAJJ8+/br88tr7G8049T3bZ9LEdRvNAAAAAAAARgalkCGk1jozycdKKd9NcmyS/ZN09rykl6f13CByX5L/SPK1WusLjQ0KAAAAAACjzM0PPJ1JX72k0Yz1Vhmfy47Yu9EMAAAAAABgZFEKGYJqrVcleXMpZZ0kf5Vk9yRbJtkgyUpJlkvyfJJHk9yZ5Kok5yX5fa11XluGBgAAAACAEajWmg2PmNp4zh8O3yvrr7p84zkAAAAAAMDIohQyhNVaH0py2vwHAAAAAADQQv956d354m9ubjTjU3tvmn9402aNZgAAAAAAACOXUggAAAAAAEAPjz07Ozt86YLGc+444YCM6exoPAcAAAAAABi5lEIAAAAAAADm++uvXZrr//xUoxm/+Ngu2WHCao1mAAAAAAAAo4NSCAAAAAAAMOr9fvqjed9//rHRjDduvma+/8GdGs0AAAAAAABGF6UQAAAAAABg1Jo9tyubH31O4znXH7dvVll+bOM5AAAAAADA6KIU0k+llB8nmbSY0z+qtX6qlfMAAAAAAAAD8/lf3ZTvXzaj0Ywv/802OWiHVzaaAQAAAAAAjF5KIf23dZJVezlek3yrtaMAAAAAAAD9deejz2bvr/yu0YwVluvMTV/YL6WURnMAAAAAAIDRTSmk/9ZPdwGkp5Jkeq315jbMAwAAAAAALIVaazY/+py80DWv0ZyLPvvGbLjGio1mAAAAAAAAJEohA7HyIj+XdJdErmzDLAAAAAAAwFL4+VX35nP/Pa3RjA/ttmGOffOWjWYAAAAAAAD0pBTSf4v7+LDbWjoFAAAAAADQp6dmzsm2Xzyv8ZzpXzogy43paDwHAAAAAACgJ6WQ/nsmyeq9HH+q1YMAAAAAAACL977//GN+P/3RRjN+9OGdssemazaaAQAAAAAAsDhKIf33ZHovhcxt8RwAAAAAAEAvrprxRA765uWNZmz/qlXzy0N3azQDAAAAAACgL0oh/XdHkk2S1EWOr9SGWQAAAAAAgPnmds3LJked3XjONUfvk9VfNq7xHAAAAAAAgL4ohfTfbUn27+X4q1o9CAAAAAAA0O0r592WUy68o9GMLxy4Vd6/64RGMwAABKEecgABAABJREFUAAAAAPpDKaT/LkvyqV6OT2z1IAAAAAAAMNr9+S8zs/s/X9R4zt0nTUoppfEcAAAAAACA/lAK6b/zk8xLsuCdnzr/+51LKcvXWp9v22QAAAAAADCKvO7E3+ahp2c1mnH2p/bIq9ddudEMAAAAAACAgepo9wDDTa31yXQXQxb9OLDxSd7a8oEAAAAAAGCU+c0ND2TC4Wc1Wgg56LWvyIwpkxVCAAAAAACAIc2mkIE5Jcl+ixwrST6X5CetHwcAAAAAAEa+52bPzVbHndt4zi1f3D/LL9fZeA4AAAAAAMCyUgoZgFrr1FLKH5PsuOBQukshW5dS/r7W+vX2TQcAAAAAACPPx39ybX5zw4ONZnz7va/Nvlut02gGAAAAAADAYFIKGbhDkvwxScf8nxcUQ75cSrm61npl2yYDAAAAAIARYtqfn8qbv3ZpoxkbrbFiLvzsGxvNAAAAAAAAaIJSyADVWv9USvlMkpPTXQjJ/K/jk5xdSjmw1trsu1QAAAAAADBCzZtXs9GRUxvPueKIvbPOKuMbzwEAAAAAAGhCR9+XsDi11q8m+Wq6N4T83+Ekqya5sJTyL6UU7yQBAAAAAEA/fOt3dzZeCPnH/TbPjCmTFUIAAAAAAIBhzaaQZVRrPayU8kSSz2fhjSFjknwmydtLKV9J8tNa61/aMyUAAAAAAAx9jzw9Kzud+NvGc+48cVI6O0rfFwIAAAAAAAxxSiGDoNb6xVLKVUm+k2TdBYfTvUFkwySnJPlKKeU3SX6f5Nok19Van2vHvAAAAAAAMNTsf/Lvc+tDzzSacebf75btXrlqoxkAAAAAAACtpBQyAKWUCxdz6tEk62XhjSFJdzlkXJK3zX8kSS2l/CXJU0menv+Y18jA8/NqrXs3eH8AAAAAAOi3C299OB/6/tWNZuy31dr51nt3aDQDAAAAAACgHZRCBuaNebHw0ZueO+drFi6H9Lxm9fmPZMn3W1al4fsDAAAAAEC/zJrTlS2OOafxnGmf3zcrjR+77Dea15U8Nj154LrkkZuTWU8mc2cnXS8kncslY8Yl41dN1toyWe81yRqbJh2dy54LAAAAAACwBEohy6b0fcn/XdOzHNLbNUtzr4FQBgEAAAAAYEg54pfT8tM/3ttoxsnv3C5vec36A79BrcmMS5Pbpib3X5s8dEMyZ+bSP3/sisk6E5P1t082n5RM2D0pTb0VAAAAAAAAjFZKIcumt8LF4t7RWfR4Xcz3AAAAAAAwIk1/+Jns+++/bzTj5SuMzZ+O3XfgN3j+yeT6nyVXf7d7M8hAzXkuue+K7scVpyZrbJbs8OFk23cly6868PsCAAAAAAD0oBSybJblI71a9XFgCicAAAAAALRVrTUbHjG18Zzf/+OeedXqKwzsyU/clVx6cjLtjP5tBFlaj01Pzvlc8tsvJBMPSnY/LFlto8HPAQAAAAAARhWlkGWjcAEAAAAAAEvw4yvuydFn3thoxsfesHEOP2CLgT25a25y+SnJRSclXbMHd7DezJmZXPuD7m0kex6Z7PqJpKOz+VwAAAAAAGBEUgpZNq3a9gEAAAAAAMPKX557Ia85/vzGc24/4YCM7ewY2JMfvS0585Dk/msGd6il0TU7ueC45JZfJ285NVlz89bPAAAAAAAADHtKIQPz+9gSAgAAAAAAvXrnty7PlXc/0WjGT//uddll49UH9uR587q3g1x4Qmu2gyzJ/Vcn39wj2euoZJdPJB0DLLgAAAAAAACjklLIANRa39juGQAAAAAAYKi57M7H8u7vXNloxus2Wi0/+8guA79B15zkzEOTaacP3lDLqmt2cv6xyUM3dm8N6Rzb7okAAAAAAIBhQikEAAAAAABYJnO65mXTo85uPOdPx7wpL19xuYHfYM6s5IwPJNObn3VApp2ezH4mOej7ydjx7Z4GAAAAAAAYBuwgBwAAAAAABuyks29pvBBywlu3zowpk5etENI1Z2gXQhaYfnbyiw92zwsAAAAAANAHm0IAAAAAAIB+u+fx5/KGL1/ceM7dJ01KKWXZbjJvXnLmoUO/ELLAbVO7533rt5IOn+8FAAAAAAAsnlIIAAAAAADQL9t98bw8ObPZTRbn/8Prs+naKw3OzS4/JZl2+uDcq1WmnZ6sMzHZ7ZPtngQAAAAAABjCfLwUAAAAAACwVP7nT3/OhMPParQQ8u6dX5UZUyYPXiHk0duSC08YnHu12oVf6p4fAAAAAABgMWwKAQAAAAAAluiZWXMy8fPnNZ5z6/H7Z/zYzsG7Ydfc5MxDkq7Zg3fPVuqanZx5aPLh85KOQfzvAgAAAAAAjBhKIQAAAAAAwGL93Q+vzvk3P9xoxvc+sGP23GKtwb/x5V9L7r9m8O/bSvdfnVx2SrL7Ye2eBAAAAAAAGIKUQgAAAAAAgJf4071/yVtPvazRjC3WWSnnHPb6Zm7+xF3JRSc2c+9Wu+jEZMsDk9U2avckAAAAAADAEKMUAgAAAAAA/J+ueTUbHzm18Zw/HrV31lppfHMBl56cdM1u7v6t1DW7+/Uc+NV2TwIAAAAAAAwxHe0eAAAAAAAAGBq+duHtjRdCjpy0RWZMmdxsIeT5J5NpZzR3/3aYdkYy66l2TwEAAAAAAAwxNoW0USmlJHlZkuWTjEtSFpyrtd7brrkAAAAAABhdHnzq+exy0oWN59x14qR0dJS+L1xW1/8smTOz+ZxWmjOz+3Xt/NF2TwIAAAAAAAwhSiEtUkrZKskbkrwmycQkr0iydnrf1lLjzwYAAAAAgBZ445cvyozHmy1Q/OYTu2fr9VdpNOP/1JpcdVprslrtqtOSnT6SlBYUawAAAAAAgGFB8aBBpZStk3woyTuSrNvz1CDnTEyy42JOT6u1XjWYeQAAAAAADH/n3vRQPvqjaxrNePO26+WUv31NoxkvMePS5PHbW5vZKo9NT+75QzJh93ZPAgAAAAAADBFKIQ0opeyc5AtJ3rTgUC+X1cU9fQCRM5N8K71vHbk+yfYDuCcAAAAAACPQ8y905dXHntN4zk1f2C8rjmvD2xC3TW19ZivdOlUpBAAAAAAA+D9KIYOolLJKkq8k+eCCQ/O/Lq4A0vOavq5brFrrnaWU05P8bS+nty2lbFNrvWEg9wYAAAAAYOT4zOnX57+v/XOjGV9/9/aZvM26fV/YlPuvbV92Kzwwwl8fAAAAAADQL0ohg6SUsl2S/0nyqvReBhnIBpD+ODndpZDeMt+X5LMN5wMAAAAAMETd8uDTOeA/Lmk0Y91VxufyI/ZuNKNP87qSh0b4ZyQ9eEP36+zobPckAAAAAADAEKAUMghKKZOSnJFkfLqLGAuKGYsWQXrbBDIoZZFa61WllGuSvLZHTp1///eUUv6x1jqgTSQAAAAAAAxPtdZseMTUxnMu/dyeecXLV2g8p0+PTU/mzGz3FM2a81zy2O3JWlu0exIAAAAAAGAI6Gj3AMNdKWW/JL9Msvz8QwuKGD23hSx4pMe5ntcMlh/2HK3H92sl2WGQswAAAAAAGMK+94e7Gy+EfHKvTTJjyuShUQhJkgeua/cErfHgde2eAAAAAAAAGCJsClkGpZTNk/w8yXLpfTvIosceSPL7JPckeTzJxCTvzYtFkmX1syT/noW3lSywT5KrBiEDAAAAAIAh7PFnZ+e1X7qg8Zw7TjggYzqH2GdPPXJzuydojdHyOgEAAAAAgD4phQxQKWVMktOTrJyXlj96/vxMkm8l+Xat9Y5F7vHhdJdCBkWt9dFSypVJdknvpZCTBisLAAAAAICh5y1f/0Ouu+/JRjN+8bFdssOE1RrNGLBZT7Z7gtZ4/sl2TwAAAAAAAAwRSiED95l0b/pYUiHkO0n+qdb6VAvnOjvdpZAFFmwh2aWUMq7WOruFswAAAAAA0AKX3P5o3vvdPzaa8frN1swPP7RToxnLbO4o+RX4aHmdAAAA/5+9+46SuyzUB/68u4SE3rv0Fum9I0VqsKBXuPbeRcVyVap0sFy7iFev/XoV9CdeJfQqCErvHSKI9A6BkOx+f39sIpu4KbvZd2bL53POnOx8Z3aeZwJ4jtk88wIAAHNlFDIApZTFk3whMw9Aen89Jcn7m6b5nzbU+1Ovr3v3GpueEctVLW8EAAAAAEAVL03rznqHn1k95/ov7pUlFhpTPWe+db3U7gat0WUUAgAAAAAA9DAKGZgPJVkiL5/C0XsQ0p3kXU3TnNqmbldO79C71wzjYxQCAAAAADAiHP2Hm/PjyyZVzfjyv22SA7detWrGoOpcsN0NWqNzbLsbAAAAAAAAQ4RRyMC8M/86uJgxwjiujYOQNE0zuZRyb5K1+nh4fKv7AAAAAAAwuO559Lns/p8XV80YN6Yjtx6zT0opVXMG3QKjZCwxWt4nAAAAAAAwV0Yh/VRKGZ9kw/zrKSFJcn+SE9rRaxa3JVk7fZ8UAgAAAADAMNQ0TcYfcVamTOuumnPBZ3bJWsstWjWjmnFLtrtBayy0ZLsbAAAAAAAAQ4RRSP/t0se1GeOQY5umeanFffpyfx/XSpJVW10EAAAAAID5d+pV9+dzv7mhasa7d1gjR71uw6oZ1S2/QbsbtMZoeZ8AAAAAAMBcGYX033a9vu59EkdXkt+0uMvsPDTL/Rmnmizehi4AAAAAAAzQ0y9MzaZHn1M95/bj9snYBTqr51S38mbtbtAaK23W7gYAAAAAAMAQYRTSf+vMcn/GKSF/bZrm6Tb06cvseizW0hYAAAAAAAzYu37011x8x6NVM37+vm2y87rLVc1oqWXXS8YsnEyd3O4m9YxZJFl23Xa3AAAAAAAAhgijkP5bPTOfEDLDNa0uMgcvzua6UQgAAAAAwBB31aQn8qZTLq+asemqS+b3H9uxakZbdHQmK26S3H9Fu5vUs9ImPe8TAAAAAAAgRiEDsfhsrtf9uLb+KbO5vnBLWwAAAAAAMM+mdXVnncPOrJ5z1eF7ZNlFx1bPaZtVthjZo5CVt2h3AwAAAAAAYAjpaHeBYWiR2VwfSqOQpWdzfUpLWwAAAAAAME++du4d1QchX3ztBpl00n4jexCSJOtPaHeDusaP8PcHAAAAAAD0i5NC+m9qkr5+YrZQq4vMwexGIS+0tAUAAAAAAHP09ycnZ6cvXVg9594TJ6SU2R0yPcKssVOyzLrJ43e2u8ngW3a9ZPUd290CAAAAAAAYQoxC+m9y+h6FLNPqInMwuy5PtLQFAAAAAACztd0J5+ehZ16smnHmJ3fOK1davGrGkFNKsvX7k7M+3+4mg2/r9/e8PwAAAAAAgOk62l1gGHpyNteXa2mLOdt8lvslSZPk/jZ0AQAAAACglzNueDBrfOGMqoOQN235ikw6ab/RNwiZYdM3J2MWbneLwTVm4Z73BQAAAAAA0IuTQvrv3iRrp2dkMUNJslV76syslLJEko0yc78Z7m1xHQAAAAAApnt+yrRs+MWzq+fcesw+WWjBzuo5Q9pCSyYbH5Bc89N2Nxk8Gx+QjFui3S0AAAAAAIAhxiik/+6Z5X6TnlHIJqWUxZqmebYNnXrbKT0nwMzo1Xsccl07CgEAAAAAjHYf/99r84fr/1E14/vv2DJ7b7hi1YxhZaeDk+t/lXRNaXeT+dc5tuf9AAAAAAAAzKKj3QWGob/2+rr0+rojyV4t7tKXd83hsStb1gIAAAAAgNz0wNNZ4wtnVB2ErLHMwpl00n4GIbNaeq1kt0Pb3WJw7HZoz/sBAAAAAACYhZNC+u+yOTz26SS/bVWRWZVS1kzyhrx8OkjvU0KeTnJ1y0sBAAAAAIxC3d1N1jp0YvWcyw/ZPSstsVD1nGFr+4OSW/8veWAY//H4KlslO3y83S0AAAAAAIAhykkh/dQ0ze1J7ppxNz2nhcz4dbtSyqva1S3JF5J0Tv+69Pq1SXJG0zRdbWkFAAAAADCK/Ncld1cfhHx2r/Uy6aT9DELmpnOBZP/vJZ1j291kYDrHJvufnHR0zv25AAAAAADAqOSkkIE5NcmhmfkkjhnDkB+WUrZomua5VhYqpbwmyftn6dTb/7awDgAAAADAqPPIsy9mm+PPr55z9wkT0tlR5v5Eeiy3frL7Ycm5R7a7Sf/tfnhPfwAAAAAAgNkwChmY/0ryufScytH7tJAkWTvJD5K8pVVlSimrJ/lp70uZeRxyT9M0dT+WDgAAAABgFNvnG5fktoeerZrxu4/ukM1XW6pqxoi1/ceTh25Kbjy13U3m3cYHJtsf1O4WAAAAAADAEGcUMgBN09xXSvlVkrfn5fHFjCFGSXJgKaU7ybubpplas8v0Qci5SZbqlf/Ph6df+1rNDgAAAAAAo9WFtz2S9/zkyqoZe26wQn7wzq2qZox4HR3J/icnU55N7jiz3W3mbv0JPX07OtrdBAAAAAAAGOKMQgbuiCRvTLJQXh5j9B6GvDnJyqWU9zVNc0+NAqWU/dNzKskymflkkN6nl9ye5Ps18gEAAAAARqsXp3Zl/BFnVc+58ai9sti4MdVzRoXOMckBP0lOe/fQHoasPyF50497+gIAAAAAAMyFj5gaoKZp/pbk2Mx8Mkcy8zBklyS3lFK+XEpZYbCySym7lFLOTvLb9AxCZs3+Z80kBzVN0z1Y2QAAAAAAo91hv7ux+iDk6/++aSadtJ9ByGAbMy75958nGx/Y7iZ92/jA5MCf9fQEAAAAAACYB04KmT9fTrJ7kj3z8hAkmXkYsmCSzyT5VCnlkiS/SXJ1klvmJaCU0pFktSSbJtkpyeuTrD1LzoyvM8v1bzRNc8FA3hgAAAAAADO78+Fns+fXL6maseTCY3LdkXtVzRj1Osckb/h+suJGyQXHJ11T2t0o6Ryb7H54sv1BSYfP8wIAAAAAAOadUch8aJqmKaW8JckV6Rlq9DUMmfF1Z5Jdp99meH52r11KuS/JuCRLZeYTXXqPP2YdhDS9fr0gyRfm+c0AAAAAANCnpmmy5iETq+dc/B+7ZvVlFqmeQ3qGFzt+Mllvn+T0jyQPXN2+Lqtslex/crLc+u3rAAAAAAAADFs+bmo+NU3zRJLdktybmYcgycxjjRmDkd63RWd5Xu9fX5Fk2fSMSXp/T9PH683ImPG91yR5Q9M00wbjPQIAAAAAjFb/85e/VR+EfOhVa2XSSfsZhLTDcusn7z0n2ePontM6WqlzbLLnMcn7zjEIAQAAAAAABsxJIYOgaZoHSik7J/l9kq0y80Bj1mHIrEof12Y8f3Zm/Z7eeRcneX3TNM/NrTcAAAAAAH178vmXsvmx51bPufP4fTOm0+c3tVXnAslOBycbvC659BvJjaclUyfXyxuzcLLxAT2ZS69VLwcAAAAAABgVjEIGSdM0D04fhpyc5D2ZeQTSexwy07fN48vPbTgy4/FTkhzcNM1L8/i6AAAAAADM4s3/dXmuuOeJqhm//MC22WHtZatm0E9Lr5W87lvJXscm1/8qufKHyWN3DN7rL7tesvX7k03fnIxbYvBeFwAAAAAAGNWMQgZR0zRTkryvlHJaesYha+RfTwgps/l6VvN6gkhJcn+Sg5qm+UO/CgMAAAAA8E+X3/143vKDK6pmbLPm0jn1Q9tXzWA+jVsi2fZDyTYfTP52WXLbxOQf1yQPXt+/E0TGLJKstEmy8hbJ+AnJ6jsmZU4/FgAAAAAAAOg/o5AKmqY5q5SyXpIPJPlcktVnPJTZnw7Sn5NEZjz3sSTfSPK1pmleHFhbAAAAAIDRbWpXd9Y97MzqOdcesWeWWmTB6jkMklKSNXbquSVJd1fy2J3Jg9clj9ySvPBUMm1K0jUl6RybLDA2WWjJZPkNkpU2S5ZdN+nobF9/AAAAAABgVDAKqaRpmmlJvldKOSXJXknelWSfJEvO+tRZfu1L78HItCQXJ/mfJP87/XQSAAAAAAAG4KQzb8spF99dNeO4/TfK27dbfe5PZGjr6EyWH99zAwAAAAAAGCKMQiprmqZJcnaSs0spHUm2S7Jtks2TjE+yapLl0/dJIVOS3J/kniTXJvlLkoubpnmyBdUBAAAAAEas+x6fnFd95cLqOfeeOCGl9PXHvwAAAAAAADD/jEJaqGma7iR/nn77p1JKZ5JFkiyUZEx6xiCTm6Z5vuUlAQAAAABGuM2POSdPTp5aNePcT70q666wWNUMAAAAAAAAMAoZApqm6UryzPQbAAAAAAAVnH7tAzn419dVzXjrtqvlhDdsXDUDAAAAAAAAZjAKAQAAAABgRHv2xanZ+Khzqufcduw+GTems3oOAAAAAAAAzGAUAgAAAADAiPWhn1+Vs29+uGrGj969VXYfv0LVDAAAAAAAAOiLUQgAAAAAACPOdfc/lf2/e1nVjPVXWCxnf+pVVTMAAAAAAABgToxCAAAAAAAYMbq6m6x96MTqOX899NVZfvFx1XMAAAAAAABgToxCAAAAAAAYEb574V35ytm3V834wr7j8+Fd1q6aAQAAAAAAAPPKKAQAAAAAgGHtoadfzHYnnl89554TJqSjo1TPAQAAAAAAgHllFAIAAAAAwLC1+39elHsefb5qxh8O2ikbv2KJqhkAAAAAAAAwEEYhLVZKWSzJhtNvr0iyUpJlkoxLMjZJd5IXkzyf5JEkDya5O8nNSe5omqa7DbUBAAAAAIaUc25+KB/8+dVVM/bbZKV8961bVM0AAAAAAACA+WEUUlkppSPJHklek2TXJBskKQN8ucmllD8nuSDJb5umuWtQSgIAAAAADBMvvNSVVx55VvWcm4/eO4uM9UfoAAAAAAAADG1+olVJKWXVJJ9I8s4ky864PJ8vu0h6BiZ7JDmhlHJNku8k+WXTNFPn87UBAAAAAIa0/zjt+px29d+rZnznrZvnNZusXDUDAAAAAAAABotRyCArpSyf5Pgk70rSmX8dgjTzG9Hr6y2T/Cg9A5Ejmqb50Xy+NgAAAADAkHPbQ89kn2/8qWrGCouPzV8O3aNqBgAAAAAAAAw2o5BBVEr5cJIvJVk0L483+hqBDPTEkGaW1yvTbysl+UEp5aNJ3tE0za0DfH0AAAAAgCGjaZqsecjE6jl/+txuWXXphavnAAAAAAAAwGDraHeBkaCUsmgp5f+SfDfJYukZavQecJRZbgOOmuXW9LqVJFskuaqU8oH5yAAAAAAAaLufXHZv9UHIx3dfJ5NO2s8gBAAAAAAAgGHLSSHzqZSySpIzk2yYl4ca/3y4j2/p6+SQfkX28XXvAcpCSU4ppazbNM3n5jMLAAAAAKClHn9uSrY87rzqOXcdv28W6PS5SQAAAAAAAAxvRiHzoZSyQpILk6wz/VLvk0F6m3UIMtDTQnqPP3q/zqzjkJLkM6WUBZqm+fQAswAAAAAAWuoNJ1+Wa+97qmrGaR/ePluvsXTVDAAAAAAAAGgVo5ABKqUsmOSM9AxC5mUMMuOx25Nck+T66bcHkzzT6zYmyeK9busl2XT6beskM35a2Xsg0nsc0nsY8slSyn1N03xj4O8UAAAAAKCuS+98LG//779Uzdh53WXz8/dtWzUDAAAAAAAAWs0oZOC+mmSLzH0QUpLck+R/k/yyaZpb5/K605K8kOTh6fevnv69KaUskGTvJG9N8vokC2fmEciMvN7XTiql/Klpmqv7+f4AAAAAAKp6aVp31jv8zOo51x+5V5ZYeEz1HAAAAAAAAGg1o5ABKKVsmeRj6XsQ0vvao0mOSPLDpmm65ze3aZpp6Tmd5IxSygpJTkzyrl65fQ1DFkxySnpOGQEAAAAAGBKO+cMt+dFl91bN+PK/bZIDt161agYAAAAAAAC0k1HIwHwlLw8vZjcI+VGSTzdN80yNAk3TPJzkvaWU7yb5ZZJ10/cwJEm2KKW8pWma/63RBQAAAABgXt372PPZ7asXVc0Yu0BHbjt2n5Qy6wHPAAAAAAAAMLIYhfRTKWXjJLum70HIjCHGZ5qm+Xor+jRNc3UpZev0nCCyYx+9Mv3+wUmMQgAAAACAtmiaJhsceXZemNpVNef8z+yStZdbtGoGAAAAAAAADBUd7S4wDL2zj2u9ByFfbNUg5J/hPaeR7JPkpl59kplPC9mqlPLKVvYCAAAAAEiS0666P2seMrHqIOTdO6yRSSftZxACAAAAAADAqOKkkP6bkJeHFsnMg5CLmqY5rh2lmqZ5vpRyYJLrkoxJ3yeG7Jvk1hZXAwAAAABGqadfmJpNjz6nes7tx+2TsQt0Vs8BAAAAAACAocYopB9KKYsneWX6HlwkySdb22hmTdPcVkr53vQeTR9P2a7FlQAAAACAUerdP/5rLrr90aoZP3vvNnnVestVzQAAAAAAAIChzCikf8bPcr/3KSEXNE1zU+sr/Ytvpu9xSknPoAUAAAAAoJqr//ZE/u17l1fN2PQVS+T3B+1UNQMAAAAAAACGA6OQ/llpDo/9rmUt5qBpmkmllOuSbJaXTwuZMV6ZU38AAAAAgAGb1tWddQ47s3rOVYfvkWUXHVs9BwAAAAAAAIYDo5D+WWwOj/2lZS3m7or0jEJmtWiLewAAAAAAo8DXz70j3zz/zqoZR75mg7x3pzWrZgAAAAAAAMBwYxTSP91zeOyulrWYu7tnc31O/QEAAAAA+uWBp17IjiddUD3n3hMnpJRSPQcAAAAAAACGG6OQ/nl2gI+12uy6DKWOAAAAAMAwtuNJF+SBp16omjHxEztng5UXr5oBAAAAAAAAw5lRSP88PofHFkzyYquKzMWCs9yf8RF6j7W6CAAAAAAwsky88cF89H+uqZrxxi1WydcO3KxqBgAAAAAAAIwERiH9c+scHls+yX2tKjIXy/VxrUlyW6uLAAAAAAAjw+SXpmWDI8+unnPrMftkoQU7q+cAAAAAAADASGAU0g9N0zxZSnkgycrpGVn0tlGGzihko9lcv76lLQAAAACAEeGTv7o2v7/uH1UzTnn7ltlnoxWrZgAAAAAAAMBIYxTSf2cneW/+dRSyZ5KJra8zs1JKZ5Ld8q/9kp7uAAAAAADz5KYHns5rvn1p1YzVl1k4F//HblUzAAAAAAAAYKQyCum/09MzCpmhSVKSvKWU8rmmaaa2pdXL9k+yZP51FPJQ0zR/aXkbAAAAAGDY6e5ustah9T8D5/JDds9KSyxUPQcAAAAAAABGqo52FxiGJia5u4/ryyX5SIu7zKSUUpIcPuvl9AxEvtv6RgAAAADAcPODS+6pPgj5zJ7rZdJJ+xmEAAAAAAAAwHxyUkg/NU3TXUr5UpL/ysunccw4LeSYUsofm6a5p031Ppdk0/zrKSFPxigEAAAAAJiDR559Mdscf371nLtPmJDOjlI9BwAAAAAAAEYDo5ABaJrmh6WUdyTZOTMPMBZP8vtSym5N0zzWyk6llP2THDdLnxmnhHy6aZqnW9kHAAAAABg+JnzzT7nlwWeqZvy/j+6QLVZbqmoGAAAAAAAAjDZGIQP3riRXJFlu+v0ZY4wNk1xUSnl90zR3t6JIKeU9Sb6XpDMzj0KaJP/bNM3PWtEDAAAAABheLrz9kbznx1dWzdjjlSvkh+/aqmoG/IvuruSxO5J/XJc8ckvy4lPJtClJ10tJ54LJAmOTcUsmy2+QrLx5suy6SUdnm0sDAAAAAAD0n1HIADVNM6mUsl+SC5Is2vuhJBskubqUckySbzVNM61Gh1LK6km+muSNeflUkH8+nOTcJO+ukQ0AAAAADF8vTu3K+CPOqp5zw1F7ZfFxY6rnQJommXRpcvvE5IFrkoduSKZOnvfvH7NIsuLGySpbJOtPSNbYKSmlXl8AAAAAAIBBYhQyH5qmubqUslOSPyZZNS+PMpokiyf5SpIPl1KOSvK7pmleGIzcUsqaST6U5BNJxmbmQciMn1L9Msl7aw1SAAAAAIDh6fDTb8wvrrivasbX/33TvGHzV1TNgCTJC08l1/8queq/e04GGaipzyf3X9Fzu+LkZNn1kq3el2z65mShJQerLQAAAAAAwKAzCplPTdPcWErZKsn3k+yfmYchJck6SX6eZHIp5f+S/C7JNU3T3DOvGaWUcUk2SrJjkjcn2WbGQ72yZtx/LskhTdN8d6DvCQAAAAAYee565Nns8bVLqmYssdCYXHfknilOWKC2J+5JLv1GcuNp/TsRZF49dkdy1ueT849ONj4g2engZOm1Bj8HAAAAAABgPhmFDEAp5cg+Ll+XZI0km2XmYUjSM9ZYJD2DjjdPf43nktyU5B9Jnpl+ezbJmPScMrJYkiWSrDv91tG7wiyvP+Nad5LfJFlmNh3nW9M0x9R4XQAAAACgjqZpsvahE9PdzP258+Oiz+6aNZZdpG4IdE1LLv92cuGJSdeU+nlTJyfX/LTnNJLdDk12+HjS0Vk/FwAAAAAAYB4ZhQzMUZl5kDGr3h+D12TmccgMiyXZbh6y+vpIvVnHIL2/ftc8vOb8MAoBAAAAgGHil3+5L4f+7saqGR981Vo5dMIrq2ZAkuTR25PTP5I8cHXrs7umJOd9Mbn1D8n+JyfLrd/6DgAAAAAAAH0wCpk/fQ02Zvec3uOQ/nx/X+OT2X3fvLze/Kj8WYIAAAAAwGB4avJL2eyYc6vn3Hn8vhnT2TH3J8L86O7uOR3kguNbczrInDxwVXLKzsnuhyXbfzzp8O8/AAAAAADQXkYh82d+Bht9jUTmZKADksFSe3ACAAAAAAyCt/7givz57serZvzyA9tmh7WXrZoBSZKuqcnpH01uPLXdTV7WNSU598jkoZt6Tg3pHNPuRgAAAAAAwChmFDJ/5mcoUWNkUWu44YQQAAAAABjirrjn8bz5v66omrH1GkvltA/vUDUD/mnqi8lp707uOLPdTfp246nJlGeTA36SjBnX7jYAAAAAAMAoZRQCAAAAADCMTe3qzrqH1f9L89ccsWeWXmTB6jmQpOeEkKE8CJnhjjOT37wnOfBnTgwBAAAAAADaoqPdBYa5ZpTcAAAAAIAh6Etn3VZ9EHLs/htl0kn7GYTQOt3dyekfHfqDkBlun9jTt7u73U0AAAAAAIBRyEkhA1faXQAAAAAAGJ3uf2Jydv7yhdVz7j1xQkrxR6G02OXfTm48td0t+ufGU5MVN052/ES7mwAAAAAAAKOMUcgANE3jhBUAAAAAoC22PPbcPP78S1UzzvnUq7LeCotVzYA+PXp7csHx7W4xMBccl6y3d7Lc+u1uAgAAAAAAjCLGDQAAAAAAw8Dvr3sga3zhjKqDkLdss2omnbSfQQjt0TUtOf0jSdeUdjcZmK4pyekfTbq72t0EAAAAAAAYRZwUAgAAAAAwhD03ZVo2+uLZ1XNuO3afjBvTWT0HZuvy7yQPXN3uFvPngauSP3872engdjcBAAAAAABGCaMQAAAAAIAh6sM/vzpn3fxQ1Yz/ftdWefUrV6iaAXP1xD3JhSe0u8XguPCEZIPXJUuv1e4mAAAAAADAKGAUAgAAAAAwxFx3/1PZ/7uXVc1Yb4VFc86ndqmaAfPs0m8kXVPa3WJwdE3peT+v+1a7mwAAAAAAAKOAUQgAAAAAwBDR1d1k7UMnVs/566GvzvKLj6ueA/PkhaeSG09rd4vBdeNpyV7HJuOWaHcTAAAAAABghOtodwEAAAAAAJLvXnhX9UHIF/Ydn0kn7WcQwtBy/a+SqZPb3WJwTZ3c874AAAAAAAAqc1IIAAAAAEAbPfT0i9nuxPOr59xzwoR0dJTqOdAvTZNc+cN2t6jjyh8m23wwKf67AwAAAAAA6jEKAQAAAABok1f/50W5+9Hnq2b830E7ZpNXLFk1AwZs0qXJ43e2u0Udj92R/O2yZI2d2t0EAAAAAAAYwYxCAAAAAABa7NxbHs4HfnZV1Yz9Nlkp333rFlUzYL7dPrHdDeq6baJRCAAAAAAAUJVRCAAAAABAi7w4tSvjjzires7NR++dRcb641+GgQeuaXeDuv4xwt8fAAAAAADQdn4qCAAAAADQAp/7zfU59aq/V8349ls2z2s3XblqBgya7q7koRva3aKuB2/oeZ8dne1uAgAAAAAAjFBGIQAAAAAAFd320DPZ5xt/qpqx3GJjc+Vhe1TNgEH32B3J1MntblHX1OeTx+5Mlh/f7iYAAAAAAMAIZRQCAAAAAFBB0zRZ85CJ1XP+9LndsurSC1fPgUH3j+va3aA1HrzOKAQAAAAAAKjGKKSFSimLJlkuyRJJxiZZMElpVX7TNJe0KgsAAAAARrOf/nlSvvh/N1fNOGi3dfLZvdevmgFVPXJLuxu0xmh5nwAAAAAAQFsYhVRSSlk+yd5JdkiyWZL10zMGaZcm/nkDAAAAQFWPPzclWx53XvWcu47fNwt0dlTPgapefKrdDVrjhafa3QAAAAAAABjBjAQGUSllTJIDk3wwPWOQ3j+VbdmJIAAAAABA673x5MtyzX1PVc049UPbZ5s1l66aAS0zbUq7G7TGaHmfAAAAAABAWxiFDJJSyluTHJ9ktRmXZnlK09pGMzFIAQAAAIBKLrvrsbzth3+pmrHTOsvmF+/ftmoGtFzXS+1u0BpdRiEAAAAAAEA9RiHzqZSyZJKfJdkvM48v+hqBtGOc0c4xCgAAAACMWC9N6856h59ZPef6I/fKEguPqZ4DLde5YLsbtEbn2HY3AAAAAAAARjCjkPlQSlktydlJ1kvP4GPWAYYTOgAAAABgBDruj7fkh5feWzXjpDdunDdvs9rcnwjD1QKjZCwxWt4nAAAAAADQFkYhA1RKWSbJuUnWnX5pxiCkryGI0zoAAAAAYAS497Hns9tXL6qasWBnR24/bp+U4jNnGOHGLdnuBq2x0JLtbgAAAAAAAIxgRiED99/pGYTMbgzi1BAAAAAAGCGapslGXzw7z7/UVTXnvE/vknWWX7RqBgwZy2/Q7gatMVreJwAAAAAA0BZGIQNQSnl9ktdl7oOQGdcfSHJtkluS3JXk2STPJXk+ThEBAAAAgCHtN1f/PZ897fqqGe/afvUc/fqNqmbAkLPyZu1u0BorbdbuBgAAAAAAwAhmFDIwR/X6uvcgpPcY5MUkpyT5VdM0f21RLwAAAABgkDzz4tRsctQ51XNuP26fjF2gs3oODDnLrpeMWTiZOrndTeoZs0iy7LrtbgEAAAAAAIxgRiH9VErZIsmm6RmAzDoImXH/D0kOaprm/hbXAwAAAAAGwXt/cmUuuO2Rqhk/fe822WW95apmwJDW0ZmsuEly/xXtblLPSpv0vE8AAAAAAIBKjEL6b78+rs0YhDRJfpTkQ03TdLe0FQAAAAAw367+2xP5t+9dXjVj41WWyB8+vlPVDBg2VtliZI9CVt6i3Q0AAAAAAIARziik/7af5X7vE0KuS/LBpmmaljYCAAAAAOZLV3eTtQ+dWD3nysP2yHKLja2eA8PG+hOSK05ud4t6xk9odwMAAAAAAGCEMwrpv3XTMwSZVZPk4wYhAAAAADC8fOO8O/KN8+6smnHEazbI+3Zas2oGDEtr7JQss27yeN3/Btti2fWS1XdsdwsAAAAAAGCEMwrpv+V7fd17AHJ/0zR/bnUZAAAAAGBgHnjqhex40gXVc+45YUI6OsrcnwijUSnJ1u9Pzvp8u5sMvq3f3/P+AAAAAAAAKjIK6b+FZ7lf0jMOObsNXQAAAACAAdjpSxfk70++UDXjjE/slA1XXqJqBowIm745Of/oZOrkdjcZPGMW7nlfAAAAAAAAlXW0u8Aw9Pxsrv+9pS0AAAAAgH4788YHs8YXzqg6CHnj5qtk0kn7GYTAvFpoyWTjA9rdYnBtfEAyzv8GAAAAAAAA9TkppP+eTrJYH9cfbXURAAAAAGDeTH5pWjY4sv5hv7ccs3cWXtAfu0K/7XRwcv2vkq4p7W4y/zrH9rwfAAAAAACAFnBSSP89kKT0cb2voQgAAAAA0GYH/+ra6oOQU96+RSadtJ9BCAzU0mslux3a7haDY7dDe94PAAAAAABAC/gJZf9dl2S7Pq6v0OIeAAAAAMAc3PyPp7Pfty6tmrHq0gvlT5/bvWoGjBrbH5Tc+n/JA1e3u8nArbJVssPH290CAAAAAAAYRYxC+u/KJB/u4/oaLe4BAAAAAPShu7vJWodOrJ7z5y/snpWXXKh6DowanQsk+38vOWXnpGtKu9v0X+fYZP+Tk47OdjcBAAAAAABGkY52FxiG/pBkWq/7TZKSZPdSip/0AAAAAEAb/fBP91QfhHxqj/Uy6aT9DEKghuXWT3Y/rN0tBmb3w3v6AwAAAAAAtJCTQvqpaZrHSikXJNkrPYOQGZZIslOSi9tSDAAAAABGsUefnZKtjz+ves7dJ0xIZ0epngOj2vYfTx66Kbnx1HY3mXcbH5hsf1C7WwAAAAAAAKOQUcjAnJieUcisPh+jEAAAAABoqdd8+0+56YFnqmb89iM7ZMvVl6qaAUzX0ZHsf3Iy5dnkjjPb3Wbu1p/Q07fD4ewAAAAAAEDr+QnFADRNc3GSc5PM+EjAZvrXe5dS9mlbMZhHpZSmzbc92v17AAAAAAx/F93+SNb4whlVByGvHr98Jp20n0EItFrnmOSAnyTr7dvuJnO2/oTkTT/u6QsAAAAAANAGTgoZuA8muS7J4tPvzxiG/KCUskPTNPe3qxgAAAAAjGRTpnVl/cPPqp5zw1F7ZfFx/qI3tM2Yccm//zw5/aPJjae2u82/2vjAnhNCDEIAAAAAAIA2clLIADVN87f0DENmupxklSTnllKWa30rAAAAABjZjvz9TdUHIf95wKaZdNJ+BiEwFHSOSd7w/WTPY5LOse1u06NzbLLnsT29DEIAAAAAAIA2c1LIfGia5rTp44/vpGcQkum/rpfkulLK+5qmqf+RhQAAAAAwwt31yHPZ42sXV81YbNwCueGLe6WUUjUH6KeOjmTHTybr7ZOc/pHkgavb12WVrXpOB1lu/fZ1AAAAAAAA6MUoZD41TXNyKaUrybeTdM64nGSlJGeUUn6R5GtN01zfro4AAAAAMFw1TZN1DjszXd3N3J88Hy767K5ZY9lFqmYA82m59ZP3npNc/p3kwhOSrimty+4cm+x+WLL9QUlH59yfDwAAAAAA0CId7S4wEjRN8/0kr07ySJIZHyPYTP/67UmuKaX8qZTy2VLKjqWUIXLGPQAAAAAMXb/6631Z85CJVQchH9h5zUw6aT+DEBguOhdIdjo4+dgVyRbvSsYsXDdvzMI9OR+7oue0EoMQAAAAAABgiHFSyCBpmuZPpZRNknwtydvSMwqZMQxJkh2m35Kkq5TyeJInp99a8XFmTdM0r25BDsPfH5L8X+WMWyq/PgAAADCMPTX5pWx2zLnVc+44bt8suIDPzYFhaem1ktd9K9nr2OT6XyVX/jB57I7Be/1l10u2fn+y6ZuTcUsM3usCAAAAAAAMMqOQQdQ0zaOllHcleSzJJ/PyMCR5eRyS9Py+rzD9Vu9jDl9WWpTDyHBN0zQ/bHcJAAAAYHR62w+vyGV3PV4145fv3zY7rLNs1QygRcYtkWz7oWSbDyZ/uyy5bWLyj2uSB69Ppk6e99cZs0iy0ibJylsk4yckq++YlDL37wMAAAAAAGgzo5BBUkrpTHJQkoOTrJaZTwlJZj/KqP1TJWMQAAAAAIa8v9zzeP79v66omrH1GkvltA/vMPcnAsNPKckaO/XckqS7K3nszuTB65JHbkleeCqZNiXpmpJ0jk0WGJsstGSy/AbJSpsly66bdHS2rz8AAAAAAMAAGYUMglLKTkm+n2R8Zj/ymN1AxGgDAAAAgFFrWld31jnszOo51xyxZ5ZeZMHqOcAQ0dGZLD++5wYAAAAAADCCGYXMp1LKh5N8Mz2/lyUvjzzmdAJIK8+cNzoBAAAAYEj68lm35eSL7q6acezrN8w7tl+jagYAAAAAAABAuxiFzIdSyqeSfDUvjzzmNggx0AAAAABg1Lv/icnZ+csXVs+598QJKaWVn88CAAAAAAAA0FpGIQNUSnldkq9kzqeDzGkE4qfRAAAAAIw6Wx13Xh57bkrVjLMPflXWX3GxqhkAAAAAAAAAQ4FRyACUUhZPckqSjvQ9COk9Bpn1+oNJnk3yXJLn4/QQAAAAAEaB31/3QD75q+uqZvz7VqvmS2/apGoGAAAAAAAAwFBiFDIwhydZMT2DjtmdDlKSTElyXpLfJbkmye1N07zQqpIAAAAA0G7PTZmWjb54dvWc247dJ+PGdFbPAQAAAAAAABhKjEL6qZQyNsn78q8nfPS+Py3JyUmOaZrmyVZ1AwAAAICh5KP/c3Um3vhQ1YwfvnOr7LHBClUzAAAAAAAAAIYqo5D+e12SpTLzKSG9Twd5Isk+TdNc1YZuAAAAANB219//VF7/3cuqZqy7/KI599O7VM0AAAAAAAAAGOqMQvpv51nu9x6EvJhk16ZpbmptJQAAAABov+7uJmsdOrF6zl8OfXVWWHxc9RwAAAAAAACAoc4opP+26eNaSc845MsGIQAAAACMRt+76O586azbqmZ8fp/x+ciua1fNAAAAAAAAABhOjEL6b5W8fDpI0+v61CT/2fo6AAAAANA+Dz/zYrY94fzqOfecMCEdHaV6DgAAAAAAAMBwYhTSf0vNcn/GKSGXNE3zbBv6QDWllDFJ1k6yWpKlk4xLzwDqhSRPJfl7kvubpnmhXR0BAACA9tnzaxfnzkeeq5rx+4/tmE1XXbJqBgAAAAAAAMBwZRTSf2Nmc/3alraAejYopXw5yW5JNk4ydi7P7y6l3JHkqiTnJTmzaZpHKncEAAAA2ui8Wx7O+392VdWMCRuvmJPftmXVDAAAAAAAAIDhziik/55Jz4kJs/KX4BkpDujn8zuSjJ9+e3t6RiJnJTklyR+bpmkGuR8AAADQJi9O7cr4I86qnnPT0Xtn0bH+6BIAAAAAAABgbvxktf+eTN+jkMmtLgJDVEeSCdNv15RSPt80zXlt7gQAAADMpy/89ob86sr7q2Z86y2b53Wbrlw1AwAAAAAAAGAkMQrpv9uTrJNk1tMPlm9DFxjqtkhybinlx0kObprmmXYXAgAAAPrn9oeezd7fuKRqxrKLjs1Vh+9RNQMAAAAAAABgJDIK6b+bkuzXx/UVWl0EhpH3JNmulPKapmnuaXeZeVFK+ViSj7Ygau0WZAAAAEC/NU2TNQ+ZWD3nT5/bLasuvXD1HAAAAAAAAICRyCik/85N8vlZrpUkW7ehCwwnr0zyl1LKrk3T3NzuMvNguSQbtLsEAAAAtMPPL5+UI35f9/++f3TXtfO5fcZXzQAAAAAAAAAY6YxC+u+SJE8lWWL6/SY9o5DNSykrNU3zYLuKwSC4KcnVSW6cfrs/ydPTby8lWTrJMkmWT7Jtkl2S7Jhk8Xl8/WWTnFtK2bFpmnsHtzoAAAAwv554/qVscey51XPuOn7fLNDZUT0HAAAAAAAAYKQzCumnpmmmlVJ+mOSz6RmEzFCSvDnJ19tSDAamK8k5Sf6Q5Iymae6by/Mfnn67JclFSb5UShmX5F3p+W9inXnIXCnJb0spOzRN8+JAiwMAAACD603f+3Ou+tuTVTN+/cHtsu1ay1TNAAAAAAAAABhNfBzfwHw9yQu97s84LeSwUspS7akE/fJgkmOTrNE0zYSmab43D4OQPjVN82LTNN9Psn6Sg5NMnYdv2zzJCQPJAwAAAAbXZXc9ljW+cEbVQciO6yyTSSftZxACAAAAAAAAMMicFDIATdM8WEr5YpIvZ+bTQpZK8qUkH2xLMZh3qzVNM20wX7Bpmu4k3yylXJ7k1CSrz+VbPl5K+XHTNDcOZg8AAABg3rw0rTvrHX5m9ZzrjtwzSy68YPUcAAAAAAAAgNHIKGTgvpZkQpJd0zMMmXFayPtKKfc1TXNcG7vBHA32IGSW1/5rKeVVSS5NsuocnrpAkmOSvKFWl/n0aJJbWpCzdpKxLcgBAACAfzr+jFvygz/dWzXjxDdunLdss1rVDAAAAAAAAIDRzihkgJqm6S6lvCHJn5O8MjMPQ44upSyQ5JjppyfAqNI0zX2llP3T89/HnAYPryulrNs0zZ2taTbvmqb5bpLv1s4ppdycZIPaOQAAAJAkkx57Prt+9aKqGWM6S+44bt+UUqrmAAAAAAAAAJB0tLvAcNY0zdNJdktydXrGIMnLw5AjklxaSlmvTfWgrZqmuSbJCXN5WkeSt7egDgAAAIxqTdNkoy+eXX0Qct6nd8mdx08wCAEAAAAAAABoEaOQ+dQ0zSNJdkny6/zrMGS7JDeXUk4vpexR/DSc0efLSR6Zy3Pe1IoiAAAAMFr99uq/Z81DJua5KdOqZbxju9Uz6aT9ss7yi1bLAAAAAAAAAOBfLdDuAsNRKeVVfVz+XpJnknwgPaOQGcOQziSvnX57vpTy1yRXJLk/yZPTb1NaUDtN01zSihyYoWmaF0sppyQ5cg5P26CUsvz0gRUAAAAwSJ55cWo2Oeqc6jm3H7dPxi7QWT0HAAAAAAAAgH9lFDIwF6Vn9DE7vU8M6X1/0SS7Tb+1WhP/vGmPUzPnUUiSbJ/k9y3oAgAAAKPC+396Zc67te7nL/zkPVtn1/WXr5oBAAAAAAAAwJwZCcyfMg+Pzzg1ZF6/B0aUpmluLqU8kmROf0tkfIxCAAAAYL5d/bcn82/f+3PVjI1WWTx//PjOVTMAAAAAAAAAmDdGIfOnr9NCZh199L4/60CkVQxRaLdrk+w9h8fXaFEPAAAAGJG6upusfejE6jlXHrZHlltsbPUcAAAAAAAAAOaNUcj86e/Yoh3jjHaMUGBWk+by+JxOEQEAAADm4Jvn3Zmvn3dH1YzD93tl3r/zWlUzAAAAAAAAAOg/oxCgFZ6ey+MLt6QFAAAAjCD/eOqF7HDSBdVz7jlhQjo6HEQLAAAAAAAAMBQZhcwfp3DAvHlpLo+PaUkLAAAAGCF2/vIFuf+JF6pmnPGJnbLhyktUzQAAAAAAAABg/hiFDJyPR4R5t9BcHq/7t1gAAABghDjrpgfz4V9cUzVj/81WzjfevHnVDAAAAAAAAAAGh1HIwOzW7gIwzKw4l8efa0kLAAAAGKYmvzQtGxx5dvWcW47ZOwsv6I8MAQAAAAAAAIYLP+EdgKZpLm53Bxhm1pnL4w+0pAUAAAAMQ5/69XX53bV1/6/z9962RfbdeKWqGQAAAAAAAAAMPqMQoKpSytgkm83lafe2oAoAAAAMKzf/4+ns961Lq2a8YqmFcunnd6+aAQAAAAAAAEA9RiFAba9OMnYuz7mhFUUAAABgOOjubrLWoROr51z2hd2zypILVc8BAAAAAAAAoB6jEKC2d87l8alJrmxFEQAAABjq/vvSe3PsH2+pmnHwHuvm4D3Wq5oBAAAAAAAAQGsYhQDVlFLWTfKmuTztkqZpXmxFHwAAABiqHn12SrY+/rzqOXefMCGdHaV6DgAAAAAAAACtYRQC1PStJJ1zec6prSgCAAAAQ9Vrv31pbnzg6aoZv/3IDtly9aWqZgAAAAAAAADQekYhQBWllM8m2WcuT3smya9bUAcAAACGnIvveDTv+tFfq2bsPn75/OjdW1fNAAAAAAAAAKB9jEJglCilbJHk1qZpXmhB1ruSfHkennpy0zR1PwoVAAAAhpgp07qy/uFnVc+5/ot7ZYmFxlTPAQAAAAAAAKB9OtpdAGiZdya5u5TyiVLKIjUCSikLllK+keQnScpcnv5wki/V6AEAAABD1Rd/f1P1QchXD9g0k07azyAEAAAAAAAAYBRwUgiMLisl+WaSo0opP03yk6Zprh+MFy6l7JLkK0m2nsdv+UTTNE8NRjYAAAAMdXc98lz2+NrFVTMWHbtAbjxqr5Qyt89pAAAAAAAAAGCkMAqB0WmpJAcnObiUckeSPya5IMnlTdM8Ma8vUkpZMcmrk3wiyTb9yP920zSn9uP5AAAAMCw1TZN1Dzsz07qbqjkXfnbXrLlslYNBAQAAAAAAABjCjEJarJSySpKNk7wiySpJFk+yUJKxSWZ8jGPTNM372tOQUWi9JJ+efmtKKfcnuS3JpCQPJXkyyZTpz10qyTJJlkuy7fTv7a/Tp2cBAADAiPbrK+/L5397Y9WM9++0Zg5/zQZVMwAAAAAAAAAYuoxCKiulLJPkjUn2SrJLev5C/Ry/JUmTxCiEdihJVpt+q+HXSd7RNM20Sq8PAAAAbff05KnZ9Jhzqufccdy+WXCBjuo5AAAAAAAAAAxdRiGVlFK2S/KZJK9NMmbG5UpZr03y3dk8/LumaT5ZIxf6oSvJ4U3TnNTuIgAAAFDT23/4l1x612NVM/7n/dtmx3WWrZoBAAAAAAAAwPBgFDLISinrJPlWkr1nXOr1cDMvLzGA2IlJpiZZs4/H3lNKOaRpmskDeF0YDFcm+WDTNNe1uwgAAADU8td7n8iB37+8asaWqy+V335kh6oZAAAAAAAAAAwvRiGDqJTyqSTHJRmXl8cdsw5B5jT6mJfRyL9+U9N0lVK+np4xSu/XKEkWSfLGJL8YyGszolyb5J4ka7Uo75okJyT5f03TDOjfbQAAABjqpnV1Z53Dzqyec80Re2bpRRasngMAAAAAAADA8NLR7gIjQSllbCnlf5N8NclC6RljNHl5oFF63Wbo/fhg+EmS52bz2LsHMYdhqmmanzZNs3aS1dPz78SPktyQnlNmBstdSb6RZMumabZsmua3BiEAAACMVF89+/bqg5CjX7dhJp20n0EIAAAAAAAAAH1yUsh8KqWMS/L7JHvk5TFI8q8DkKqapnmulPLrJO/rlddM77FrKWXZpmkeq92Doa9pmvuS/HT6LaWUBZNslGSTJGsmWXX6bZUki6dn6LRwkrFJXkryYpKnkzyY5O9JbkvPuOSK6a8NAAAAI9r9T0zOzl++sHrOvSdOSClzOnQWAAAAAAAAgNHOKGT+/SrJnvnXk0GSmccgs/4Ef3J6TmhYIi+PN+bXL9IzCpmR17vPq5P8ehAyGGGapnkpyTXTbwAAAMAcbH38eXn02SlVM846eOeMX3HxqhkAAAAAAAAAjAwd7S4wnJVSjkjyusw8vph1EFLSc7LCL5N8MMn4JAs1TbNoks8OcqVLkjwyS/4MewxyFgAAAMCo8Yfr/5E1vnBG1UHIgVu9IpNO2s8gBAAAAAAAAIB55qSQASqlbJTkiMz+dJCS5Lkk30jyraZpHqvdqWmappRyVpJ39uox4xSSV9fOBwAAABhpnpsyLRt98ezqObcdu0/GjemsngMAAAAAAADAyGIUMnDfTs/v34zRRTLzIOTGJAc0TXNHi3udl55RyIweMzqtXkpZtWma+1vcBwAAAGBY+tj/XJMzbnywasYP3rlV9txghaoZAAAAAAAAAIxcRiEDUErZMcku+ddByIwRxoVJ9mua5sU21Lt8Do9tmMQoBAAAAGAObvj7U3nddy6rmrHWcovkgs/sWjUDAAAAAAAAgJHPKGRgDprlfu9ByG1J3timQUiaprm7lPJUkiXy8ikhM4xPclbLSwEAAAAMA93dTdY6dGL1nCsOeXVWXGJc9RwAAAAAAAAARj6jkH4qpSyS5LV5eXDRe3jRJHlr0zRPt7zYzG5Psm36HoUAAAAAMIvvXXR3vnTWbVUzPrfP+vnorutUzQAAAAAAAABgdDEK6b9XJVk4M58OMuPXXzdNc30bu81wV3pGIbNat9VFAAAAAIayh595MduecH71nHtOmJCOjlI9BwAAAAAAAIDRxSik/3aaw2NfbVmLOXuwj2slyTKtLgIAAAAwVO319Ytzx8PPVc34/cd2zKarLlk1AwAAAAAAAIDRyyik/zbu9XXT6+uHm6a5ttVlZuPRWe7POM1k8TZ0AQAAABhSzr/14bzvp1dVzdhnwxVzyju2rJoBAAAAAAAAAEYh/bdWZh6DlOn3L2hPnT5Nns31xVraAgAAAGAIeXFqV8YfcVb1nJuO3juLjvXHbgAAAAAAAADU56fT/bfCbK7f39IWc/bSbK4bhQAAAACj0iH/74b871/r/vHNN9+8WV6/2SpVMwAAAAAAAACgN6OQ/ltkNtcfbWmLOVt0NtdLS1sAAAAAtNkdDz+bvb5+SdWMZRZZMFcfsWfVDAAAAAAAAADoi1FI/42ZzfXJLW0xZ0vP5voLLW0BAAAA0CZN02TNQyZWz/nT53bLqksvXD0HAAAAAAAAAPpiFNJ/k9P3SRzLtLrIHCw1m+vPtbQFAAAAQBv8/Iq/5YjTb6qa8ZFd187n9xlfNQMAAAAAAAAA5sYopP+eT9+jkNmdztEOq89yv0z/9cFWFwEAAABolSeefylbHHtu9Zw7j983Yzo7qucAAAAAAAAAwNwYhfTfA0lWTNLMcn3NNnSZnR3yr/2aJPe1oQsAAABAdQec8udcOenJqhm/+uB22W6toXRYLAAAAAAAAACjnVFI/92bZMte95v0nMSxU3vqzKyUslGSpfJyr97jkNvbUgoAAACgkj/f9Vje+sO/VM3YYe1l8ssPbFc1AwAAAAAAAAAGwiik/25O8qbpX/ceXSxTStmgaZpb2lPrn/aZw2NXtqwFAAAAQEVTu7qz7mFnVs+57sg9s+TCC1bPAQAAAAAAAICBMArpv8vm8Nh7kvxHq4rMqpTSmeSgzHw6SG+Xt7AOAAAAQBUnTLw1/3XJPXUz3rBx3rrtalUzAAAAAAAAAGB+GYX03+VJpiRZMC+PL5r0nBrywVLKsU3TPNOmbgckWa1Xnxm/Jsk1TdM81KZeAAAAAPNt0mPPZ9evXlQ1o7Oj5K7j900pZe5PBgAAAAAAAIA2Mwrpp6Zpni+lnJlk/8w8vkiSRZMcmeSzre5VSlk8yXHp+5SQJsn/a20jAAAAgMHRNE02PfqcPPPitKo55336VVln+cWqZgAAAAAAAADAYOpod4Fh6hd9XJsxEDm4lLJvi/skyY+SrDX9695DlSSZluQnrS4EAAAAML/+3zV/z5qHTKw6CHn7dqtl0kn7GYQAAAAAAAAAMOw4KWRgTk9yV5K1M/NpIU16hjY/K6Xs3TTNNa0oU0o5LMkbe3X550PTr/2/pmkebEUXAAAAgMHwzItTs8lR51TPue3YfTJuTGf1HAAAAAAAAACoYdSOQkopCydZtq/Hmqa5b07f2zRNdynlhPSczjHjRI7ew5BlklxUSjmwaZqzBq/1zEopnUm+lORTmflkkFlPCTmqVgcAAACAwfb+n16Z8259pGrGj9+zdXZbf/mqGQAAAAAAAABQ26gdhSR5S5L/6uN6k3n4fWma5iellA8k2S4vn9DRexiyaJI/llJ+kuSwpmkeHqTeSZJSyvZJvpVki165fZ0S8v2maW4fzGwAAACAGq6578m88eQ/V83YYKXFM/GTO1fNAAAAAAAAAIBWGc2jkGTmEcVAfCDJX5IsnL6HIR1J3pPkgFLKz5P8ummaPw24bClLJNlveu6rZlzOzIOQptevdyc5ZKB5AAAAAK3Q1d1k7UMnVs/562GvzvKLjaueAwAAAAAAAACtMtpHIcnLI4qknyORpmlumX5ayC/z8hBk1mFISbJYko8k+Ugp5ZEk1ya5JcmKs3vtUsp7k4xLsnySNZJsmmTDJJ2zdO1rEFKSvJjkrU3TPN+f9wQAAADQSt86/8587dw7qmYcvt8r8/6d16qaAQAAAAAAAADtYBTSY8aIo9+apvlVKWW1JCdl9sOQGRlJskKSvaffMstjvX/9QR8dZ4qe5Xrv+11J3tY0zVX9fT8AAAAArfDg0y9k+xMvqJ5zzwkT0tExv4fFAgAAAAAAAMDQZBQyCJqm+XIppSQ5YcalvDwMmXG/vyeS9PWc2b1G70HItCTvb5rmd/OQAQAAANByu3zlwvzt8clVM/748Z2y0SpLVM0AAAAAAAAAgHYzChkkTdN8qZRyd5KfJFkoMw81Zh1wzMtAZHYnl8zpxJDnkry5aZqJ81gbAAAAoGXOuumhfPgXV1fNeP1mK+ebb968agYAAAAAAAAADBVGIYOoaZrflFJuTPKjJNtn5gFImeXXuZnb82Ydlvw1yduaprl7Hl8fAAAAoCVeeKkrrzzyrOo5txyzdxZe0B93AQAAAAAAADB6+Cn5IGua5vZSyk5J3pfk8CSrzXholqfO6zjkny/dx7WS5PEkRyU5pWmarn6+JgAAAEBVnz71uvy/ax6omnHy27bIhI1XqpoBAAAAAAAAAEORUUgFTdM0SX5YSvlpknck+UCSbXs/JX2PPOam95Dk3iQnJ/lB0zTPDLQrAAAAQA23/OOZTPjWn6pmrLLkQrnsC7tXzQAAAAAAAACAocwopKKmaaYm+VGSH5VS1kvymiT7JNk6yRL9fLmuJDcnOS/J75L8efr4BAAAAGDIaJomax4ysXrOZV/YPassuVD1HAAAAAAAAAAYyoxCWqRpmjuSfG36LaWUtZKMT7JqkpWTLJZkoSRjkkxJMjnJ40nuS3JPkhuappnc+uYAAAAA8+ZHl96bY/54S9WMT7563Xxqz/WqZgAAAAAAAADAcGEU0iZN09yTnrEHAAAAwLD22HNTstVx51XPuev4fbNAZ0f1HAAAAAAAAAAYLoxCAAAAYLB1dyWP3ZH847rkkVuSF59Kpk1Jul5KOhdMFhibjFsyWX6DZOXNk2XXTTo621waBub137k01//96aoZv/3I9tly9aWrZgAAAAAAAADAcGQUAgAAAPOraZJJlya3T0weuCZ56IZk6uR5//4xiyQrbpysskWy/oRkjZ2SUur1hUFwyR2P5p0/+mvVjF3XXy4/ec82VTMAAAAAAAAAYDgzCgEAAICBeuGp5PpfJVf9d8/JIAM19fnk/it6blecnCy7XrLV+5JN35wstORgtYVBMWVaV9Y//KzqOdd/ca8ssdCY6jkAAAAAAAAAMJwZhQAAAEB/PXFPcuk3khtP69+JIPPqsTuSsz6fnH90svEByU4HJ0uvNfg50E9H/d/N+cmfJ1XN+OoBm+ZNW76iagYAAAAAAAAAjBRGIQAAADCvuqYll387ufDEpGtK/bypk5NrftpzGsluhyY7fDzp6KyfC7O4+9Hn8ur/vLhqxsILdubmo/dOKaVqDgAAAAAAAACMJEYhAAAAMC8evT05/SPJA1e3PrtrSnLeF5Nb/5Dsf3Ky3Pqt78Co1DRN1j/8rLzU1V0158LP7po1l12kagYAAAAAAAAAjEQd7S4AAAAAQ1p3d3LZN5NTdm7PIKS3B67q6XHZN3t6QUW/vvK+rHnIxKqDkPfuuGYmnbSfQQgAAAAAAAAADJCTQgAAAGB2uqYmp380ufHUdjd5WdeU5Nwjk4du6jk1pHNMuxsxwjw9eWo2Peac6jl3HLdvFlzA55UAAAAAAAAAwPwwCgEAAIC+TH0xOe3dyR1ntrtJ3248NZnybHLAT5Ix49rdhhHiHf/9l/zpzseqZvzifdtmp3WXrZoBAAAAAAAAAKOFUUgfSik/aneHCpqmad7X7hIAAADDQtfUoT0ImeGOM5PfvCc58GdODGG+XDnpiRxwyuVVM7ZYbcn8v4/uWDUDAAAAAAAAAEYbo5CXlV6/vqudRSooSZokRiEAAABz092dnP7RoT8ImeH2iT193/D9pKOj3W0YZqZ1dWedw+r/u3714XtkmUXHVs8BAAAAAAAAgNHGKKRvZe5PAQAAYES6/NvJjae2u0X/3HhqsuLGyY6faHcThpH/POf2fPuCu6pmHP26DfOuHdaomgEAAAAAAAAAo5lRSN+adhcYZEYuAAAA8+LR25MLjm93i4G54Lhkvb2T5dZvdxOGuPufmJydv3xh9Zx7T5yQUvyRBAAAAAAAAADUZBTSt5H0NxZG2sAFAACgjq5pyekfSbqmtLvJwHRNSU7/aPK+c5KOzna3YYja9oTz8vAzdf8dP+vgnTN+xcWrZgAAAAAAAAAAPTraXQAAAACGhMu/kzxwdbtbzJ8Hrkr+/O12t2AI+uMN/8gaXzij6iDkgC1fkUkn7WcQAgAAAAAAAAAt5KSQvjldAwAAYDR54p7kwhPa3WJwXHhCssHrkqXXancThoDnp0zLhl88u3rOrcfsk4UWdEINAAAAAAAAALSaUUjfSrsLAAAA0EKXfiPpqneCQkt1Tel5P6/7Vrub0GYf++U1OeOGB6tm/Nc7tsxeG65YNQMAAAAAAAAAmD2jkJc16RmDNEl+1uYuAAAAtMoLTyU3ntbuFoPrxtOSvY5Nxi3R7ia0wY1/fzqv/c6lVTPWWnaRXPDZXatmAAAAAAAAAABzZxTSh6Zp3tPuDgAAALTI9b9Kpk5ud4vBNXVyz/va9kPtbkILdXc3WevQidVzrjjk1VlxiXHVcwAAAAAAAACAuetodwEAAABom6ZJrvxhu1vUceUPe94fo8L3L767+iDkP/ZeP5NO2s8gBAAAAAAAAACGECeFAAAAMHpNujR5/M52t6jjsTuSv12WrLFTu5tQ0SPPvJhtTji/es7dJ0xIZ0epngMAAAAAAAAA9I9RCAAAAKPX7XVPVmi72yYahYxge3/9ktz+8LNVM07/2I7ZbNUlq2YAAAAAAAAAAANnFAIAAMDo9cA17W5Q1z9G+PsbpS647eG89ydXVc3Ye8MV8v13bFU1AwAAAAAAAACYf0YhAAAAjE7dXclDN7S7RV0P3tDzPjs6292EQfDi1K6MP+Ks6jk3HrVXFhs3pnoOAAAAAAAAADD/jEIAAAAYnR67I5k6ud0t6pr6fPLYncny49vdhPl06O9uzC//cl/VjG/8+2bZf/NVqmYAAAAAAAAAAIPLKAQAAIDR6R/XtbtBazx4nVHIMHbHw89mr69fUjVjqYXH5Noj96qaAQAAAAAAAADUYRQCAADA6PTILe1u0Bqj5X2OME3TZM1DJlbPueQ/dstqyyxcPQcAAAAAAAAAqMMoBAAAgNHpxafa3aA1Xniq3Q3op19c8bccfvpNVTM+vMva+cK+TpABAAAAAAAAgOHOKAQAAIDRadqUdjdojdHyPkeAJ59/KZsfe271nDuP3zdjOjuq5wAAAAAAAAAA9RmFAAAAMDp1vdTuBq3RZRQyHBz4/cvz13ufqJrxvx/YLtuvvUzVDAAAAAAAAACgtYxCAAAAGJ06F2x3g9boHNvuBszBn+9+LG/9wV+qZmy31tL51Qe3r5oBAAAAAAAAALSHUQgAAACj0wKjZCwxWt7nMDO1qzvrHnZm9Zxrj9gzSy0ySgZQAAAAAAAAADAKGYUAAAAwOo1bst0NWmOhJdvdgFmcOPHWfP+Se6pmHP+GjfK2bVevmgEAAAAAAAAAtJ9RCAAAAKPT8hu0u0FrjJb3OQz87fHns8tXLqqaUUpyzwkTUkqpmgMAAAAAAAAADA1GIQAAAIxOK2/W7gatsdJm7W5Akk2PPidPvzC1asa5n3pV1l1hsaoZAAAAAAAAAMDQYhQCAADA6LTsesmYhZOpk9vdpJ4xiyTLrtvuFqPa7679ez716+urZrxt29Vy/Bs2rpoBAAAAAAAAAAxNRiEAAACMTh2dyYqbJPdf0e4m9ay0Sc/7pOWefXFqNj7qnOo5tx27T8aN8c8YAAAAAAAAAEYro5AeTbsLAAAA0AarbDGyRyErb9HuBqPSB352Vc695eGqGT9+99bZbfzyVTMAAAAAAAAAgKHPKCQp7S4AAABAm6w/Ibni5Ha3qGf8hHY3GFWuve/JvOHkP1fNGL/iYjnr4FdVzQAAAAAAAAAAho/RPAo5I8lu7S4BAABAG62xU7LMusnjd7a7yeBbdr1k9R3b3WJU6OpusvahE6vn/PWwV2f5xcZVzwEAAAAAAAAAho9ROwppmuahJA+1uwcAAABtVEqy9fuTsz7f7iaDb+v397w/qvr2+XfmP8+9o2rGYRNemQ+8aq2qGQAAAAAAAADA8DRqRyEAAACQJNn0zcn5RydTJ7e7yeAZs3DP+6KaB59+IdufeEH1nHtOmJCODuMeAAAAAAAAAKBvRiEAAACMbgstmWx8QHLNT9vdZPBsfEAybol2txixdv3KhZn0eN0R0R8/vlM2WsU/QwAAAAAAAABgzjraXQAAAADabqeDk86x7W4xODrH9rwfBt3ZNz+UNb5wRtVByGs3XTmTTtrPIAQAAAAAAAAAmCdOCgEAAICl10p2OzQ574vtbjL/dju05/0waF54qSuvPPKs6jk3H713Fhnrj2oAAAAAAAAAgHnnbxoAAABAkmx/UHLr/yUPXN3uJgO3ylbJDh9vd4sR5TOnXp/fXvP3qhnffesW2W+TlapmAAAAAAAAAAAjk1EIAAAAJEnnAsn+30tO2TnpmtLuNv3XOTbZ/+Sko7PdTUaEW/7xTCZ8609VM1ZaYlwuP+TVVTMAAAAAAAAAgJHNKAQAAABmWG79ZPfDknOPbHeT/tv98J7+zJemabLmIROr51z6+d3yiqUWrp4DAAAAAAAAAIxsHe0uAAAAAEPK9h9PNj6w3S36Z+MDk+0PaneLYe/Hl91bfRDyid3XyaST9jMIAQAAAAAAAAAGhZNCAAAAoLeOjmT/k5MpzyZ3nNnuNnO3/oSevh0+92GgHntuSrY67rzqOXcdv28W6PTPCQAAAAAAAAAYPEYhAAAAMKvOMckBP0lOe/fQHoasPyF50497+jIgr//uZbn+/qeqZvzmw9tnqzWWrpoBAAAAAAAAAIxOPp4SAAAA+jJmXPLvP082PrDdTfq28YHJgT/r6Um//enOR7PGF86oOgjZZb3lMumk/QxCAAAAAAAAAIBqnBQCAAAAs9M5JnnD95MVN0ouOD7pmtLuRknn2GT3w5PtD0o6fNZDf700rTvrHV7/9Jfrv7hXlljICS4AAAAAAAAAQF1GIQAAADAnHR3Jjp9M1tsnOf0jyQNXt6/LKlsl+5+cLLd++zoMY0f/4eb8+LJJVTO+/KZNcuBWq1bNAAAAAAAAAACYwSgEAAAA5sVy6yfvPSe5/DvJhSe09tSQzrHJ7odNPx2ks3W5I8Q9jz6X3f/z4qoZC43pzC3H7J1SStUcAAAAAAAAAIDejEIAAABgXnUukOx0cLLB65JLv5HceFoydXK9vDELJxsf0JO59Fr1ckaopmky/oizMmVad9WcCz6zS9ZabtGqGQAAAAAAAAAAfTEKAQAAgP5aeq3kdd9K9jo2uf5XyZU/TB67Y/Bef9n1kq3fn2z65mTcEoP3uqPIqVfdn8/95oaqGe/ZcY188bUbVs0AAAAAAAAAAJgToxAAAAAYqHFLJNt+KNnmg8nfLktum5j845rkwev7d4LImEWSlTZJVt4iGT8hWX3HpJR6vUewp1+Ymk2PPqd6zh3H7ZsFF+iongMAAAAAAAAAMCdGIQAAADC/SknW2KnnliTdXcljdyYPXpc8ckvywlPJtClJ15Skc2yywNhkoSWT5TdIVtosWXbdpKOzff1HiHf+6K+55I5Hq2b8/H3bZOd1l6uaAQAAAAAAAAAwr4xCAAAAYLB1dCbLj++5Ud1Vk57Im065vGrGZqsumdM/tmPVDAAAAAAAAACA/jIKAQAAAIalaV3dWeewM6vnXH34Hllm0bHVcwAAAAAAAAAA+ssoBAAAABh2vnbuHfnW+XdWzTjqtRvk3TuuWTUDAAAAAAAAAGB+GIUAAAAAw8bfn5ycnb50YfWce0+ckFJK9RwAAAAAAAAAgPlhFAIAAAAMC9ufeH4efPrFqhlnfnLnvHKlxatmAAAAAAAAAAAMFqMQAAAAYEg744YH87FfXlM149+2eEX+88BNq2YAAAAAAAAAAAw2oxAAAABgSHp+yrRs+MWzq+fcesw+WWjBzuo5AAAAAAAAAACDzSgEAAAAGHIO+uU1+eMND1bN+P47tszeG65YNQMAAAAAAAAAoCajEAAAAGDIuOmBp/Oab19aNWPNZRfJhZ/dtWoGAAAAAAAAAEArGIUAAAAAbdfd3WStQydWz7n8kN2z0hILVc8BAAAAAAAAAGgFoxAAAACgrf7rkrtzwsTbqmZ8dq/1ctDu61bNAAAAAAAAAABoNaMQAAAAoC0eefbFbHP8+dVz7j5hQjo7SvUcAAAAAAAAAIBWMwoBAAAAWm6fb1yS2x56tmrG7z66QzZfbamqGQAAAAAAAAAA7WQUAgAAALTMhbc9kvf85MqqGXtusEJ+8M6tqmYAAAAAAAAAAAwFRiEAAABAdS9O7cr4I86qnnPjUXtlsXFjqucAAAAAAAAAAAwFRiEAAABAVYf+7sb88i/3Vc34xr9vlv03X6VqBgAAAAAAAADAUGMUAgAAAFRx58PPZs+vX1I1Y8mFx+S6I/eqmgEAAAAAAAAAMFQZhQAAAACDqmmarHnIxOo5F//Hrll9mUWq5wAAAAAAAAAADFVGIQAAAMCg+Z+//C2H/e6mqhkf2mWtHLLvK6tmAAAAAAAAAAAMB0YhAAAAwHx78vmXsvmx51bPufP4fTOms6N6DgAAAAAAAADAcGAUAgAAAMyXN//X5bninieqZvzyA9tmh7WXrZoBAAAAAAAAADDcGIUAAAAAA3L53Y/nLT+4omrGtmsunV9/aPuqGQAAAAAAAAAAw5VRCAAAANAvU7u6s+5hZ1bPufaIPbPUIgtWzwEAAAAAAAAAGK6MQgAAAIB5dtKZt+WUi++umnHc/hvl7dutXjUDAAAAAAAAAGAkMAoBAAAA5uq+xyfnVV+5sHrOvSdOSCmleg4AAAAAAAAAwEhgFAIAAADM0ebHnJMnJ0+tmnHup16VdVdYrGoGAAAAAAAAAMBIYxQCAAAA9On0ax/Iwb++rmrGW7ZZLSe+ceOqGQAAAAAAAAAAI5VRCAAAADCTZ1+cmo2POqd6zm3H7pNxYzqr5wAAAAAAAAAAjFRGIQAAAMA/ffBnV+WcWx6umvGjd2+V3cevUDUDAAAAAAAAAGA0MAoBAAAAct39T2X/715WNWP8iovlrINfVTUDAAAAAAAAAGA0MQoBAACAUayru8nah06snvPXQ1+d5RcfVz0HAAAAAAAAAGA0MQoBAACAUeq7F96Vr5x9e9WMQ/Ydnw/tsnbVDAAAAAAAAACA0cooBAAAAEaZh55+MdudeH71nHtOmJCOjlI9BwAAAAAAAABgtDIKAQAAgFFk969elHsee75qxh8O2ikbv2KJqhkAAAAAAAAAABiFAAAAwKhwzs0P5YM/v7pqxms2WSnfeesWVTMAAAAAAAAAAHiZUQgAAACMYC+81JVXHnlW9Zybj947i4z1xwwAAAAAAAAAAK3kb2sAAADACPUfp12f067+e9WM77x187xmk5WrZgAAAAAAAAAA0DejEAAAABhhbn3wmez7zT9VzVhh8bH5y6F7VM0AAAAAAAAAAGDOjEIAAABghGiaJmseMrF6zqWf3y2vWGrh6jkAAAAAAAAAAMyZUQgAAACMAD+57N4c9YdbqmZ8Yvd18um91q+aAQAAAAAAAADAvDMKAQAAgGHs8eemZMvjzquec9fx+2aBzo7qOQAAAAAAAAAAzDujEAAAABim3nDyZbn2vqeqZpz24e2z9RpLV80AAAAAAAAAAGBgjEIAAABgmPnTnY/mHf/916oZO6+7bH7+vm2rZgAAAAAAAAAAMH+MQgAAAGCYeGlad9Y7/MzqOdcfuVeWWHhM9RwAAAAAAAAAAOaPUQgAAAAMA8f84Zb86LJ7q2Z8+d82yYFbr1o1AwAAAAAAAACAwWMUAgAAAEPYPY8+l93/8+KqGQsu0JHbj90npZSqOQAAAAAAAAAADC6jEAAAABiCmqbJBkeenRemdlXNOf8zu2Tt5RatmgEAAAAAAAAAQB1GIQAAADDEnHbV/fmP39xQNePdO6yRo163YdUMAAAAAAAAAADqMgoBAACAIeLpF6Zm06PPqZ5z+3H7ZOwCndVzAAAAAAAAAACoyygEAAAAhoB3//ivuej2R6tm/Oy92+RV6y1XNQMAAAAAAAAAgNYxCgEAAIA2uvpvT+Tfvnd51YxNX7FEfn/QTlUzAAAAAAAAAABoPaMQAAAAaINpXd1Z57Azq+dcdfgeWXbRsdVzAAAAAAAAAABoPaMQAAAAaLGvn3tHvnn+nVUzjnzNBnnvTmtWzQAAAAAAAAAAoL2MQgAAAKBFHnjqhex40gXVc+49cUJKKdVzAAAAAAAAAABoL6MQAAAAaIEdTjw//3j6xaoZEz+xczZYefGqGQAAAAAAAAAADB1GIQAAAFDRxBsfzEf/55qqGW/cYpV87cDNqmYAAAAAAAAAADD0GIUAAABABZNfmpYNjjy7es6tx+yThRbsrJ4DAAAAAAAAAMDQYxQCAAAAg+wT/3tt/u/6f1TNOOXtW2afjVasmgEAAAAAAAAAwNBmFAIAAACD5KYHns5rvn1p1YzVl1k4F//HblUzAAAAAAAAAAAYHoxCAAAAYD41TZP1Dz8rL3V1V825/JDds9ISC1XNAAAAAAAAAABg+DAKAQAAgPlw3i0P5/0/u6pqxmf2XC8ff/W6VTMAAAAAAAAAABh+jEIAAABgAJ5+YWo2Pfqc6jl3nzAhnR2leg4AAAAAAAAAAMOPUQgAAAD004kTb833L7mnasb/++gO2WK1papmAAAAAAAAAAAwvBmFAAAAwDy6+R9PZ79vXVo1Y49XrpAfvmurqhkAAAAAAAAAAIwMRiEAAAAwF1O7urPvN/+Uux55rmrOjUftlcXGjamaAQAAAAAAAADAyGEUAgAAAHPw6yvvy+d/e2PVjK8duGneuMUrqmYMZV3dXbn36XtzyxO35K4n78ozLz2TKV1TMrV7asZ0jMnYzrFZfMHFs85S62TDZTbMGouvkc6OznbXBgAAAAAAAABoO6MQAAAA6MNDT7+Y7U48v2rG4uMWyPVf3CullKo5Q03TNLnq4atywX0X5ObHb85tT9yWF6a9MM/fv9ACC2X80uOz4TIbZvfVds9WK2w16n4PAQAAAAAAAAASoxAAAACYSdM0+fj/Xps/3vBg1ZyLPrtr1lh2kaoZQ80zLz2TP9z9h/z69l/n3qfvHfDrvDDthVz7yLW59pFr84tbf5E1l1gz/77+v+e1a782iy+4+CA2BgAAAAAAAAAY2oxCAAAAYLpL73wsb//vv1TN+NCr1sohE15ZNWOouf+Z+/PfN/13Jt47sV8ngsyre5++Nyf99aR885pvZsKaE/K+jd6XVRdfddBzAAAAAAAAAACGGqMQAAAARr3np0zL1sefl8kvdVXNufP4fTOms6NqxlAyrXtafnrzT3PydSfnpe6Xque9MO2F/PbO3+YPd/8hH9v8Y3nXBu9KZ0dn9VwAAAAAAAAAgHYxCgEAAGBU++Z5d+br591RNeOX7982O6yzbNWMoeaep+7J4Zcdnhsfu7Hl2S91v5SvX/31nP+383PsjsdmrSXXankHAAAAAAAAAIBWMAoBAABgVLrz4Wez59cvqZrxid3Xyaf3Wr9qxlDT3XTnpzf/NN+59jstOR1kTm547IYc8IcDctDmB+VdG74rHWX0nNICAAAAAAAAAIwORiEAAACMKl3dTf7te3/Odfc/VS1jwQU6cs0Re2bRsaPr/3ZP7Z6aIy47Imfcc0a7q/zTS90v5WtXfy23P3l7jt3x2IzpGNPuSgAAAAAAAAAAg2Z0/e0UAAAARrXfX/dAPvmr66pm/PS922SX9ZarmjEUTemaks9e9Nlc9PeL2l2lT2fcc0aef+n5fHXXr2Zs59h21wEAAAAAAAAAGBRGIQAAAIx4jz03JVsdd17VjH03WjEnv22LlFKq5gxFU7unDulByAwX/f2ifPbiz+Zru37NiSEAAAAAAAAAwIjQ0e4CAAAAUNPnf3ND9UHIn7+we7739i1H5SCku+nOEZcdMeQHITNcdP9FOeKyI9LddLe7CgAAAAAAAADAfHNSCAAAACPSlZOeyAGnXF414/g3bJS3bbt61Yyh7qc3/zRn3HNGu2v0yxn3nJHxS43Puzd6d7urAAAAAAAAAADMF6MQAAAARpQXp3Zlpy9dmMeem1ItY63lFslZn3xVFvz/7N13lJ11vfbh+5lJhxRCL6GFGjqE3qsKghVFVBBFRQH1iF3AAigqFhSwooANxIIiiPTeeyB0EnoLEAKkzzzvH4H3cBQyKfObPXv2da0166zFftif7yyVCevMvXa/1v4AzgcnP5gTbjmh0WcskJ/c8pNst8J2WXXEqo0+BQAAAAAAAABggbX2b68AAADQp/zy8gez1hHnFR2EnH3INrn4sB1afhAyu3N2Dr/q8MzsnNnoUxbIzM6ZOeKqI9LR2dHoUwAAAAAAAAAAFphPCgEAAKDpTZz0cnY47tKijY9ss0qOeOuYoo1mctr40zJu0rhGn7FQbp90e04df2o+vO6HG30KAAAAAAAAAMACMQoBAACgaXV21vngr6/LVfc/W7Rz25G7ZfiQ/kUbzeSRKY/kxFtObPQZ3eLEW07MrivumlHDRjX6FAAAAAAAAACA+dbW6AMAAABgQfz7ziez6lfOLToI+cUHN8nEY/cwCPkPJ99xcmZ2zmz0Gd1iZufMnHzHyY0+AwAAAAAAAABggfikEAAAAJrK5Kkzs+E3Lyja2Hb1JXLqAZulra0q2mlGU2ZOybkTzm30Gd3q3Ann5rCxh2XogKGNPgUAAAAAAAAAYL4YhQAAANA0vnn2+Pz6qglFG5d9foestPgiRRvN7OwHzs602dMafUa3mjZ7Wv7xwD/y/rXf3+hTAAAAAAAAAADmi1EIAAAAvd7tj07OXidcVbRx+B5r58BtVy3aaHZ1Xef0u09v9BlFnHHPGdl3rX1TVT4dBgAAAAAAAABoHkYhAAAA9FozZ3fmTT+6PBMmvVyssdTQgbn8CztmUP/2Yo2+4sanbszEKRMbfUYRE16YkBufujGbLrNpo08BAAAAAAAAAJhnRiEAAAD0Sr+79qEcftYdRRt/PmjLjF15ZNFGX3Lxwxc3+oSiLnnkEqMQAAAAAAAAAKCpGIUAAADQqzw2eVq2Prbs+GCfTUfl2HetX7TRF9357J2NPqGoOyf17e8PAAAAAAAAAOh7jEKAeVJV1cAkayRZIcnQJEOSTE3yYpJHk9xT1/XMxl0IAECzq+s6H//tTTl//FNFOzcevkuWWHRg0UZf1NHZkbufu7vRZxR113N3paOzI+1t7Y0+BQAAAAAAAABgnhiFAG+oqqotkrw9yVuSrJNkbr8Z1VFV1Z1Jzk3y97qury1/IQAAfcVl9z6T/X99fdHG8ftsmLdtuHzRRl824YUJmTZ7WqPPKGra7GmZOGViRo8Y3ehTAAAAAAAAAADmiVEI8F+qqtonyeeTbDwff1t7kvVf+fpSVVU3JfleXddnFDgRAIA+4sXps7LxURdkVkddrLHxiiNy5kFbpb2tKtZoBeOfG9/oE3rE+GfHG4UAAAAAAAAAAE3DKAT4/6qqWivJz5Ns1w1vt0mS06uqOijJQXVd39MN7wkAQB/y/fPvyU8uvr9o48LPbpfVlhpatNEq7n++7H9WvcV9k+9r9AkAAAAAAAAAAPPMKARIklRV9c4kpyZZtJvfeockN1ZVtV9d13/r5vcGAKAJ3f3klLz5R1cUbXx21zXyqZ1XL9poNVNmTmn0CT1iyozW+D4BAAAAAAAAgL7BKARIVVUHJ/lJkqpQYtEkf6mq6pC6rk8q1AAAoJeb3dGZt514Ve58vNwv3S86sF+u+8rOWWSgf93tbjM6ZjT6hB4xs2Nmo08AAAAAAAAAAJhnfksGWlxVVfun7CDk/6eSnFBV1Ut1XZ9WuAUAQC/zl5sezWFn3la08fsDN8/Wqy1RtNHKZnXOavQJPWJmp1EIAAAAAAAAANA8jEKghVVVtVmSX2beBiFXJ/nDK/93YpIXkwxNsmqSrZK8P8nmXSWT/LKqqrvqur5hAc8GAKCJPP3i9Gx2zEVFG3ttsFyO32fDVFXpnXNr69/Wv9En9IgBbQMafQIAAAAAAAAAwDwzCoEWVVXVsCSnJ+nqN7vuS/KJuq5f7zf5nk9y0ytfP6mqarckJyUZPZf3G5DkjKqqNqzresr8Xw4AQDOo6zqH/em2/PWWx4p2rv3yzllm+KCiDeYY2D6w0Sf0iAHtRiEAAAAAAAAAQPMwCoHW9c0kq3TxzIVJ3l3X9Qvz8oZ1XZ9fVdXYJH9NsuNcHl0lydeTfHZe3hcAgOZy7YPPZp9fXFu08d13rZ/3bDqqaIP/a9iAYY0+oUcMG9ga3ycAAAAAAAAA0DcYhUALqqpqTJKDu3jsmiRvq+t66vy8d13Xk6uq2jPJxUk2m8ujh1ZV9cu6ru+an/cHAKD3mjazI1t8+6K8MG1WscZaywzN2Yduk/7tbcUavL7VFlut0Sf0iNVHrN7oEwAAAAAAAAAA5plRCLSmr2Xu//t/Lsl753cQ8qq6rl+uquo9SW5NMuINHuuX5Mgk71uQBgAAvctJl96f7553T9HGOZ/aJussN7xogzc2ZuSYRp/QI8Ys3hrfJwAAAAAAAADQNxiFQIupqmrVJO/q4rHD67p+ZGE6dV0/VFXV15IcP5fH9q6q6st1XU9cmBYAAI3zwDMvZefvX1a0cdD2o/Olt6xVtEHXVhm+Sgb3G5xps6c1+pRiBvcbnJWHrdzoMwAAAAAAAAAA5llbow8AetzBSdrn8vp9SX7RTa2Tkjw4l9fbX7kHAIAm09lZ5z0/v6b4IOT2r+9mENJLtLe1Z62Rffs/i7VHrp32trn96xIAAAAAAAAAQO9iFAItpKqq9iTv6+KxH9Z13dEdvbquZyf5cReP7VtVlX8WAQA0kXPHPZFVv3Jurp/wXLHGrz80NhOP3SPDBvUv1mD+rbP4Oo0+oah1lujb3x8AAAAAAAAA0Pf4RWxoLTslWXYur09P8rtubp6aZOZcXl8uyQ7d3AQAoIDnXp6Zlb90Tj75+5uLNXZaa6lM+Pbu2WmtpYs1WHA7rbhTo08oasdROzb6BAAAAAAAAACA+dKv0QcAPWrPLl4/p67rF7szWNf15Kqq/pXkbXN5bM8kF3dnFwCA7nXEWXfkt9c+VLRxxRd2zKiRQ4o2WDhjlx6blYetnIlTJjb6lG63yvBVMnbpsY0+AwAAAAAAAABgvvikEGgtu3Tx+jmFul29766FugAALKRbHn4+K3/pnKKDkK/vOSYTj93DIKQJVFWVfdbap9FnFPHeNd+bqqoafQYAAAAAAAAAwHzxSSHQIqqqWjbJ2l08dmGh/AVdvL5OVVXL1HX9ZKE+AADzacbsjux03GV5bPK0Yo3lRwzOxZ/bPgP7tRdr0P32HL1njr/5+EybXe6/Gz1tcL/B2Wv0Xo0+AwAAAAAAAABgvvmkEGgdm3Xx+iN1XT9SIlzX9cQkT3Tx2KYl2gAAzL9TrpqQNQ8/r+gg5G+f3CpXfWkng5AmNGzAsOy+yu6NPqNb7b7K7hk6YGijzwAAAAAAAAAAmG9GIdA6Nu7i9ZsL92/s4vWNCvcBAOjCI89NzcpfOidfP3t8scZ+W66UicfukY1WXKxYg/I+su5HMqBtQKPP6BYD2gbkI+t+pNFnAAAAAAAAAAAsEKMQaB0bdvH67YX7Xb2/UQgAQIPUdZ0Pn3JDtv3uJUU7Nx+xa775tnWLNugZo4aNysEbHdzoM7rFwRsdnFHDRjX6DAAAAAAAAACABdKv0QcAPWaNLl6/r3D//i5eX71wHwCA13Hx3U/lw6d09aFuC+fEfTfOHusvW7RBz9tvzH658KELM27SuEafssDWX2L97D9m/0afAQAAAAAAAACwwIxCoAVUVVUlWbmLx7oabSysrt5/5cJ9AABe44Vps7LBN84v2th8lZH540e3SFtbVbRDY/Rr65ejtz46e5+9d2Z2zmz0OfNtQNuAHLX1UWlva2/0KQAAAAAAAAAAC6yt0QcAPWLpJIO6eObxwjd09f6LVFW1VOEbAABI8u1/3VV8EHLxYdvnjI9vaRDSx606YtUcstEhjT5jgRy60aFZdcSqjT4DAAAAAAAAAGCh+KQQaA3LzcMzTxa+YV7ef7kkTxe+AwCgZd35+AvZ48dXFm184c1r5pM7rFa0Qe+y/zr7557n78k5D57T6FPm2R6r7pH91tmv0WcAAAAAAAAAACw0oxBoDYt38fqUuq5nlDygruupVVW9lGTRuTzW1Z0AACyAWR2d2ePHV+Tep14q1lhsSP9c/aWdM3hAe7EGvVNb1Zajtj4qL898OZc+emmjz+nSDqN2yFFbH5W2yoenAgAAAAAAAADNzygEWsPILl6f0iNXzOnMbRTS1Z09pqqqg5N8sgdSo3ugAQC0sDNueDhf/Mu4oo3TP7ZFtljVvreV9W/rn+N2OC6fu/RzvXoYssOoHXLc9self1v/Rp8CAAAAAAAAANAtjEKgNSzWxesv9sgVXXd6zSgkyZJJxjT6CACABfXkC9OzxbcvKtp418Yr5Li9109VVUU7NIeB7QPzgx1/kCOuOiLnPHhOo8/5L3usukeO2voogxAAAAAAAAAAoE8xCoHWMKiL11/ukSuSl7p4vas7AQDoQl3XOfSPt+Sftz9RtHP9V3fOUkP98Y3/q39b/3xrm29lzcXWzAm3nJCZnTMbfVIGtA3IoRsdmv3W2S9tVVujzwEAAAAAAAAA6FZGIdAaBnTx+uweuaLrTld3AgAwF1fdPynv/9V1RRvf33uDvGuTFYo2aG5tVVsOWPeAbL/C9jn8qsMzbtK4ht2y/hLr56itj8qqI1Zt2A0AAAAAAAAAACUZhUBrMAoBAOjDXp4xO5sdc2FentlRrLHu8sNy1ie3Tr92n7TAvFl1xKo57S2n5bTxp+XEW07s0U8NGdA2IIdsdEj2G7Nf2tvae6wLAAAAAAAAANDTjEKgNXT1m3vlfntw/jp+WwsAYD4df+F9+eGF9xZtnPeZbbPWMsOKNuib+rX1y4fX/XB2XXHXnHzHyTl3wrmZNntasd7gfoOz+yq75yPrfiSjho0q1gEAAAAAAAAA6C2MQqA1dPUJHT31z4KuOrN65Ip580yS8T3QGZ1kYA90AIA+5v6nX8wuP7i8aOPQnVbLYbutWbRBaxg1bFS+vtXXc9jYw/KPB/6RM+45IxNemNBt77/K8FXy3jXfm71G75WhA4Z22/sCAAAAAAAAAPR2RiHQGmZ28XpP/bOgfxevd3Vnj6nr+sQkJ5buVFV1Z5IxpTsAQN/R0Vnn3T+7Orc8PLlYo397lZuP2DVDB3X1xzeYP0MHDM37135/9l1r39z41I255JFLcuekO3PXc3fN1yeIDO43OGuPXDvrLLFOdhy1Y8YuPTZVVRW8HAAAAAAAAACgdzIKgdbQ1SdwDOiRK5poFAIA0Bv9/dbH8unTby3aOOWATbPDmksVbUBVVdl0mU2z6TKbJkk6OjsyccrEjH92fO6bfF+mzJiSmR0zM7NzZga0DciA9gEZNnBYVh+xesYsPiYrD1s57W3tDf4uAAAAAAAAAAAazygEWsNLXby+aI9ckQzt4vWu7gQAaEmTXpqRsUdfWLTx5nWWyU8/sLFPW6Ah2tvaM3rE6IweMbrRpwAAAAAAAAAANBWjEGgNz3Xx+rAeuaLrTld3AgC0nC//9fb88fpHijau+tJOWX7E4KINAAAAAAAAAACg+xmFQGt4tovXR/TEEUmGd/F6V3cCALSMGyc+l3f/7JqijaPfvm4+sMVKRRsAAAAAAAAAAEA5RiHQGiZ18frAqqpG1HU9udQBVVWNTDKgi8eMQgCAljd9Vke2++4lefrFGcUaqyyxSP79me0yoF9bsQYAAAAAAAAAAFCeUQi0hofn4Zmlk0wueMPS8/DMvNwJANBn/eqKB3P0OXcVbfzjkK2z/gojijYAAAAAAAAAAICeYRQCLaCu65eqqno2yeJzeWylJPcUPGPlLl5/uq7rlwv2AQB6rYeefTnbf+/Soo0Pb71KjtxzTNEGAAAAAAAAAADQs4xCoHVMyNxHIasnOb9gf7UuXp9QsA0A0Ct1dtbZ/zfX54r7JhXt3HrkrhkxZEDRBgAAAAAAAAAA0POMQqB13Jlk7FxeX7Nwv6v3v7NwHwCgVzn/zifzsd/eVLTx8w9ukjets0zRBgAAAAAAAAAA0DhGIdA6bk6y/1xe36hwf+MuXr+lcB8AoFd4YeqsbPDNkh/Qlmy7+hI59YDN0tZWFe0AAAAAAAAAAACNZRQCrePmLl7fsKqq9rquO7o7XFVVvyQbdPGYUQgA0Ocd9c/xOfnKCUUbl31+h6y0+CJFGwAAAAAAAAAAQO9gFAKt48Yk05MMeoPXF02ySZLrC7Q3SzJkLq9PT3JTgS4AQK8w7tEXsucJVxZtfHX3tfPR7VYt2gAAAAAAAAAAAHoXoxBoEXVdT6+q6qokO8/lsV1TZhSySxevX1HX9fQCXQCAhpo5uzNv+tHlmTDp5WKNpYYOzOVf2DGD+rcXawAAAAAAAAAAAL2TUQi0lgsy91HIO5McU6D77i5eP79AEwCgoX5/3UP56t/uKNr480FbZuzKI4s2AAAAAAAAAACA3ssoBFrLn5McO5fXN66qas26ru/prmBVVesmWW8uj9Sv3AUA0Cc8Pnlatjr24qKNfTYdlWPftX7RBgAAAAAAAAAA0PsZhUALqev6gaqqrk2yxVweOzTJId2Y/VQXr19d1/XEbuwBADREXdc56Hc35d93PlW0c+Phu2SJRQcWbQAAAAAAAAAAAM3BKARaz68z91HIAVVVHVPX9RMLG6qqaoUkH+zisVMWtgMA0GiX3ftM9v/19UUbx++zYd624fJFGwAAAAAAAAAAQHMxCoHW89skRydZ6g1eH5Lk2CT7d0PrO0kGzeX1p165BwCgKb04fVY2OerCzOzoLNbYeMUROfOgrdLeVhVrAAAAAAAAAAAAzckoBFpMXdfTq6o6Pskxc3lsv6qqzqrr+m8L2qmq6j1J9u3isR/VdT1jQRsAAI30g/PvyY8vvr9o44L/2S6rLz20aAMAAAAAAAAAAGheRiHQmn6U5KAko+byzKlVVT1W1/X18/vmVVVtkeTkLh57KMnx8/veAACNds+TL+ZNP7q8aON/dlkjn95l9aINAAAAAAAAAACg+RmFQAuq63pqVVWfTXLmXB4bmuT8qqo+UNf1P+f1vauqeluS05Is2sWjh9V1PW1e3xcAoNFmd3TmHSddnXGPvVCsMWRAe2746i5ZZKB/VQMAAAAAAAAAALrW1ugDgMao6/rPSf7QxWPDk/yjqqrfV1W11twerKpqTFVVpyc5K8mwLt7393Vd/2WejwUAaLC/3vxoVvvqv4oOQn73kc0z/ptvNggBAAAAAAAAAADmmd82gtb28SSbJFlzLs9USfZNsm9VVbckuTrJhCQvZc6niaySZOskG8xj8+4kBy3owQAAPenpF6dns2MuKtrYc4Pl8uN9NkxVVUU7AAAAAAAAAABA32MUAi2sruuXqqp6U5Irkoyah79lo1e+FtTDSd5U1/VLC/EeAADF1XWdz515e/5y86NFO9d+eecsM3xQ0QYAAAAAAAAAANB3GYVAi6vr+qGqqnZKcl6S0QVT9yd5c13XDxdsAAAstOsefDbv/cW1RRvHvnO97LPZikUbAAAAAAAAAABA32cUAqSu6/urqto0yR+TvKlA4rwk76vrenKB9wYA6BbTZnZkq2MvyvNTZxVrrLH0ojnnU9umf3tbsQYAAAAAAAAAANA6jEKAJEld188neXNVVfsn+W6SpbrhbZ9O8vm6rk/rhvcCACjmp5c+kO+cd3fRxj8P3SbrLj+8aAMAAAAAAAAAAGgtRiHA/1HX9alVVf05yf5JDkmy9gK8zfgkJyY5pa7rqd15HwBAd3rwmZey0/cvK9r4+Har5su7L8gfqQAAAAAAAAAAAObOKAT4L3Vdv5zkpCQnVVW1RpI3J9k4yTpJlk8yNMmQJFOTvJjk0cwZgtyc5F91Xd/XiLsBAOZVZ2ed9/3y2lw34bmindu+tluGD+5ftAEAAAAAAAAAALQuoxBgruq6vjfJvY2+AwCgu5w77ol88vc3F22cvP/Y7Lz20kUbAAAAAAAAAAAARiEAAEBLeP7lmdnoqAuKNnZaa6mcvP/YVFVVtAMAAAAAAAAAAJAYhQAAAC3gyL/fkdOueaho44ov7JhRI4cUbQAAAAAAAAAAALyWUQgAANBn3fLw83nHSVcXbXx9zzH50NarFG0AAAAAAAAAAAC8HqMQAACgz5kxuyM7f/+yPPr8tGKN5UcMzkWHbZ9B/duLNQAAAAAAAAAAAObGKAQAAOhTTr16Yr72jzuLNv76ya2y8YqLFW0AAAAAAAAAAAB0xSgEAADoEx55bmq2/e4lRRsf3GKlHPX2dYs2AAAAAAAAAAAA5pVRCAAA0NTqus6Bp96Yi+5+umjn5iN2zchFBhRtAAAAAAAAAAAAzA+jEAAAoGldcvfTOeCUG4o2Ttx34+yx/rJFGwAAAAAAAAAAAAvCKAQAAGg6U6bPyvpfP79oY7NVRub0j26RtraqaAcAAAAAAAAAAGBBGYUAAABN5Tvn3Z2fXvpA0cZFh22f0UsuWrQBAAAAAAAAAACwsIxCAACApjD+8SnZ/cdXFG18/k1r5uAdVyvaAAAAAAAAAAAA6C5GIQAAQK82q6Mze/7kytz95IvFGsMH9881X94pQwb4VyQAAAAAAAAAAKB5+I0nAACg1/rTjY/kC3++vWjjjx/dIluOXrxoAwAAAAAAAAAAoASjEAAAoNd5asr0bP6ti4o23rnR8vn+ezZIVVVFOwAAAAAAAAAAAKUYhQAAAL1GXdf59Om35h+3PV60c/1Xds5SwwYVbQAAAAAAAAAAAJRmFAIAAPQKV98/Kfv+6rqijeP23iDv3mSFog0AAAAAAAAAAICeYhQCAAA01NSZs7PZMRflpRmzizXWWW5Y/n7w1unX3lasAQAAAAAAAAAA0NOMQgAAgIb5yUX35fsX3Fu0cd5nts1aywwr2gAAAAAAAAAAAGgEoxAAAKDH3f/0i9nlB5cXbRyy42r53JvWLNoAAAAAAAAAAABoJKMQAACgx3R01tn7Z1fn5ocnF2v0b69y8xG7Zuig/sUaAAAAAAAAAAAAvYFRCAAA0CP+cdvj+dQfbynaOOWATbPDmksVbQAAAAAAAAAAAPQWRiEAAEBRk16akbFHX1i08aZ1ls7PPrBJqqoq2gEAAAAAAAAAAOhNjEIAAIBivvzXcfnj9Q8XbVz1pZ2y/IjBRRsAAAAAAAAAAAC9kVEIAADQ7W566Lm866fXFG0c9fZ188EtViraAAAAAAAAAAAA6M2MQgAAgG4zfVZHtvvuJXn6xRnFGqsssUj+/ZntMqBfW7EGAAAAAAAAAABAMzAKAQAAusWvrngwR59zV9HGPw7ZOuuvMKJoAwAAAAAAAAAAoFkYhQAAAAvl4WenZrvvXVK0ccDWK+dre65TtAEAAAAAAAAAANBsjEIAAIAF0tlZ50On3JDL732maOfWI3fNiCEDijYAAAAAAAAAAACakVEIAAAw386/88l87Lc3FW387AOb5M3rLlO0AQAAAAAAAAAA0MyMQgAAgHn2wtRZ2eCb5xdtbL3a4vnthzdPW1tVtAMAAAAAAAAAANDsjEIAAIB5cvQ/x+dXV04o2rj0cztk5SUWKdoAAAAAAAAAAADoK4xCAACAuRr36AvZ84Qriza+svta+dh2o4s2AAAAAAAAAAAA+hqjEAAA4HXNnN2ZNx9/eR585uVijSUWHZgrv7hjBvVvL9YAAAAAAAAAAADoq4xCAACA//KH6x7OV/42rmjjzIO2zKYrjyzaAAAAAAAAAAAA6MuMQgAAgP/v8cnTstWxFxdtvGfsCvnuuzco2gAAAAAAAAAAAGgFRiEAAEDqus4nf39z/nXHk0U7N3x1lyw5dGDRBgAAAAAAAAAAQKswCgEAgBZ3+b3PZL9fX1+0cfw+G+ZtGy5ftAEAAAAAAAAAANBqjEIAAKBFvTRjdjY+6oLMnN1ZrLHhqBH5yye2SntbVawBAAAAAAAAAADQqoxCAACgBf3g/Hvy44vvL9q44H+2y+pLDy3aAAAAAAAAAAAAaGVGIQAA0ELuefLFvOlHlxdtfGaX1fOZXdYo2gAAAAAAAAAAAMAoBAAAWsLsjs6846SrM+6xF4o1hgxozw1f3SWLDPSvGQAAAAAAAAAAAD3Bb2sBAEAf99ebH81n/3Rb0cbvPrJ5tll9iaINAAAAAAAAAAAA/i+jEAAA6KOeeXFGNj3mwqKNt66/bH7yvo1SVVXRDgAAAAAAAAAAAP/NKAQAAPqgz595W8686dGijWu+vFOWHT64aAMAAAAAAAAAAIA3ZhQCAAB9yHUPPpv3/uLaoo1j37le9tlsxaINAAAAAAAAAAAAumYUAgAAfcC0mR3Z6tiL8vzUWcUaqy+1aM799Lbp395WrAEAAAAAAAAAAMC8MwoBAIAm97PLHsix/7q7aOOfh26TdZcfXrQBAAAAAAAAAADA/DEKAQCAJjVh0svZ8bhLizY+tt2q+cruaxdtAAAAAAAAAAAAsGCMQgAAoMl0dtbZ91fX5toHnyvaue1ru2X44P5FGwAAAAAAAAAAACw4oxAAAGgi593xRA763c1FG7/ab2x2GbN00QYAAAAAAAAAAAALzygEAACawPMvz8xGR11QtLHDmkvmNx/aNFVVFe0AAAAAAAAAAADQPYxCAACgl/va3+/Iqdc8VLRxxRd2zKiRQ4o2AAAAAAAAAAAA6F5GIQAA0Evd+sjkvP3Eq4o2jnzrmHx4m1WKNgAAAAAAAAAAACjDKAQAAHqZGbM7sssPLssjz00r1lhu+KBc/LkdMqh/e7EGAAAAAAAAAAAAZRmFAABAL3LaNRNz5N/vLNr4yye2yiYrLVa0AQAAAAAAAAAAQHlGIQAA0As8+vzUbPOdS4o23r/5ijnmHesVbQAAAAAAAAAAANBzjEIAAKCB6rrOR0+7MRfe9XTRzk2H75LFFx1YtAEAAAAAAAAAAEDPMgoBAIAGueTup3PAKTcUbZyw70Z56/rLFW0AAAAAAAAAAADQGEYhAADQw6ZMn5UNvnF+6rpcY7OVR+aPH9si7W1VuQgAAAAAAAAAAAANZRQCAAA96Dvn3Z2fXvpA0cZFh22f0UsuWrQBAAAAAAAAAABA4xmFAABADxj/+JTs/uMrijY+/6Y1c/COqxVtAAAAAAAAAAAA0HsYhQAAQEGzOjqz50+uzN1PvlisMXxw/1zz5Z0yZIA/3gMAAAAAAAAAALQSvzUGAACF/OnGR/KFP99etPHHj26RLUcvXrQBAAAAAAAAAABA72QUAgAA3eypKdOz+bcuKtp4+4bL5Yfv3TBVVRXtAAAAAAAAAAAA0HsZhQAAQDep6zqfPv3W/OO2x4t2rv/Kzllq2KCiDQAAAAAAAAAAAHo/oxAAAOgGVz8wKfv+8rqije+9e/3sPXZU0QYAAAAAAAAAAADNwygEAAAWwtSZs7P5MRflxRmzizXWXnZYzj5k6/RrbyvWAAAAAAAAAAAAoPkYhQAAwAI64eL7ctz59xZt/OvT22btZYcVbQAAAAAAAAAAANCcjEIAAGA+3f/0S9nlB5cVbRy84+h8/k1rFW0AAAAAAAAAAADQ3IxCAABgHnV01nnvz6/JjQ89X6zR3lbl1iN3zdBB/Ys1AAAAAAAAAAAA6BuMQgAAYB6cfdvjOfSPtxRt/OaATbPjmksVbQAAAAAAAAAAANB3GIUAAMBcPPvSjGxy9IVFG7uOWTq/+OAmqaqqaAcAAAAAAAAAAIC+xSgEAADewFf+Ni5/uO7hoo0rv7hjVlhsSNEGAAAAAAAAAAAAfZNRCAAA/IebHno+7/rp1UUbR71tnXxwy5WLNgAAAAAAAAAAAOjbjEIAAOAV02d1ZIfvXZonp0wv1lhp8SE5/3+2y8B+7cUaAAAAAAAAAAAAtAajEAAASHLylRNy1D/HF238/eCts8GoEUUbAAAAAAAAAAAAtA6jEAAAWtrDz07Ndt+7pGjjQ1utnK/vtU7RBgAAAAAAAAAAAK3HKAQAgJbU2VnnQ6fckMvvfaZo55Yjds1iiwwo2gAAAAAAAAAAAKA1GYUAANByLhj/VD562o1FGz/7wMZ587rLFm0AAAAAAAAAAADQ2oxCAABoGS9MnZUNvnl+0cbWqy2e335487S1VUU7AAAAAAAAAAAAYBQCAEBLOOac8fnlFROKNi753A5ZZYlFijYAAAAAAAAAAADgVUYhAAD0aXc89kLe+pMriza+/Ja18vHtRxdtAAAAAAAAAAAAwH8yCgEAoE+a1dGZN//o8jzwzMvFGkssOiBXfnGnDOrfXqwBAAAAAAAAAAAAb8QoBACAPueP1z+cL/91XNHGnz6+ZTZbZWTRBgAAAAAAAAAAAMyNUQgAAH3G45OnZatjLy7aeM/YFfLdd29QtAEAAAAAAAAAAADzwigEAICmV9d1Dv7DzTl33JNFOzd8dZcsOXRg0QYAAAAAAAAAAADMK6MQAACa2hX3PZMPnnx90caP3rth3r7R8kUbAAAAAAAAAAAAML+MQgAAaEovzZidsUdfkOmzOos1NlhheP7yia3Sr72tWAMAAAAAAAAAAAAWlFEIAABN54cX3JvjL7qvaOP8/9kuayw9tGgDAAAAAAAAAAAAFoZRCAAATePep17Mbj+8vGjj0zuvnv/ZdY2iDQAAAAAAAAAAAOgORiEAAPR6szs6866fXp3bHn2hWGNQ/7bcePiuWXSgPyIDAAAAAAAAAADQHPzGGwAAvdpZtzyWz5xxa9HGbz+yWbZdfcmiDQAAAAAAAAAAAOhuRiEAAPRKz7w4I5sec2HRxh7rLZsT9t0oVVUV7QAAAAAAAAAAAEAJRiEAAPQ6nz/ztpx506NFG9d8eacsO3xw0QYAAAAAAAAAAACUZBQCAECvcf2E5/Ken19TtPHtd66X9222YtEGAAAAAAAAAAAA9ASjEAAAGm76rI5sfezFefblmcUaqy21aM791LYZ0K+tWAMAAAAAAAAAAAB6klEIAAAN9fPLHsi3/3V30cY/D90m6y4/vGgDAAAAAAAAAAAAeppRCAAADTFh0svZ8bhLizY+uu0q+eoeY4o2AAAAAAAAAAAAoFGMQgAA6FGdnXXe/6vrcs2Dzxbt3Hbkbhk+pH/RBgAAAAAAAAAAADSSUQgAAD3mvDueyEG/u7lo41f7jc0uY5Yu2gAAAAAAAAAAAIDewCgEAIDinn95ZjY66oKijR3WXDK/+dCmqaqqaAcAAAAAAAAAAAB6C6MQAACK+vo/7swpV08s2rj88ztmxcWHFG0AAAAAAAAAAABAb2MUAgBAEbc9MjlvO/Gqoo0j3zomH95mlaINAAAAAAAAAAAA6K2MQgAA6FYzZndktx9enoeenVqsscywQbn08ztkUP/2Yg0AAAAAAAAAAADo7YxCAADoNr+9ZmKO+PudRRt/+cRW2WSlxYo2AAAAAAAAAAAAoBkYhQAAsNAefX5qtvnOJUUb+26+Yr71jvWKNgAAAAAAAAAAAKCZGIUAALDA6rrOx357Uy4Y/1TRzk2H75LFFx1YtAEAAAAAAAAAAADNxigEAIAFcsk9T+eA39xQtPGT922UPTdYrmgDAAAAAAAAAAAAmpVRCAAA8+XF6bOy4TcvSEdnXawxdqXFcsbHt0x7W1WsAQAAAAAAAAAAAM3OKAQAgHn2vX/fnRMveaBo48LPbp/Vllq0aAMAAAAAAAAAAAD6AqMQAAC6dNcTU/KW468o2vjcbmvkkJ1WL9oAAAAAAAAAAACAvsQoBACANzS7ozN7nnBV7npiSrHG0EH9ct1Xds6QAf5oCgAAAAAAAAAAAPPDb94BAPC6zrzxkXz+z7cXbfzho5tnq9FLFG0AAAAAAAAAAABAX2UUAgDA//H0lOnZ7FsXFW28fcPl8sP3bpiqqop2AAAAAAAAAAAAoC8zCgEAIElS13X+54xbc9atjxftXPeVnbP0sEFFGwAAAAAAAAAAANAKjEIAAMjVD0zKvr+8rmjju+9eP+8ZO6poAwAAAAAAAAAAAFqJUQgAQAubOnN2Nv/WRXlx+uxijbWXHZZ/HLJ1+re3FWsAAAAAAAAAAABAKzIKAQBoUSdecn++9+97ijbO/dS2GbPcsKINAAAAAAAAAAAAaFVGIQAALeb+p1/KLj+4rGjjkzuMzhfevFbRBgAAAAAAAAAAALQ6oxAAgBbR0Vlnn19ckxsmPl+s0d5W5ZYjd82wQf2LNQAAAAAAAAAAAIA5jEIAAFrAP29/PIf84Zaijd98aNPsuNZSRRsAAAAAAAAAAADA/zIKAQDow559aUY2OfrCoo1dxyydX3xwk1RVVbQDAAAAAAAAAAAA/F9GIQAAfdThZ43L7659uGjjyi/umBUWG1K0AQAAAAAAAAAAALw+oxAAgD7m5oefzztPurpo4xt7rZP9t1q5aAMAAAAAAAAAAACYO6MQAIA+Yvqsjux03KV5/IXpxRorjhySCz67XQb2ay/WAAAAAAAAAAAAAOaNUQgAQB9w8pUTctQ/xxdtnHXw1tlw1IiiDQAAAAAAAAAAAGDeGYUAADSxR56bmm2/e0nRxv5brpRvvG3dog0AAAAAAAAAAABg/hmFAAA0obquc8ApN+TSe54p2rnliF2z2CIDijYAAAAAAAAAAACABWMUAgDQZC4c/1QOPO3Goo2fvn/jvGW9ZYs2AAAAAAAAAAAAgIVjFAIA0CRemDYrG3zj/KKNLVddPL8/cPO0tVVFOwAAAAAAAAAAAMDCMwoBAGgC3zr3rvzi8geLNi753A5ZZYlFijYAAAAAAAAAAACA7mMUAgDQi93x2At560+uLNr40lvWykHbjy7aAAAAAAAAAAAAALqfUQgAQC80q6Mzbzn+itz/9EvFGosvMiBXfnGnDB7QXqwBAAAAAAAAAAAAlGMUAgDQy5x+/cP50l/HFW2c8bEtsvmqixdtAAAAAAAAAAAAAGUZhQAA9BJPvDAtW3774qKNvTdZId/be4OiDQAAAAAAAAAAAKBnGIUAQE/o7Egm3Zs8fmvy9Phk+uRk9oykY2bSPiDpNzAZNCJZakyy3EbJEqsnbe0NPpqeUtd1DvnDLTln3BNFOzd8dZcsOXRg0QYAAAAAAAAAAADQc4xCAKCEuk4mXpncc27y2M3Jk7cns6bO+9/ff5FkmfWS5TdO1tw9WXmbpKrK3UvDXHnfpHzg5OuKNn743g3yjo1WKNoAAAAAAAAAAAAAep5RCAB0p2mTk9tOT248ec4ngyyoWS8nj1w75+vak5Il1kjGfiTZYJ9k8IjuupYGemnG7Iw9+oJMn9VZrLHBCsPzl09slX7tbcUaAAAAAAAAAAAAQOMYhQBAd3juweTKHyXjzpy/TwSZV5PuTc77YnLRN5L19k62+UwyctXu79AjfnjBvTn+ovuKNs7/n+2yxtJDizYAAAAAAAAAAACAxjIKAYCF0TE7ueYnySXfTjpmlO/NmprcfOqcTyPZ8SvJVocmbe3lu3SL+556Mbv+8PKijU/tvHo+u+saRRsAAAAAAAAAAABA72AUAgAL6pl7krM+kTx2U8+3O2YkF34tuevs5O0nJUuu2fM3MM86Ouu866dX59ZHJhdrDOzXlpuO2DWLDvTHOwAAAAAAAAAAAGgVfmsQAOZXZ+ecTwe5+Jie+XSQuXnsxuRn2yY7fTXZ8tCkra2x9/BfzrrlsXzmjFuLNk778GbZbo0lizYAAAAAAAAAAACA3scoBADmR8es5KxPJuP+1OhL/lfHjOSCI5Mn75jzqSHt/Rt9EUkmvTQjY4++sGhj9/WWyYn7bpyqqop2AAAAAAAAAAAAgN7JKAQA5tWs6cmZH0ru/VejL3l94/6UzHgx2fuUpP+gRl/T0r7459tzxo2PFG1c/aWdstyIwUUbAAAAAAAAAAAAQO9mFAIA86JjVu8ehLzq3n8lfz4gec9pPjGkAW6Y+Fz2/tk1RRvHvGPdvH/zlYo2AAAAAAAAAAAAgOZgFAIAXensTM76ZO8fhLzqnnPn3PuOnydtbY2+piVMn9WRbb5zcSa9NLNYY/SSi+Rfn94uA/r5zxQAAAAAAAAAAACYwygEALpyzU+ScX9q9BXzZ9yfkmXWS7b+VKMv6fN+efmDOebcu4o2zj5km6y3wvCiDQAAAAAAAAAAAKD5GIUAwNw8c09y8TGNvmLBXHx0ssabkiXXbPQlfdLESS9nh+MuLdo4cJtVcvhbxxRtAAAAAAAAAAAAAM3LKAQA3kjH7OSsTyQdMxp9yYLpmJGc9cnkI+cnbe2NvqbP6Oys88FfX5er7n+2aOe2I3fL8CH9izYAAAAAAAAAAACA5mYUAgBv5JoTksduavQVC+exG5Orf5Js85lGX9InnHfHkznod2X/O/GLD26S3dZZpmgDAAAAAAAAAAAA6BuMQgDg9Tz3YHLJtxp9Rfe45FvJmL2Skas2+pKmNXnqzGz4zQuKNrZbY8mc8qFN09ZWFe0AAAAAAAAAAAAAfYdRCAC8nit/lHTMaPQV3aNjxpzvZ68fN/qSpvSNs+/Mb66aWLRx+ed3zIqLDynaAAAAAAAAAAAAAPoeoxAA+E/TJifjzmz0Fd1r3JnJbkclg4Y3+pKmcfujk7PXCVcVbRy+x9o5cFuf4AIAAAAAAAAAAAAsGKMQAPhPt52ezJra6Cu616ypc76vzT/e6Et6vZmzO7PrDy/LQ8+W++/AMsMG5dLP75BB/duLNQAAAAAAAAAAAIC+zygEAF6rrpMbftXoK8q44VfJZh9LqqrRl/Rav732oRxx1h1FG3/5xJbZZKWRRRsAAAAAAAAAAABAazAKAYDXmnhl8ux9jb6ijEn3Jg9dlay8TaMv6XUemzwtWx97cdHG+zZbMd9+53pFGwAAAAAAAAAAAEBrMQoBgNe659xGX1DW3ecahbxGXdf52G9vygXjnyrauenwXbL4ogOLNgAAAAAAAAAAAIDWYxQCAK/12M2NvqCsx/v49zcfLr3n6XzoNzcUbfz4fRtlrw2WK9oAAAAAAAAAAAAAWpdRCAC8qrMjefL2Rl9R1hO3z/k+29obfUnDvDh9Vjb85gXp6KyLNcautFjO+PiWaW+rijUAAAAAAAAAAAAAjEIA4FWT7k1mTW30FWXNejmZdF+y1FqNvqQhjvv3PTnhkvuLNi787PZZbalFizYAAAAAAAAAAAAAEqMQAPhfj9/a6At6xhO3ttwo5O4np+TNP7qiaOOzu66RT+28etEGAAAAAAAAAAAAwGsZhQDAq54e3+gLekarfJ9JZnd0Zq8Trsr4J6YUawwd1C/XfWXnDBngj1UAAAAAAAAAAABAz/LbiwDwqumTG31Bz5g2udEX9Ii/3PRoDjvztqKNPxy4ebZabYmiDQAAAAAAAAAAAIA3YhQCAK+aPaPRF/SMPv59Pj1lejb71kVFG3ttsFyO32fDVFVVtAMAAAAAAAAAAAAwN0YhAPCqjpmNvqBndPTNUUhd1znsT7flr7c8VrRz3Vd2ztLDBhVtAAAAAAAAAAAAAMwLoxAAeFX7gEZf0DPaBzb6gm53zQPP5n2/vLZo47vvXj/vGTuqaAMAAAAAAAAAAABgfhiFAMCr+vW9scTr6kPf57SZHdni2xflhWmzijXWWmZozj50m/RvbyvWAAAAAAAAAAAAAFgQRiEA8KpBIxp9Qc8YPKLRF3SLEy+5P9/79z1FG+d8apuss9zwog0AAAAAAAAAAACABWUUAgCvWmpMoy/oGU3+fT7wzEvZ+fuXFW0ctP3ofOktaxVtAAAAAAAAAAAAACwsoxAAeNVyGzb6gp6x7IaNvmCBdHbW2ecX1+b6ic8Va1RVctvXdsuwQf2LNQAAAAAAAAAAAAC6i1EIALxqiTWS/kOSWVMbfUk5/RdJlli90VfMt3NufyIH/+Hmoo1ff2hsdlpr6aINAAAAAAAAAAAAgO5kFAIAr2prT5ZZP3nk2kZfUs6y68/5PpvEcy/PzMZHXVC0scvaS+WX+41NVVVFOwAAAAAAAAAAAADdzSgEAF5r+Y379ihkuY0bfcE8O/yscfndtQ8XbVzxhR0zauSQog0AAAAAAAAAAACAUoxCAOC11tw9ufakRl9Rzlq7N/qCLt388PN550lXF218Y691sv9WKxdtAAAAAAAAAAAAAJRmFAIAr7XyNsniqyfP3tfoS7rfEmskK23d6Cve0PRZHdnpuEvz+AvTizVGjRycCz+7fQb2ay/WAAAAAAAAAAAAAOgpRiEA8FpVlWx6YHLeFxt9Sffb9MA5318v9JurJuQbZ48v2jjr4K2z4agRRRsAAAAAAAAAAAAAPckoBAD+0wb7JBd9I5k1tdGXdJ/+Q+Z8X73MI89NzbbfvaRoY/8tV8o33rZu0QYAAAAAAAAAAABAIxiFAMB/GjwiWW/v5OZTG31J91lv72TQ8EZf8f/VdZ0DTrkhl97zTNHOLUfsmsUWGVC0AQAAAAAAAAAAANAoRiEA8Hq2+Uxy2+lJx4xGX7Lw2gfO+X56iQvHP5UDT7uxaOOn7984b1lv2aINAAAAAAAAAAAAgEYzCgGA1zNy1WTHryQXfq3Rlyy8Hb8y5/tpsBemzcoG3zi/aGPLVRfP7w/cPG1tVdEOAAAAAAAAAAAAQG9gFAIAb2TLQ5K7/pE8dlOjL1lwy49Ntjq00Vfk2/+6Kz+/7MGijYsP2z6rLrlo0QYAAAAAAAAAAABAb2IUAgBvpL1f8vafJj/bNumY0ehr5l/7wOTtJyVt7Q074c7HX8geP76yaONLb1krB20/umgDAAAAAAAAAAAAoDcyCgGAuVlyzWSnryYXHNnoS+bfTofPub8BZnV0Zo8fX5F7n3qpWGPkIgNy1Rd3yuABjRu9AAAAAAAAAAAAADSSUQgAdGXLQ5Mn70jG/anRl8y79d6TbHlIQ9Jn3PBwvviXcUUbp39si2yx6uJFGwAAAAAAAAAAAAC9nVEIAHSlrS15+0nJjBeTe//V6Gu6tubuc+5ta+vR7JMvTM8W376oaONdG6+Q4/ZeP1VVFe0AAAAAAAAAAAAANAOjEGghVVWtnGRCg89Yva7r+xt8A8y/9v7J3qckZ36odw9D1tw9efdv5tzbQ+q6zqF/vCX/vP2Jop3rv7pzlho6qGgDAAAAAAAAAAAAoJkYhQDAvOo/KHnvb5OzPpmM+1Ojr/lv671nzieE9OAg5Kr7J+X9v7quaOMH79kg79x4haINAAAAAAAAAAAAgGZkFAIA86O9f/KOnyfLrJtcfEzSMaPRFyXtA5OdDk+2PCRpa+uR5MszZmfTYy7M1JkdxRrrLT88f/vkVunX3jPfEwAAAAAAAAAAAECzMQoBgPnV1pZs/elkjTcnZ30ieeymxt2y/Ng5nw6y5Jo9ljz+wvvywwvvLdr492e2y5rLDC3aAAAAAAAAAAAAAGh2RiEAsKCWXDP58PnJNSckl3yrZz81pH1gstNXX/l0kPYeSd731IvZ9YeXF218aqfV8tndem7gAgAAAAAAAAAAANDMjEIAYGG090u2+UwyZq/kyh8l485MZk0t1+s/JFlv7znNkauW67xGR2edd/306tz6yORijQH92nLT4btk6KD+xRoAAAAAAAAAAAAAfY1RCPBav0lydeHG04XfHxpj5KrJXj9Odjsque305IZfJZPu7b73X2KNZNMDkw32SQYN77737cLfb30snz791qKNUz+8WbZfY8miDQAAAAAAAAAAAIC+yCgEeK3L67o+pdFHQFMbNDzZ/OPJZh9LHroqufvc5PGbkydum79PEOm/SLLs+slyGydr7Z6stHVSVeXu/g+TXpqRsUdfWLTxlnWXyUnv3zhVD35fAAAAAAAAAAAAAH2JUQgAlFBVycrbzPlKks6OZNJ9yRO3Jk+PT6ZNTmbPSDpmJO0Dk34Dk8EjkqXGJMtumCyxetLW3pDTv/jn23PGjY8UbVz9pZ2y3IjBRRsAAAAAAAAAAAAAfZ1RCAD0hLb2ZKm15nz1UjdMfC57/+yaoo1j3rFu3r/5SkUbAAAAAAAAAAAAAK3CKAQAWtz0WR3Z5juXZNJLM4o1Vl1ykZz36e0yoF9bsQYAAAAAAAAAAABAqzEKAYAW9svLH8wx595VtHH2IdtkvRWGF20AAAAAAAAAAAAAtCKjEABoQRMnvZwdjru0aOMj26ySI946pmgDAAAAAAAAAAAAoJUZhQBAC+nsrPPBX1+Xq+5/tmjntiN3y/Ah/Ys2AAAAAAAAAAAAAFqdUQgAtIh/3/lkPv7bm4o2fvHBTbLbOssUbQAAAAAAAAAAAAAwh1EIAPRxk6fOzIbfvKBoY9vVl8ipB2yWtraqaAcAAAAAAAAAAACA/2UUAgB92DfPHp9fXzWhaOOyz++QlRZfpGgDAAAAAAAAAAAAgP9mFAIAfdC4R1/InidcWbRx+B5r58BtVy3aAAAAAAAAAAAAAOCNGYUAQB8yc3Zn3vSjyzNh0svFGksNHZjLv7BjBvVvL9YAAAAAAAAAAAAAoGtGIQDQR/zu2ody+Fl3FG38+aAtM3blkUUbAAAAAAAAAAAAAMwboxDgdVVVNTjJ6CSjkoxIMijJjCTTkjyX5JEkj9Z1PbNRNwJzPDZ5WrY+9uKijX02HZVj37V+0QYAAAAAAAAAAAAA88coBHitzauq2jjJDknGJGnv4vnZVVXdmeTGJP9Ocn5d1y+UPRF4VV3XOeh3N+Xfdz5VtHPj4btkiUUHFm0AAAAAAAAAAAAAMP+MQoDXOmg+n++XZINXvj6SZGZVVX9L8tO6ri/r7uOA/3XZvc9k/19fX7Rx/D4b5m0bLl+0AQAAAAAAAAAAAMCCMwoButOAJO9N8t6qqi5O8sW6rm9s8E3Qp7w4fVY2PuqCzOqoizU2XnFEzjxoq7S3VcUaAAAAAAAAAAAAACw8oxCglJ2SXFtV1XFJjqzremajD4Jm9/3z78lPLr6/aOPCz26X1ZYaWrQBAAAAAAAAAAAAQPcwCgFKak/yxSTbVFX1jrqun2n0QfOqqqqDk3yyB1Kje6BBk7v7ySl584+uKNr47K5r5FM7r160AQAAAAAAAAAAAED3MgoBesLWSa6pqmq7uq4fb/Qx82jJJGMafQStbXZHZ9524lW58/EpxRqLDuyX676ycxYZ6I8EAAAAAAAAAAAAAM3Gb4ACSVInuSnJLUnGvfL1RJIXXvnqTLJ4kpFJlk2yVZLtkmyZZPA8NkYnubCqqm3qun6uW6+HPugvNz2aw868rWjj9wdunq1XW6JoAwAAAAAAAAAAAIByjEKgdc1I8s9Xvs6t6/rpLp5//JWvO5JckCRVVQ1LclCSz2TOWKQrayf5bVVVb63rul7Au6FPe/rF6dnsmIuKNvbaYLkcv8+GqaqqaAcAAAAAAAAAAACAsoxCoPU8kOTnSX5T1/WkhXmjuq6nJPluVVU/SvKNJF9M0tVvme+e5NAkP16YNvQ1dV3nsD/dlr/e8ljRzrVf3jnLDB9UtAEAAAAAAAAAAABAzzAKgdbySJLVu/tTOuq6npnky1VVXZ7kd0lGdvG3fLOqqj/Vdf1kd94BzeraB5/NPr+4tmjju+9aP+/ZdFTRBgAAAAAAAAAAAAA9yyiEPquqqjFJzm/0Hd2prusVFvLv7+iuW97g/f9VVdXOSS5NMnwujw7PnE8V+Z+S9yykZ5KM74HO6CQDe6BDLzRtZke2PPaiTJ46q1hjrWWG5uxDt0n/9rZiDQAAAAAAAAAAAAAawyiEvmxAkuUbfUSrqev61qqqPpDkH0mquTx6YFVV36jrenLPXDZ/6ro+McmJpTtVVd2ZZEzpDr3PTy99IN857+6ijXM+tU3WWW5u+ywAAAAAAAAAAAAAmplRCNDt6rr+Z1VVpyQ5YC6PLZrkHUl+0yNHQS8xdebsjDny30UbB20/Ol96y1pFGwAAAAAAAAAAAAA0nlEIUMpXk+ybZOBcnnl3jEJoIS9MnZUDTrm+aOP2r++WYYP6F20AAAAAAAAAAAAA0DsYhQBF1HX9RFVVZyTZby6PbVtVVXtd1x09dRc0Sl3X+cipN+TmhycXef+T9x+bnddeush7AwAAAAAAAAAAANA7tTX6AKBP+1MXrw9Nsm5PHAKNds2Dz+bGh57v9vfdaa2lMuHbuxuEAAAAAAAAAAAAALQgnxQClHR5ko4k7XN5Zq0kt/XMOdA4v7/24W5/zyu+sGNGjRzS7e8LAAAAAAAAAAAAQHMwCqHPquv61iRVo+9oZXVdv1hV1f1J1pzLYyv30DnQUE+/OL3b3uvre47Jh7ZepdveDwAAAAAAAAAAAIDmZBQClDYxcx+FLNVDd0BDTZ/VudDvsfyIwbn4c9tnYL+5ffgOAAAAAAAAAAAAAK3CKAQo7YUuXh/SI1dAg6297NCMe6yr/zm8sb99cqtstOJi3XgRAAAAAAAAAAAAAM2urdEHAH3ezC5e798jV0CDvWvjFRbo7/vgFitl4rF7GIQAAAAAAAAAAAAA8F98UghQ2uAuXp/WI1dAg222ysjssOaSufSeZ+b577n5iF0zcpEBBa8CAAAAAAAAAAAAoJn5pBCgtGW6eP2lHrkCGqyqqvz0/Ztk7Epdf+LHiftunInH7mEQAgAAAAAAAAAAAMBc+aQQoLTVunj9sR65AnqBwQPa87sDN89fbn40v7piQiZMejlJ0lYl266+ZHZee6l8YPOV0tZWNfhSAAAAAAAAAAAAAJqBUQhQTFVVKyVZuovHJvTELdBbDOrfnvdvvlLet+mKmTJ9VqbN6sigfu1ZzKeCAAAAAAAAAAAAADCfjEKAkvaYh2duL34F9EJtbVVGDBmQEY0+BAAAAAAAAAAAAICm1dboA4A+bb8uXn+0rutHeuQSAAAAAAAAAAAAAIA+xigEKKKqqh2TbN7FY//uiVsAAAAAAAAAAAAAAPoioxCg21VVNSDJ8fPw6J9K3wIAAAAAAAAAAAAA0FcZhQAl/CDJel0880CSi3rgFgAAAAAAAAAAAACAPskoBFpAVVWbV1XVr4daRyQ5eB4e/V5d1x2l7wEAAAAAAAAAAAAA6KuMQqA1fDnJ+Kqq9q+qakCJQFVVQ6uqOj3JN+fh8TuSnFziDgAAAAAAAAAAAACAVmEUAq1j9SSnJJlYVdVRVVWt1h1vWs2xV5Kbkrx3Hv6WjiQfr+t6dnf0AQAAAAAAAAAAAABalVEItJ5lkxye5L6qqm6tquroqqp2rqpq6Py8SVVVK1VV9fEkdyb5e+aMTubFF+q6vnr+TgYAAAAAAAAAAAAA4D/1a/QBQENt8MrXV5N0VlU1IcndSR5O8mSSF5LMSNKeZOQrX8sk2SrJigvQO6Gu6x90w90AAAAAAAAAAAAAAC3PKAR4VVuS0a98lfCDuq4PK/TeAAAAAAAAAAAAAAAtxygEKG1akk/UdX1qow8BAAAAAAAAAAAAAOhL2hp9ANCn/TvJugYhAAAAAAAAAAAAAADdzygEWsM1SR7vwd6lSXap6/rNdV0/2INdAAAAAAAAAAAAAICW0a/RBwDl1XX9nSTfqapqjSQ7JtkuycZJ1kj3jMPqJHck+UeS0+q6vrcb3hMAAAAAAAAAAAAAgLkwCoEW8spY494kP0+SqqqGJFk/yXpJVk4yKskKSZZLMjTJkCSDk/RPMjPJ9CTPJ3kiySNJxie5Pck1dV0/1YPfCgAAAAAAAAAAAABAyzMKgRZW1/XUJNe+8gUAAAAAAAAAAAAAQBNpa/QBAAAAAAAAAAAAAAAAzD+jEAAAAAAAAAAAAAAAgCZkFAIAAAAAAAAAAAAAANCEjEIAAAAAAAAAAAAAAACakFEIAAAAAAAAAAAAAABAEzIKAQAAAAAAAAAAAAAAaEJGIQAAAAAAAAAAAAAAAE3IKAQAAAAAAAAAAAAAAKAJGYUAAAAAAAAAAAAAAAA0IaMQAAAAAAAAAAAAAACAJmQUAgAAAAAAAAAAAAAA0ISMQgAAAAAAAAAAAAAAAJqQUQgAAAAAAAAAAAAAAEATMgoBAAAAAAAAAAAAAABoQkYhAAAAAAAAAAAAAAAATcgoBAAAAAAAAAAAAAAAoAkZhQAAAAAAAAAAAAAAADQhoxAAAAAAAAAAAAAAAIAmZBQCAAAAAAAAAAAAAADQhIxCAAAAAAAAAAAAAAAAmpBRCAAAAAAAAAAAAAAAQBMyCgEAAAAAAAAAAAAAAGhCRiEAAAAAAAAAAAAAAABNyCgEAAAAAAAAAAAAAACgCRmFAAAAAAAAAAAAAAAANCGjEAAAAAAAAAAAAAAAgCZkFAIAAAAAAAAAAAAAANCEjEIAAAAAAAAAAAAAAACakFEIAAAAAAAAAAAAAABAEzIKAQAAAAAAAAAAAAAAaEJGIQAAAAAAAAAAAAAAAE3IKAQAAAAAAAAAAAAAAKAJGYUAAAAAAAAAAAAAAAA0IaMQAAAAAAAAAAAAAACAJmQUAgAAAAAAAAAAAAAA0ISMQgAAAAAAAAAAAAAAAJqQUQgAAAAAAAAAAAAAAEATMgoBAAAAAAAAAAAAAABoQkYhAAAAAAAAAAAAAAAATcgoBAAAAAAAAAAAAAAAoAkZhQAAAAAAAAAAAAAAADQhoxAAAAAAAAAAAAAAAIAmZBQCAAAAAAAAAAAAAADQhIxCAAAAAAAAAAAAAAAAmpBRCAAAAAAAAAAAAAAAQBMyCgEAAAAAAAAAAAAAAGhCRiEAAAAAAAAAAAAAAABNyCgEAAAAAAAAAAAAAACgCRmFAAAAAAAAAAAAAAAANCGjEAAAAAAAAAAAAAAAgCZkFAIAAAAAAAAAAAAAANCEjEIAAAAAAAAAAAAAAACakFEIAAAAAAAAAAAAAABAEzIKAQAAAAAAAAAAAAAAaEJGIQAAAAAAAAAAAAAAAE2oquu60TcAtKyqqqYkGfqff33gwIEZPXp0Ay4CAAAAAAAAAAAAgObzwAMPZMaMGa/30ot1XQ/r6Xt6ilEIQANVVTU9ycBG3wEAAAAAAAAAAAAAfdSMuq4HNfqIUtoafQAAAAAAAAAAAAAAAADzzygEAAAAAAAAAAAAAACgCRmFAAAAAAAAAAAAAAAANCGjEAAAAAAAAAAAAAAAgCbUr9EHALS4yUlGvM5fn5nkkR69ZOGMTjLwdf76jCQP9PAtAODnEgC9iZ9LAPQmfi4B0Jv4uQRAb+NnEwC9iZ9LsGBGJRnwOn99cg/f0aOMQgAaqK7rZRp9Q3eoqurOJGNe56UH6rpep6fvAaC1+bkEQG/i5xIAvYmfSwD0Jn4uAdDb+NkEQG/i5xIwP9oafQAAAAAAAAAAAAAAAADzzygEAAAAAAAAAAAAAACgCRmFAAAAAAAAAAAAAAAANCGjEAAAAAAAAAAAAAAAgCZkFAIAAAAAAAAAAAAAANCEjEIAAAAAAAAAAAAAAACakFEIAAAAAAAAAAAAAABAEzIKAQAAAAAAAAAAAAAAaEJGIQAAAAAAAAAAAAAAAE3IKAQAAAAAAAAAAAAAAKAJGYUAAAAAAAAAAAAAAAA0IaMQAAAAAAAAAAAAAACAJmQUAgAAAAAAAAAAAAAA0ISMQgAAAAAAAAAAAAAAAJqQUQgAAAAAAAAAAAAAAEATMgoBAAAAAAAAAAAAAABoQkYhAAAAAAAAAAAAAAAATcgoBAAAAAAAAAAAAAAAoAkZhQAAAAAAAAAAAAAAADQhoxAAAAAAAAAAAAAAAIAmZBQCAAAAAAAAAAAAAADQhIxCAAAAAAAAAAAAAAAAmpBRCAAAAAAAAAAAAAAAQBMyCgEAAAAAAAAAAAAAAGhC/Rp9AAB9wklJlnydv/5MTx8CAPFzCYDexc8lAHoTP5cA6E38XAKgt/GzCYDexM8lYJ5VdV03+gYAAAAAAAAAAAAAAADmU1ujDwAAAAAAAAAAAAAAAGD+GYUAAAAAAAAAAAAAAAA0IaMQAAAAAAAAAAAAAACAJmQUAgAAAAAAAAAAAAAA0ISMQgAAAAAAAAAAAAAAAJqQUQgAAAAAAAAAAAAAAEATMgoBAAAAAAAAAAAAAABoQkYhAAAAAAAAAAAAAAAATcgoBAAAAAAAAAAAAAAAoAkZhQAAAAAAAAAAAAAAADQhoxAAAAAAAAAAAAAAAIAmZBQCAAAAAAAAAAAAAADQhIxCAAAAAAAAAAAAAAAAmpBRCAAAAAAAAAAAAAAAQBMyCgEAAAAAAAAAAAAAAGhCRiEAAAAAAAAAAAAAAABNyCgEAAAAAAAAAAAAAACgCRmFAAAAAAAAAAAAAAAANCGjEAAAAAAAAAAAAAAAgCZkFAIAAAAAAAAAAAAAANCEjEIAAAAAAAAAAAAAAACakFEIAAAAAAAAAAAAAABAEzIKAQAAAAAAAAAAAAAAaEJGIQAAAAAAAAAAAAAAAE3IKAQAAAAAAAAAAAAAAKAJGYUAAAAAAAAAAAAAAAA0IaMQAAAAAAAAAAAAAACAJmQUAgAAAAAAAAAAAAAA0ISMQgAAAAAAAAAAAAAAAJpQv0YfAABdqaqqX5LRSVZOMjTJokmmJ5mS5Ikk99R1PbVhBwLQcqqqGphkjSQrZM7PpiFJpiZ5McmjmfOzaWbjLgSglfi5BEBv4ucSAL2J/x8TAL2Jn0sAzauqqv6Z88/vZZMsmWRwkv5JZiaZlmRS5vyzfGJd17MadOZ88XOJ/9fefUfLUlQNG382OeeogCAgiChBMaAgICiKGHjNiWRWzJ/p9TUHzJgQAwoqKiYUAwZEFEQERFQUBMkoSXJOd39/1Fy84J3uCd1zTs95fmudxeJWndp17p3p3We6dpWmS2TmTM9BkjSC3o3mpsDmwAN6/10HWKn3tSJwJ+VG7SrgX8B5wJ+Bk4ETZvPD14h4ILAH8ARgS2CJiu4JnA38FDgSOCZNcJI0URGxCHBf4IHARsC6wHq9/65CWQS0LOWDkTso+elq4FLgAuBvwB+A4zPzmglPfyAR8XDgKcDjKbl30YrudwJ/BX4C/CAzT2x9gpKkOcW8JEmaTcxLkjR9ImIzYCfK86f78Z9FQssDiwA3AjdQnkGdC5wD/B04CTg9M++c/KwLnzFJkmYT85IkdVNELEu5dj8GeCSwCaUIpM7twJnA8cAvgaNmU2GFeUmaXhaFSFJH9BbbbkX5AP4xwHaUBbajugn4OXAo8KPMvGPsSTYgIh4HvBnYYYxhzgI+DnxhJh86SNI0i4gNKR98PJLyQcHmjJeX5psH/A74FvDVzLy6gTHHEhHPAv4fsPUYw/wB+HBmHt7MrCRJbYiIlYEzgDUH6H5oZu7V7oz+m3lJkma3iJjphy67ZObRkwpmXpKk6RIR9wdeCDwLuNcYQ91IKQ75KfDjzPxrA9Or5TMmSZp9ImI5Sl6ZlTLzi22NbV6SpG6KiM2B1wNPp2x8Oa4bgMOBj2TmmQ2MNxLzkjT9LAqRpFmsd0TbY4BnAk+m7LTehvOA/YGDZ+qGLSLuDXwKeGqDw/4JeElm/r7BMSVpTouIgyi7vw6yWHZcNwIHA+/JzH9PIN7dRMSmwOeA7Rsc9ljgpZn59wbHlCQ1JCK+BOw9YPeJFoWYlySpG+ZKUYh5SZKmS0RsTXlOtEtLIf6amZu3NLbPmCRpFouI9SnrEWalzIymxzQvSVI3RcRawAeB5wON5wfKqRtfAt48yfUP5iVp7lhkpicgSfpvEfGAiPgCcCllF6W9aa8gBGADykPckyJiqxbjLFREbAecSrM3nwBbAMdFxMsaHleS5rKdmUxBCJRdN14F/CMiXjihmABExB7AyTS7wAnKrhunRETTOU+SNKaI2InBC0ImyrwkSZpNzEuSND0iYsWIOAQ4hfYKQgDWaWtgnzFJkmYT85IkdVNEPAH4C/AC2ikIoTfuvsBfIuIxLcW4e0DzkjSnWBQiSbPT7pTjuVedcNytgd9FxEsmFTAingz8ElijpRCLAwdGxP4tjS9Jat+KwBci4vCIWKrtYBHxCuA7wHIthVgO+G5EvLyl8SVJQ4qIpYHPz/Q8Fsa8JEmaTcxLkjQ9IuJRlN1d96S9RU+t8hmTJGlMjZ70aF6SpG7qFTb8EFhtQiHXAn4aES9oM4h5SZp7LAqRJN3TksBBEfGutgNFxC7A4ZSbxLa9KSL+bwJxJEnteQbwi4hYtq0AEbEn5ejUth+EB/Dptj/okSQN7F3AhjM9iXsyL0mSZhPzkiRNj4h4NmVx0H1mei6j8hmTJKkBxzY1kHlJkropIvYGDmTya6kXAw6JiGe0Mbh5SZqbIrPRomdJUgMi4s3AB4b4ljuBvwJnAOcB/wZuBJainDayNvAoYJMhp/LmzPzgkN8zkIhYH/gjsNIA3f8CfBU4DjgbuBZYFlgXeDjwTOAxDPZA+imZ+YPhZyxJAoiIf1C/aPZO4ELg78A5lOv29cB1wKLACr2vjYGtgPWHnMZPgd0yc96Q31cpIh4KHM9gH4ycAHy999/zKT/f8sB9gW2B5wIPG2Cc24BHZebJI0xZktSAiNgKOInyAfwwDs3MvZqfUWFekqRuioiZfuiyS2Ye3fSg5iVJmh69U5+GKfK7gfI709nABb3/v53yfGclYHXgQcDmlOdSC3NtZq406pzvyWdMktQdvWv2eTM9jz6el5mHjTuIeUmSuikiHkL5/GrQwolTgKOA3wL/AK6ifO61ArAysCnls68nUn5HGsQtwEMy86+Dz7yaeUmauywKkaRZaMCikDMpR9cdBfw+M28aYNy1gRcD+1GKReok8MTM/MkAfQcWEYtRbpAfWtP1MmC/zPz2AGNuAxwEbF3T9Wpgy8y8cJC5SpLurk9RyMWUxUHH9f57ZmbeNsSYawHPAfamPDwexP9m5vsHjTHAHFYATgM2qOl6NvCyzPzlAGM+lrKrSF0RzXmU3HTdAFOVJDUoIhYFTqYUKQ6rtaIQ85IkdVdNUcgPgSNbnsJPMvNfTQ5oXpKk6RERzwS+Qf2Cnpt7/b4C/DYz7xhg7EWBzYDHA0+mLCCav9tuY0UhPmOSpG6ZxUUh1wBrZ+Yt4wxiXpKkbupdv/9E+R2mzvHAWzLz+CHGfwywP/CQAbqfAjw0G1jMbV6S5jaLQiRpFqooCrkGOAT4amaeOsb4ywIHAC8coPslwGaZec2o8RYS/zXAx2u6/Ql4wjAPsSNiSeDLwLNruh6RmXsMOq4k6T96RSHrUz5I+D5wZGae09DYi1CKF99P2Umjyq3AJpl5QUOxDwBeXdPtaOBpmXntEOOuBHwP2LGm68cz83WDjitJakZEvBHodzriuZQdzftpsyjkAMxLktRJNUUh78rMd05qLk0xL0nSdIiIRwG/BJao6fpF4O2ZecmY8dagbALzMmClBotCXoPPmCRJFSJiHcrpVotUdDswM1/RQKzXYF6SpM6JiH2Agwfo+h7KZ3p3jhBjcUphyCCfaz07M785bIyFxHwN5iVpzrIoRJJmoYUUhfwD+DDwtUFOBBkizguALwGL1nTdPzPf0lDM1Sm7Bq5Y0e0fwLaZecUI4y8KfJeyC1WVXTLz6GHHl6S5LiJ2B07IzCtbjLEx8Cvg3jVdv5iZL2og3maUDz4Wq+j2O2DnUfJwrxjzGKp347gDeFBmnjHs+JKk0UTEhpRjsZdeSPMJlMWtb68YopWiEPOSJHXbtBWFmJckaTpExMrAn4F1KrpdDTwnM3/acOxFKc9kxh7XZ0ySpEFExNsoi3irPHicjTh7ccxLktRREfEn4EE13T6QmW9tINYngFfVdPt9Zj58zDjmJWmOq6qIliTNvLOA5wGbZubnmywIAcjMrwD7DdB1v4hYoaGwb6D65vM24Bmj3HwC9Cqz9wTOr+n67lHGl6S5LjN/2GZBSC/G2cCjgRtquj47IpZvIOQ7qF7gdBXwzFHzcGbeCDyDcuJXP4tRvfBYktS8z7HwgpDbgZcAM7WTinlJkjSbmJckaTp8nuqCkH8Bj2q6IATKc5sGx/UZkySpUkQE5aSqKqeNWxDSY16SpA6KiM2pLwg5HvjfhkK+Fjipps/DepuZjcO8JM1xFoVI0ux0GfBy4AGZedgoR9ANKjM/C3ylptuylIezY+kVlrykptsBmfnHceJk5rXAq2u6PSIithsnjiSpPZl5DmXxUZVlgZ3GiRMR9wX+p6bb2zLzonHiZOYF1P88T4+I9ceJI0kaTO9Y8Mf0af5oZp4+yfnMZ16SJM0m5iVJmg4RsRvwtIou1wNPyMy/TWhKI/EZkyRpQDsA963pc/C4QcxLktRp/Z4PLegtmdnI5mGZOQ948wBddx41hnlJElgUIkmzUmZ+OTM/m5l3TCjkW4G63fye0kCcPamuSL4GeF8DccjMI4HjarrVHc0nSZpZn6J6t1iA7ceM8Qpg0Yr2syk7KTbhQODcivZFe/ORJLUoItYEPtKn+Vxmdgcj85IkaTYxL0lSx0XE4sBHa7q9NDP/NIn5jMlnTJKkQexb034LcFgDccxLktRdW9e0/z0zj28yYGb+CvhHTbeHjBHCvCTJohBJEmTmP4Fv1HTbLiLGzRvPr2n/fGZeN2aMBdU96Ng9IqpuiCVJMygzbwd+UtPt/qOOHxGLAs+u6fbxpk7s6hV7frKm23MayLeSpGqfBFbu0/byzLx5kpOZz7wkSZpNzEuSNDX2BTapaD8yM78+qcmMyWdMkqRKvevyHjXdjsjMqxsIZ16SpO7asKb95y3F/VlN+0ZjjG1ekmRRiCTpLj+qaV8BuM+og0fExsA2Nd2+MOr4ffwQuKSifUngfxqOKUlq1u9q2u81xtg7AWtXtN8CfG2M8RfmUOC2ivZ7UY42lyS1ICJ2B57Rp/nwzKz7QL5N5iVJ0mxiXpKkjusV0r2uosudwJsmNJ2x+IxJkjSg5wBL1/Q5eNwg5iVJ6rx+G4fN9+eW4taNu9oog5qXJM1nUYgkab7fDNDnvmOMv3tN+x8ys+6YvKFk5jzgWzXd6uYlSZpZl9W0LzvG2HU54MeZef0Y4/+XzLwGOKqmm7lJkloQEcsDB/ZpvgZ4zcQms3DmJUnSbGJekqTuexKwcUX7dzPzzElNZkw+Y5IkDWKfmvbzgWMaiGNekqRuW7Km/d8txb2ipr2usLEf85IkwKIQSVJPZl5F9U58ACuNEWLnmvYfjzH2OOPuGBGLthRbkjS+a2vabxpj7Nmam3ZpKa4kzXX7A+v0aXtLZl46yckshHlJkjSbmJckqfv2rmk/aCKzaMZszUs+Y5KkWSIiHgQ8pKbblzMzGwhnXpKkbqtbg3BjS3Hrxr1uxHHNS5IAi0IkSXdXV+k8UkVyRCwGbF/T7ehRxh7AccAtFe0rUn+EniRp5qxR0z7SLh0RsTZw/5pubeWmX9S0PyAi1moptiTNSRGxLfCyPs2/Az43wen8F/OSJGk2MS9JUvdFxErArhVdLgGOnchkxuQzJknSgOpOCZkHHDJuEPOSJE2FK2vaV20pbt24dfP6L+YlSQuyKESStKBlatqrbuSqPABYtqL9duCkEceulJm3AH+s6eYNqCTNXuvWtJ874rgPrWm/KDMvGnHsSpl5PuXBexVzkyQ1JCKWAL4IxEKa7wBe0tAOgeMwL0mSZhPzkiR131OBJSrafzQLfg8alM+YJEmVep//Pa+m2y8y88IGwpmXJKn7/lbT3taGJHXjjrL2wbwk6S4WhUiSAIiI5SkVulWuHnH4rWva/5aZt4449iBOqWnfqsXYkqTxVO1oCGX3iVHU5aZTRxx3UOYmSZqc/6X/bucfy8y/THIyfZiXJEmziXlJkrpvl5r2YyYyi2b4jEmSVOfJ1O++fnBDscxLktR9dWsMtmspbt2JHsePMKZ5SdJdLAqRJM23FQvfOXdB54w49pY17X8ecdxB1Y3vDagkzUIRsR7wyIoudzD6Uadb1rSbmyRpCkTEZsCb+zSfD7xrcrOptGVNu3lJkjRJW9a0m5ckafbboab995OYREO2rGk3L0mS9q1pvxL4QUOxtqxpNy9J0ux3DHBLRftOEbFkkwEjYmlgp4ou84BfjTD0ljXt5iVpDllspicgSZo1dqtpvw4Y9TjV+9W0nz3iuIP6R037xi3HlySN5gBg0Yr272bmv0Yc29wkSVMuIhYBvggs0afLyzPzpglOqYp5SZLmmIhYHNgQWA9YBVgKuB24GbgGuBi4KDNvnoHpmZckqcMiYiNg7You12TmeQOMsxjlmrsB5aT5JYGbgOuBi4DzM/OG8Wdcy7wkSeorItal/oSsr2bmbQ2FNC9JUsdl5tURcRj9iwpXAl5GWa/QlP2AFSraf5iZF48wrnlJ0l0sCpEkERGLAs+s6XZ8Zs4bMcQGNe11N4jjqht/2YhYPTOvaHkekqQBRcRrgKdWdLkD2H/EsQNYv6bbTOem9VuOL0lzwSuAR/Rp+1ZmHjXJyfRjXpKkOWWziPgQsCPwQMri2irzIuIs4BTKKYlHZeblbU7QvCRJU2HLmva+19mIWA14LrA7sB39i+wBMiLOAI6n7L5+dIMLbhfkMyZJUpW9gEVq+hzcYDzzkiRNh48Az6f/7zxvjYhvZ+Y/xw0UEfeh/6n2831sxOHNS5LuUndTLEmaG54C3Kemz5GjDNx7kFw39qi7vA/qUsoxe1XqbpIlSRMQEYtHxLuAj9d0/UBmnjZimDUpu/BWaTs31Y2/bESs0fIcJGlq9XYIfF+f5muB10xuNrXMS5I0dzwd+H/AQ6gvCIHyDGdT4HnAIcAlEfHjiNi995lbG8xLktR9m9e0n3PPP4iINSLis5QT4w8AHkN1QQhAAJsBLwZ+DFwcEe+IiJWHnnG/AD5jkiRV6OWJvWq6nZSZpzcYz7wkSVMgM88E3l3RZXXgRxGx/DhxImIV4Cig6vekL2fmb0YY27wk6W4sCpGkOa53SkjVTS7AbcC3RwyxMvUPki8dceyBZOYdwJU13e7V5hwkSdV6xSBPAU4D3l7T/afAe8YIN8g1v9XcNOD45iZJGt2BQL8P6t+amZdMcjI1zEuSpEEtAjyBsnnLKRGxcwsxzEuS1H2b1bRftuD/RMS+wN+BlwJLjxF3deCdwFkR8aIxxlmQz5gkSVV2BO5b06fJU0LMS5I0XfYHfl7RviVwckRsMcrgEfEwygnA96/odg7w2lHGx7wk6R4sCpEkvYz6BwSHZuZVI46/6gB9Lh9x7GFcVtM+yDwlSWOKiEUjYuWIWC8ito2Il0fEwcAlwBHU56SfAk/NzNvHmEbdNf+6zLx1jPFrZeZNwA013cxNkjSCiHgW8MQ+zScCB01wOoMwL0mSRrE18IuI+FJErNDguOYlSeq+dWvar4C7Nmk5GPgisFKD8VcDPh8R320gR/mMSZJUZZ+a9puAbzYYz7wkSVMkM+8EngL8uqLbJsBJvc/gBioOiYhtIuIw4HiqT8m4GNg5M68dcMr3ZF6SdDeLzfQEJEkzJyLWBz5Q0+124INjhFllgD7XjTH+oOpiDDJPSVKNiNgc+EsLQ99BOR3kfb0PZ8ZRd82fRF6aH2e5inZzkyQNqXcM9yf6NN8BvCQz646xnjTzkiRpHHsDD4+IJ2bmuQ2MZ16SpO5bu6b9uohYDPgG8D8tzmMPYIOIeFxmXjHiGD5jkiQtVESsSMk1Vb6dmU3mCfOSJE2ZzLw5InYFPgq8vE+3JSifwe0dEf8CfgucDVxN2dhkecqpHZsAjwTWHCD0qcDTM/P8MaZvXpJ0NxaFSNIcFRGLAodS/XAV4IDMPGeMUCvXtN/cwOLeQVxf0+4NqCTNTgn8AHhnZv6poTHrclNdzmiKuUmSmvcxYI0+bR/PzD9PcjIDMi9JksZ1f+D3EbFDZv51zLHMS5LUfWvVtN8GHEi7BSHzbQUcExGPHHFRrs+YJEn9PAdYuqbPwQ3HNC9J0hTKzFuAV0TEjygbJz+wovu9gKePEe424JPA/2bmbWOMA+YlSfdgUYgkzV3vAbav6XNRr984lqppv3HM8Qd1Q0173TwlSZN1JnAE8LXM/FvDY5ubJGkKRcTOwJ59mi8A3jm52QzFvCRJc8PpwB8oJyv+hfK527W9r9soD0dXpRQ3Pgx4NGVnwRUGHH814Be9RbfnjTFP85IkdVhELAUsWdPtGcCOFe03A7+kbNRyKnAZcAWwIqXgZBNgd2A3Su6qsznwzYjYLTNzgP4LMi9JkvrZt6b9rMw8ruGY5iVJmmKZeVRE/BR4CrAPsDPNXVOvA74OvD8zL2poTPOSpLuxKESS5qCI2B14c023BPbJzHF3/1uipv2OMccfVF2cunlKkibnDuBc4J/ATS2Mb26SpCkTEcsAn6vo8orMbCOnNMG8JEnT6U7g58APgR9n5oU1/S/rff0NOBb4YG9h757AG4CNBoi5NvDdiNi2t8PhKMxLktRtdTumQ/+CkAS+CrwpMy9dSPsVva+/AN+JiKWBNwFvHCDu44H9KDviDsO8JEn6LxHxIODBNd2+1EJo85IkTbleIfsREXEG8FzK53LjFDXcDnwIeF9m3tzAFBdkXpJ0N4vM9AQkSZMVEZsDhwFR0/XTmXl0AyG9AZUkDWsx4AnAp4FzIuJ7EfHwBsc3N0nS9Hk3cN8+bd/JzB9PcjJDMi9J0nS5hHLy7vqZ+YTM/OwABSELlZm3ZObnKDuyv4byELnOVsD7R4nXY16SpG4bdbHSTcDjM3PPPgUh/yUzb87MdwJbAOcP8C0fiIh7DTkv85IkaWHqTgm5Azi0hbjmJUmaYhGxWES8ICJOB84A3sb4p1wsDvwvcF5EHBQRm4w7zwWYlyTdjUUhkjSHRMQalN0Jl6/pejKl0rkJdbnmzobi1KmLs+hEZiFJGtYiwFOB30XE1yNi5YbGrGJukqQOiYgHUxbKLsx1wKsmN5uRmJckabqsl5lvz8yLmxowM+dl5ieARwEXDPAt+0XEA0cMZ16SpG5bfITvuR54bGb+bJSAmXk2sB1wVk3XZYC3Dzm8eUmSdDcRsQRl5/YqPxm0yHFI5iVJmlIRsRtwNqWo8AEthFgTeAnwt4j4dkRs2MCY5iVJd7PYTE9AkjQZEbEc8BNg/ZquVwJPz8zbGgpdVw08qVxUF2eQnRYlSfX+Cbyoon1pYKXe13rAQ3v/HcSzge0j4umZ+bsx5mhukqQpERGLAV+k/wfKb83MSyY4pVGYlyRpimRmazvwZeZJEbE9cDywbkXXxSinaD11hDDmJUnqtlEW/eyXmb8dJ2hmXhwRT6dsOla1C+xeEfG2zPz3gEOblyRJ9/QUYNWaPge3FNu8JElTJiKWBj4KvGxCIRcBngbsGhGvzswvjTGWeUnS3VgUIklzQG+3jCOAB9d0vRl4cmYOsuPgoOqKSyaVi+p2x2qqCEaS5rTMvJqyOHdgvZOs9qDsjLFlTfd7Az+LiMeP8bDa3CRJ0+MN9M8dJwGfndxURmZekiQNLDMvjIinACcAS1Z0fVJEbNzbvX0Y5iVJ6rZhr49HZuahTQTOzD9HxLuB91Z0WxLYG/jwgMOalyRJ97RPTfullM0y22BekqQp0isI+RGw0wDd7wSOAX4D/Ba4mLLx8nXAisAqlE1cHgls3xuz6iSP5YCDI+LBmfmKEX8E85Kku6k7PkiS1HERsSjwDWDnmq63U04IGWs3qD7jVqnaMapJ3oBK0iyVmZdn5kGZuRXwGOCcmm9ZHvhpRGw2YkhzkyRNgYjYCHhHn+Y7gJdk5rwJTmlU5iVJ0lAy81Tg/TXdFgGeN8Lw5iVJ6rZhr4//23D8j1IWRlX5nyHGMy9Jku4SEesCu9R0O7TFExzNS5I0JXobLB9JfUHI7cBngPtl5mMz872Z+avMPDszr8rMOzLzyt7/H5OZ78nMXYD7AQdSf5rHyyPi0yP+GOYlSXdjUYgkTbGICMpu7XvUdJ0HvCAzf9zCNG6oaV+uhZgLs3xNe908JUkTkJnHAA8C6o5JXQ74WkTUfcCwMOYmSZoOnweW6tP2icw8bYJzGYd5SZI0ig8Bl9f0edoI45qXJKnbbhqi73GZeXqTwTPzFuDLNd22iYjVBhzSvCRJWtBe1K91q3u+NA7zkiRNj3dRv8HyBcB2mfnKzDx3mMEz85zeCSCPBi6q6f6KiHjpMOP3mJck3Y1FIZI03T5B+WCkzksz85stzeGqmvbFI6LfQq4mrVDTXjdPSdKEZOZNwAup/+B+K+BNI4Sou+bX5YymmJskaUQRsS+wY5/mC+h/gshsZF6SJA2tt+j2oJpum0XEGkMObV6SpA7LzNuB6wfsfkhL06grClkEeOiAY/mMSZIE3LUh5t413Y7LzLNanIZ5SZKmQERsC7yxptvZwEMy8/fjxMrME4AHA+fUdP1IRGw45PDmJUl3Y1GIJE2piHg/sN8AXV+fmV9ocSp1x4QDrNRi/EFjDDJPSdKEZGYCLwKOren66ohYesjh6675Kw053qhWrGk3N0nSQkTEmsCHK7q8MjNvnNR8GmBekiSN6lsD9HnEkGOalySp+wa9Rv62pfhnANfU9Nl6wLF8xiRJmm8nYIOaPge3PAfzkiRNh/2pXjt9FbBbZv67iWCZeQWwG9W/Jy1L9bOvhTEvSbobi0IkaQpFxFuBtwzQ9R2Z+bGWpzPIDfJaLc9hkBjegErSLJOZ8ygFjndWdFsNeMGQQ9flpiUjYqUhxxxKRKwCLFHTzdwkSQv3aWDlPm3fzcwfTXIyDTAvSZJGkpl/BS6v6bbpkMOalySp+wZ5LnM10MpO6r3NXk6q6TboDrg+Y5IkzbdPTfv1wLdbnoN5SZI6LiK2Abar6fbOzDy7ybiZ+Xfg3TXdnjzkaSHmJUl3Y1GIJE2ZiHg18L4Bun44M+tuNseWmTdRf3O3ZptziIhlgOVrul3Q5hwkSaPJzNOBw2u6PWnIYS8coE+ruWnA8QeZpyTNKRHxJOBpfZqvA141wek0xbwkSRrHH2va1x9yPPOSJHXfINfIM3rFG235W037uoMM4jMmSRJArzB9j5pu3+zljdaYlyRpKtQVGV4EfL6l2AcCF1e0LwK8ZNDBzEuS7smiEEmaIhHxYuCAAbp+OjPf2PJ0FnR+Tft9Wo4/yPjntzwHSdLovl/T/qiIGPh3m8y8gfoPR9rOTevXtF+emTe2PAdJ6qKqkw7flpn/mthMGmJekiSN6fya9jWGGcy8JElT4bwB+lzT8hyurmlfZYixzq9p9xmTJE2/5wBL1fQ5eBITwbwkSV23Y0374Zl5axuBe+N+q6bbY4Yc9vyadvOSNIcsNtMTkCQ1IyKeDxw0QNeDmfzuuecBD65o37jl+BvVtF/W9q4hkqSx/BSYR/+i9hWATYAzhhjzPGDVivaNgZ8PMd6w6nLTIA/vJWkuWq3Pn18H3BoRL2ww1tY17RsPEO/XAx4xbl6SJI3q2pr2ZUYY07wkSd127gB9rml5DnXjD5OffMYkSdq3pv2vmfn7iczEvCRJnRURa1DWFVRp8zOv+eO/rqJ9i4hYITOvG3A885Kku1gUIklTICKeDnwZiJqu3wBe3PKR4AvzV+BpFe11N9zjqhv/ry3HlySNITOvj4h/U73D7RoMVxTyV+AhFe3mJknqlhWAz0045ra9ryp7A4MUhZiXJEmjuq2mffERxjQvSVK3nT5An5tbnkPd+MOsU/AZkyTNYRGxBfWbt0zqlBAwL0lSl20wQJ+TWp5DXRHjopRCjj8MOJ55SdJd+u20K0nqiIh4EnAY5aawyhHACzJzXvuz+i+n1rRv1XL8ug+J/thyfEnS+C6raa/axXZhzE2SpNnEvCRJGtXSNe2jLPo1L0lSt/2RcupulRVbnkPd+MPkJ/OSJM1tdaeE3AZ8dRIT6TEvSVJ31a0puC0z607lHUtmXgPcXtNtmLUP5iVJd7EoRJI6LCIeB3yL+h3/jgKelZl3tD+rhaq7AV2nd0RfW6qOyQNvQCWpC+qOR61bCHVPdblpy4ioK7gcSUQsBmxR083cJElzi3lJkjSqtWrabxhhTPOSJHVYZl4PnFXTbaWWp7FyTfsw+clnTJI0R0XEksBza7odmZn/nsR8esxLktRddb+nXDmRWdTHabIoxLwkzSEWhUhSR0XEDpTTP5as6XoMsEdm3tb2nPrJzIuBC2q67dBG7Ii4F3C/mm7HtxFbktSoZWvabxxyvFOAWyral6P+A4xRPRRYpqL9FgY/DlaSNB3MS5KkUW1U0/7PEcY0L0lS99U992hzUdAg4w+cn3zGJElz2lOAVWr6HDyBedzFvCRJnXZnTXvdGrymLFXTnoMOZF6StCCLQiSpgyLiEcAPqd8V/XjgSZlZ9RB3Uo6uad+lpbg717SfnZl1N8eSpJm3bk371cMM1suNv63pNlO56bhZkrslSRNiXpIkjaK3a+6WNd3OG3Zc85IkTYWf1bRvFhFVRXjjekhN+7DPZXzGJElz0z417RcBP5/ERO7BvCRJ3VS30eTKbZ2OO19ELE79yY03DTmseUkSYFGIJHVORDwYOIqyI1+Vk4HdMnPYndPb8oua9ie1dGP9tJr2mfiQSJI0hIi4N/VHpJ4zwtB1uWmPEcYchLlJkrQw5iVJ0rAeQ/0Ohn8ecWzzkiR129FU74K7GPWFGyPpFZs8sKbbn4Yc1mdMkjTHRMR61C82PSQz501iPvdgXpKkbrq0pj2Ae7c8h3UG6HPZkGOalyQBFoVIUqdExAMpuzutWNP1T8DjMvO69mc1sB9TXcm8BvUf6gwlIlYBHlfT7dtNxpQkteKxNe3XA/8cYdzv1LRvHRGbjDBuXxGxOdUPxZP6eUnSnJWZK2VmTOILeFfNdA4dYJxDhvjxzEuSpGG9oKb9dsrGMaMwL0lSh2XmNdQvwKn7zG1UjwHqFhz9fsgxfcYkSXPPXlSva0vgy5OZyn8xL0lSNw1you5OLc/hMQP0GfbkX/OSJMCiEEnqjIi4H6Wyt26n9L8Bu2Tm1e3PanCZeQNwZE23/RoO+1JgiYr2i4DfNBxTktS8vWraj8vMHHbQzDwHOLGmW9O56VU17Sdk5vkNx5QkdYB5SZI0jIjYmPrd+H6TmbeMMr55SZKmwqE17ftGxOItxH1ZTfv5mfn3YQb0GZMkzS0REcDeNd2OycxhF802wrwkSd2Umf8GLq7ptmvL03h8TfulmXn5MAOalyTNZ1GIJHVARKwP/BJYs6br2cDOmXlF65MazZdq2p8QEVs2ESgilqP+hvYroywiliRNTkTsBGxf0+1nY4Soy017R8TaY4x/l4hYB3h+TbdDmoglSeos85IkaVCfpH4X9m+NGcO8JEnd9gPg3xXtawFPbzJgr2ixbrfY7484vM+YJGnu2AlYv6bPwROYRxXzkiR10wk17XtExAZtBI6ITYEn13T73YjDm5ckWRQiSbNdRNyLUhCyTk3X84GdMvOS1ic1osz8BfDnii4BHNBQuLdQHmj0cyvwqYZiSZJaEBHLA5+v6XY78I0xwnwVqNppYxlg/zHGX9AHgaUq2i/rzUeSNHeZlyRJtSLiDdTvWngdcPiYocxLktRhvdOiPlHT7SMRsXIT8Xq7un+e+jUIXxhlfJ8xSdKcsm9N+9XAEZOYSD/mJUnqrLoTNRYH3tNS7PdRv8nLD0cZ2LwkCSwKkaRZLSJWpxSE3Lem68WUgpC6I+5mgw/WtD86Il47ToCI2BZ4Y023QzLzsnHiSNJcEhE7R8SyE4y3DOUD/Q1run5znBOyBnw4/oKIeOqoMQAi4hnAc2q6HZCZt44TR5LUbeYlSeqmiNg6IpaeUKw9gQ8N0PXAzLx2nFjmJUmaCp8GqvLB2sCBDcV6NbBDTZ+fZ+bfxojhMyZJmnIRsRJQ9zvGYb3fV2aaeUmSuudI4IaaPs+NiBc3GTQiXg/sUdPtFkY/WRHMS9KcZ1GIJM1SvQ87fg5sWtP1UkpByHmtT6oZ3wBOrunzwYjYfZTBe0eTfwdYrKLb9cA7RxlfkuawVwLnRcQbegUbrYmITYBfAY+p6XobzVzPDwAuqulzaEQ8dJTBI+Lh1B9jfgH1i60kSXPDAZiXJKlrXgCcExGvaquYPiKWiIgDgEMoO/tVuYz6h8CDOgDzkiR1VmZeA7y9ptuzIuLA3kkfI4mIfYGP1k0HePOoMXp8xiRJ0++5VJ8iCPW/Q0yKeUmSOiYzr2ew0ws/ExHPaiJmROzDYJu8fDkzrx4jlHlJmuMsCpGkWSgilgOOAras6fpv4DGZeXbrk2pIZiZlYXFWdFsc+HZEvHCYsSPikcCvKTtbVXlXZl46zNiSJABWBz5MKQ75aEQ8rMnBI2L5iHgv5VjTQRYUvSszzx03bmbeBLyuptvywM8j4onDjB0RTwZ+BixX0/X1mXnzMGNLkqaTeUmSOmttSuHCRRHx8YjYoqmBI+LRwPGUHdgH8areIuCxmZckaSp8Bji1ps/LgG/2TrAfWEQsGRHvpCyqqlt7cFBm/nGY8e/JZ0ySNCfsU9N+amaeNomJ1DEvSVJnfYjqExWhFD58IyI+M+qmmb31D1+mFDPW/b50I/CBUeLMZ16SFOU6IEmaTSLih8AgD1E/A5zW7mzu5pLM/HETA0XE+4C3DtD1p8DbM7NvJXNE3Ad4E/AiqquRodygPiYz7xx0rpIkiIjvA09eSNMFlN0gfgmcOOzOFRGxPLAd8Lze+IN+oPJL4HFNXs8j4jDgOTXdkrLDxnsy88yKsTaj7ML4zAFCH5aZzxt4opKkiegtbHpHRZdDM3OvFuOblySpI3oneCysYOMs4EfAMcDvMvOqIcZci3J64qsYrGh+vk9l5quG6D/ofMxLktRhEXF/4CTqC/GuAd4HfK1qIU9vc7PdgfcAGw4whb8DW/eKDcfmMyZJmk694vrTarq9IjMPnMB0BmZekqTuiYiXAp8dsPuVwIHAFzPzwgHG3gB4MfBSYKUBY7w2Mw8YsG9dfPOSNEdZFCJJs1BEnA/cZ6bnsRC/zswdmhgoIhalPBDffsBvORM4DjgbuA5YFlgXeBjwcGCQY80vB7bKzH8NPWFJmuMqikIWlMBFlIe8FwCXAlcBtwB3UnaPXaH33/tQTsTagMGu4Qs6DXh0Zl435PdV6j3MPgXYZMBv+SNwAnAecAPl59oAeCQw6K7AZwLbZOYNw81WktS2WVAUYl6SpI6oKApZ0Pzfl84Ezqf8vnQ1cGuvfWVgVcoJjQ8D7jfCVL4PPD0z7xjheyuZlySp+yLi6cDhDPZZXAInUk4YuYyyCGoFYE1gU2BHYMkBQ/8b2LbJU+99xiRJ0ykiPgnsV9HlFmDtpk5GbIp5SZK6KSK+Djx7yG87n3Ki78WUtRDXU35XWoVyLX8UsN6QY34PeFo2tJjbvCTNXRaFSNIsNBeKQgAiYmXgVwz+IHgc1wA7zpajZCWpawYsCpmE3wBPbusD/95OF8dRPuRo24XAdoPsJiJJmryZLgrpzcG8JEkdMGBRSNsOB56fmbe3FcC8JEndFxEvp5xCPylXA7tm5klND+wzJkmaLhGxJPAvyqLafmbtSYLmJUnqnohYCjgC2HUGp3EMsHtTpyrOZ16S5qZFZnoCkqS5KzOvBnah7DLYpsuBx3nzKUmdlsDHgce2uQNUZl4A7ASc01aMnn8AO7nASZJUxbwkSRrAncBbMvNZbRaEgHlJkqZBZh4IvBhoNWf0XARs30ZBCPiMSZKm0FOoLggBOHgC8xiJeUmSuiczb6Hkn6/M0BQOB57YdEEImJekucqiEEnSjMrMK4DtaO8G+2TgIW09dJAkTcQfKTtLvC4zb207WGb+A9gG+FlLIX4KbJOZbS+kkiRNAfOSJKnC/M+99p9UQPOSJHVfZn4B2AG4uMUwPwC2zMzTW4zhMyZJmi771rSfCxw7gXmMzLwkSd2Tmbdm5p7AiygnXkzCdcDLe5u83NxWEPOSNPdYFCJJmnGZeUvvBvuJlA9zmnA98DrgEZl5UUNjStJctj9wAHDWBGOeCDyL8kHCrycYl8y8OjN3Bfai7G7RhMuBPTPz8W2ediJJmj7mJUma9f5Ic59pDeJU4GnAw2ZiFz7zkiR1X2aeANwf+CBwW4NDnwU8OTOfkplXNThuXz5jkqTui4j1gMfUdPtSZuYk5jMO85IkdVNmfhHYBPgk0Fahxi3AgcAmmfnZlmLcjXlJmluiA/fLkjTnRMT5wH1meh4L8evM3KHNABGxOPBM4FWUXQeHdQFwEPD5ST1wkKS5JiLuCzwO2BZ4GLAREA0MPQ/4M3Ak8J3M/EsDY44tIpYF9gReSXlYPqy/AZ8BDmnj6FdJUjsi4p3AOyq6HJqZe01mNv9hXpKk2au3kGlHYHvgIZTr9OINDf8P4EfAVzPz1IbGHJt5SZK6LyLWBl5C2aF9nRGGuA04Gvg88MPMnNfg9IbiMyZJ6qaIeAfwzoou84D7ZGabp1w1zrwkSd0UEasBz+59PRRYdIzh5lFO1PgmcFjv9I4ZYV6Spp9FIZKkWSsi1gUeT7kR3YxSKLMCsAxwK6Xy+BLgDOA04GeZ+acZmawkzWERsRLlWn0/YIPe1/rASsBywLLA0sCdlOv3jcAVwGXA+cCZwOnA7zLz2knOfVgRcT9gV2Br4AHAvYHlKbnpJkpuupiysOlU4KjMPHtmZitJGkdE7ADsUNHltMz8/iTm0o95SZJmt4hYAtgceBDl96R1e1/3pnzGtTTlmr0kZUHtLcC1lM+7Lqb8rvRn4MTMvHDS8x+WeUmSui8itgB2AbYANuXu1/LbKZ/rXQqcR+/zPODY2fiZns+YJEmziXlJkropIlakbACzFeXzrvsAawErA0tRNoS5nfK53tWU35cuoHz+dRrwm8y8euITr2FekqaTRSGSJEmSJEmSJEmSJEmSJEmSJEkdtMhMT0CSJEmSJEmSJEmSJEmSJEmSJEnDsyhEkiRJkiRJkiRJkiRJkiRJkiSpgywKkSRJkiRJkiRJkiRJkiRJkiRJ6iCLQiRJkiRJkiRJkiRJkiRJkiRJkjrIohBJkiRJkiRJkiRJkiRJkiRJkqQOsihEkiRJkiRJkiRJkiRJkiRJkiSpgywKkSRJkiRJkiRJkiRJkiRJkiRJ6iCLQiRJkiRJkiRJkiRJkiRJkiRJkjrIohBJkiRJkiRJkiRJkiRJkiRJkqQOsihEkiRJkiRJkiRJkiRJkiRJkiSpgywKkSRJkiRJkiRJkiRJkiRJkiRJ6iCLQiRJkiRJkiRJkiRJkiRJkiRJkjrIohBJkiRJkiRJkiRJkiRJkiRJkqQOsihEkiRJkiRJkiRJkiRJkiRJkiSpgywKkSRJkiRJkiRJkiRJkiRJkiRJ6iCLQiRJkiRJkiRJkiRJkiRJkiRJkjrIohBJkiRJkiRJkiRJkiRJkiRJkqQOsihEkiRJkiRJkiRJkiRJkiRJkiSpgywKkSRJkiRJkiRJkiRJkiRJkiRJ6iCLQiRJkiRJkiRJkiRJkiRJkiRJkjrIohBJkiRJkiRJkiRJkiRJkiRJkqQOsihEkiRJkiRJkiRJkiRJkiRJkiSpgywKkSRJkiRJkiRJkiRJkiRJkiRJ6iCLQiRJkiRJkiRJkiRJkiRJkiRJkjrIohBJkiRJkiRJkiRJkiRJkiRJkqQOsihEkiRJkiRJkiRJkiRJkiRJkiSpgywKkSRJkiRJkiRJkiRJkiRJkiRJ6iCLQiRJkiRJkiRJkiRJkiRJkiRJkjrIohBJkiRJkiRJkiRJkiRJkiRJkqQOsihEkiRJkiRJkiRJkiRJkiRJkiSpgywKkSRJkiRJkiRJkiRJkiRJkiRJ6iCLQiRJkiRJkiRJkiRJkiRJkiRJkjrIohBJkiRJkiRJkiRJkiRJkiRJkqQOsihEkiRJkiRJkiRJkiRJkiRJkiSpgywKkSRJkiRJkiRJkiRJkiRJkiRJ6iCLQiRJkiRJkiRJkiRJkiRJkiRJkjrIohBJkiRJkiRJkiRJkiRJkiRJkqQOsihEkiRJkiRJkiRJkiRJkiRJkiSpgywKkSRJkiRJkiRJkiRJkiRJkiRJ6iCLQiRJkiRJkiRJkiRJkiRJkiRJkjrIohBJkiRJkiRJkiRJkiRJkiRJkqQOsihEkiRJkiRJkiRJkiRJkiRJkiSpgywKkSRJkiRJkiRJkiRJkiRJkiRJ6iCLQiRJkiRJkiRJkiRJkiRJkiRJkjrIohBJkiRJkiRJkiRJkiRJkiRJkqQOsihEkiRJkiRJkiRJkiRJkiRJkiSpgywKkSRJkiRJkiRJkiRJkiRJkiRJ6iCLQiRJkiRJkiRJkiRJkiRJkiRJkjrIohBJkiRJkiRJkiRJkiRJkiRJkqQOsihEkiRJkiRJkiRJ0t1E8buIyIV8HTPT81O9iNihz7/f/K8dZnqOUtMiYq+a1/36Mz3HuS4ijq349zl2pucnSZIkSVIXWRQiSZIkSZIkSZIk6Z72Bh6+kD9P4I0TnoskSZIkSZIkqQ+LQiRJkiRJkiRJkiTdJSJWBvbv03x4Zp4yyflIkiRJkiRJkvpbbKYnIEmSJEmSJHVJRKwN7DbT82jQNzPzhpmehCRJmlXeC6y+kD+/DXjrOANHxHLAs8YZo0FXZuYRMz0JSZIkSZIkSRqHRSGSJEmSJEnScDYBvjDTk2jQ0YBFIZIkCYCI2Ap4aZ/mgzLzvDFDrMbsuZf6E2BRiCRJkiRJkqROW2SmJyBJkiRJkiRJktSWiFg/IrLia6+ZnqM0y3yIhT9DvA344ITnIknSwCLikIp7vvNnen6SJEmSJLXFohBJkiRJkiRJkiRJRMQOwM59mg/NzH9NbjaSJEmSJEmSpEFYFCJJkiRJkiRJkiQJ4P19/nwe5QQRSZIkSZIkSdIsY1GIJEmSJEmSJEmSNMdFxBOBR/Rp/k5m/mOS85EkSZIkSZIkDcaiEEmSJEmSJEmSJEnvqWj78MRmIUmSJEmSJEkaymIzPQFJkiRJkiSpSzLzWCCaHjciDgH2rOhyaGbu1XRcSZKkiNgF2LJP86mZecoEpwOwQWaeP+GYkqQJyMwdZnoOkiRJkiRNG08KkSRJkiRJkiRJkua211W0fX5is5AkSZIkSZIkDc2iEEmSJEmSJEmSJGmOiojNgMf1ab4B+PoEpyNJkiRJkiRJGpJFIZIkSZIkSZIkSdLc9Vog+rR9MzOvn+RkJEmSJEmSJEnDsShEkiRJkiRJkiRJmoMiYkXgeRVdvjqpuUiSJEmSJEmSRmNRiCRJkiRJkiRJkjQ3PQNYqk/bZcDxE5yLJEmSJEmSJGkEi830BCRJkiRJkiRJ3RMRqwD3B1YFlqdsQnQ9cAlwZmZeO4PTkyQN5vkVbd/PzHkTm4kkSZIkSZIkaSQWhUiSJEmSJEm6S0QsBzwCeCTwAGAD4N7AssAywO3AjZTdw88F/kLZRfw3mXnDTMx5UBGxOLA9sAuwObAJsDKwAuXnuhr4J3AScBxwZGbe0kDc1YHdgW2ALSl/nytS/k5vAi4HzgZ+B/w4M/8wbsw2RMSiwBOApwCPo/wcVf3PAH4CfCUz/9z6BIcQEZtSXuMPBe5LeZ2vTHmNL055jV8HXAD8AzgR+HVmnjEjEx5CRKxMeY1vS3mNbwSsxH8Kd66jvM5Pz8znjhFnSeDBlMKgTXtf61HeTyv04iVwC3BtL+YFwJ+AU4Djmnh/qbt6r6HtgB0pr6P7AasBy1FOrriBcn08B3hJZl7YQMz1Ke/9h1PeGxtQCtuWBZYAbqYUt13Yi3syJb+dOm7s2SgiNgAeVdHlu5OaS5fMtetfRGwOPBHYinJvuAbl51yEch8z/57wFOBY4NjMvHNGJjuAiAjKz7IL8EBKrrwX5dqzLOU6cBVwHvDBzDyqgZirUPLyIymvlw2AtXrxlgZupdx7XEL5uzyNci96fGbeNm78NvX+Preh3CNuwX8KhlekvA/m/1znUO6xjwF+l5k5IxMewDT8TBGxGLA15TW3FeV+dz3K9WlZys9xE/95rZ8J/Bb4VWZeOhNzliRJkiRJ44lZ9NmEJEmSJEmSNGdFxCHAnhVdDs3MvVqKvShlof/zgMcDS44wzE3AD4FPZ+bxzc3uPyJiB+BXFV12zMxjF/J99wJeA7yIsjh+UFcDBwPvHeXUi4h4NPAW4DEMt0HPn4B3Zub3h4054LyqPhR+V2a+8x79A9gXeDOw4YhhjwX+X2aeMuL3jy0i7kN5DTyTshh8FH8FvgJ8rq2TUCLiWODRfZp/nZk7LOR7gvLe3Q94LGWhbp1rM3OlIeYVlIKxnSiL+LelLNwf1c3AL4DPA0c1dRrBANfSpl2QmevXdRr2fdeUUa+bA479TuAd/dozM/p83xaU1+qzKYVYg9gqM08bcorz461OuYY9i7K4dxTnA1+j5LjLRhxj1omI/wPe3af5GmD1zLyjhbjrUxYhV9kgM89vOvYounL9W5gx7p2WolxLX0spmhjGFcBBwAGZedWQ31trjJ9pbeCllHuBtQcM99rMPGC4Gd4Vb0nKde45lNfOoiMMcw3wPeATbRXYRsRewJcruiz0vRgRK1D+PvcD1hky7IXAJ4HPZuZNQ35vrWn8mQYVEQ8H9gH2oBSyDGse8GvK70DfbKvAa5T73YWMsT71uaRpe2fmIROOKUmSJEnSQAZ5MCRJkiRJkiRpCkWxF2Vn2O9QCkNGKQiBsrD3mcBxEXFsRDywkUmOISIWjYg3UE56+H8MVxAC5eSINwBnRsSTh4i7fkT8jFII8TiGP7F5C+CIiPhBRKw25Pc2qrfY6ljgC4xeEAKwA3BSRHyqt0hyYnr/Hl+hvA7+l9ELQqDskP5B4IKIeHPv9JkZFRFb0TtlBtiVhj/3j4htIuJjwEWUHaTfQ1ncOs6CaCg7oz8J+BHwl4h44pjjaZaLiDUj4quUHfD3ZfCCkFHjrRYRn6Sc0PABRi8IAVgfeBtwfkR8OCKWbWCKs8FTK9p+3UZBSJfM1etfROxKuTc8iOELQgBWB/4POCsintPk3EYREUtExNsopzq8ncELQkaNt3hEvJayWP3LlBNJRikIgXLvug9wWkQc0StwnXER8XzKiSYfZPjiCSgnVnwE+FtE7NLk3EbV9Z8pIrbrFVr8jlL4NEpBCJT7yB0phZB/j4inNDJBSZIkSZLUOotCJEmSJEmSpDkoIjYDjqcsVhtnkfzCPBo4NSLe3ttde+IiYiXKLtwfpiy+HMdawPci4nUDxH06ZcHzY8eMCWXB6AkztQAwIh4M/B7YvqkhgVdSfqa1Ghqzf7CIRSLiTZTTPZ7P8MU5VVakLDL/Q0Rs2uC4Q4mIVwEnAw9rafzPAydRdoq/dxsxejYDfhgRX+vt0q0pExHbU96Lz5tQvL2Bv1N2ex83ByxoKUqx4N8iYtsGx5243nV4y4oux05mJrPTXLz+9YppPwkcBTRx77EqcFhEfHwG7wfXAU6kFPQ0eS3oF29byn3gx2i2+CQoxdt/jYgXNzjucJOIWCYivk05NW3UooMF3Qf4aUS8voGxRtL1nykiVo6ILwO/of/JG6PakFKo/p2Zvj5JkiRJkqR6FoVIkiRJkiRJc0xEPIuy0LHNBa2LAe8Cvh8RrS/CW1BErEHZ0XvHBoddBPhoRLy8Iu7LgcMpBQNN2Rj4eUSs0uCYtXonvfwKWKOF4bemnCizbgtjAxARq1IWte5Pu6cRPBD4fW9X9YmKiAOATzD67uODmPQCwOdSXhutFw1pciLiGcDRNLPYti7W0r3TSL4EtHndXA/4Ve+0ra7albLQvJ9jJzSP2WpOXf8iYingh5RCqqa9hpKvJioi7k+5391qQvFeC/yaUujTlmWBz0XEZyNios/5e/dWvwGe1vDQiwAfGaT4umld/5kiYgvgFGCvNuMA/0M58e++LceRJEmSJEljsChEkiRJkiRJmkMi4o3ANyiLyibhScCRkyoMiYhlgR/T3oK8T/R2vL9n3JcAn6F6ge2o7kfZvXgiekU1PwKWbzHMRsBRbew6HBH3Bn5HM6e1DGIF4AcRsduE4hERbwdePal4E/YgymL7lWZ6IhpfROwMfBVYfAKxVgSOYUKnkQBLAF+KiBdNKF7TqorZrgb+PKmJ6C4zcv2LiMWAbwGPbzHMfhGxT4vj303vXuBnNHtaR79YERGfppwO0uSpZFVeCnx5UoUhEbEc8BPgwS2G+UgvZ0xE13+miNiRUgQ/qUKNTYBjLQyRJEmSJGn2mtQHU5IkSZIkSZJmWES8iXJywqCuBI4HzgOu6v3/MsDqwLrATsCaA4yzM3AI8MwhYo/qi8BD+rQl8EfgZOAy4HLKz7MGZRfp7alfuLwYZYfmB2Xm7QARsR3w6YrvuZayUPn8XtzrKX+H6wCPo/xd1tktIp6XmV8boO+4PkfZBX9hrqAUFf0COJ3yd3gbpYBkI+BhwFMpr406DwC+DjxxzPneJSLuRdmle8MBv2UeZeHzKZSf7UrgZsq/z+qUU00eSv1pHEsA34mIR2bmqSNMfWAR8QTKKTz93AL8HvgLcCHl9bYY5QSbTSj/RvdrcErzF4+fDVxDeb1fS/m7XbH3tSHlfXmfAcfclPI6a3OBslrWez9+i/L+WJh5lNfpKcC5/Od1szywAeW6vA0DbHDWW9z7i17/QZ0JnEi5Ll9Fea+sSskJmwHbVcz9rtCUnPCvzPzxELFnVEQEsEtFlxMzc96k5tNh03L9OwDYvaL9csrpYf+k5MrrKO+VNSn3Tg8cMM4nI+JnmfnP0ac6kEWBb1N9f3U+pYD0bEruvxVYjlJE8kDK+3/QguYDKUUag7qEcn99US/21ZTr3hqUa99OwEoDjPMCyvXrjUPEHkVQ7tceWtHnQsqJG5dSXi83Ue6j1qac3LfxgHEOiYhNMvPGsWY8WKzO/ky9gpAfM/hrdP694emU19xVlOvUmr2v7Sj3iHXWBX4aEdtk5rXDzluSJEmSJLXLohBJkiRJkiRpDoiIpwEfGKDrDcAXgC8Bf83MrBgzKIvm30Ap+Kg6JeMZEXFSZn508FkP7TnAsxby51cD7we+UbUQsbfL/Ospi+uWrIizKfBK4OO9UzW+zcI/a/058EHguPkFJH3iPgr4FLBlRUyA90XEtzPz1pp+43hyn3lcD7wDOLBP/KspxTYnA5+OiAcBnwB2qIm3W0S8PDMPHHnGPRGxFPB9BisI+T1lR++f1S1qi4iVgacB/0f1AtOlgCMiYsvMvHqgSQ9vJcr7c2FOBz4EfK9u4WFEbA68ZMQ5XE45SeZHwKmZecGg3xgRawPPB/alvjBl14h4YWZ+ccj5fYmy2HZBq1JdEPdl4IQh48x3/YjfNxd8EVh5IX9+OfBx4CuZ+a+qASJiTeAVlMW4/fosAhzGYAUhZwAfBY7MzCtqYi9LKVp7B3D/qq7AYRGxdWaeO8AcZoONgVUq2j0lZOFm+/VvFP9DeY/d053AwZSc84ea+8H1gLcDe1NdxLUs5X5sz5FnO5jXA49YyJ/fSvmZPpeZla/xiFiGck95TU2/NzBYQci/KQXEh2XmP2rGXBR4JPBWSvFwlf8XEb/PzO8OMIdRvY6FFw3dTLl//Upm/rVqgIjYDHgf8JSaWPem3Ie/Y/hpDqWzP1NEbAx8l/qCkHnA9ygnGZ6QmbfVjLs+8ELgNVSfKLkx5QSwJw0241b9G1jYaV17A9v2+Z4rgTePEfO3Y3yvJEmSJEmtiorP8CRJkiRJkiRNSEQcQvUiuUMzc68Rx94EOJVyKkY/SVnE/67MvGaEGFtRdtzdtKLbLcAWmXnWsOP3YuxA2al6GF8C3piZVw4R50G9OFULZi8E7ks5AeV592j7F/DiYXaN7y0A/DywT03XF2TmVwcdt0+sYT8UPgN4cmaePWScoBRSVJ1qAaUQaePMvHTIed0z3sHU//2dC7wwM4d9Hc0vOnkr8DaqC6C+nJl186iKcyzw6CG+5VbKYsNPVS3aHXEu36QUfN0CfAX4GvDbcU8Q6C3ifxXwXqoXHl4JrJ+ZN4wZb33KiUf97J2Zh4wTY4A5VP3bvCsz39lS3B2ovm7umJnHjjj2Oxl+kesXgddlZmPFNBHxf8C7a7pdQVm4fcSw75Pe9fmllEKWqtOkfpmZOw8z9kyJiOdQCmn6eW5mfr3F+OtT/Z4E2CAzz29rDnWm6Pq3A8PfOx0LvCwzzxwy1vaUgpnlK7rdAdw3My8ack4LxtmB4X+m3wJ7ZuY5o8ZdyDweTTkJrqoQ5g7KdfLjmXnzCDF2orz21q7odgVw/2Hude8RYy9KceQwvgO8NjMvHjLWMyg/T9W19GpgnczsWww4QJy9mLKfqRdrScrvdJvVdP0F5T089Os9ItYCDqIUilfZMzO/Muz4C8Q5lv73u7/OzB3GGPsQ+v9efUFmrj/q2JIkSZIkzWa1R25LkiRJkiRJ6q7e4sMvUV0QchXwpMx87SgFIQCZ+UfKjqzHVnRbCvjkKOOP6J2Zue+wi+R6u0fvCvQ93QNYj7Lb/D0LQv4BPHKYgpBezDuBFwM/rOn64mHGbcCZwA7DFoQAZPFuyo7dVZaj7LQ8sojYlfqCkG8DW41SEAKQmbdk5tspJ9JUndayd0QsbIfyNlwL7JSZn2y6IKTnCspi+/Uy8yWZedy4C6IBMnNeZh4APASoKgZaFXj5uPE0a+yXmS9quCDkgZTisyrHUgoSvzfK+yQz78zMz1B27L+moutjImJhp1XNRg+paf/LRGYxu83V69/XgMcOWxACkJm/odw/VeXIxSinEUzS1ykFcE0WhCxDub+uetZ+IbBdZr5/lIIQgMw8BngY1e/J1RnzPmpIHwSeMWzxBEBmfgt4dk23lSkFWZPUlZ/pXVQXhMyjFC/vOurrvVekvQelELLKRyOiqgBMkiRJkiRNmEUhkiRJkiRJ0nTbh1Ks0c+NlIVDPxo3UGZeDTyB6oVrj4uIqvk05b2ZWXdCRV+ZeTJwYE23V9/j/y+lLP47f8SYdwKvpOxK3s+2vR18J+F6ygkhl48zSGZ+jLJwssqeEXGfUcaPiMWp/7c6HHhmZl43SowFZeY3qV/QOvJrbwh3Uv59TmgrQGbul5nvyMwrWhr/TGAnqhfaT7oQSu34v8z8dAvjHkj17uzHUXLcJeMG6hWUPZXy3uvnHb1izNlum4q22ykFgXPaHL3+fYVyIllVUWylXk76SE23p486/gh+RjnRYOSfqY+3Uk6M6+cySlHtieMG6p2qsjNQdR3bZ9T7qCG9JzPfPE4hamZ+l+qTimCyr5FO/Ey9kx/fUNNtv8x837gFbL3itdcBB1d0Ww3Yb5w4kiRJkiSpWYvN9AQkSZIkSZIktSMilqB6B/WkLJQ/uamYmXlzRDwdOIVyAsTCvB5obSE7cBLNLMp/N/BSYMkB+7+wt7vuyDLzwog4CHhNny6LUHarP3ScOAN6T2ae1dBYrwN2p+xmvTCLAq+i/lSRhXkhsEFF+3GUBaGNnaSRmV+LiO2BF/XpsktEPKh36kxbPpGZv25x/InIzDMi4v+AT/XpsmFEbNtm8YtadzLw/qYHjYjHA4+q6PJ3SuFU1akFQ8nMYyPi7fTflX9TYDfqT32aaVU7zV/cwgL6UTwzIoY66WtI38vMq1ocv9Ysu/6dBby8oVz5PkpuXrNP+/0jYt1esUObrgP2zcw7mhw0IlbnvwuDF3QzsFtmntdUzMy8vHcS0TGUe6Z7WpzR76MGdRzNFb2+gVIksUSf9h0jYonMvK2heP106Wd6Nwv/t5/vQ5lZVyQ9rP0oRYQP6tP+qoj4UNPvMUmSJEmSNBqLQiRJkiRJkqTp9TxgvYr2QzPzx00Hzcy/R8QBwNv6dNk9IlZvafftecBeTSxOysyrIuJoygLfOoc1+Hf5TfoXhWfjEkUAACJJSURBVEA5+aXtopBzgE80NVhmXttb+HpQRbcXRMSbhvm36+3I/6aKLrdTFoQ2tih8AW8EngUs36d9H6r/HcdxPtUFX13zWcoC2436tO9Ku4Vkas8dlIK5sXYt7+MtNe0v6Z1g1bQPUQrC1u/Tvi+zuCgkIpYHVqno8s9JzaXG/i2Pfwowo0UhPbPl+rdnZt7YxEC9AuFvUl048SjgG03Eq/DmzGzj9bwf/QufAT6YmX9oOmhm/iYivkG5v1+Y50fEm1sq6roNeH7vVLuxZealEXEU8OQ+XZYCHgz8rol4fXTmZ4qIjag+aeQs+v/eNbLee/l1wNF9uqwJPBH4ftOxJUmSJEnS8LpwhLUkSZIkSZKk0by4ou0G4K0txv4kZafkhVkc2KOluD/JzDMaHO+IAft9tMGYJ1G9KHfLBmP1864Wdmf+InBuRftqwM5DjvlY4D4V7Z/KzLOHHHMgmXkN8LmKLs9oI27PxzLzphbHn6jegszvVXTZaVJzUeOObOPEnIjYFNiuosv32jpJp1e49pGKLk+IiKoF4zNt/Zr22VIUMifMkuvfrzPzxIbHrCv42KLhePd0GfCFpgeNiEUpRZ/9XAx8uOm4C/gg5aS/hVmd9l4v38jMC5oes6a97ddIl36mFwJR0f6Gtk54ysxfUk786ueZbcSVJEmSJEnDsyhEkiRJkiRJmkIRsQnwsIouX8vMS9qK3zsFpKqg4rEthf50w+OdOkCfEzLzj00FzMwEqsbbpKlYfdxE9QLVkfQWvtYtlnvikMPuWdE2j+qF2034fEXb2hHxwBZi3gZ8vYVxZ9pRFW1bRETVYkjNXl9uadyq9z6U0zzadAjlJKKFWRzYseX446gqpAOLQmbCTF//Pt7CmKdS8lU/m7YQc0Ffa+LUuIXYGbh3Rfun2yzazMzTqT5poq376zZeI3WFSG2/RjrxM/Xe/8+v6HJGZrZ9OlVVgdXOvZP7JEmSJEnSDPMXdEmSJEmSJGk61S2u/+YE5nBsRdujW4h3I3B0w2P+nf47Ms/3g4ZjAvytom3FiFihhZjzHZmZN7Y0dl0xww6DDtTbrXvXii6/abPwCaB3Csm/Krq08Tr/UWZe2cK4M61qt+7lqD/dQLPP5VQvdh9HVY47LzN/31JcAHrXyKqd09t47zdlvZr2Vq+bWqiZvP7dQgvv096pBWdWdFm36Zj3cGhL49bdXx/eUtwFHVvR1sa159zM/FPTg/ZO6bi2okubr5Eu/UxbA/eqaJ/p19xqwGYTmIMkSZIkSaphUYgkSZIkSZI0naoWy18OHDeBOfymom3ViGh6sddJvdMoGtPb7blugWzVjs2j+kdN++otxJyv6oSXsWTm3yiFNv1sFhErDjjcw4GVKtq/M+i8xlT1Ot9qwvG67NKa9vUnMQk16oSmr8kAEXFvYPOKLt9tOmYfk37vN6XuGnvDRGahBc3k9e/kzKw60WMcVUUha7QUE+DqzPxLS2NX3V+fkpnntxR3QVXXns0jYrGG4/224fEWVHVP2OZrpEs/U9VrDiZwv9srgq66Ts3mnCdJkiRJ0pzR9IdCkiRJkiRJkmZYRASwTUWXP2bmvAlMpWrna4AHAhc1GO/EBsda0PUVbXcCp0w4JtQv6h3HqS2OPX/8Tfq0BfAA4IQBxnlYTfsfhpnUGKpe5w9sIV7b/z4j6V137gWsTdk1egVgSWAJyr/ruNZuYAxNVluv1bn63m/KsjXtN09kFlOk49e/QfLtqKpOTGjzPuaPbQwaEasAG1V0mQ3XniWB+1F94tywpvE10qWfqSrn3QycMcKYo7gAWKtP22zOeZIkSZIkzRkWhUiSJEmSJEnT575ULzpqcqFYX5l5S0TcBCzTp8s6DYdsssBkQVW7pl+ZmW0soK3bqX3JFmLOj3tOS2PP9yfg2RXtgxaF1O1KPJHXOXBlRVvTr/EETmt4zJFExOrAE4BtKUVom9D/vd6EVVscW+1oqyikC+/91SNiycy8dUJzGUbd+3S2FIVsMKFTF4Y2Zde/C1scu6rAta37GJjb1x4o9x5NzmUaXyNd+pmqXndnTqjQHyZ7vytJkiRJkkZgUYgkSZIkSZI0fTataV8rIl44kZnA7RVt92441tUNjzffjbMsJpTdx9twemZmS2PP96ea9kEXllW9zm8EnlE2b29d1e7Ia0bEopl5Z0Oxrs7MulNkWhMRiwFPA14MPBpYZILhl55gLDWjrUW3dTluu4h4aEuxF7RZTfu9gPMmMI9heVLICKb4+tfWfQxUF7i2dR8DM3ft2WhC99eL1rR35f4aZu410omfKSKWpfq+OCf4O91qFW1Nv+YkSZIkSdIILAqRJEmSJEmSps+6Ne3PpvqkhklZoeHx2lrgVVUkMRMxAdqqdvhXS+Mu6JKa9rUHHKfqdb4s8IUBx2nTIsBywLUNjdfUOEOLiP8B9gc2mqEptLljuNrR1uu1Lsd9uqW4w2o6xzWlbkF5U0VsU2PKr39XtTh220Wm/czUtWe/luIOq+lrz0y9Rtqs7O3Kz1T3mtua2XG/O1vznSRJkiRJc4pFIZIkSZIkSdL0uddMT2BATe98fWvD483WmG26bhbEWLVugN6O7Ws0M53WLU1zC1Qn8e9zNxGxPHAw8PRJx76HuoXsmn3aer3O1RzXlLqTQJaayCw6YI5c/6btPga89kzD/XXbuvIzzdXXnCRJkiRJGoFFIZIkSZIkSdL0WX6mJzAgd/6ffWZDUcggC5KXpd0dpJvU5Ot8okUhEbEG8HNgi0nG1dRo6/VqjhvPjTXtLu7F61/Hee3RtPA1J0mSJEmSBrbITE9AkiRJkiRJUuO6sqCzK4v655LrJxCjbrHmIAvLuvIah2Zf5/MaHKtSRCwL/BgXRGtEmdnW67Ur7//ZmuNuqmnvyt9va7z+dZ7XHk0LX3OSJEmSJGlgnhQiSZIkSZIkTZ/FZ3oC6qxJvHbqYgyymNPXePs+CjxkwL53AqcCpwB/B84FLgWuAG6gnExwR2beXjVIROTIs9Vc4vt/PJ4UUs/rnxbGa48mzdecJEmSJEkamEUhkiRJkiRJ0vS5daYnoM5aYRbEuGWAMXyNtygitgFeMkDXU4DPAEdk5rVjxnSXaQ3qVixcGMclNe2rTWQWs5TXP1Xw3kOT5mtOkiRJkiQNzKIQSZIkSZIkafrcVNP+osz84kRmoq5ZfgIx6opC6naxh/rX+D8zc50B56P/9vaa9juAN2bmxxuMuWKDY2m63UR1UcjimXnHpCbTQRfUtN97IrOYvbz+qZ+6e49dMvPoicxEc0Xda+6wzHzeRGYiSZIkSZJmPYtCJEmSJEmSpOlzZU37UhOZhbpoEgtT64pCLh9gjBspuycv2afd1/iIImJt4PE13Z6RmUc0HHrlhsdT0e890mVXAqtWtC8F3DChuXTR+TXtc7agzuufanh/rUnzNSdJkiRJkga2yExPQJIkSZIkSVLjLqxpX2Mis1AXbTyBGPerab+kboDMTOCiii4rR4SbIo3micCiFe1faGFBNMAqLYzZFdHi2FXFE11ljhvPJcBtFe1z+aQQr3+q4rVHk+ZrTpIkSZIkDcyiEEmSJEmSJGn6nFvTvv4kJqFO2jgilmk5xhY17ecMOE7V63wRYL0Bx9HdPaqm/UMtxb1vS+POFndUtLX5npvGxebmuDFk5jzgvIou605qLrOQ1z9V8dqjSbsEuKWiff0JzUOSJEmSJHWARSGSJEmSJEnS9PkzcGdFe92ifM1diwCbtxyj7vX31wHH+eOYcbRwm1W0nZaZ/2gp7iNbGne2uLWibYUW467T4tgzxff++E6taFsxIu41sZnMLl7/VMVrjyaqV8T3p4ou60bENBZ/SpIkSZKkEVgUIkmSJEmSJE2ZzLyR6oX1D4iIlSc1H3VOa4tTI2JxYJuKLjcBZw043O9r2ut2fNfC3aei7W8txp32RdHXVrSt2GLcafx79b0/vlNq2h84kVnMPl7/VOXvVF/LHxERPntX0+pyntcPSZIkSZIEWBQiSZIkSZIkTaujK9oWBXab1ETUOc9qcezHAVU7Gp+QmXcMONavgaq+Tx54VlrQ8hVtl7YRMCLuDWzZxtg9VScnASzeYuz5Lq9o27SNgBGxBPCQNsaeYX8Grqhof2xELDWpyXTUyTXtD5rILGafabz+qSGZmcAvK7qsDmw7oelo7qj6nQ68312Yqvu+SdzzSZIkSZI0IywKkSRJkiRJkqbTETXtL5rILNRFD42IDVsa+zk17ccMOlBmXkUpDOlnw4jYcdDxdJclKtrqiitG9QpgsZbGBritpn3pFmPPd2FF2/0joo2f//HA1BVHZOadwJEVXZYDnj2h6XTVqcC8iva5elLINF7/1CzvrzVpvwBurGh/RkRUFbTNRVX3fZO455MkSZIkaUZYFCJJkiRJkiRNpxOA8yrat4+IR05qMuqclzQ9YESsRf1uxt8dctjDatrfOuR4gpsr2tZoOlhELE37i2ivr2lfoeX4AH+vaGvrRI/XtTDmbFH33v9/LRXaTIXMvBH4Q0WXB09qLrPMNF7/1KwjgRsq2p8VEfed1GQ0/TLzFqrvj5cHXjWh6XRF1X3fchERE5uJJEmSJEkTZFGIJEmSJEmSNIUycx5wYE23T0bE4pOYjzrnVRGxQcNjvh9YpqL91Mw8a8gxvwH8u6J954jYY8gx57orKtq2aSHee4HVWhj3Lpl5E3BTRZdJLOA9raa90ZMtIuIRwPZNjjmbZOavgNMrutwfF8nWOaqi7f4RsfrEZjJ7TN31T83KzOuAQyu6LAEcMJnZaA75VE37myPiPhOZSTdUXcsXB9ad1EQkSZIkSZoki0IkSZIkSZKk6fUF4MqK9q2BD05oLuqWJYGPNDVYRDwY2Kum22eGHbe3e/IBNd2+0EKByzQ7p6Jts4i4X1OBImIH4LVNjVfjooq2zSYQ/7ia9mdGRFXR1MAiYjmqFy1Pi/1r2t8fEW0s5J8WVUUhAewwoXnMJtN6/VOzPgbcVtG+e0RYlKbGZOYpwNEVXZYDvhERS05oSrNd1T0fTOa+T5IkSZKkibMoRJIkSZIkSZpSmXkt8M6abq+NiLdNYDoARMRiEfGkScXTWPaIiH3HHSQiVgS+Tllk3M+lwGEjhvgY1Yu/VgF+ERHrjzj+0CJio4h40KTiNezkmvb3NhGkt6P116h+XTTpzIq2bdo+FSEzLwL+VtFlTeB/x40TEUE5JWrjccfqgK9T/XpdEvhJRGw5melARKzdO6WlC06iunB0hwnNYzaZ1uufGpSZ51J/csPHI2LPScwHICKWjojHTyqeZsTrgXkV7Y8Avt1UgekgIuLREbHKpOINoeqeD2C3icxCkiRJkqQJsyhEkiRJkiRJmm4HURZ+VnlPRHy3t3i/FRGxfES8EjiLsmBZ3fDZiHjqqN/cO7HgR0Dd7upvz8xbR4mRmTcDr6zptiFwakTsPkqMQUXEQyPiMMpitIe2GatFP69pf3pE7DNOgIjYBDgGuPc44wzp9xVtiwBvnsAcvlXT/oaIeNSog0fE4sBXgeePOkaXZGYCLwNur+i2GvC7iHhhm3OJiPtHxIHAuXRksWlmzgN+VtFlhwlNZTaZ1uufmvdu4PyK9kWAQyLiM22e3hARq0fEW4HzaKCwULNXZv4Z+ERNt92B30fEpm3NIyIWjYinRsRxwLGU4uvZ5nTgxor2F0SE12BJkiRJ0tSxKESSJEmSJEmaYpl5B/Bc4IaarntQFs0/OyIWayJ2RCwSETtExBeAf1F2Vd6gibHVmrzH/y9O2XX4zREx1OfJvQVpJwB1i9xPAw4eZux7yswjKQVQVVYGfhARn4+I+44Tb0ERsUZE7BcRp1AKD54DLNrU+DPgN1SfvALw+V6R19B6O6f/Hrjnv8Gdo4w3hKNr2l8TEftHxMotzuFgqgsYlgCOiohHDztwRNwf+AXlej9nZOYfgP+r6bYU8IVe8WNjJ/hExIoRsU9E/IpyCszLerG65BsVbZtN8oSlWWJar39qWGZeR7ne1v3bvRw4MSJ2653kNLaIWLw33jcor9f3UU6b0vR7C/Cnmj6bA6f07t0bK/jvFT++l1KA9D3q7+9nTO/3319XdFkB+GVEbD+hKUmSJEmSNBGNPNyVJEmSJEmSNHtl5j8i4lnA96n+TPC+wNeB/SPi08BPgdN7u7EPJCI2Ah4B7AzsCqwx6rw1I74CPA1YdoE/WxT4APCs3mKw7/cWWy1URGwAvIqyEHKJmni3AM/v7Vg/rtcA9weqFtQH8CJgn4g4AjgUOD4zrxk0SEQsC2wDbAc8HngYU7QBU2beGRGfAD5S0W1R4FO9U2Q+CPyi6joREUsBTwHeADy4T7cPAG8badIDyMyTI+Jc/nsx9nyLAG8CXhsRx1N2mf4nZafpqlNsrs/Mwwecw8UR8TVg74puywHHRMSXgfdk5gX9OvYWGD8YeElvzIUVI30K2G+Q+XXYh4AHUQqyquwB7BERvwC+APwmMy8bNEhvt/+tKQthd+39t+4aN9v9FLic/rn6f4CPTm46M2tar39qR2aeEBGvoL4odUvKqWl/691fH52ZZw8ap1eUe39gW2CX3tdKo8xZ3ZaZt0bEUyhF12tXdF2Wcl15a0R8kVLEcfIwp/JFxBrAw4EdKfe7m4w67xlyOPCEivZNgF9HxHnAiZTTLK+l3PdV/V7y62Hev5IkSZIkTZJFIZIkSZIkSdIckJk/jogXAl+ifgH7epRFth8Cro6IE4ALgKuBqyinjiwBLAOsTlmUtBFlcc1KbcxfE3M+ZRfiTy6kbQvg28A1vZ3xTweuAG4Dlgc2pCwe23KIeK/NzNPHmO9degvlngwcQ1m4XWVRSvHL04B5EXE68EfgSspr/CrKqSlLASsCawHrAptSTruZmiKQPj4NvJTyvq6yU+/rkt514q+U68TNlAWJ6wAPpCxkXaZinD8A76b9RdEHsPDX9oKW4D8/1yAuoCw8HNT/Ul53y1f0WQTYF9g3Iv4EHAdcRnl9Lk9ZwL8OZaFmVeHdpykLQae6KCQzMyL2AlahFGvUmb+omog4CziZci2b/96/g/LeX57y3l+Hkt82pJyeNDUy847eaQOv7tPlacyhopCeab3+qQWZ+bne4vl3D9B9M+BAgIi4jLKw/5/85/76JmBJyutnDeBewMaU68+yCxlPc1Bmnh8Rj6fc765S03154LW9r1sj4iTgTP6T766l3BMvBaxKyXkbUF5z92rlB5icw4H9qS6egfLzDnOS5d6ARSGSJEmSpFnJohBJkiRJkiRpjsjMQyPiBuAwyqKzQawM7NberDTbZOanIuLh9N91fyXgqb2vcXwsM+t21x5KZl4bETsCRzD4ov5FKKcMPKjJuXRZr8Dm+ZRihEGeI6xNOVHgf0YIdwHwpMy8vRx80arPUU7VeEDbgfrJzEsi4uXAVwf8li16X8P6IWUR6KNG+N7O6b1+ngQcQv2JIQu6X+9rLvsK/YtCHhYR987Mf05yQjNpiq9/aklmvicirqEUHg5aNLom499HaY7KzD9FxKMopz2tN+C3LUk55W671iY2i/Su5W+g/N4rSZIkSdKcMO27mUmSJEmSJElaQGZ+F9geOGem56JZbR/g6BbH/yTwhjYGzszrgMcDH6ec9qERZOaJlNdBm3+HFwO7Zua/Woxxl8y8DdiDcirEjMnMrwEfbjHEz4FnZOYdLcaYdTLzduB5wJuA22d4Op2RmacCp/VpDsppIXPKNF7/1K7M/BTwRODymZ6L5obMPAN4GPCLmZ7LbJWZX6f+hDhJkiRJkqaGRSGSJEmSJEnSHJOZJwFbAZ8BJr1o+Ebg+xOOqSFl5q2UE2K+0fDQtwNvyMxXZ2Zri20z87bMfB3wWODvbcWp8GfgLzMQt1GZ+VVKEcW1LQx/MvDQzDyzhbH7ysyzgIcDv59k3IXM443AB1sY+iBgt8y8pYWxZ70sPgQ8gvIam7R/ACfOQNxxfbyibd+JzWIWmcbrn9qVmUdRTh375gyEvwr4yQzE1QzKzEuBxwGvAq6ecPh5lCLUqyYcdyiZ+WpKIfrNMz0XSZIkSZLaZlGIJEmSJEmSNAdl5vWZ+UrK4rVv0W5xSAK/AvYC1urF1SzXK6x4DrA3zSw0+yPwqMz8aANjDSQzjwY2B14JnNtyuMuBA4CtMnOLzJzRooOmZOb3gW2APzQ05E3Am4FtM/OShsYcSmaeSykaeBZwPDN0okxmvplyCsNlDQz3L+ApmfmyuXZCyMJk5h8oO6g/l/YLtK4Fvghsl5kbZ+aPWo7Xhm8C/d6PD4yIR0xyMrPFNF7/1K7MvCwzn03JMT+l3fxyB/BDSh5ZOzPf32IszVK9YshPARsBHwGuaTnkGZTr2HqZ+bjMnNVFIQC93z02BT4B/HuGpyNJkiRJUmsWm+kJSJIkSZIkSZo5mXkG8MyIuDelaGMPYOsGhr4A+CVwNPDLzLy8gTE1AzLzkIj4AfCK3tdaQw5xCmUR1tczc17T86vTWyD/mYj4LPAE4NmUU1BWHHPoW4HfUV7jRwOnZOadY445K2Xm2RGxDbA78BbKSRvD+hfweeCgzOxXBFG18PpfI8Tsq3dSzeHA4RGxFrAjZfH3JsB6wOrACsCStLjBVmZ+NyKOBvYDXg6sPeQQ51PeX1/IzBsbnl6n9f6Nvw58PSIeDTyP8hpec8yh76Sc9DA/x52QmbeNOeaMyszbIuLTwPv6dHkx5Xo350zj9U/ty8wTgcdHxMaU4tqnUhalj+vv/Ofa86vMvKaBMTUFesUZ/y8i3km513065d5m8TGHvho4lt79bu/Etc7JzAuB10TE6ylFo4+kbI6wIeV3m1WBpSnrZ2Km5ilJkiRJ0jiifCYuSZIkSZIkSUVE3Iuyw/GCC6TXBpajLJZJ4Pre13XAlcDZwJm9r79m5gWTn7kGERFVHwq/KzPfWfG9i1AWUj0O2IKywHE1YHnKwvkbKLvNnwGcCByVmX9tZubNiYjFgQdTXuNbAhsA6wKrUF7jS1J2dF/wdX4R/3mNnwn8JTNvnvTcZ4OI2JCy0HBHyjVi1d7XMvzn7+2flMWrf6YsJDwtfSBRqff+2h7YCXgIZaHimsCywDzK3+u/gb9RTt45CviDf6+D6/0dP4hyHdua8t5fj3IdWxpYCriFu7/3/8V/v/evm/jkWxYRq1Cuc8sspPkm4F6Zee1kZzX7eP3TqCLivpRrz0OA+1GuPWtRXjtLU07+uH6Br8uBs7j7tefSyc9cXRURK1Becw8FHgDch3K/uzzldbco5d59/mvuGsrJevNfc2cAZ8xEUbckSZIkSRqeRSGSJEmSJEmSNIeMUxQiSZpeEfER4PV9ml+XmR+f5HwkSZIkSZIkSYNp7chzSZIkSZIkSZIkSZ2xP2W3+IV5Xe+UJUmSJEmSJEnSLGNRiCRJkiRJkiRJkjTHZea/gX6ngawDPG+C05EkSZIkSZIkDciiEEmSJEmSJEmSJEkAHwWu6tP2xoiISU5GkiRJkiRJklTPohBJkiRJkiRJkiRJZOZ1wAf6NG8KPHWC05EkSZIkSZIkDcCiEEmSJEmSJEmSJEnzfRI4u0/buyLC54uSJEmSJEmSNIv4oa0kSZIkSZIkSZIkADLzNmC/Ps2bA3tNbjaSJEmSJEmSpDoWhUiSJEmSJEmSJEm6S2b+DDiiT/O7ImLpSc5HkiRJkiRJktSfRSGSJEmSJEmSJEmS7um1wM0L+fN1gFdPeC6SJEmSJEmSpD4Wm+kJSJIkSZIkSZIkSZpdMvOCiHgusMVCmm+Z9HwkSZIkSZIkSQtnUYgkSZIkSZIkSZKk/5KZRwBHzPQ8JEmSJEmSJEn9LTLTE5AkSZIkSZIkSZIkSZIkSZIkSdLwLAqRJEmSJEmSJEmSJEmSJEmSJEnqIItCJEmSJEmSJEmSJEmSJEmSJEmSOsiiEEmSJEmSJEmSJEmSJEmSJEmSpA6yKESSJEmSJEmSJEmSJEmSJEmSJKmDIjNneg6SJEmSJEmSJEmSJEmSJEmSJEkakieFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR1kUYgkSZIkSZIkSZIkSZIkSZIkSVIHWRQiSZIkSZIkSZIkSZIkSZIkSZLUQRaFSJIkSZIkSZIkSZIkSZIkSZIkdZBFIZIkSZIkSZIkSZIkSZIkSZIkSR30/wHQ6XrlGzm3AAAAAABJRU5ErkJggg==\n",
      "text/plain": "<Figure size 3600x2400 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light",
      "transient": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_t_p = model(train_t_u, *params)\n",
    "val_t_p = model(val_t_u, *params)\n",
    "\n",
    "fig = plt.figure(dpi=600) #dpi is dots per inch\n",
    "plt.xlabel(\"Temperature (Fahrenheit\")\n",
    "plt.ylabel(\"Temperature Celsius\")\n",
    "plt.plot(train_t_u.numpy(), train_t_p.detach().numpy())\n",
    "plt.plot(train_t_u.numpy(), train_t_c.numpy(), 'o')\n",
    "plt.plot(val_t_u.numpy(), val_t_c.numpy(), 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should always use detach() when taking an output that shouldn't\n",
    "# be part of computation trees, can be cases where requires_grad is True\n",
    "# even within no_grad\n",
    "\n",
    "# can also make grad optional within model as so\n",
    "def calc_forward(t_u, t_c, is_train):\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Training loss 3.3664\n",
      "    Validation loss 5.1514\n",
      "Epoch 1000, Training loss 3.1994\n",
      "    Validation loss 4.9696\n",
      "Epoch 1500, Training loss 3.0055\n",
      "    Validation loss 4.7527\n",
      "Epoch 2000, Training loss 2.8394\n",
      "    Validation loss 4.5719\n",
      "Epoch 2500, Training loss 2.6977\n",
      "    Validation loss 4.3721\n",
      "Epoch 3000, Training loss 2.5808\n",
      "    Validation loss 4.2169\n",
      "Epoch 3500, Training loss 2.4822\n",
      "    Validation loss 4.0721\n",
      "Epoch 4000, Training loss 2.4019\n",
      "    Validation loss 3.9366\n",
      "Epoch 4500, Training loss 2.3709\n",
      "    Validation loss 3.4749\n",
      "Epoch 5000, Training loss 2.2786\n",
      "    Validation loss 3.7094\n",
      "Epoch 5500, Training loss 2.2327\n",
      "    Validation loss 3.6175\n",
      "Epoch 6000, Training loss 2.2771\n",
      "    Validation loss 3.1950\n",
      "Epoch 6500, Training loss 2.1627\n",
      "    Validation loss 3.4564\n",
      "Epoch 7000, Training loss 2.1616\n",
      "    Validation loss 3.1173\n",
      "Epoch 7500, Training loss 2.1145\n",
      "    Validation loss 3.3310\n",
      "Epoch 8000, Training loss 2.0964\n",
      "    Validation loss 3.2681\n",
      "Epoch 8500, Training loss 2.0815\n",
      "    Validation loss 3.2171\n",
      "Epoch 9000, Training loss 2.0692\n",
      "    Validation loss 3.1498\n",
      "Epoch 9500, Training loss 2.0589\n",
      "    Validation loss 3.1316\n",
      "Epoch 10000, Training loss 2.0505\n",
      "    Validation loss 3.0938\n"
     ]
    },
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7f6a5ee60790>]"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 3600x2400 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light",
      "transient": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise\n",
    "\n",
    "# 1. Redefine the model to be `w2 * t_u ** 2 + w1 * t_u + b`.\n",
    "\n",
    "# a. What parts of the training loop, and so on, need to change \n",
    "# to accommodate this redefinition?\n",
    "\n",
    "# Model needs to change\n",
    "def model(t_u, w2, w1, b):\n",
    "    return w2 * t_u ** 2 + w1 * t_u + b\n",
    "\n",
    "params = torch.tensor([0., 0., 0.], requires_grad=True)\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "\n",
    "training_loop3(\n",
    "    n_epochs=10000,\n",
    "    optimizer=optimizer,\n",
    "    params=params,\n",
    "    train_t_u=train_t_u,\n",
    "    train_t_c=train_t_c,\n",
    "    val_t_u=val_t_u,\n",
    "    val_t_c=val_t_c\n",
    ")\n",
    "\n",
    "train_t_p = model(train_t_u, *params)\n",
    "val_t_p = model(val_t_u, *params)\n",
    "\n",
    "fig = plt.figure(dpi=600) #dpi is dots per inch\n",
    "plt.xlabel(\"Temperature (Fahrenheit\")\n",
    "plt.ylabel(\"Temperature Celsius\")\n",
    "plt.plot(np.arange(15, 90, 0.1), [model(torch.tensor(a), *params.detach()) for a in np.arange(15, 90, 0.1)])\n",
    "plt.plot(train_t_u.numpy(), train_t_c.numpy(), 'o')\n",
    "plt.plot(val_t_u.numpy(), val_t_c.numpy(), 'o')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "d6a4bbd05ce9c893b429f45c3c159d278c088d407cccb8e9de1a5ef0145565cd"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}